<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mr.Ai</title>
  
  <subtitle>春暖花开去见你</subtitle>
  <link href="https://leslieaibin.github.io/atom.xml" rel="self"/>
  
  <link href="https://leslieaibin.github.io/"/>
  <updated>2021-09-11T02:31:35.974Z</updated>
  <id>https://leslieaibin.github.io/</id>
  
  <author>
    <name>Leslie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>05.分布式锁</title>
    <link href="https://leslieaibin.github.io/2021/09/11/MySQL/05.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>https://leslieaibin.github.io/2021/09/11/MySQL/05.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</id>
    <published>2021-09-11T12:17:42.000Z</published>
    <updated>2021-09-11T02:31:35.974Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><h2 id="什么是锁"><a href="#什么是锁" class="headerlink" title="什么是锁"></a>什么是锁</h2><ul><li>在单线程的系统中，当存在多个线程可以同时改变某个变量（可变共享变量）时，就需要对变量或代码块做同步，使其在修改这种变量时能够线性执行消除并发修改变量</li><li>而同步的本质是通过锁实现的。为了实现多个线程在一个时刻同一代码块只能有一个线程可执行，那么需要在某个地方做个标记，这个必须每个线程都能看到，当标记不存在时可以设置该标记，其余后续线程发现已经有标记了则等待拥有标记的线程结束同步代码块取消标记后再去尝试设置标记。这个标记可以理解为锁。</li><li>不同地方实现锁的方式也不一样，只要能满足所有线程都能看到标记即可。如java中synchroniuze是 在对象头设置标记，Lock接口的实现类基本上都只是某一个volitile修饰的int型变量其保证每个线程都能拥有对该int的可见性和原子性修改，linux内核中也是利用互斥量或信号量等内存数据标记</li><li>除了利用内存数据做锁其他任何互斥的都能做锁（只考虑互斥情况），如流水表中流水号与实践结合做幂等校验可以看作是一个不会释放的锁，或者使用某个文件是否存在作为锁等。只需要满足在对标记进行修改能保证原子性和内存可见性即可。</li></ul><h2 id="什么是分布式"><a href="#什么是分布式" class="headerlink" title="什么是分布式"></a>什么是分布式</h2><p>分布式的CAP理论告诉我们：</p><p>任何一个分布式系统都无法同时满足一致性（Consistency）、 可用性（Avaiability）和分区容错性（Partition tolerance)，最多只能同时满足两项。</p><p>目前很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。基于CAP理论，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证最终一致性</p><h2 id="分布式场景"><a href="#分布式场景" class="headerlink" title="分布式场景"></a>分布式场景</h2><p>在许多的场景中，我们为了保证数据的最终一致性，需要很多技术方案来支持，比如分布式事务，分布式锁等。很多时候我们需要保证一个方法在同一时间只能被同一线程执行。在单机环境中，通过java提供的并发API我们可以解决，但是在分布式环境下，就没有那么简单。</p><ul><li>分布式与单机情况下最大的不同在于其不是多线程而是多进程</li><li>多线程由于共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一物理机上，因此需要将标记存储在一个所有进程都能看到的地方</li></ul><h2 id="什么是分布式锁"><a href="#什么是分布式锁" class="headerlink" title="什么是分布式锁"></a>什么是分布式锁</h2><ul><li>当在分布式模型下，数据只有一份（或有限制），此时需要利用锁的技术控制某一时刻修改数据的进程数</li><li>与单机模型下的锁不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。</li><li>分布式锁还是可以将标记存在内存，只是该内存不是某个进程分配的内存而是公共内存如 Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要保证标记能互斥就行</li></ul><h2 id="我们需要怎样的分布式锁"><a href="#我们需要怎样的分布式锁" class="headerlink" title="我们需要怎样的分布式锁"></a>我们需要怎样的分布式锁</h2><ul><li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。</li><li>这把锁要是一把可重入锁（避免死锁）</li><li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li><li>这把锁最好是一把公平锁（根据业务需求考虑要不要这条）</li><li>有高可用的获取锁和释放锁功能</li><li>获取锁和释放锁的性能要好</li></ul><h1 id="基于表主键唯一做分布式锁"><a href="#基于表主键唯一做分布式锁" class="headerlink" title="基于表主键唯一做分布式锁"></a>基于表主键唯一做分布式锁</h1><p>利用主键的特性，如果多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以任务操作成功的那个县城获得该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可</p><p>上面这种简单的实现有以下几个问题：</p><ul><li>这把锁依赖数据库的可用性，数据库是一个单点，一旦数据库挂了，会导致业务系统不可用</li><li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获取锁</li><li>这把锁只能是非阻塞的，因为 数据insert操作，一旦插入失败就会直接报错。没有获得锁的线程比不会进入排队队列，想要再次获得锁就要再次触发获得锁操作。</li><li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</li><li>这把锁是非公平锁，所有等待锁的线程凭运气去争夺锁。</li><li>在 MySQL 数据库中采用主键冲突防重，在大并发情况下有可能会造成锁表现象。</li></ul><p><strong>我们也可以有其他方式解决上面的问题</strong></p><ul><li>数据库是单点？ 搞两个数据库，数据之前双向同步，一旦挂掉快速切换到备库上</li><li>没有失效时间？ 只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍</li><li>非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。</li><li>非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li><li>非公平的？再建一张中间表，将等待锁的线程全记录下来，并根据创建时间排序，只有最先创建的允许获取锁。</li><li>比较好的办法是在程序中生产主键进行防重。</li></ul><h1 id="基于Redis做分布式锁"><a href="#基于Redis做分布式锁" class="headerlink" title="基于Redis做分布式锁"></a>基于Redis做分布式锁</h1><h2 id="基于redis-的-setnx-、expire-方法做分布式锁"><a href="#基于redis-的-setnx-、expire-方法做分布式锁" class="headerlink" title="基于redis 的 setnx()、expire()方法做分布式锁"></a>基于redis 的 setnx()、expire()方法做分布式锁</h2><h3 id="setnx"><a href="#setnx" class="headerlink" title="setnx()"></a>setnx()</h3><p>setnx 的含义就是 SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果 key 不存在，则设置当前 key 成功，返回 1；如果当前 key 已经存在，则设置当前 key 失败，返回 0。</p><h3 id="expire"><a href="#expire" class="headerlink" title="expire()"></a>expire()</h3><p>expire 设置过期时间，要注意的是 setnx 命令不能设置 key 的超时时间，只能通过 expire() 来对 key 设置。</p><h3 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h3><p>1、setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功</p><p>2、expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。</p><p>3、执行完业务代码后，可以通过 delete 命令删除 key。</p><p>这个方案其实是可以解决日常工作中的需求的，但从技术方案的探讨上来说，可能还有一些可以完善的地方。<strong>比如，如果在第一步 setnx 执行成功后，在 expire() 命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题，所以如果要对其进行完善的话，可以使用 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。</strong></p><h2 id="基于-redis-的-setnx-、get-、getset-方法做分布式锁"><a href="#基于-redis-的-setnx-、get-、getset-方法做分布式锁" class="headerlink" title="基于 redis 的 setnx()、get()、getset()方法做分布式锁"></a>基于 redis 的 setnx()、get()、getset()方法做分布式锁</h2><p>这个方案的背景主要是在 setnx() 和 expire() 的方案上针对可能存在的死锁问题，做了一些优化。</p><h3 id="getset"><a href="#getset" class="headerlink" title="getset()"></a>getset()</h3><p>这个命令主要有两个参数 getset(key，newValue)。该方法是原子的，对 key 设置 newValue 这个值，并且返回 key 原来的旧值。假设 key 原来是不存在的，那么多次执行这个命令，会出现下边的效果：</p><ol><li>getset(key, “value1”) 返回 null 此时 key 的值会被设置为 value1</li><li>getset(key, “value2”) 返回 value1 此时 key 的值会被设置为 value2</li><li>依次类推！</li></ol><h3 id="使用步骤-1"><a href="#使用步骤-1" class="headerlink" title="使用步骤"></a>使用步骤</h3><ol><li>setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。</li><li>get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。</li><li>计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。</li><li>判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。</li><li>在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。</li></ol><h1 id="基于-ZooKeeper-做分布式锁"><a href="#基于-ZooKeeper-做分布式锁" class="headerlink" title="基于 ZooKeeper 做分布式锁"></a>基于 ZooKeeper 做分布式锁</h1><h2 id="zookeeper-锁相关基础知识"><a href="#zookeeper-锁相关基础知识" class="headerlink" title="zookeeper 锁相关基础知识"></a>zookeeper 锁相关基础知识</h2><ul><li>zk一般由多个节点构成（单数），采用zab一致性协议。因此可以将zk看成一个单点结构，对其修改数据其内部自动将所有节点数据进行修改后才提供查询服务</li><li>zk的数据以目录树的形式，每个目录称为znode，znode中可存储数据（一般不超过1M），还可以在其中增加子节点</li><li>子节点有三种类型。序列化节点，每在该节点下增加一个节点自动给该节点的名称上自增。一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。最后就是普通节点。</li><li>Watch 机制，client 可以监控每个节点的变化，当产生变化会给 client 产生一个事件。</li></ul><h2 id="zk基本锁"><a href="#zk基本锁" class="headerlink" title="zk基本锁"></a>zk基本锁</h2><ul><li>原理：利用临时节点与 watch 机制。每个锁占用一个普通节点 /lock，当需要获取锁时在 /lock 目录下创建一个临时节点，创建成功则表示获取锁成功，失败则 watch/lock 节点，有删除操作后再去争锁。临时节点好处在于当进程挂掉后能自动上锁的节点自动删除即取消锁。</li><li>缺点：所有取锁失败的进程都监听父节点，很容易发生羊群效应，即当释放锁后所有等待进程一起来创建节点，并发量很大。</li></ul><h2 id="zk-锁优化"><a href="#zk-锁优化" class="headerlink" title="zk 锁优化"></a>zk 锁优化</h2><ul><li>原理：上锁改为创建临时有序节点，每个上锁的节点均能创建节点成功，只是其序号不同。只有序号最小的可以拥有锁，如果这个节点序号不是最小的则 watch 序号比本身小的前一个节点 (公平锁)。</li><li>步骤：</li><li>在 /lock 节点下创建一个有序临时节点 (EPHEMERAL_SEQUENTIAL)。</li><li>判断创建的节点序号是否最小，如果是最小则获取锁成功。不是则取锁失败，然后 watch 序号比本身小的前一个节点。</li><li>当取锁失败，设置 watch 后则等待 watch 事件到来后，再次判断是否序号最小。</li><li>取锁成功则执行代码，最后释放锁（删除该节点）。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;分布式锁&quot;&gt;&lt;a href=&quot;#分布式锁&quot; class=&quot;headerlink&quot; title=&quot;分布式锁&quot;&gt;&lt;/a&gt;分布式锁&lt;/h1&gt;&lt;h2 id=&quot;什么是锁&quot;&gt;&lt;a href=&quot;#什么是锁&quot; class=&quot;headerlink&quot; title=&quot;什么是锁&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>04.MySQL索引原理及慢查询优化</title>
    <link href="https://leslieaibin.github.io/2021/09/10/MySQL/04.MySQL%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%8F%8A%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
    <id>https://leslieaibin.github.io/2021/09/10/MySQL/04.MySQL%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%8F%8A%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</id>
    <published>2021-09-10T12:17:42.000Z</published>
    <updated>2021-09-11T02:30:25.218Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>MySQL凭借着出色的性能、低廉的成本、丰富的资源，已经成为绝大多数互联网公司的首选关系型数据库。虽然性能出色，但所谓“好马配好鞍”，如何能够更好的使用它，已经成为开发工程师的必修课，我们经常会从职位描述上看到诸如“精通MySQL”、“SQL语句优化”、“了解数据库原理”等要求。我们知道一般的应用系统，读写比例在10:1左右，而且插入操作和一般的更新操作很少出现性能问题，遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，所以查询语句的优化显然是重中之重。背景</p><h2 id="MySQL索引原理"><a href="#MySQL索引原理" class="headerlink" title="MySQL索引原理"></a>MySQL索引原理</h2><h3 id="索引目的"><a href="#索引目的" class="headerlink" title="索引目的"></a>索引目的</h3><p>索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？</p><h3 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a>索引原理</h3><p>除了词典，生活中随处可见索引的例子，如火车站的车次表、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。</p><p>数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&gt;、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。</p><h3 id="磁盘IO与预读"><a href="#磁盘IO与预读" class="headerlink" title="磁盘IO与预读"></a>磁盘IO与预读</h3><p>前面提到了访问磁盘，那么这里先介绍下磁盘IO和预读，磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分，寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。那么访问一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17 = 9ms左右，听起来还挺不错的，但要知道一台500 -MIPS的机器每秒可以执行5亿条指令，因为指令依靠的是电的性质，换句话说执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒的时间，显然是个灾难。下图是计算机硬件延迟的对比图，供大家参考：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/7f46a0a4.png" alt="various-system-software-hardware-latencies"></p><p>考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。</p><h3 id="索引的数据结构"><a href="#索引的数据结构" class="headerlink" title="索引的数据结构"></a>索引的数据结构</h3><p>前面讲了生活中索引的例子，索引的基本原理，数据库的复杂性，又讲了操作系统的相关知识，目的就是让大家了解，任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，我们现在总结一下，我们需要这种数据结构能够做些什么，其实很简单，那就是：每次查找数据时把磁盘IO次数控制在一个很小的数量级，最好是常数数量级。那么我们就想到如果一个高度可控的多路搜索树是否能满足需求呢？就这样，b+树应运而生。</p><p><strong>详解B+树</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/7af22798.jpg" alt="b+树"></p><p>如上图，是一颗b+树，关于b+树的定义可以参见<a href="http://zh.wikipedia.org/wiki/B%2B%E6%A0%91">B+树</a>，这里只说一些重点，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。</p><h4 id="b-树的查找过程"><a href="#b-树的查找过程" class="headerlink" title="b+树的查找过程"></a>b+树的查找过程</h4><p>如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。</p><h4 id="b-树性质"><a href="#b-树性质" class="headerlink" title="b+树性质"></a>b+树性质</h4><p>1.通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。</p><p>2.当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。</p><h2 id="慢查询优化"><a href="#慢查询优化" class="headerlink" title="慢查询优化"></a>慢查询优化</h2><p>关于MySQL索引原理是比较枯燥的东西，大家只需要有一个感性的认识，并不需要理解得非常透彻和深入。我们回头来看看一开始我们说的慢查询，了解完索引原理之后，大家是不是有什么想法呢？先总结一下索引的几大基本原则：</p><h3 id="建索引的几大原则："><a href="#建索引的几大原则：" class="headerlink" title="建索引的几大原则："></a>建索引的几大原则：</h3><ul><li><p>最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p></li><li><p>=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。</p></li><li><p>尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。</p></li><li><p>索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。</p></li><li><p>尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可</p></li></ul><h2 id="回到开始的慢查询"><a href="#回到开始的慢查询" class="headerlink" title="回到开始的慢查询"></a>回到开始的慢查询</h2><p>根据最左匹配原则，最开始的sql语句的索引应该是status、operator_id、type、operate_time的联合索引；其中status、operator_id、type的顺序可以颠倒，所以我才会说，把这个表的所有相关查询都找到，会综合分析；比如还有如下查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from task where status &#x3D; 0 and type &#x3D; 12 limit 10;</span><br><span class="line">select count(*) from task where status &#x3D; 0 ;</span><br></pre></td></tr></table></figure><p>那么索引建立成(status,type,operator_id,operate_time)就是非常正确的，因为可以覆盖到所有情况。这个就是利用了索引的最左匹配的原则</p><h3 id="查询优化神器-explain命令"><a href="#查询优化神器-explain命令" class="headerlink" title="查询优化神器 - explain命令"></a>查询优化神器 - explain命令</h3><p>关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网<a href="http://dev.mysql.com/doc/refman/5.5/en/explain-output.html">explain-output</a>，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。</p><h3 id="慢查询优化基本步骤"><a href="#慢查询优化基本步骤" class="headerlink" title="慢查询优化基本步骤"></a>慢查询优化基本步骤</h3><p>0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE</p><p>1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高</p><p>2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）</p><p>3.order by limit 形式的sql语句让排序的表优先查</p><p>4.了解业务方使用场景</p><p>5.加索引时参照建索引的几大原则</p><p>6.观察结果，不符合预期继续从0分析</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;MySQL凭借着出色的性能、低廉的成本、丰富的资源，已经成为绝大多数互联网公司的首选关系型数据库。虽然性能出色，但所谓“好马配好鞍”，如何能</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>03.一条SQL查询语句如何执行</title>
    <link href="https://leslieaibin.github.io/2021/09/09/MySQL/03.MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/"/>
    <id>https://leslieaibin.github.io/2021/09/09/MySQL/03.MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/</id>
    <published>2021-09-09T12:17:42.000Z</published>
    <updated>2021-09-11T02:30:12.521Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一条SQL查询语句如何执行"><a href="#一条SQL查询语句如何执行" class="headerlink" title="一条SQL查询语句如何执行"></a>一条SQL查询语句如何执行</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210910095617441.png" alt="image-20210910095617441"></p><p>MySQL可以分为Server层和存储引擎层两部分</p><p>Server层包括 <strong>连接器、查询缓存、分析器、优化器、执行器</strong>等，涵盖了MySQL的大多数核心功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程，触发器，视图等。</p><p>而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎InnoDB，它从MySQL5.5.5版本开始成为默认存储引擎。</p><p>也就是说，你执行create table建表的时候，如果不执行搜索引擎，默认的是innodb，不过，你也可以通过执行存储引擎的类型来选择别的引擎，比如在create table 语句中使用 engine=memory，来执行使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同。</p><h2 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h2><p>第一步，你会先连接到这数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接，获取权限，位置和管理连接。连接命令一般是这么写的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h$ip -P$port -u$user -p</span><br></pre></td></tr></table></figure><p>输完命令后，你就需要在交互对话里面输入密码。虽然密码也可以直接在-p后面卸载命令行中，但这样可能会导致你的密码泄露。</p><ul><li>如果用户名或密码不对，你就会收到一个”Access denied for user的错误，然后客户端程序结束执行。</li><li>如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。</li></ul><p>这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。<br>连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist令中看到它。文本中这个图是 show processlist的结果，其中的 Command列显示为Sleep的这一行，就表示现在系统里面有一个空闲连接</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210910103606002.png" alt="image-20210910103606002"></p><p>客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait timeout控制的，默认值是8小时。</p><p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒：Lost connection to MySQL server during query.这时候如果你要继续，就需要重连，然后再执行请求了数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断连接，下次查询再重新建立一个</p><h2 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h2><p>连接建立完成后，你就可以执行 select语句了执行逻辑就会来到第二步：查询缓存MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key- -value对的形式，被直接缓存在内存中。key是查询的语句， value是查询的结果。如果你的查询能够直接在这个缓存中找到key.那么这个 value就会被直接返回给客户端。<br>如果语句不在查询缓存中，就会继续后面的执行阶段执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存， MySQ不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p><p>但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。<br>查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会史新一次。</p><p>比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。<br>好在MSQL也提供了这种“按需使用”的方式。你可以将参数query cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL CACHE显式指定，像下面这个语句一样：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select SQL_CACHE from T where ID&#x3D;10：</span><br></pre></td></tr></table></figure><p><strong>需要注意的是， MySQL8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。</strong></p><h2 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h2><p>如果没有命中查询缓存，就要开始真正执行语句了。首先，MQL需要知道你要做什么，因此需要对SQL语句做解析。</p><p>分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句， MySQL需要识别出里面的字符串分别是什么，代表什么</p><p>MySQL从你输入的”select这个关键字识别出来，这是一个查询语句。它也要把字符串“T识别成“名T，把字符串识别成列D做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MSQL语法</p><p>如果你的语句不对，就会收到You have an error in your SQL syntax的错误提醒，比如下面这个语句 select少打了开头的字母s”。</p><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>经过了分析器，MySQL就知道你要做什么，在开始执行之前，要经过优化器的处理</p><p>优化器是在表里面有多个索引的时候，决定使用哪个索引，或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * <span class="function">from t1 join t2 <span class="title">using</span><span class="params">(ID)</span> where t1.c</span>=<span class="number">10</span> and t2.d = <span class="number">20</span>;</span><br></pre></td></tr></table></figure><ul><li>既可以先从表t1里面取出 c = 10的记录的ID值，在根据ID关联到表t2，再判断t2里面d的值是否等于20</li><li>也可以先从表t2里面取出d=20的记录的id值，在根据ID值关联到t1，在判断t1里面c的值是否等于10</li></ul><p>这两种执行方法的逻辑结果是一样的，但执行的效率会有不同，而优化器的作用是决定选择使用哪个方案</p><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h2><p>MSQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。</p><p>开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from where ID=<span class="number">10</span>;</span><br></pre></td></tr></table></figure><p>如果有权限，就打开表继续执行，打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口</p><p>比如我们这个例子中的表T中，D字段没有索引那么执行器的执行流程是这样的：</p><ul><li>调用InnoDB引擎接口取这个表的第一行，判断D值是不是10，如果不是则跳过，如果是则将这行存在结果集中</li><li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li><li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端至此，这个语句就执行完成了。</li></ul><p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的你会在数据库的慢查询日志中看到一个 rows examined的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。</p><p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rowsexamined并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一条SQL查询语句如何执行&quot;&gt;&lt;a href=&quot;#一条SQL查询语句如何执行&quot; class=&quot;headerlink&quot; title=&quot;一条SQL查询语句如何执行&quot;&gt;&lt;/a&gt;一条SQL查询语句如何执行&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http://test-1874</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>4.HashMap实现原理</title>
    <link href="https://leslieaibin.github.io/2021/09/05/Collection/4.HashMap%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/"/>
    <id>https://leslieaibin.github.io/2021/09/05/Collection/4.HashMap%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/</id>
    <published>2021-09-04T16:15:42.000Z</published>
    <updated>2021-09-05T08:36:32.595Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HashMap的实现原理"><a href="#HashMap的实现原理" class="headerlink" title="HashMap的实现原理"></a>HashMap的实现原理</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>HashMap是Java中对Map接口的实现类，是最常用的实现类中之一。主要有以下几个特性：</p><ul><li>HashMap中的key 和 value 都允许为null， 但最多智能拥有一个null的key</li><li>HashMap不保证顺序性</li><li>HashMap非线性安全</li></ul><p>HashMap的数据结构：</p><p>HashMap内部是以数组+链表的方式存储的数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210904213431065.png" alt="image-20210904213431065"></p><p>HashMap的数组中，每个元素称之为“<strong>桶</strong>”。需要注意的是，这个“桶”并不等同于“键值对（Entity）”。至于它是什么请往下看。</p><p><strong>初始化</strong></p><p>HashMap在初始化时会创建一个Entity的数组。其个数为<strong>16</strong>。其源码类似下面的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    V value;</span><br><span class="line">    Entry&lt;K,V&gt; next;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">    ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中key和value不必多说，不过它还包含了一个next属性，这说明它可以组织成一个链表结构。</p><p><strong>put()方法</strong></p><p>put方法被调用时，HashMap会根据key计算出对应的hashcode，然后根据hashcode确定该Entity应该存放在数组的哪个位置（应该放在哪个桶里）。</p><p>这种设定有一个问题：实际引用中有可能会发生hash碰撞（即两个数据虽然内容不同，但其hashcode有可能是相同的）！因此，HashMap如果发现hashcode已经存在，则会对key进行euqals对比：</p><ul><li>equals结果是true，则认为确实是同一个key，然后将新的value覆盖旧的value（此时put方法将会返回旧value值）。</li><li>equals结果是false，则认为是hash碰撞，此时会将之前的Entity作为新Entity的next，此时形成一个链表，新Entity则处在链表的首位。</li></ul><p>因此，所谓的<strong>“桶”就是数组每个位置放置的“链表”</strong>。</p><p><strong>get()方法</strong></p><p>如果理解了上述的put逻辑，则get方法就很容易理解。主要有以下几个步骤：</p><ul><li>根据key计算hashcode，然后得出其数组下标（位置）。</li><li>去对应位置获取桶（链表）。</li><li>从头到尾遍历链表的每一个Entity，通过equals方法找到对应的Entity。</li><li></li></ul><p>上述的过程中有一个点未详细说明：<strong>如何根据key的hashcode计算出对应的数组坐标呢？</strong></p><p>HashMap的内部实现用了一个非常巧妙的方法。HashMap的初始容量被定为<strong>16</strong>，且每次增长都是2的倍数。这样设计的目的是要<strong>保证存入map中的元素尽量分散</strong>，尽量避免出现桶中出现链表，这可以有效降低数据查询时的处理速度。</p><p>key是这么一步步转化成数组下标的：</p><p>第一步：Object Key –&gt; int hash</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">static final int hash(Object key) &#123;</span><br><span class="line">    int h;</span><br><span class="line">    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果key是null，则其hash为0；否则便将 <strong>hashcode</strong> 与 <strong>hashcode的高位</strong> 做 <strong>异或运算</strong>。这是为了尽量避免“低位不变，高位变化”时造成的hash冲突。</p><p>第二步：hash –&gt; i</p><p>上一步计算出的hash是个长度较长的二进制数字，而通常情况下HashMap的底层数组长度（length）较小，因此如果我们进行 <strong>hash % length</strong> 计算，则一定能得到一个下标，且相对比较分散。而在源码中使用了性能更高的算法：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">i = (length - 1) &amp; hash</span><br></pre></td></tr></table></figure><p>这个公式对hash和length进行了<strong>按位与</strong>运算，等价于<strong>取余。</strong></p><h2 id="为什么底层数组的长度总要是2的n次方呢"><a href="#为什么底层数组的长度总要是2的n次方呢" class="headerlink" title="为什么底层数组的长度总要是2的n次方呢"></a>为什么底层数组的长度总要是2的n次方呢</h2><p>这时就能说清楚另外一件事情：<strong>为什么底层数组的长度总要是2的n次方呢？</strong></p><p>下图是个示例：</p><p><img src="https://pic2.zhimg.com/80/v2-417a388c7b8ae370fc1ede9e854e54a5_720w.jpg" alt="img"></p><p>可以看到，如果数组长度是2的n次方，那么<strong>length-1</strong>的二进制表示中，一定所有位都是<strong>1</strong>，此时取&amp;运算则可以完整保留hash响应位置的二进制数据。相反的，如果数组长度不是2的n次方，则出现hash碰撞的可能性大大提高。</p><h2 id="JDK8中HashMap的改进"><a href="#JDK8中HashMap的改进" class="headerlink" title="JDK8中HashMap的改进"></a>JDK8中HashMap的改进</h2><p>上文曾提到“<strong>桶</strong>”的概念。其实这个概念在JDK8中才是真正有意义的。因为JDK7中，原始数组的每个元素都一定是个链表（链表的节点一个或者多个），而到了JDK8的时候就不一定是链表了。</p><p>JDK8对存储方式进行改进的原因很简单：如果在一个HashMap中，有很多Key发生了碰撞的时候，就会产生一个超级长的链表。那么在数据查询的时候就会花费O(n)的时间。所以，JDK8中HashMap采用了“<strong>桶</strong>+<strong>链表/红黑树</strong>”数据存储方式：如果链表的长度大于等于8时，其内部便会将链表转化为红黑树的结构。红黑树的查询时间是O(log n)。</p><p>由于数据存储方式发生变化，因此列表扩容时也会发生一些变化。具体细节请看下一篇HashMap的扩容。</p><h1 id="扩容机制"><a href="#扩容机制" class="headerlink" title="扩容机制"></a>扩容机制</h1><p>为了方便说明，这里明确几个名词：</p><ul><li>capacity 即容量，默认16。</li><li>loadFactor 加载因子，默认是0.75</li><li>threshold 阈值。阈值=容量*加载因子。默认12。当元素数量超过阈值时便会触发扩容。</li></ul><p><strong>什么时候触发扩容？</strong></p><p>一般情况下，<strong>当元素数量超过阈值时</strong>便会触发扩容。每次扩容的容量都是之前容量的2倍。</p><p>HashMap的容量是有上限的，必须小于<strong>1&lt;&lt;30</strong>，即1073741824。如果容量超出了这个数，则不再增长，且阈值会被设置为<strong>Integer.MAX_VALUE</strong>（2^31^  - 1) ，即永远不会超出阈值了)。</p><h2 id="JDK7中的扩容机制"><a href="#JDK7中的扩容机制" class="headerlink" title="JDK7中的扩容机制"></a><strong>JDK7中的扩容机制</strong></h2><p>JDK7的扩容机制相对简单，有以下特性：</p><ul><li>空参数的构造函数：以默认容量、默认负载因子、默认阈值初始化数组。内部数组是<strong>空数组</strong>。</li><li>有参构造函数：根据参数确定容量、负载因子、阈值等。</li><li>第一次put时会初始化数组，其容量变为<strong>不小于指定容量的2的幂数</strong>。然后根据负载因子确定阈值。</li><li>如果不是第一次扩容，则 <img src="https://www.zhihu.com/equation?tex=%E6%96%B0%E5%AE%B9%E9%87%8F=%E6%97%A7%E5%AE%B9%E9%87%8F%5Ctimes2" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=%E6%96%B0%E9%98%88%E5%80%BC=%E6%96%B0%E5%AE%B9%E9%87%8F%5Ctimes%E8%B4%9F%E8%BD%BD%E5%9B%A0%E5%AD%90" alt="[公式]"> 。</li></ul><h2 id="JDK8的扩容机制"><a href="#JDK8的扩容机制" class="headerlink" title="JDK8的扩容机制"></a><strong>JDK8的扩容机制</strong></h2><p>JDK8的扩容做了许多调整。</p><p>HashMap的容量变化通常存在以下几种情况：</p><ol><li>空参数的构造函数：实例化的HashMap默认内部数组是null，即没有实例化。第一次调用put方法时，则会开始第一次初始化扩容，长度为16。</li><li>有参构造函数：用于指定容量。会根据指定的正整数找到<strong>不小于指定容量的2的幂数</strong>，将这个数设置赋值给<strong>阈值</strong>（threshold）。第一次调用put方法时，会将阈值赋值给容量，然后让 <img src="https://www.zhihu.com/equation?tex=%E9%98%88%E5%80%BC=%E5%AE%B9%E9%87%8F%5Ctimes%E8%B4%9F%E8%BD%BD%E5%9B%A0%E5%AD%90" alt="[公式]"> 。（因此并不是我们手动指定了容量就一定不会触发扩容，超过阈值后一样会扩容！！）</li><li>如果不是第一次扩容，则容量变为原来的2倍，阈值也变为原来的2倍。<em>（容量和阈值都变为原来的2倍时，负载因子还是不变）</em></li></ol><p>此外还有几个细节需要注意：</p><ul><li>首次put时，先会触发扩容（算是初始化），然后存入数据，然后判断是否需要扩容；</li><li>不是首次put，则不再初始化，直接存入数据，然后判断是否需要扩容；</li></ul><h2 id="JDK7的元素迁移"><a href="#JDK7的元素迁移" class="headerlink" title="JDK7的元素迁移"></a><strong>JDK7的元素迁移</strong></h2><p>JDK7中，HashMap的内部数据保存的都是链表。因此逻辑相对简单：在准备好新的数组后，map会遍历数组的每个“桶”，然后遍历桶中的每个Entity，重新计算其hash值（也有可能不计算），找到新数组中的对应位置，以<strong>头插法</strong>插入新的链表。</p><p>这里有几个注意点：</p><ul><li>是否要重新计算hash值的条件这里不深入讨论，读者可自行查阅源码。</li><li>因为是头插法，因此新旧链表的元素位置会发生转置现象。</li><li>元素迁移的过程中在多线程情境下有可能会触发死循环（无限进行链表反转）。</li></ul><h2 id="JDK8的元素迁移"><a href="#JDK8的元素迁移" class="headerlink" title="JDK8的元素迁移"></a><strong>JDK8的元素迁移</strong></h2><p>JDK8则因为巧妙的设计，性能有了大大的提升：由于数组的容量是以2的幂次方扩容的，那么一个Entity在扩容时，新的位置要么在<strong>原位置</strong>，要么在<strong>原长度+原位置</strong>的位置。原因如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-da2df9ad67181daa328bb09515c1e1c8_720w.png" alt="img"></p><p>数组长度变为原来的2倍，表现在二进制上就是<strong>多了一个高位参与数组下标确定</strong>。此时，一个元素通过hash转换坐标的方法计算后，恰好出现一个现象：最高位是0则坐标不变，最高位是1则坐标变为“10000+原坐标”，即“原长度+原坐标”。如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-ac1017eb1b83ce5505bfc032ffbcc29a_720w.jpg" alt="img"></p><p>因此，在扩容时，不需要重新计算元素的hash了，只需要判断最高位是1还是0就好了。</p><p>JDK8的HashMap还有以下细节：</p><ul><li>JDK8在迁移元素时是正序的，不会出现链表转置的发生。</li><li>如果某个桶内的元素超过8个，则会将链表转化成红黑树，加快数据查询效率。</li></ul><h2 id="HashMap扩容死循环问题"><a href="#HashMap扩容死循环问题" class="headerlink" title="HashMap扩容死循环问题"></a>HashMap扩容死循环问题</h2><ul><li><p>当插入一个新的键值对时，会根据key对HashMap底层数组长度取模，得到键值对存放的数组下标，然后调用addEntry() 函数把这个键值对插入到这个下标所在的链表中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(<span class="keyword">int</span> hash, K key , V value, <span class="keyword">int</span> bucketIndex)</span></span>&#123;</span><br><span class="line">    Entry&lt;K, V&gt; e = table[bucketIndex];</span><br><span class="line">    table[bucketIndex] = <span class="keyword">new</span> Entry&lt;&gt;(hash, key , value, e);</span><br><span class="line">    <span class="keyword">if</span>(size++ &gt;= threshold)<span class="comment">// 如果键值对个数超过hashmap当前的阈值</span></span><br><span class="line">        resize(<span class="number">2</span> * table.length)<span class="comment">// 调整resize()函数进行扩容</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>在这个addEntry() 函数中，会判断键值对个数是否超过了HashMap当前容量的阈值，如果超过了，则说明需要扩容，接下来就调用resize() 函数扩容为原来的两倍</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">resize</span><span class="params">(<span class="keyword">int</span> newCapacity)</span> </span>&#123;</span><br><span class="line">    Entry[] oldTable = table;</span><br><span class="line">    <span class="keyword">int</span> oldCapacity = oldTable.length;</span><br><span class="line">    <span class="keyword">if</span> (oldCapacity == MAXIMUM_CAPACITY) &#123;</span><br><span class="line">           threshold = Integer.MAX_VALUE;</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">     &#125;</span><br><span class="line">    Entry[] newTable = <span class="keyword">new</span> Entry[newCapacity];  <span class="comment">// 创建一个新数组</span></span><br><span class="line">    transfer(newTable);        <span class="comment">// 把老数组中的所有键值对都拷贝到新数组中</span></span><br><span class="line">    table = newTable;        <span class="comment">// 修改老数组的指向，把老数组指向新数组，完成扩容</span></span><br><span class="line">    threshold = (<span class="keyword">int</span>)(newCapacity * loadFactor);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>resize()函数会先创建一个新数组，然后调用 transfer() 函数把老数组中的所有键值对都拷贝到新数组中，最后修改老数组的指向，把老数组指向新数组，完成扩容。</p><p>扩容过程中会出现循环链表的情况就是多个线程在执行 transfer() 函数导致的，下面看看 transfer() 函数的代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Entry[] newTable)</span> </span>&#123;</span><br><span class="line">    Entry[] src = table;        <span class="comment">// 老数组</span></span><br><span class="line">    <span class="keyword">int</span> newCapacity = newTable.length;     <span class="comment">// 新数组的长度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; src.length; j++) <span class="comment">// 遍历老数组，把老数组中所有键值对拷贝到新数组</span></span><br><span class="line">        Entry&lt;K,V&gt; e = src[j];    <span class="comment">// 记录下老数组第 j 个链表，接下来会链表上的键值对都拷贝到新数组</span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;        <span class="comment">// 如果链表不为空才需要拷贝</span></span><br><span class="line">            src[j] = <span class="keyword">null</span>;        <span class="comment">// 先老数组第j个链表置为空链表</span></span><br><span class="line">            <span class="keyword">do</span> &#123;                <span class="comment">// 循环遍历刚才记录下来的链表，把所有键值对都采用头插法插入到新数组对应链表</span></span><br><span class="line">                Entry&lt;K,V&gt; next = e.next;        <span class="comment">// 记录下当前结点的下个结点</span></span><br><span class="line">                <span class="keyword">int</span> i = indexFor(e.hash, newCapacity);    <span class="comment">// 求出该键值对在新数组的下标,即该键值对应该被插入到新数组第几个链表</span></span><br><span class="line">                e.next = newTable[i];    <span class="comment">// 把结点的next指针指向新数组的第i个链表头结点</span></span><br><span class="line">                newTable[i] = e;    <span class="comment">// 新数组第i个链表的头结点前移，指向当前结点</span></span><br><span class="line">                e = next;        <span class="comment">// 把指向当前结点的指针后移</span></span><br><span class="line">            &#125; <span class="keyword">while</span> (e != <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>其中最关键的就是其中的 do while()循环，这里面就是会发生循环链表的代码。</p></li></ul><p>现在先走一遍正常扩容的流程,假设有下面这个HashMap, 假设数组大小为2</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210822148-740596617.png" alt="img"></p><p>现在需要对它进行扩容，扩容后数组大小为原来的两倍，创建一个大小为4的数组</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210822686-391022651.png" alt="img"></p><p>假设a、b两个数扩容后刚好又hash冲突了，即又在同一个链表中，所在下标为3；c在下标为1的链表中。下面开始扩容。</p><p>e指针指向了老数组的第1个链表</p><h3 id="执行上面的do-while循环，第一轮循环："><a href="#执行上面的do-while循环，第一轮循环：" class="headerlink" title="执行上面的do while循环，第一轮循环："></a>执行上面的do while循环，第一轮循环：</h3><p><a href="https://img2020.cnblogs.com/blog/1456655/202012/1456655-20201211210823926-116268729.png"><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210823926-116268729.png" alt="img"></a></p><h3 id="第二轮循环："><a href="#第二轮循环：" class="headerlink" title="第二轮循环："></a>第二轮循环：</h3><h3 id=""><a href="#" class="headerlink" title=""></a><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20210820225941991-619872774.png" alt="img"></h3><h3 id="第三轮也是最后一轮循环，前面已经假设结点-c-将在新数组中的第二个链表"><a href="#第三轮也是最后一轮循环，前面已经假设结点-c-将在新数组中的第二个链表" class="headerlink" title="第三轮也是最后一轮循环，前面已经假设结点 c 将在新数组中的第二个链表"></a>第三轮也是最后一轮循环，前面已经假设结点 c 将在新数组中的第二个链表</h3><p><a href="https://img2020.cnblogs.com/blog/1456655/202012/1456655-20201211210826842-959746908.png"><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210826842-959746908.png" alt="img"></a></p><p>至此，老数组中的健值对已全部拷贝到新数组中</p><h3 id="多线程环境中扩容"><a href="#多线程环境中扩容" class="headerlink" title="多线程环境中扩容"></a>多线程环境中扩容</h3><p>假设在第 二 次循环中的第二步（执行完e.next = newTable[i]；）后当前线程的时间片刚好用完了，当前线程被挂起，这时刚好又有一个线程 P2 也来执行扩容操作，它并不会从第二步开始执行，而是重新从第一步开始执行，加入新线程后的扩容图为</p><p><a href="https://img2020.cnblogs.com/blog/1456655/202012/1456655-20201211210829300-1877613427.png"><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210829300-1877613427.png" alt="img"></a></p><p>可以看到，线程2扩容之后的newTable中的单链表形成了一个环，后续执行get操作的时候，会触发死循环，引起CPU的100%问题。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过解读HashMap源码并结合实例可以发现，HashMap扩容导致死循环的主要原因在于<strong>扩容过程中使用头插法将oldTable中的单链表中的节点插入到newTable的单链表中</strong>，所以newTable中的单链表会倒置oldTable中的单链表。那么在多个线程同时扩容的情况下就可能导致<strong>扩容后的HashMap中存在一个有环的单链表</strong>，从而导致后续执行get操作的时候，会触发死循环，引起CPU的100%问题。所以一定要避免在并发环境下使用HashMap。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;HashMap的实现原理&quot;&gt;&lt;a href=&quot;#HashMap的实现原理&quot; class=&quot;headerlink&quot; title=&quot;HashMap的实现原理&quot;&gt;&lt;/a&gt;HashMap的实现原理&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;</summary>
      
    
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/categories/Collection/"/>
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/tags/Collection/"/>
    
  </entry>
  
  <entry>
    <title>02.索引</title>
    <link href="https://leslieaibin.github.io/2021/09/04/MySQL/02.%E7%B4%A2%E5%BC%95/"/>
    <id>https://leslieaibin.github.io/2021/09/04/MySQL/02.%E7%B4%A2%E5%BC%95/</id>
    <published>2021-09-04T12:17:42.000Z</published>
    <updated>2021-09-04T08:47:40.314Z</updated>
    
    <content type="html"><![CDATA[<h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h2 id="什么是索引"><a href="#什么是索引" class="headerlink" title="什么是索引"></a>什么是索引</h2><p>索引是一个单独的，存储在磁盘上的数据结构，包含着对数据表里所有记录的引用指针，使用索引可以快速记录找出在某个或多个列中有一特定值的行，所有MySQL列数据都可以被索引，所有MySQL列类型都可以被索引，对相关列使用时提高查询操作速度的最佳途径。</p><p>索引是在存储引擎中实现的，因此，每种存储引擎的索引都不一定完全相同，并且每种存储引擎也不一定支持所有索引类型。MySQL中索引的存储类型有两种，即BTREE和HASH，具体和表的存储引擎相关。<strong>MyISAM和InnoDB存储引擎只支持BTREE索引；MEMORY/HEAP存储引擎可以支持HASH和BTREE索引。</strong></p><p>优点：</p><ul><li>通过创建唯一索引，可以保证数据库表中每一行数据的唯一性</li><li>可以大大加快数据的查询速度，这也是创建索引的主要原因</li><li>在实现数据的参考完整性方面，可以加速表和表之间的连接</li><li>在使用分组和排序子句进行数据查询时，也可以显著减少查询中分组和排序的时间。</li></ul><p>缺点：</p><ul><li>创建索引和维护索引需要耗费时间，并且随着数据量的增加所耗费的时间也会增加</li><li>索引需要占磁盘空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果有大量的索引，索引文件可能比数据文件更快达到最大文件尺寸</li><li>当对表中的数据进行增加、删除和修改的时候，索引也要动态地维护，这样就降低了数据的维护速度。</li></ul><h2 id="索引的分类"><a href="#索引的分类" class="headerlink" title="索引的分类"></a>索引的分类</h2><p>按数据结构分类可分为：<strong>B+tree索引、Hash索引、Full-text索引</strong>。</p><p>按物理存储分类可分为：<strong>聚簇索引、二级索引（辅助索引）</strong>。</p><p>按字段特性分类可分为：<strong>主键索引、普通索引、前缀索引</strong>。</p><p>按字段个数分类可分为：<strong>单列索引、联合索引（复合索引、组合索引）</strong>。</p><h3 id="按数据结构分类"><a href="#按数据结构分类" class="headerlink" title="按数据结构分类"></a>按数据结构分类</h3><p>MySQL索引按数据结构分类可分为：<strong>B+tree索引、Hash索引、Full-text索引</strong>。</p><table><thead><tr><th>-</th><th>InnoDB</th><th>MyISAM</th><th>Memory</th></tr></thead><tbody><tr><td>B+tree索引</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Hash索引</td><td>×</td><td>×</td><td>√</td></tr><tr><td>Full-text索引</td><td>√（MySQL5.6+）</td><td>√</td><td>×</td></tr></tbody></table><p><strong>B+tree</strong> 是MySQL中被存储引擎采用最多的索引类型。<strong>B+tree</strong> 中的 <code>B</code> 代表平衡（balance），而不是二叉（binary），因为 <strong>B+tree</strong> 是从最早的平衡二叉树演化而来的。下面展示B+tree数据结构与其他数据结构的对比。</p><h4 id="B-tree与B-tree的对比"><a href="#B-tree与B-tree的对比" class="headerlink" title="B+tree与B-tree的对比"></a><strong>B+tree与B-tree的对比</strong></h4><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037684393" alt="B-tree结构（图片来源于网络）"></p><p><strong>相对于B-tree，B+tree有以下两点不同：</strong></p><ul><li>B+tree 非叶子节点只存储键值信息， 数据记录都存放在叶子节点中。而B-tree的非叶子节点也存储数据。所以B+tree单个节点的数据量更小，在相同的磁盘I/O次数下，能查询更多的节点。</li><li>B+tree 所有叶子节点之间都采用<strong>双向链表</strong>连接。适合MySQL中常见的基于范围的顺序检索场景，而B-tree无法做到这一点。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037684392" alt="B+tree结构（图片来源于网络）"></p><h4 id="B-tree与红黑树的对比"><a href="#B-tree与红黑树的对比" class="headerlink" title="B+tree与红黑树的对比"></a>B+tree与红黑树的对比</h4><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037684042" alt="红黑树结构（图片来源于网络）"></p><p><strong>红黑树</strong>是一种<strong>弱平衡二叉查找树</strong>。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，<strong>红黑树确保没有一条路径会比其他路径长出两倍</strong>。</p><p>对于有N个叶子结点的 <strong>B+tree</strong>，其搜索复杂度为 <code>O(logdN)</code> ，其中 <strong>d</strong>(degree) 为 <strong>B+tree</strong> 的度，表示节点允许的最大子节点个数为<strong>d</strong>个，在实际应用当中，<strong>d</strong>值一般是大于100的，即使数据量达到千万级别时<strong>B+tree</strong>的高度依然维持在3-4左右，保证了3-4次磁盘I/O操作就能查询到目标数据。</p><p><strong>红黑树</strong>是二叉树，节点子节点个数为两个，意味着其搜索复杂度为 <code>O(logN)</code>，树的高度也会比 <strong>B+tree</strong> 高出不少，因此<strong>红黑树</strong>检索到目标数据所需经历的磁盘I/O次数更多。</p><h4 id="B-tree与Hash的对比"><a href="#B-tree与Hash的对比" class="headerlink" title="B+tree与Hash的对比"></a>B+tree与Hash的对比</h4><p>Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。虽然 Hash 索引效率高，但是 Hash 索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些。 Hash 索引仅仅能满足 <code>=</code> , <code>IN</code> 和 <code>&lt;=&gt;</code>(表示NULL安全的等价) 查询，不能使用范围查询。</p><p>由于 Hash 索引比较的是进行 Hash 运算之后的 Hash值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。</p><ul><li>Hash 索引无法适用数据的排序操作。</li><li>Hash 索引不能利用部分索引键查询</li><li>Hash 索引依然需要回表扫描。</li><li>Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。</li></ul><p><strong>由于范围查询是MySQL数据库查询中常见的场景，Hash表不适合做范围查询，它更适合做等值查询。另外Hash表还存在Hash函数选择和Hash值冲突等问题。因此，B+tree索引要比Hash表索引有更广的适用场景。</strong></p><h3 id="按照物理存储分类"><a href="#按照物理存储分类" class="headerlink" title="按照物理存储分类"></a>按照物理存储分类</h3><p>MySQL索引按叶子节点存储的是否为完整表数据分为：<strong>聚簇索引、二级索引（辅助索引）</strong>。全表数据存储在聚簇索引中，聚簇索引以外的其他索引叫做二级索引，也叫辅助索引。</p><h4 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h4><p>聚簇索引的每个叶子节点存储了一行完整的表数据，叶子节点间按id列递增连接，可以方便地进行顺序检索。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688814" alt="聚簇索引B+tree示意图（图片来源于网络）"><br>（图片来源于网络）</p><p>InnoDB表要求必须有聚簇索引，默认在主键字段上建立聚簇索引，在没有主键字段的情况下，表的第一个非空的唯一索引将被建立为聚簇索引，在前两者都没有的情况下，InnoDB将自动生成一个隐式的自增id列，并在此列上建立聚簇索引。</p><h5 id="以MyISAM为存储引擎的表不存在聚簇索引。"><a href="#以MyISAM为存储引擎的表不存在聚簇索引。" class="headerlink" title="以MyISAM为存储引擎的表不存在聚簇索引。"></a>以MyISAM为存储引擎的表不存在聚簇索引。</h5><p>MyISAM表中的主键索引和非主键索引的结构是一样的，索引的叶子节点不存储表数据，存放的是表数据的地址。所以，MyISAM表可以没有主键。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688815" alt="MyISAM索引B+tree示意图（图片来源于网络）"><br>（图片来源于网络）</p><p>MyISAM表的数据和索引是分开存储的。MyISAM表的主键索引和非主键索引的区别仅在于主键索引的B+tree上的key必须符合主键的限制，非主键索引B+tree上的key只要符合相应字段的特性就可以了。</p><h4 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h4><p>二级索引的叶子节点并不存储一行完整的表数据，而是存储了聚簇索引所在列的值。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688816" alt="二级索引B+tree示意图（图片来源于网络）"><br>（图片来源于网络）</p><h5 id="回表查询"><a href="#回表查询" class="headerlink" title="回表查询"></a>回表查询</h5><p>由于二级索引的叶子节点不存储完整的表数据，索引当通过二级索引查询到聚簇索引列值后，还需要回到聚簇索引也就是表数据本身进一步获取数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688817" alt="回表查询示意图（图片来源于网络）"><br>（图片来源于网络）</p><p>回表查询 需要额外的 <strong>B+tree</strong> 搜索过程，必然增大查询耗时。</p><p>需要注意的是，<strong>通过二级索引查询时，回表不是必须的过程</strong>，当<strong>SELECT的所有字段在单个二级索引中都能够找到</strong>时，就不需要回表，MySQL称此时的二级索引为<strong>覆盖索引</strong>或触发了<strong>索引覆盖</strong>。<br>可以用Explain命令查看SQL语句的执行计划，执行计划的Extra字段中若出现<strong>Using index</strong>，表示查询触发了<strong>索引覆盖</strong>。</p><h3 id="按字段特性分类"><a href="#按字段特性分类" class="headerlink" title="按字段特性分类"></a>按字段特性分类</h3><p>MySQL索引按字段特性分类可分为：<strong>主键索引、普通索引、前缀索引</strong>。</p><ul><li><strong>主键索引</strong></li></ul><p>建立在主键上的索引被称为<strong>主键索引</strong>，一张数据表只能有一个主键索引，索引列值不允许有空值，通常在创建表时一起创建。</p><ul><li><strong>唯一索引</strong></li></ul><p>建立在UNIQUE字段上的索引被称为<strong>唯一索引</strong>，一张表可以有多个唯一索引，索引列值允许为空，列值中出现多个空值不会发生重复冲突。</p><ul><li><strong>普通索引</strong></li></ul><p>建立在普通字段上的索引被称为<strong>普通索引</strong>。</p><ul><li><strong>前缀索引</strong></li></ul><p><strong>前缀索引</strong>是指对字符类型字段的前几个字符或对二进制类型字段的前几个bytes建立的索引，而不是在整个字段上建索引。前缀索引可以建立在类型为char、varchar、binary、varbinary的列上，可以大大减少索引占用的存储空间，也能提升索引的查询效率。</p><h3 id="按索引字段个数分类"><a href="#按索引字段个数分类" class="headerlink" title="按索引字段个数分类"></a>按索引字段个数分类</h3><p>MySQL索引按字段个数分类可分为：<strong>单列索引、联合索引（复合索引、组合索引）</strong>。</p><ul><li>单列索引</li></ul><p>建立在单个列上的索引被称为单列索引。</p><ul><li>联合索引（复合索引、组合索引）</li></ul><p>建立在多个列上的索引被称为联合索引，又叫复合索引、组合索引。</p><h2 id="聚簇索引和非聚簇索引有什么区别"><a href="#聚簇索引和非聚簇索引有什么区别" class="headerlink" title="聚簇索引和非聚簇索引有什么区别"></a>聚簇索引和非聚簇索引有什么区别</h2><p>在InnoDB存储引擎中，可以将B+树索引分为聚簇索引和辅助索引（非聚簇索引）。无论是何种索引，每个页的大小都为16KB，且不能更改。</p><p>聚簇索引是根据主键创建的一棵B+树，聚簇索引的叶子节点存放了表中的所有记录。辅助索引是根据索引键创建的一棵B+树，与聚簇索引不同的是，其叶子节点仅存放索引键值，以及该索引键值指向的主键。也就是说，如果通过辅助索引来查找数据，那么当找到辅助索引的叶子节点后，很有可能还需要根据主键值查找聚簇索引来得到数据，这种查找方式又被称为书签查找。因为辅助索引不包含行记录的所有数据，这就意味着每页可以存放更多的键值，因此其高度一般都要小于聚簇索引。</p><h2 id="索引的实现原理"><a href="#索引的实现原理" class="headerlink" title="索引的实现原理"></a>索引的实现原理</h2><p>在MySQL中，索引是在存储引擎层实现的，不同存储引擎对索引的实现方式是不同的，下面我们探讨一下MyISAM和InnoDB两个存储引擎的索引实现方式。</p><h3 id="MyISAM索引实现："><a href="#MyISAM索引实现：" class="headerlink" title="MyISAM索引实现："></a>MyISAM索引实现：</h3><p>MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址，MyISAM索引的原理图如下。这里假设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-1.png" alt="img"></p><p>如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示。同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-2.png" alt="img"></p><h3 id="InnoDB索引实现："><a href="#InnoDB索引实现：" class="headerlink" title="InnoDB索引实现："></a>InnoDB索引实现：</h3><p>虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。</p><p>第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。</p><p>下图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-3.png" alt="img"></p><p>第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。下图为定义在Col3上的一个辅助索引。这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-4.png" alt="img"></p><p>了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;索引&quot;&gt;&lt;a href=&quot;#索引&quot; class=&quot;headerlink&quot; title=&quot;索引&quot;&gt;&lt;/a&gt;索引&lt;/h1&gt;&lt;h2 id=&quot;什么是索引&quot;&gt;&lt;a href=&quot;#什么是索引&quot; class=&quot;headerlink&quot; title=&quot;什么是索引&quot;&gt;&lt;/a&gt;什么是索</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>01.事务的隔离性</title>
    <link href="https://leslieaibin.github.io/2021/09/04/MySQL/01.%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/"/>
    <id>https://leslieaibin.github.io/2021/09/04/MySQL/01.%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/</id>
    <published>2021-09-04T11:17:42.000Z</published>
    <updated>2021-09-04T08:47:01.699Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL事务"><a href="#MySQL事务" class="headerlink" title="MySQL事务"></a>MySQL事务</h1><p>MySQL事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你既需要删除人员的基本资料，也要删除该人员相关的信息，如信箱、文章等等，这样，这些数据库操作语句就构成一个事务</p><ul><li>在MySql中只有使用了Innodb数据库引擎的数据库或表才支持事务</li><li>事务处理可以用来维护数据库的完整性，保证成批的SQL语句要么全部执行，要么全部不执行</li><li>事务用来管理insert、update、delete语句</li></ul><p>一般来说，事务是必须满足四个条件（ACID）：</p><ul><li>原子性（Atomicity）：一个事务中的所有操作要么全部完成，要么全部不完成，不会在结束中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样</li><li>一致性（Consistency）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的数据必须完全符合所有的预设规则，这包含资料的精度，串联性以及后续数据库可以自发性地完成预定的工作</li><li>隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。</li><li>持久性（Durability）：事务处理结束后，对数据的修改是永久的，即使系统故障也不会丢失。</li></ul><p>在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。</p><p>简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。MySQL是一个支持多引擎的系统，但并不是所有引擎都支持事务。比如MySQL原生的MyISAM引擎不支持事务，这也是MyISAM被InnoDB取代的重要原因之一。</p><h1 id="隔离性和隔离级别"><a href="#隔离性和隔离级别" class="headerlink" title="隔离性和隔离级别"></a>隔离性和隔离级别</h1><p>当数据库上多个事务同时执行的时候就可能出现脏读（dirty read)、不可重复读（nonrepeatable read)、幻读（phantom read)等问题。</p><ul><li><p><strong>脏读（读取未提交数据）</strong></p><p>A事务读取B事务尚未提交的数据，此时如果B事务发生错误并执行回滚操作，那么A事务读取到的数据就是脏数据。就好像原本的数据比较干净、纯粹，此时由于B事务更改了它，这个数据变得不再纯粹。这个时候A事务立即读取了这个脏数据，但事务B良心发现，又用回滚把数据恢复成原来干净、纯粹的样子，而事务A却什么都不知道，最终结果就是事务A读取了此次的脏数据，称为脏读。</p></li><li><p><strong>不可重复读（前后多次读取，数据内容不一致）</strong></p><p>事务A在执行读取操作，由整个事务A比较大，前后读取同一条数据需要经历很长的时间 。而在事务A第一次读取数据，比如此时读取了小明的年龄为20岁，事务B执行更改操作，将小明的年龄更改为30岁，此时事务A第二次读取到小明的年龄时，发现其年龄是30岁，和之前的数据不一样了，也就是数据不重复了，系统不可以读取到重复的数据，成为不可重复读</p></li><li><p><strong>幻读（前后多次读取，数据总量不一致）</strong></p><p>事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，成为幻读。</p></li></ul><h2 id="SQL标准的事务隔离级别包括："><a href="#SQL标准的事务隔离级别包括：" class="headerlink" title="SQL标准的事务隔离级别包括："></a>SQL标准的事务隔离级别包括：</h2><ul><li>读未提交（read committed）： 一个事务还没提交，让做的变更就能被其他事务看到</li><li>读提交（read committed）：一个事务提交之后，它做的变更才会被其他事务看到</li><li>可重复读（repeatable read）： 一个事务执行过程中看到的数据，总跟这个事务启动时看到的数据是一值的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li><li>串行化：对于同一行记录，写会加“写锁”，读会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等待前一个事务执行完成，才能继续执行</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210904144955378.png" alt="image-20210904144955378"></p><ul><li>若隔离级别是”读未提交”：则V1的值就是2。 这时候事务B虽然还没有提交， 但是结果已经被A看到了。 因此， V2、 V3也都是2  </li><li>若隔离级别是”读提交”:  则V1是1， V2的值是2。 事务B的更新在提交后才能被A看到。 所以，V3的值也是2。  </li><li>若隔离级别是”可重复读”：则V1、 V2是1， V3是2。 之所以V2还是1， 遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的  </li><li>若隔离级别是”串行化”：则在事务B执行“将1改成2”的时候， 会被锁住。 直到事务A提交后，事务B才可以继续执行。 所以从A的角度看， V1、 V2值是1， V3的值是2。  </li></ul><table><thead><tr><th>隔离级别</th><th>脏读（Dirty Read）</th><th>不可重复读（NonRepeatable Read）</th><th>幻读（Phantom Read）</th></tr></thead><tbody><tr><td>未提交读（Read uncommitted）</td><td>可能</td><td>可能</td><td>可能</td></tr><tr><td>已提交读（Read committed）</td><td>不可能</td><td>可能</td><td>可能</td></tr><tr><td>可重复读（Repeatable read）</td><td>不可能</td><td>不可能</td><td>可能</td></tr><tr><td>可串行化（Serializable ）</td><td>不可能</td><td>不可能</td><td>不可能</td></tr></tbody></table><p>在实现上， 数据库里面会创建一个视图， 访问的时候以视图的逻辑结果为准。 在“可重复读”隔离级别下， 这个视图是在事务启动时创建的， 整个事务存在期间都用这个视图。 在“读提交”隔离级<br>别下， 这个视图是在每个SQL语句开始执行的时候创建的。 这里需要注意的是， “读未提交”隔离<br>级别下直接返回记录上的最新值， 没有视图概念； 而“串行化”隔离级别下直接用加锁的方式来避<br>免并行访问。</p><p>我们可以看到在不同的隔离级别下， 数据库行为是有所不同的。 Oracle数据库的默认隔离级别其实就是“读提交”， 因此对于一些从Oracle迁移到MySQL的应用， 为保证数据库隔离级别的一致，<br>你一定要记得将MySQL的隔离级别设置为“读提交”。配置的方式是， 将启动参数transaction-isolation的值设置成READ-COMMITTED。 你可以用show variables来查看当前的值。  </p><h1 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h1><p>在MySQL中， 实际上每条记录在更新的时候都会同时记录一条回滚操作。 记录上的最新值， 通<br>过回滚操作， 都可以得到前一个状态的值。假设一个值从1被按顺序改成了2、 3、 4， 在回滚日志里面就会有类似下面的记录。  </p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210904150457737.png" alt="image-20210904150457737"></p><p>当前值是4， 但是在查询这条记录的时候， 不同时刻启动的事务会有不同的read-view。 如图中看到的， 在视图A、 B、 C里面， 这一个记录的值分别是1、 2、 4， 同一条记录在系统中可以存在多<br>个版本， 就是数据库的多版本并发控制（MVCC） 。 对于read-view A， 要得到1， 就必须将当前<br>值依次执行图中所有的回滚操作得到。</p><p>同时你会发现， 即使现在有另外一个事务正在将4改成5， 这个事务跟read-view A、 B、 C对应的事务是不会冲突的。</p><p>你一定会问， 回滚日志总不能一直保留吧， 什么时候删除呢？ 答案是， 在不需要的时候才删除。也就是说， 系统会判断， 当没有事务再需要用到这些回滚日志时， 回滚日志会被删除。</p><p>什么时候才不需要了呢？ 就是当系统里没有比这个回滚日志更早的read-view的时候。</p><p>基于上面的说明， 我们来讨论一下为什么建议你尽量不要使用长事务  </p><p>长事务意味着系统里面会存在很老的事务视图。 由于这些事务随时可能访问数据库里面的任何数据， 所以这个事务提交之前， 数据库里面它可能用到的回滚记录都必须保留， 这就会导致大量占<br>用存储空间。</p><p>在MySQL 5.5及以前的版本， 回滚日志是跟数据字典一起放在ibdata文件里的， 即使长事务最终<br>提交， 回滚段被清理， 文件也不会变小。 我见过数据只有20GB， 而回滚段有200GB的库。 最终<br>只好为了清理回滚段， 重建整个库。</p><h3 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h3><p>如前面所述， 长事务有这些潜在风险， 我当然是建议你尽量避免。 其实很多时候业务开发同学并不是有意使用长事务， 通常是由于误用所致。 MySQL的事务启动方式有以下几种：</p><ul><li>显式启动事务语句， begin 或 start transaction。 配套的提交语句是commit， 回滚语句是<br>rollback。</li><li>set autocommit=0， 这个命令会将这个线程的自动提交关掉。 意味着如果你只执行一个<br>select语句， 这个事务就启动了， 而且并不会自动提交。 这个事务持续存在直到你主动执行commit 或 rollback 语句， 或者断开连接  </li></ul><p>有些客户端连接框架会默认连接成功后先执行一个set autocommit=0的命令。 这就导致接下来的<br>查询都在事务中， 如果是长连接， 就导致了意外的长事务。</p><p>因此， 我会建议你总是使用set autocommit=1, 通过显式语句的方式来启动事务。  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MySQL事务&quot;&gt;&lt;a href=&quot;#MySQL事务&quot; class=&quot;headerlink&quot; title=&quot;MySQL事务&quot;&gt;&lt;/a&gt;MySQL事务&lt;/h1&gt;&lt;p&gt;MySQL事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你既需</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Redis基础</title>
    <link href="https://leslieaibin.github.io/2021/09/01/Redis/Redis%E5%9F%BA%E7%A1%80%EF%BC%881%EF%BC%89/"/>
    <id>https://leslieaibin.github.io/2021/09/01/Redis/Redis%E5%9F%BA%E7%A1%80%EF%BC%881%EF%BC%89/</id>
    <published>2021-09-01T01:15:42.000Z</published>
    <updated>2021-09-01T08:37:09.270Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h2><p>Redis是一个使用C语言写成，凯源的高性能key-value非关系缓存数据库。他支持存储的value类型比较多，包括String(字符串)、list(集合)、set(集合)、zset(sorted-set–有序集合) 和 hash (哈希类型）。Redis都是基于缓存的，所以很快，每秒都可以处理10万读写操作，是一直性能最好的key-value DB。redis也可以实现数据写入磁盘中，保证了数据的安全不丢失，而且redis的操作时原子性的</p><h2 id="Redis-有那些优缺点"><a href="#Redis-有那些优缺点" class="headerlink" title="Redis 有那些优缺点"></a>Redis 有那些优缺点</h2><p>优点：</p><ul><li>读写性能优异，redis能读的速度是110000次/s，写的速度是810000次/s</li><li>支持数据持久化，支持AOF和RDB两种持久化方式</li><li>支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操控台合并的原子执行</li><li>数据结构丰富，除了支持String类型的value 外还支持hash、set、zset、list等数据结构</li><li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离</li></ul><p>缺点：</p><ul><li><p>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</p></li><li><p>Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。</p></li><li><p>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。</p></li><li><p>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。</p></li></ul><h2 id="使用redis-有哪些好处"><a href="#使用redis-有哪些好处" class="headerlink" title="使用redis 有哪些好处"></a>使用redis 有哪些好处</h2><ul><li>速度快，因为数据存在内存中，类似于HashMap，HashMap的优势在于查找和操作的时间复杂度低</li><li>支持丰富数据类型，支持String，list，set，zset， hash</li><li>支持事务，操作都是原子性</li><li>丰富的特性：可用于缓存，消息，按key设置过期时间，过期后自动删除</li></ul><h2 id="为什么要用-Redis-而不用-map-guava-做缓存"><a href="#为什么要用-Redis-而不用-map-guava-做缓存" class="headerlink" title="为什么要用 Redis 而不用 map/guava 做缓存?"></a>为什么要用 Redis 而不用 map/guava 做缓存?</h2><ul><li>缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。</li><li>使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。</li></ul><h2 id="Redis为什么这么快"><a href="#Redis为什么这么快" class="headerlink" title="Redis为什么这么快"></a>Redis为什么这么快</h2><ul><li>完全基于内存，绝大部分请求内存操作，影响速度的内存和网络速度，而非CPU</li><li>数据结构简单：Redis的数据结构是为自身专门量身打造的，而这些数据结构查找和操作的时间复杂度都是O(1)</li><li>避免上下文切换：因为单线程模型，因此就避免了不必要的上下文切换和多线程竞争，这就省去了多线程切换带来的时间和性能上的开销，而且单线程不会导致死锁</li><li>多路复用和非阻塞I/O：Redis 使用 I/O 多路复用功能来监听多个 socket 连接客户端，这样就可以使用一个线程来处理多个情况，从而减少线程切换带来的开销，同时也避免了 I/O 阻塞操作，从而大大地提高了 Redis 的性能</li><li>使用底层模型不同，他们之间底层实现方式以及客户端之间通信的应用协议不一样，Redis直接构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定时间去移动和请求</li></ul><h2 id="Redis有哪些数据类型"><a href="#Redis有哪些数据类型" class="headerlink" title="Redis有哪些数据类型"></a>Redis有哪些数据类型</h2><ul><li>Redis主要有5种数据类型，包括String、List、Set、Zset、Hash满足大部分使用要求</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210901105110111.png" alt="image-20210901105110111"></p><h2 id="Redis的应用场景"><a href="#Redis的应用场景" class="headerlink" title="Redis的应用场景"></a>Redis的应用场景</h2><ul><li><p>计数器</p><p>可以对String 进行自增自减运算，从而实现计数器功能。Redis这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量</p></li><li><p>缓存</p><p>将热点数据放到内存中，设置内存的最大使用两以及淘汰策略来保证缓存的命中率</p></li><li><p>会话缓存</p><p>可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。</p></li><li><p>全页缓存 FPC</p><p>除基本的会话token之外，Redis还提供很简便的FPC平台。以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。</p></li><li><p>查找表</p><p>例如DNS记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。</p></li><li><p>消息队列（发布/订阅功能）</p><p>List是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。</p></li><li><p>分布式锁实现</p><p>在分布式场景下，无法使用单机环境下的锁来多个节点上的进程进行同步。可以使用Redis自带的SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。</p></li><li><p>其他</p><p>Set 可以实现交集，并集等操作，从而实现共同好友等功能。ZSet 可以实现有序性操作，从而实现排行榜等功能。</p></li></ul><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><ul><li>什么是Redis 持久化 持久化就是把内存的数据写到磁盘中区，防止服务器宕机了内存数据丢失</li></ul><h2 id="Redis-的持久化机制是什么？-各自的优缺点？"><a href="#Redis-的持久化机制是什么？-各自的优缺点？" class="headerlink" title="Redis 的持久化机制是什么？ 各自的优缺点？"></a>Redis 的持久化机制是什么？ 各自的优缺点？</h2><ul><li>Redis 提供两种持久话机制RDB(默认) 和 AOF 机制：</li></ul><p><strong>RDB：是Redis DataBase缩写快照</strong></p><ul><li>RDB是Redis默认的持久化方式，按照一定时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件dumb.rdb。通过配置文件中的save参数来定义快照的周期</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1717449419419e78~tplv-t2oaga2asx-watermark.awebp" alt="在这里插入图片描述"></p><p>优点：</p><ul><li>只有一个文件dumb.rdb，方便持久化</li><li>容灾性好，一个文件可以保存到安全的磁盘</li><li>性能最大化，fork子进程来完成写操作，让主进程继续处理命令，所以是IO最大化，使用单子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能</li><li>相对于数据集大时，比AOF的启动效率更高</li></ul><p>缺点：</p><ul><li>数据安全性低，RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失，所以这种方式更是华数据要求不严谨的时候</li><li>AOF（Append-only file)持久化方式： 是指所有的命令行记录以 redis 命令请 求协议的格式完全持久化存储)保存为 aof 文件。</li></ul><p><strong>AOF：持久化</strong></p><ul><li>AOF持久化（即Append Only File 持久化）， 则是将Redis 执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志文件恢复数据</li><li>当两种方式同时开启，数据恢复Redis会有限选择AOF恢复</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/171744941b1f2a80~tplv-t2oaga2asx-watermark.awebp" alt="在这里插入图片描述"></p><p>优点：</p><ul><li>数据安全，aof持久化可以配置appendfsync属性，有always，每进行一次命令操作就记录在aof文件中一次</li><li>通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。</li><li>AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)</li></ul><p>缺点：</p><ul><li>AOF文件比RDB文件大，且恢复速度慢</li><li>数据集大的时候，比RDB启动效率低</li></ul><p>两种持久化的优缺点是什么</p><ul><li>AOF文件比RDB更新频率高，优先使用AOF还原数据</li><li>AOF比RDB更安全也更大</li><li>RDB性能比AOF好</li><li>如果两个都配了有限加载AOF</li></ul><h2 id="如果选择合适的持久化方式"><a href="#如果选择合适的持久化方式" class="headerlink" title="如果选择合适的持久化方式"></a>如果选择合适的持久化方式</h2><ul><li><p>一般来说，如果想达到足以媲美PostgreSQL的安全性，你应该同时使用两种持久化功能，在这种情况下，当Redis重启的时候回有限载入AOF文件来恢复原始数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据要完整</p></li><li><p>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。</p></li><li><p>有很多用户都只使用AOF持久化，但并不推荐这种方式，因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免AOF程序的bug。</p></li><li><p>如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。</p></li></ul><h2 id="Redis持久化数据和缓存怎么做扩容？"><a href="#Redis持久化数据和缓存怎么做扩容？" class="headerlink" title="Redis持久化数据和缓存怎么做扩容？"></a>Redis持久化数据和缓存怎么做扩容？</h2><ul><li>如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。</li><li>如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。</li></ul><h2 id="Redis的过期键的删除策略"><a href="#Redis的过期键的删除策略" class="headerlink" title="Redis的过期键的删除策略"></a>Redis的过期键的删除策略</h2><p>Redis是Key - value数据库，我们可以设置Redis中缓存的key的过期时间，Redis的过期缓存策略就是指当 Redis 中缓存的key过期了，Redis如何处理，通常有三种：</p><ul><li><p>定时过期：每个 设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据对内存很友好，但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的相同和吞吐量</p></li><li><p>惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。</p></li><li><p>定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。 (expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)</p></li></ul><p>  Redis中同时使用了惰性过期和定期过期两种过期策略。</p><h2 id="Redis-key的过期时间和永久有效分别怎么设置？"><a href="#Redis-key的过期时间和永久有效分别怎么设置？" class="headerlink" title="Redis key的过期时间和永久有效分别怎么设置？"></a>Redis key的过期时间和永久有效分别怎么设置？</h2><ul><li>expire和persist命令。</li></ul><h2 id="我们知道通过expire来设置key-的过期时间，那么对过期的数据怎么处理呢"><a href="#我们知道通过expire来设置key-的过期时间，那么对过期的数据怎么处理呢" class="headerlink" title="我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?"></a>我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?</h2><ul><li>除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：<ul><li>定时去清理过期的缓存；</li><li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。</li></ul></li></ul><p>两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。</p><h2 id="MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据"><a href="#MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据" class="headerlink" title="MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据"></a>MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据</h2><ul><li>redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</li></ul><h2 id="Redis的内存淘汰策略有哪些"><a href="#Redis的内存淘汰策略有哪些" class="headerlink" title="Redis的内存淘汰策略有哪些"></a>Redis的内存淘汰策略有哪些</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。</span><br></pre></td></tr></table></figure><ul><li>全局的键空间选择性移除<ul><li>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。</li><li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的）</li><li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</li></ul></li><li>设置过期时间的键空间选择性移除<ul><li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。</li><li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。</li><li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</li></ul></li><li>总结</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据；过期策略用于处理过期的缓存数据。</span><br></pre></td></tr></table></figure><h2 id="Redis主要消耗什么物理资源？"><a href="#Redis主要消耗什么物理资源？" class="headerlink" title="Redis主要消耗什么物理资源？"></a>Redis主要消耗什么物理资源？</h2><ul><li>内存。</li></ul><h2 id="Redis的内存用完了会发生什么？"><a href="#Redis的内存用完了会发生什么？" class="headerlink" title="Redis的内存用完了会发生什么？"></a>Redis的内存用完了会发生什么？</h2><ul><li>如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。</li></ul><h2 id="Redis如何做内存优化？"><a href="#Redis如何做内存优化？" class="headerlink" title="Redis如何做内存优化？"></a>Redis如何做内存优化？</h2><ul><li>可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面</li></ul><h1 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h1><ul><li>Redis基于Reactor模式开发了网络事件处理器，这个事件处理器称为文件事件处理器（file event handler)。它的组成结构分为四部分：多个套接字，IO多路复用程序，文件事件分派器，时间处理器。因为文件分派器队列的消费是单线程的，所以Redis是单线程模型</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210901152454724.png" alt="image-20210901152454724"></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210901152509838.png" alt="image-20210901152509838"></p><ul><li>文件事件处理器使用IO多路复用程序同时监听套接字，并根据套接字目前执行的任务为套接字关联不同的时间处理器。</li><li>当被监听的套接字准备好执行连接应答（accept），读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事假处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</li></ul><p>虽然文件事件处理器以单线程方式运行，但通过使用IO多路复用程序来监听多个套接字，文件事件处理器实现了高性能的网络通信模型，又可以很好地与redis服务器中其他 以单线程方式运行的模块进行对接，保持了redis内部单线程设计的简单性</p><p>时间事件：时间事件记录着那些在指定时间点运行的事件，多个时间事件以无序链表结构保存在服务器状态中。服务器需要定期对自身的资源和状态进行检查、整理， 保证服务器维持在一个健康稳定状态， 这类操作被统称为常规操作（cron job）。在 Redis 中， 常规操作由 redis.c/serverCron 实现，包括如下操作： - 更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等 - 清理数据库中的过期键值对 - 对不合理的数据库进行大小调整 - 关闭和清理连接失效的客户端 - 尝试进行 AOF 或RDB 持久化操作 - 如果服务器是主节点的话，对附属节点进行定期同步 - 如果处于集群模式的话，对集群进行定期同步和连接测试。Redis 将 serverCron（后文简称为sC） 作为时间事件运行， 确保它能够定期自动运行一次，又因 sC 需要在 Redis 服务器运行期一直定期运行， 所以它是一个循环时间事件：sC 会一直定期执行，直至服务器关闭。  </p><p>两种事件的调度：简单地说， Redis 里面的两种事件呈协作关系， 它们之间包含如下属性： - 一种事件会等待另一种事件执行完后，才开始执行，事件之间不会出现抢占 - 事件处理器先处理文件事件（即处理命令请求），再执行时间事件（调用 sC） - 文件事件的等待时间（类 poll 函数的最大阻塞时间），由距离到达时间最短的时间事件决定。这表明， 实际处理时间事件的时间， 通常会比事件所预定的时间要晚， 延迟时间取决于时间事件执行前， 执行完成文件事件所耗时间。  </p><h1 id="Redis事务"><a href="#Redis事务" class="headerlink" title="Redis事务"></a>Redis事务</h1><ul><li>事务是一个单独的隔离操作：事务中所有命令都会序列化、按顺序执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断</li><li>事务是一个原子操作：事务中的命令要么全部被执行，要门全部都不执行</li></ul><h2 id="Redis事务的概念"><a href="#Redis事务的概念" class="headerlink" title="Redis事务的概念"></a>Redis事务的概念</h2><ul><li>Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</li><li>总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。</li></ul><h2 id="Redis事务的三个阶段"><a href="#Redis事务的三个阶段" class="headerlink" title="Redis事务的三个阶段"></a>Redis事务的三个阶段</h2><ul><li>事务开始MULTI</li><li>命令入队</li><li>事务执行EXEC</li></ul><p>事务执行过程中，如果服务端收到EXEC、DISCARD、WATCH、MULTI之外的请求，将会请求放入队列排队</p><h2 id="Redis事务相关命令"><a href="#Redis事务相关命令" class="headerlink" title="Redis事务相关命令"></a>Redis事务相关命令</h2><p>Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的</p><p>Redis会将一个事务中的所有命令序列化，然后按顺序执行。</p><ol><li><strong>redis 不支持回滚</strong>，“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。</li><li><strong>如果在一个事务中的命令出现错误，那么所有的命令都不会执行</strong>；</li><li><strong>如果在一个事务中出现运行错误，那么正确的命令会被执行</strong>。</li></ol><ul><li>WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。</li><li>MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。</li><li>EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。</li><li>通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。</li><li>UNWATCH命令可以取消watch对所有key的监控。</li></ul><h2 id="事务管理（ACID）-概述"><a href="#事务管理（ACID）-概述" class="headerlink" title="事务管理（ACID） 概述"></a>事务管理（ACID） 概述</h2><ul><li><p>原子性（Atomicity）</p><p>原子性是指事务是一个不可分割的工作，要么事务中的操作都发生，要么都不发生</p></li><li><p>一致性（Consistency)</p><p>事务前后数据的完整性必须保持一致</p></li><li><p>隔离性（lsolation）</p><p>多个事务并发执行时，一个事务不影响其他事务的执行</p></li><li><p>持久性（Durability）</p><p>持久性是一个事务一旦被提交的，他对数据库中的数据的改变是永久的，接下来即使数据库发生故障也不应该对其有任何影响</p></li></ul><p>Redis的事务总是具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在_AOF_持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性</p><h2 id="Redis事务支持隔离性吗"><a href="#Redis事务支持隔离性吗" class="headerlink" title="Redis事务支持隔离性吗"></a>Redis事务支持隔离性吗</h2><ul><li>Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，<strong>Redis 的事务是总是带有隔离性的</strong>。</li></ul><h2 id="Redis事务保证原子性吗，支持回滚吗"><a href="#Redis事务保证原子性吗，支持回滚吗" class="headerlink" title="Redis事务保证原子性吗，支持回滚吗"></a>Redis事务保证原子性吗，支持回滚吗</h2><ul><li>Redis中，单条命令是原子性执行的，但<strong>事务不保证原子性，且没有回滚</strong>。事务中任意命令执行失败，其余的命令仍会被执行。</li></ul><h2 id="Redis事务其他实现"><a href="#Redis事务其他实现" class="headerlink" title="Redis事务其他实现"></a>Redis事务其他实现</h2><ul><li>基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，<br> 其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完</li><li>基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;h2 id=&quot;什么是Redis&quot;&gt;&lt;a href=&quot;#什么是Redis&quot; class=&quot;headerlink&quot; title=&quot;什么是Redis&quot;</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>java异常</title>
    <link href="https://leslieaibin.github.io/2021/08/30/java%E5%9F%BA%E7%A1%80/java%E5%BC%82%E5%B8%B8%E4%BD%93%E7%B3%BB/"/>
    <id>https://leslieaibin.github.io/2021/08/30/java%E5%9F%BA%E7%A1%80/java%E5%BC%82%E5%B8%B8%E4%BD%93%E7%B3%BB/</id>
    <published>2021-08-30T01:15:42.000Z</published>
    <updated>2021-08-30T12:38:40.708Z</updated>
    
    <content type="html"><![CDATA[<p>java把异常作为一类，当做对象来处理。所有异常类的基类是Throwable类，两大子类分别是Error  和 Exception。</p><p>系统错误由Java虚拟机抛出，用Error类表示，Error类描述的是内部系统错误，例如Java虚拟机崩溃。这种情况仅凭程序自身是无法处理的，在程序中也不会对Error异常进行捕捉和抛出。</p><p>异常（Exception）又分为RuntimeException（运行时异常）和 CheckedException（检查时异常），两者区别如下：</p><ul><li>RuntimeException：程序运行过程中才可能发生的异常，一般为代码的逻辑异常，例如：类型错误，数组越界，空指针异常等</li><li>CheckedException：编译期间可以检查到的异常，必须显示的进行处理（捕获或者抛出到上一层）。例如：IOException, FileNotFoundException等等。</li></ul><h2 id="java异常体系结构图"><a href="#java异常体系结构图" class="headerlink" title="java异常体系结构图"></a>java异常体系结构图</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1294391-20180919152605174-2400592.png" alt="img"></p><p>首先说明一点，java中的Exception类的子类不仅仅只是像上图所示只包含IOException和RuntimeException这两大类，事实上Exception的子类很多很多，主要可概括为：运行时异常与非运行时异常。</p><p>Thorwable类（表示可抛出）是所有异常和错误的超类，两个直接子类为Error和Exception，分别表示错误和异常。其中异常类Exception又分为运行时异常(RuntimeException)和非运行时异常， 这两种异常有很大的区别，也称之为不检查异常（Unchecked Exception）和检查异常（Checked Exception）。下面将详细讲述这些异常之间的区别与联系：</p><p>1、Error与Exception</p><p>Error是程序无法处理的错误，它是由JVM产生和抛出的，比如OutOfMemoryError、ThreadDeath等。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。 Exception是程序本身可以处理的异常，这种异常分两大类运行时异常和非运行时异常。程序中应当尽可能去处理这些异常。</p><p>2、运行时异常和非运行时异常</p><p> 运行时异常都是RuntimeException类及其子类异常，如NullPointerException、IndexOutOfBoundsException等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。非运行时异常是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。</p><h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><p><strong>常用关键字：try、catch、throw（抛出一个异常，动词）、throws（声明一个方法可能抛出的异常）、finally。</strong></p><h3 id="throws-声明异常"><a href="#throws-声明异常" class="headerlink" title="throws(声明异常)"></a>throws(声明异常)</h3><p>若方法中存在检查时异常，如果不对其捕获，那必须在方法头中显式声明该异常，以便于告知方法调用者此方法有异常，需要进行处理。 </p><p>在方法中声明一个异常，方法头中使用关键字throws，后面接上要声明的异常。若声明多个异常，则使用逗号分割。</p><p>若是父类的方法没有声明异常，则子类继承方法后，也不能声明异常。</p><h2 id="try-catch-捕获异常"><a href="#try-catch-捕获异常" class="headerlink" title="try-catch(捕获异常)"></a>try-catch(捕获异常)</h2><p>若执行try块的过程中没有发生异常，则跳过catch子句。若是出现异常，try块中剩余语句不再执行。开始逐步检查catch块，判断catch块的异常类实例是否是捕获的异常类型。匹配后执行相应的catch块中的代码。如果异常没有在当前的方法中被捕获，就会被传递给该方法的调用者。这个过程一直重复，直到异常被捕获或被传给main方法（交给JVM来捕获）。</p><p>对于try..catch捕获异常的形式来说，对于异常的捕获，可以有多个catch。对于try里面发生的异常，他会根据发生的异常和catch里面的进行匹配(按照catch块从上往下匹配)，如果有匹配的catch，它就会忽略掉这个catch后面所有的catch。</p><p>如果有finally的话进入到finally里面继续执行。</p><p>try ctach fianally 中有return 时，会先执行return ，但是不会返回。在执行完 finally 后 进行返回。</p><p>return 的是基本类型数据时， fianlly 里面的语句不会影响 return 的值，</p><p>return 的是引用类型数据时，此时已经确定了要返回对象的地址（地址一），后面 fianlly 里面的可以通过修改前面地址一中的内容修改返回的内容，</p><p>但是如果将对象指向另一个地址（地址二），则不会影响返回的内容。因为返回的对象地址已经确定为地址一，只能通过修改地址一对象的内容修改返回的信息。 </p><h2 id="try、catch、finally三个语句块应注意的问题"><a href="#try、catch、finally三个语句块应注意的问题" class="headerlink" title="try、catch、finally三个语句块应注意的问题"></a>try、catch、finally三个语句块应注意的问题</h2><ul><li>try、catch、finally三个语句块均不能单独使用，三者可以组成 try…catch…finally、try…catch、try…finally三种结构，catch语句可以有一个或多个，finally语句最多一个。</li><li>try、catch、finally三个代码块中变量的作用域为代码块内部，分别独立而不能相互访问。如果要在三个块中都可以访问，则需要将变量定义到这些块的外面。</li><li>多个catch块时候，最多只会匹配其中一个异常类且只会执行该catch块代码，而不会再执行其它的catch块，且匹配catch语句的顺序为从上到下，也可能所有的catch都没执行。</li><li>先Catch子类异常再Catch父类异常。</li></ul><h2 id="throw、throws关键字"><a href="#throw、throws关键字" class="headerlink" title="throw、throws关键字"></a>throw、throws关键字</h2><p>  throw关键字是用于方法体内部，用来抛出一个Throwable类型的异常。如果抛出了检查异常，则还应该在方法头部声明方法可能抛出的异常类型。该方法的调用者也必须检查处理抛出的异常。如果所有方法都层层上抛获取的异常，最终JVM会进行处理，处理也很简单，就是打印异常消息和堆栈信息。throw关键字用法如下： </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> <span class="keyword">throws</span> Exception  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">   <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">&quot;方法test中的Exception&quot;</span>);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>  throws关键字用于方法体外部的方法声明部分，用来声明方法可能会抛出某些异常。仅当抛出了检查异常，该方法的调用者才必须处理或者重新抛出该异常。当方法的调用者无力处理该异常的时候，应该继续抛出.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;java把异常作为一类，当做对象来处理。所有异常类的基类是Throwable类，两大子类分别是Error  和 Exception。&lt;/p&gt;
&lt;p&gt;系统错误由Java虚拟机抛出，用Error类表示，Error类描述的是内部系统错误，例如Java虚拟机崩溃。这种情况仅凭程序自</summary>
      
    
    
    
    <category term="计算机基础知识" scheme="https://leslieaibin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
  </entry>
  
  <entry>
    <title>17.锁升级和锁状态</title>
    <link href="https://leslieaibin.github.io/2021/08/30/JVM/17.%E9%94%81%E5%8D%87%E7%BA%A7%E5%92%8C%E9%94%81%E7%8A%B6%E6%80%81/"/>
    <id>https://leslieaibin.github.io/2021/08/30/JVM/17.%E9%94%81%E5%8D%87%E7%BA%A7%E5%92%8C%E9%94%81%E7%8A%B6%E6%80%81/</id>
    <published>2021-08-30T01:15:42.000Z</published>
    <updated>2021-08-30T12:38:16.016Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>锁的状态总共有四种，级别由低到高依次为：无锁、偏向锁、轻量级锁、重量级锁，这四种锁状态分别代表什么，为什么会有锁升级。在JDK1.6之前，synchronized还是一个重量级锁，是一个效率比较低下的锁，但在JDK1.6后，JVM为了提高锁的获取与释放效率(sychronized) 进行了优化，引入了偏向锁和轻量级锁，从此以后锁的状态就有四种（无锁， 偏向锁， 轻量级锁，重量级锁），并且四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级，也就是说只能进行锁升级（从低级别到高级别），不能锁降级（高级别到低级别），意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</p><h1 id="锁的四种状态"><a href="#锁的四种状态" class="headerlink" title="锁的四种状态"></a>锁的四种状态</h1><p>在synchronized最初的实现方式是“阻塞或唤醒一个Java线程需要操作系统切换cpu状态来完成，这种状态切换需要耗费处理器时间，如果同步代码块中内容过于简单，这种切换的时间可能比用户代码执行的时间还长”，这种方式就是synchronized实现同步最初的方式，这也是当初开发者诟病的地方，这也是在JDK6以前 synchronized效率低下的原因，JDK6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。</p><p>所以目前锁状态一种有四种，从级别由低到高依次是：无锁、偏向锁，轻量级锁，重量级锁，锁状态只能升级，不能降级</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904666" alt="img"></p><h1 id="锁状态的思路以及特点"><a href="#锁状态的思路以及特点" class="headerlink" title="锁状态的思路以及特点"></a>锁状态的思路以及特点</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904667" alt="img"></p><h1 id="锁对比"><a href="#锁对比" class="headerlink" title="锁对比"></a>锁对比</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904669" alt="img"></p><h1 id="Synchronized锁"><a href="#Synchronized锁" class="headerlink" title="Synchronized锁"></a>Synchronized锁</h1><p>synchronized用的锁是存在Java对象头里的，那么什么是对象头</p><h2 id="Java对象头"><a href="#Java对象头" class="headerlink" title="Java对象头"></a>Java对象头</h2><p>我们以Hotspot虚拟机为例，Hopspot 对象头主要包括两部分数据：Mark Word（标记字段） 和 Klass Pointer（类型指针）</p><p>Mark Word：默认存储对象的hashcode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。</p><p>Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。</p><p>在上面中我们知道了，synchronized 用的锁是存在Java对象头里的，那么具体是存在对象头哪里呢？答案是：存在锁对象的对象头的Mark Word中，那么MarkWord在对象头中到底长什么样，它到底存储了什么呢？</p><p>在64位的虚拟机中：<img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904668" alt="img"></p><p>在32位的虚拟机中：<img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904670" alt="img"></p><p><strong>无锁 ：</strong>对象头开辟 25bit 的空间用来存储对象的 hashcode ，4bit 用于存放对象分代年龄，1bit 用来存放是否偏向锁的标识位，2bit 用来存放锁标识位为01</p><p><strong>偏向锁：</strong> 在偏向锁中划分更细，还是开辟 25bit 的空间，其中23bit 用来存放线程ID，2bit 用来存放 Epoch，4bit 存放对象分代年龄，1bit 存放是否偏向锁标识， 0表示无锁，1表示偏向锁，锁的标识位还是01</p><p><strong>轻量级锁：</strong>在轻量级锁中直接开辟 30bit 的空间存放指向栈中锁记录的指针，2bit 存放锁的标志位，其标志位为00</p><p><strong>重量级锁：</strong> 在重量级锁中和轻量级锁一样，30bit 的空间用来存放指向重量级锁的指针，2bit 存放锁的标识位，为11</p><p>GC标记： 开辟30bit 的内存空间却没有占用，2bit 空间存放锁标志位为11。</p><p>其中无锁和偏向锁的锁标志位都是01，只是在前面的1bit区分了这是无锁状态还是偏向锁状态</p><p>关于内存的分配，我们可以在git中openJDK中 markOop.hpp 可以看出：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// Constants</span></span><br><span class="line">  <span class="class"><span class="keyword">enum</span> </span>&#123; age_bits                 = <span class="number">4</span>,</span><br><span class="line">         lock_bits                = <span class="number">2</span>,</span><br><span class="line">         biased_lock_bits         = <span class="number">1</span>,</span><br><span class="line">         max_hash_bits            = BitsPerWord - age_bits - lock_bits - biased_lock_bits,</span><br><span class="line">         hash_bits                = max_hash_bits &gt; <span class="number">31</span> ? <span class="number">31</span> : max_hash_bits,</span><br><span class="line">         cms_bits                 = LP64_ONLY(<span class="number">1</span>) NOT_LP64(<span class="number">0</span>),</span><br><span class="line">         epoch_bits               = <span class="number">2</span></span><br><span class="line">  &#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>age_bits： 就是我们说的分代回收的标识，占用4字节</p><p>lock_bits： 是锁的标志位，占用2个字节</p><p>biased_lock_bits： 是是否偏向锁的标识，占用1个字节</p><p>max_hash_bits： 是针对无锁计算的hashcode 占用字节数量，如果是32位虚拟机，就是 32 - 4 - 2 </p><p>-1 = 25 byte，如果是64 位虚拟机，64 - 4 - 2 - 1 = 57 byte，但是会有 25 字节未使用，所以64位的 </p><p>hashcode 占用 31 byte</p><p>hash_bits： 是针对 64 位虚拟机来说，如果最大字节数大于 31，则取31，否则取真实的字节数</p><p>cms_bits： 不是64位虚拟机就占用 0 byte，是64位就占用 1byte</p><p>epoch_bits： 就是 epoch 所占用的字节大小，2字节。</p><h2 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h2><p>Monitor 可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个 Java 对象就有一把看不见的锁，称为内部锁或者 Monitor 锁。</p><p>Monitor 是线程私有的数据结构，每一个线程都有一个可用 monitor record 列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个 monitor 关联，同时 monitor 中有一个 Owner 字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。</p><p>Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的，监视器锁本质又是依赖于底层的操作系统的 Mutex Lock（互斥锁）来实现的。而操作系统实现线程之间的切换需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么 Synchronized 效率低的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为重量级锁。</p><p>随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级）。JDK 1.6中默认是开启偏向锁和轻量级锁的，我们也可以通过-XX:-UseBiasedLocking=false来禁用偏向锁。</p><h1 id="锁的分类"><a href="#锁的分类" class="headerlink" title="锁的分类"></a>锁的分类</h1><h2 id="无锁"><a href="#无锁" class="headerlink" title="无锁"></a>无锁</h2><p>无锁是指没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。</p><p>无锁的特点是修改操作会在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。</p><h2 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h2><p>初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），字面意思是“偏向于第一个获得它的线程”的锁。执行完同步代码块后，线程并不会主动释放偏向锁。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。</p><p>偏向锁是指当一段同步代码一直被同一个线程所访问时，即不存在多个线程的竞争时，那么该线程在后续访问时便会自动获得锁，从而降低获取锁带来的消耗，即提高性能。</p><p>当一个线程访问同步代码块并获取锁时，会在 Mark Word 里存储锁偏向的线程 ID。在线程进入和退出同步块时不再通过 CAS 操作来加锁和解锁，而是检测 Mark Word 里是否存储着指向当前线程的偏向锁。轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 ThreadID 的时候依赖一次 CAS 原子指令即可。</p><p>偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程是不会主动释放偏向锁的。</p><p>关于偏向锁的撤销，需要等待全局安全点，即在某个时间点上没有字节码正在执行时，它会先暂停拥有偏向锁的线程，然后判断锁对象是否处于被锁定状态。如果线程不处于活动状态，则将对象头设置成无锁状态，并撤销偏向锁，恢复到无锁（标志位为01）或轻量级锁（标志位为00）的状态。</p><h2 id="轻量级锁（自旋锁）"><a href="#轻量级锁（自旋锁）" class="headerlink" title="轻量级锁（自旋锁）"></a>轻量级锁（自旋锁）</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904671" alt="img"></p><p>轻量级锁是指当锁是偏向锁的时候，却被另外的线程所访问，此时偏向锁就会升级为轻量级锁，其他线程会通过自旋（关于自旋的介绍见文末）的形式尝试获取锁，线程不会阻塞，从而提高性能。</p><p>轻量级锁的获取主要由两种情况：</p><p>① 当关闭偏向锁功能时；</p><p>② 由于多个线程竞争偏向锁导致偏向锁升级为轻量级锁。</p><p>一旦有第二个线程加入锁竞争，偏向锁就升级为轻量级锁（自旋锁）。这里要明确一下什么是锁竞争：如果多个线程轮流获取一个锁，但是每次获取锁的时候都很顺利，没有发生阻塞，那么就不存在锁竞争。只有当某线程尝试获取锁的时候，发现该锁已经被占用，只能等待其释放，这才发生了锁竞争。</p><p>在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。</p><p>长时间的自旋操作是非常消耗资源的，一个线程持有锁，其他线程就只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做忙等（busy-waiting）。如果多个线程用一个锁，但是没有发生锁竞争，或者发生了很轻微的锁竞争，那么synchronized就用轻量级锁，允许短时间的忙等现象。这是一种折衷的想法，短时间的忙等，换取线程在用户态和内核态之间切换的开销。</p><h2 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h2><p>重量级锁显然，此忙等是有限度的（有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁（依然是CAS修改锁标志位，但不修改持有锁的线程ID）。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起（而不是忙等），等待将来被唤醒。</p><p>重量级锁是指当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态。</p><p>简言之，就是所有的控制权都交给了操作系统，由操作系统来负责线程间的调度和线程的状态变更。而这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，从而消耗大量的系统资源</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;锁的状态总共有四种，级别由低到高依次为：无锁、偏向锁、轻量级锁、重量级锁，这四种锁状态分别代表什么，为什么会有锁升级。在JDK1.6之前，s</summary>
      
    
    
    
    <category term="JVM" scheme="https://leslieaibin.github.io/categories/JVM/"/>
    
    
    <category term="JVM" scheme="https://leslieaibin.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>平衡二叉树、B 树、B+树</title>
    <link href="https://leslieaibin.github.io/2021/08/29/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%81B%20%E6%A0%91%E3%80%81B+%E6%A0%91/"/>
    <id>https://leslieaibin.github.io/2021/08/29/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%81B%20%E6%A0%91%E3%80%81B+%E6%A0%91/</id>
    <published>2021-08-29T01:15:42.000Z</published>
    <updated>2021-08-29T13:40:53.923Z</updated>
    
    <content type="html"><![CDATA[<h1 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h1><p>平衡二叉树是基于二分法的策略提高数据的查找速度的二叉树的数据结构</p><p><strong>特点：</strong></p><p>平衡二叉树是采用二分法思维把数据按规则组装成一个树型结构的数据，用这个树形结构的数据减少无关数据的检索，大大的提升了数据检索的速度；平衡二叉树的数据结构组装过程有以下规则：</p><ul><li>非叶子节点只能允许最多两个子节点存在</li><li>每一个非叶子检点数据分布规则按照左边的子节点小于当前节点的值，右边的子节点大于当前节点的值（这里的值是基于自己的算法规则而定的，比如hash值）</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-28e39093993f673de576f57ea614d604_720w.jpg" alt="img"></p><p>平衡树的层级结构：因为平衡二叉树查询性能和树的层级（h高度）成反比，h值越小查询越快、为了保证树的结构左右两端数据大致平衡降低二叉树的查询难度一般会采用一种算法机制实现节点数据结构的平衡，实现了这种算法的有比如Treap、红黑树，使用平衡二叉树能保证数据的左右两边的节点层级相差不会大于1.，通过这样避免树形结构由于删除增加变成线性链表影响查询效率，保证数据平衡的情况下查找数据的速度近于二分法查找；</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2b52d4e523f374f41b5429cd587443db_720w.jpg" alt="img"></p><p>总结平衡二叉树特点：</p><ul><li>非叶子节点最多拥有两个子节点</li><li>非叶子节点大于左边子节点，小于右边子节点</li><li>树的左右两边的层级数相差不会大于1</li><li>没有值相等重复的节点</li></ul><h1 id="B树（BTree"><a href="#B树（BTree" class="headerlink" title="B树（BTree)"></a>B树（BTree)</h1><p>B树和平衡二叉树稍有不同的是B树属于多叉树有名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用B树 和 B+树。</p><p><strong>规则：</strong></p><ul><li>排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则；</li><li>子节点数：非叶节点的子节点数&gt;1，且&lt;=M，且 M&gt;=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）；</li><li>关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2);</li><li>所有叶子节点均在同一层，叶子节点除了除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子;</li></ul><p>最后我们用一个图和一个实例的例子理解：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2c2264cc1c6c603dfeca4f84a2575901_720w.jpg" alt="img"></p><ul><li><p><strong>B树的查询流程：</strong></p><p>如上图我要从上图中找到E字母，查找流程如下：</p><ul><li>获取根节点的关键字比较，当前根节点关键字为M，E &lt; M(26个字母顺序)，所以找到指向左边的子节点(二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点);</li><li>拿到关键字D和G，D&lt;E&lt;G 所以直接找到D和G中间的节点；</li><li>拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null）；</li></ul></li><li><p>B<strong>树的插入节点流程</strong></p><p>定义一个5阶树（平衡5路查找树;），现在我们要把3、8、31、11、23、29、50、28 这些数字构建出一个5阶树出来;</p><p>遵循规则：</p><p>（1）节点拆分规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须&lt;=5-1（这里关键字数&gt;4就要进行节点拆分）；</p><p>（2）排序规则：满足节点本身比左边节点大，比右边节点小的排序规则;</p></li></ul><p>  先插入 3、8、31、11</p><p>  <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-e1d65c9c6236d4768c89e8e103e12583_720w.jpg" alt="img"></p><p>  再插入23、29</p><p>  <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-66cdb6187cbc5227fd8c4aabe7282e6c_720w.jpg" alt="img"></p><p>  再插入50、28</p><p>  <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-3057eaab2b1764dd51c2a8658791cc98_720w.jpg" alt="img"></p><ul><li><strong>B树节点的删除</strong></li></ul><p>  <strong>规则：</strong></p><p>  （1）节点合并规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须大于等于ceil（5/2）（这里关键字数&lt;2就要进行节点合并）；</p><p>  （2）满足节点本身比左边节点大，比右边节点小的排序规则;</p><p>  （3）关键字数小于二时先从子节点取，子节点没有符合条件时就向向父节点取，取中间值往父节点放；</p><p>  <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-a0f981fc847772cb28869927cd4fe66d_720w.jpg" alt="img"></p><p>  <strong>特点：</strong></p><p>  B树相对于平衡二叉树的不同是，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度;</p><h1 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h1><p>B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。为什么说B+树查找的效率要比B树更高、更稳定；</p><p><strong>规则：</strong></p><ul><li>B+ 树跟 B树不同 B树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加，</li><li>B+树<strong>叶子</strong>节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样；</li><li>B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。</li><li>非叶子节点的子节点数=关键字数（来源百度百科）（根据各种资料 这里有两种算法的实现方式，另一种为非叶节点的关键字数=子节点数-1（来源维基百科)，虽然他们数据排列结构不一样，但其原理还是一样的Mysql 的B+树是用第一种方式实现）;</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-5f069fd820637db1b877fdd6799a2b67_720w.jpg" alt="img"></p><p><strong>（百度百科算法结构示意图）</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-9644d1a1f83d3e45da779f2e63c35d55_720w.jpg" alt="img"></p><p><strong>（维基百科算法结构示意图）</strong></p><p><strong>特点：</strong></p><ul><li><strong>B+ 树的层级更少：</strong>相较于B树  B+ 树每个非叶子节点存储的关键字更多，树的层级更少所以查询数据更快</li><li><strong>B+ 树查询速度更稳定：</strong>B+ 所有的关键字数据地址都存在叶子节点上，所以每次查找的次数都相等所以查询速度要比B树更稳定</li><li><strong>B+ 树天然具备排序功能：</strong>B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高</li><li>B+<strong>树全节点遍历更快：</strong>B+树遍历整棵树只需要遍历所有的<strong>叶子</strong>节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描</li></ul><p><strong>B树</strong>相对于<strong>B+树</strong>的优点是，如果经常访问的数据离根节点很近，而<strong>B树</strong>的<strong>非叶子</strong>节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比<strong>B+树</strong>快。</p><h1 id="B-树-1"><a href="#B-树-1" class="headerlink" title="B*树"></a>B*树</h1><p>B*树是B+树的变种，相对于B+树他们的不同之处如下：</p><p>（1）首先是关键字个数限制问题，B+树初始化的关键字初始化个数是cei(m/2)，b* 树的初始化个数为（cei(2/3*m)）</p><p>（2）B+树节点满时就会分裂，而B*树节点满时会检查兄弟节点是否满（因为每个节点都有指向兄弟的指针），如果兄弟节点未满则向兄弟节点转移关键字，如果兄弟节点已满，则从当前节点和兄弟节点各拿出1/3的数据创建一个新的节点出来；</p><ul><li><strong>特点</strong></li></ul><p>在B+树的基础上因其初始化的容量变大，使得节点空间使用率更高，而又存有兄弟节点的指针，可以向兄弟节点转移关键字的特性使得B*树额分解次数变得更少；</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-e8bf8ee3230f3d39d59ce5e76a2ee32e_720w.jpg" alt="img"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><strong>相同思想和策略</strong></p><p>从平衡二叉树、B树、B+树、B*树总体来看它们的贯彻的思想是相同的，都是采用二分法和数据平衡策略来提升查找数据的速度；</p><p><strong>不同的方式的磁盘空间利用</strong></p><p>不同点是他们一个一个在演变的过程中通过IO从磁盘读取数据的原理进行一步步的演变，每一次演变都是为了让节点的空间更合理的运用起来，从而使树的层级减少达到快速查找数据的目的；</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;平衡二叉树&quot;&gt;&lt;a href=&quot;#平衡二叉树&quot; class=&quot;headerlink&quot; title=&quot;平衡二叉树&quot;&gt;&lt;/a&gt;平衡二叉树&lt;/h1&gt;&lt;p&gt;平衡二叉树是基于二分法的策略提高数据的查找速度的二叉树的数据结构&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;/stron</summary>
      
    
    
    
    <category term="数据结构" scheme="https://leslieaibin.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="树" scheme="https://leslieaibin.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/"/>
    
    
    <category term="二叉树" scheme="https://leslieaibin.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>如何保证消息队列的可靠性传输</title>
    <link href="https://leslieaibin.github.io/2021/08/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BC%A0%E8%BE%93/"/>
    <id>https://leslieaibin.github.io/2021/08/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BC%A0%E8%BE%93/</id>
    <published>2021-08-26T01:15:42.000Z</published>
    <updated>2021-08-26T13:09:45.108Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RabbitMQ如何保证消息队列的可靠性传输"><a href="#RabbitMQ如何保证消息队列的可靠性传输" class="headerlink" title="RabbitMQ如何保证消息队列的可靠性传输"></a>RabbitMQ如何保证消息队列的可靠性传输</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-6303e69011255831c54d605250a6aa67_720w.jpg" alt="img"></p><h2 id="生产者弄丢数据"><a href="#生产者弄丢数据" class="headerlink" title="生产者弄丢数据"></a>生产者弄丢数据</h2><p>生产者将数据发送到RabbitMQ的时候，可能数据就在半路丢失。此时RabbitMQ提供事务功能，就是生产者发送数据之前开启RabbitMQ事务channel.txSelect，然后发送消息，如果消息没有成功被RabbitMQ接受到，那么生产者就会异常报错，此时回滚事务channel.txRollback，然后重发消息，如果收到消息就可以提交事务channel.txCommit</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启事务</span></span><br><span class="line">channel.txSelect</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 这里发送消息</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    channel.txRollback</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里再次重发这条消息</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 提交事务</span></span><br><span class="line">channel.txCommit</span><br></pre></td></tr></table></figure><p>但是问题是，RabbitMQ 事务机制（同步）一搞，基本上<strong>吞吐量会下来，因为太耗性能</strong>。</p><p>所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 <code>confirm</code> 模式，在生产者那里设置开启 <code>confirm</code> 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 <code>ack</code> 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 <code>nack</code> 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p><p>事务机制和 <code>cnofirm</code> 机制最大的不同在于，<strong>事务机制是同步的</strong>，你提交一个事务之后会<strong>阻塞</strong>在那儿，但是 <code>confirm</code> 机制是<strong>异步</strong>的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。</p><p>所以一般在生产者这块<strong>避免数据丢失</strong>，都是用 <code>confirm</code> 机制的。</p><h2 id="RabbitMQ-弄丢了数据"><a href="#RabbitMQ-弄丢了数据" class="headerlink" title="RabbitMQ 弄丢了数据"></a><strong>RabbitMQ 弄丢了数据</strong></h2><p>就是 RabbitMQ 自己弄丢了数据，这个你必须<strong>开启 RabbitMQ 的持久化</strong>，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，<strong>恢复之后会自动读取之前存储的数据</strong>，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，<strong>可能导致少量数据丢失</strong>，但是这个概率较小。</p><p>设置持久化有<strong>两个步骤</strong>：</p><ul><li>创建 queue 的时候将其设置为持久化<br>这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。</li><li>第二个是发送消息的时候将消息的 <code>deliveryMode</code> 设置为 2<br>就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。</li></ul><p>必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。</p><p>注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。</p><p>所以，持久化可以跟生产者那边的 <code>confirm</code> 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 <code>ack</code> 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 <code>ack</code>，你也是可以自己重发的。</p><h2 id="消费端弄丢了数据"><a href="#消费端弄丢了数据" class="headerlink" title="消费端弄丢了数据"></a><strong>消费端弄丢了数据</strong></h2><p>RabbitMQ 如果丢失了数据，主要是因为你消费的时候，<strong>刚消费到，还没处理，结果进程挂了</strong>，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。</p><p>这个时候得用 RabbitMQ 提供的 <code>ack</code> 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 <code>ack</code>，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 <code>ack</code> 一把。这样的话，如果你还没处理完，不就没有 <code>ack</code> 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-83213e2ac79cd8899b09a66a5cf71669_720w.jpg" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;RabbitMQ如何保证消息队列的可靠性传输&quot;&gt;&lt;a href=&quot;#RabbitMQ如何保证消息队列的可靠性传输&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ如何保证消息队列的可靠性传输&quot;&gt;&lt;/a&gt;RabbitMQ如何保证消息队列的可靠性</summary>
      
    
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>9.synchronized、Lock、volatile</title>
    <link href="https://leslieaibin.github.io/2021/08/25/Thread/9.synchronized%E3%80%81Lock%E3%80%81volatile/"/>
    <id>https://leslieaibin.github.io/2021/08/25/Thread/9.synchronized%E3%80%81Lock%E3%80%81volatile/</id>
    <published>2021-08-25T02:15:42.000Z</published>
    <updated>2021-08-25T13:34:03.697Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>java的内存模型</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20170307155954797" alt="这里写图片描述"></p><ul><li>每个线程都有自己的本地内存空间（java栈中的帧），线程执行时，先把变量从内存读到线程自己的本地内存空间，然后对变量进行操作</li><li>对该变量操作完成后，在某个时间再把变量刷新回主内存</li></ul><p>锁提供的两种特性：<strong>互斥（mutual exclusion） 和可见性（visibility）</strong></p><ul><li>互斥：互斥即一次只允许一个线程持有某个特定的锁，因此可使用该特性实现对共享数据的协调访问协议，这样一次只有一个线程能够使用该共享数据</li><li>可见性：简单来说就是一个线程修改了变量，其他线程可以立即知道。保证可见性的方法：volatile，synchronized，final（一旦初始化完成其他线程就可见）</li></ul><h1 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h1><p>volatile 是类型修饰符（type specifier）。它是被设计用来修饰被不同线程访问和修改的变量。确保本条指令不会因编译期的优化而省略，且要求每次直接读值。</p><p>简单概述volatile，它能够使变量在值发生改变时能尽快的让其他线程知道</p><h2 id="问题来源"><a href="#问题来源" class="headerlink" title="问题来源"></a>问题来源</h2><p>编译器为了加快程序运行的速度，对一些变量的写操作会先在寄存器或者是CPU缓存上进行，最后才写入内存。而在这个过程中，变量的新值对其他线程时不可见的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RunThread</span> <span class="keyword">extends</span> <span class="title">Thread</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> isRunning = <span class="keyword">true</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isRunning</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> isRunning;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setRunning</span><span class="params">(<span class="keyword">boolean</span> isRunning)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.isRunning = isRunning;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@OverRide</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;进入到run方法中了&quot;</span>);</span><br><span class="line">        <span class="keyword">while</span> (isRunning == <span class="keyword">true</span>) &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;线程执行完成了&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Run</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            RunThread thread = <span class="keyword">new</span> RunThread();</span><br><span class="line">            thread.start();</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            thread.setRunning(<span class="keyword">false</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在main线程中，thread.setRunning(false);将启动的线程RunThread中的共享变量设置为false，从而想让RunThread.java的while循环结束。如果使用JVM -server参数执行该程序时，RunThread线程并不会终止，从而出现了死循环。</p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>现在有两个线程，一个是main线程，另一个是RunThread。它们都试图修改isRunning变量。按照JVM内存模型，main线程将isRunning读取到本地线程内存空间，修改后，再刷新回主内存。</p><p>而在JVM设置成 -server模式运行程序时，线程会一直在私有堆栈中读取isRunning变量。因此，RunThread线程无法读到main线程改变的isRunning变量。从而出现了死循环，导致RunThread无法终止。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="keyword">private</span> <span class="keyword">boolean</span> isRunning = <span class="keyword">true</span>;</span><br></pre></td></tr></table></figure><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>当对volatile标记的变量进行修改时，会将其他缓存中存储的修改前的变量清除，然后重新读取。一般来说应该是先在进行修改的缓存A中修改为新值，然后通知其他缓存清除掉此变量，当其他缓存B中的线程读取此变量时，会向总线发送消息，这时存储新值的缓存A获取到消息，将新值穿给B。最后将新值写入内存。当变量需要更新时都是此步骤，volatile的作用是被其修饰的变量，每次更新时，都会刷新上述步骤。</p><h1 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h1><p>Java语言的关键字，可用来给对象和方法或者代码块加锁，当它锁定一个方法或者一个代码块的时候，同一时刻最多只有一个线程执行这段代码。当两个并发线程访问同一个对象object中的这个加锁同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。然而，当一个线程访问object的一个加锁代码块时，另一个线程仍然可以访问该object中的非加锁代码块。</p><p><strong>（1）synchronized 方法</strong></p><p>方法声明时使用,放在范围操作符(public等)之后,返回类型声明(void等)之前.这时,线程获得的是成员锁,即一次只能有一个线程进入该方法,其他线程要想在此时调用该方法,只能排队等候,当前线程(就是在synchronized方法内部的线程)执行完该方法后,别的线程才能进入。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">synMethod</span><span class="params">()</span></span>&#123;</span><br><span class="line">    　　<span class="comment">//方法体</span></span><br><span class="line">　　&#125;</span><br></pre></td></tr></table></figure><p>如在线程t1中有语句obj.synMethod(); 那么由于synMethod被synchronized修饰,在执行该语句前, 需要先获得调用者obj的对象锁, 如果其他线程(如t2)已经锁定了obj (可能是通过obj.synMethod,也可能是通过其他被synchronized修饰的方法obj.otherSynMethod锁定的obj), t1需要等待直到其他线程(t2)释放obj, 然后t1锁定obj, 执行synMethod方法. 返回之前之前释放obj锁。<strong>synchronized 块</strong></p><p><strong>（2）synchronized 块</strong></p><p>对某一代码块使用,synchronized后跟括号,括号里是变量,这样,一次只有一个线程进入该代码块.此时,线程获得的是成员锁。</p><p><strong>（3）synchronized (this)</strong></p><ul><li>当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。　　</li><li>当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对object中所有其它synchronized(this)同步代码块的访问将被阻塞。　　</li><li>然而，当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的除synchronized(this)同步代码块以外的部分。　</li><li>第三个例子同样适用其它同步代码块。也就是说，当一个线程访问object的一个synchronized(this)同步代码块时，它就获得了这个object的对象锁。结果，其它线程对该object对象所有同步代码部分的访问都被暂时阻塞。　　</li><li>以上规则对其它对象锁同样适用。</li></ul><p><strong>（4）wait() 与notify()/notifyAll()</strong></p><p><strong>wait():</strong>  释放占有的对象锁，线程进入等待池，释放cpu,而其他正在等待的线程即可抢占此锁，获得锁的线程即可运行程序。而sleep()不同的是，线程调用此方法后，会休眠一段时间，休眠期间，会暂时释放cpu，但并不释放对象锁。也就是说，在休眠期间，其他线程依然无法进入此代码内部。休眠结束，线程重新获得cpu,执行代码。wait()和sleep()最大的不同在于wait()会释放对象锁，而sleep()不会！</p><p><strong>notify():</strong>   该方法会唤醒因为调用对象的wait()而等待的线程，其实就是对对象锁的唤醒，从而使得wait()的线程可以有机会获取对象锁。调用notify()后，并不会立即释放锁，而是继续执行当前代码，直到synchronized中的代码全部执行完毕，才会释放对象锁。JVM则会在等待的线程中调度一个线程去获得对象锁，执行代码。需要注意的是，wait()和notify()必须在synchronized代码块中调用。</p><p>notifyAll()则是唤醒所有等待的线程。</p><h1 id="lock"><a href="#lock" class="headerlink" title="lock"></a>lock</h1><h2 id="1-synchronized的缺陷"><a href="#1-synchronized的缺陷" class="headerlink" title="(1) synchronized的缺陷"></a><strong>(1) synchronized的缺陷</strong></h2><p>synchronized是java中的一个关键字，也就是说是Java语言内置的特性。那么为什么会出现Lock呢？</p><p>如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况：</p><ul><li>获取锁的线程执行完了该代码块，然后线程释放对锁的占有；</li><li>线程执行发生异常，此时JVM会让线程自动释放锁。</li></ul><p>那么如果这个获取锁的线程由于要等待IO或者其他原因（比如调用sleep方法）被阻塞了，但是又没有释放锁，其他线程便只能等待，试想一下，这多么影响程序执行效率。</p><p>因此就需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等待一定的时间或者能够响应中断），通过Lock就可以办到。</p><p>再举个例子：当有多个线程读写文件时，读操作和写操作会发生冲突现象，写操作和写操作会发生冲突现象，但是读操作和读操作不会发生冲突现象。</p><p>但是采用synchronized关键字来实现同步的话，就会导致一个问题：</p><p>如果多个线程都只是进行读操作，所以当一个线程在进行读操作时，其他线程只能等待无法进行读操作。</p><p>因此就需要一种机制来使得多个线程都只是进行读操作时，线程之间不会发生冲突，通过Lock就可以办到。</p><p><strong>另外，通过Lock可以知道线程有没有成功获取到锁。这个是synchronized无法办到的。</strong></p><p>总结一下，也就是说Lock提供了比synchronized更多的功能。但是要注意以下几点：</p><ul><li>Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问；</li><li>Lock和synchronized有一点非常大的不同，采用synchronized不需要用户去手动释放锁，当synchronized方法或者synchronized代码块执行完之后，系统会自动让线程释放对锁的占用；而Lock则必须要用户去手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。</li></ul><h2 id="2-java-util-concurrent-locks包下常用的类"><a href="#2-java-util-concurrent-locks包下常用的类" class="headerlink" title="(2) java.util.concurrent.locks包下常用的类"></a><strong>(2) java.util.concurrent.locks包下常用的类</strong></h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Lock</span> </span>&#123;</span><br><span class="line">    <span class="comment">//获取锁，如果锁被其他线程获取，则进行等待</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span></span>; </span><br><span class="line"></span><br><span class="line">    <span class="comment">//当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就使说，当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lockInterruptibly</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成</span></span><br><span class="line"><span class="comment">    *功，则返回true，如果获取失败（即锁已被其他线程获取），则返回</span></span><br><span class="line"><span class="comment">    *false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。*/</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> time, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span></span>; <span class="comment">//释放锁</span></span><br><span class="line">    <span class="function">Condition <span class="title">newCondition</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意:</p><ul><li><p>当一个线程获取了锁之后，是不会被interrupt()方法中断的。因为本身在前面的文章中讲过单独调用interrupt()方法不能中断正在运行过程中的线程，只能中断阻塞过程中的线程。</p></li><li><p>而用synchronized修饰的话，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。</p></li></ul><h2 id="3-ReentrantLock"><a href="#3-ReentrantLock" class="headerlink" title="(3) ReentrantLock"></a><strong>(3) ReentrantLock</strong></h2><p>ReentrantLock,意思是“可重入锁”,是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;Integer&gt; arrayList = <span class="keyword">new</span> ArrayList&lt;Integer&gt;();</span><br><span class="line">    <span class="keyword">private</span> Lock lock = <span class="keyword">new</span> ReentrantLock();    <span class="comment">//注意这个地方</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span>  </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Test test = <span class="keyword">new</span> Test();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread()&#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                test.insert(Thread.currentThread());</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;.start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread()&#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                test.insert(Thread.currentThread());</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;.start();</span><br><span class="line">    &#125;  </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">(Thread thread)</span> </span>&#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            System.out.println(thread.getName()+<span class="string">&quot;得到了锁&quot;</span>);</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++) &#123;</span><br><span class="line">                arrayList.add(i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// <span class="doctag">TODO:</span> handle exception</span></span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(thread.getName()+<span class="string">&quot;释放了锁&quot;</span>);</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">method1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        method2();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">method2</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码中的两个方法method1和method2都用synchronized修饰了，假如某一时刻，线程A执行到了method1，此时线程A获取了这个对象的锁，而由于method2也是synchronized方法，假如synchronized不具备可重入性，此时线程A需要重新申请锁。但是这就会造成一个问题，因为线程A已经持有了该对象的锁，而又在申请获取该对象的锁，这样就会线程A一直等待永远不会获取到的锁。</p><p>而由于synchronized和Lock都具备可重入性，所以不会发生上述现象。</p><h1 id="volatile和synchronized区别"><a href="#volatile和synchronized区别" class="headerlink" title="volatile和synchronized区别"></a>volatile和synchronized区别</h1><ul><li><p>volatile本质是在告诉jvm当前变量在寄存器中的值是不确定的,需要从主存中读取,synchronized则是锁定当前变量,只有当前线程可以访问该变量,其他线程被阻塞住.</p></li><li><p>volatile仅能使用在变量级别,synchronized则可以使用在变量,方法.</p></li><li><p>volatile仅能实现变量的修改可见性,而synchronized则可以保证变量的修改可见性和原子性.</p><p>《Java编程思想》上说，定义long或double变量时，如果使用volatile关键字，就会获得（简单的赋值与返回操作）原子性</p></li><li><p>volatile不会造成线程的阻塞,而synchronized可能会造成线程的阻塞.</p></li><li><p>当一个域的值依赖于它之前的值时，volatile就无法工作了，如n=n+1,n++等。如果某个域的值受到其他域的值的限制，那么volatile也无法工作，如Range类的lower和upper边界，必须遵循lower&lt;=upper的限制。</p></li><li><p>使用volatile而不是synchronized的唯一安全的情况是类中只有一个可变的域。</p></li></ul><h1 id="synchronized和lock区别"><a href="#synchronized和lock区别" class="headerlink" title="synchronized和lock区别"></a>synchronized和lock区别</h1><ul><li>Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；</li><li>synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；</li><li>Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；</li><li>通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。</li><li>Lock可以提高多个线程进行读操作的效率。</li></ul><p>　在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;java的内存模型&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://test-1874253.oss-cn-beijing.aliyuncs</summary>
      
    
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>3.HashMap、ConcurrentHashMap、HashTable</title>
    <link href="https://leslieaibin.github.io/2021/08/24/Collection/3.java%E9%9B%86%E5%90%88[3]--HashMap%E3%80%81ConcurrentHashMap%E3%80%81HashTable%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://leslieaibin.github.io/2021/08/24/Collection/3.java%E9%9B%86%E5%90%88[3]--HashMap%E3%80%81ConcurrentHashMap%E3%80%81HashTable%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2021-08-23T16:15:42.000Z</published>
    <updated>2021-08-24T07:13:47.377Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HashMap、ConcurrentHashMap、HashTable的区别"><a href="#HashMap、ConcurrentHashMap、HashTable的区别" class="headerlink" title="HashMap、ConcurrentHashMap、HashTable的区别"></a>HashMap、ConcurrentHashMap、HashTable的区别</h1><h2 id="HashMap-vs-ConcurrentHashMap"><a href="#HashMap-vs-ConcurrentHashMap" class="headerlink" title="HashMap vs ConcurrentHashMap"></a>HashMap vs ConcurrentHashMap</h2><p>引入ConcurrentHashMap是为了同步集合HashTable之间有更好的选择，HashTable与HashMap,ConcurrentHashMap主要区别于HashMap不是同步的，线程不安全的和不适合应用于多线程并发环境下，而ConcurrentHashMap是线程安全的集合容器，特别是在多线程和并发环境中，通常作为Map的主要实现。</p><h2 id="HashMap与ConcurrentHashMap的区别"><a href="#HashMap与ConcurrentHashMap的区别" class="headerlink" title="HashMap与ConcurrentHashMap的区别"></a>HashMap与ConcurrentHashMap的区别</h2><ul><li>ConcurrentHashMap是线程安全的并发环境下不需要额外的同步。虽然它不像Hashtable那样需要同样的同步等级（全表锁），但也有很多实际的用途</li><li>你可以使用Collections.synchronizedMap(HashMap)来包装HashMap作为同步容器，这时它的作用与hashtable一样，当每次对Map做修改操作的时候都会锁住这个Map对象，而ConcurrentHashMap会基于并发的等级来划分整个Map来达到线程安全，它之后锁操作的那一段数据而不是整个Map都上锁</li><li>ConcurrentHashMap有很好的的扩展性，在多线程环境下性能比做同步的HashMap要好，但是在但性能环境下，HashMap会比ConcurrentHashMap好一点</li></ul><p>总结一下以上两者的区别，它们在线程安全、扩展性、同步之间的区别。如果是用于缓存的话，<code>ConcurrentHashMap</code>是一个更好的选择，在Java应用中会经常用到。<code>ConcurrentHashMap</code>在读操作线程数多于写操作线程数的情况下更胜一筹。</p><h2 id="ConcurrentHashMap-vs-Hashtable-vs-Synchronized-Map"><a href="#ConcurrentHashMap-vs-Hashtable-vs-Synchronized-Map" class="headerlink" title="ConcurrentHashMap vs Hashtable vs Synchronized Map"></a>ConcurrentHashMap vs Hashtable vs Synchronized Map</h2><ul><li><p>虽然三个集合类在多线程并发应用中都是线程安全的，但是他们有一个重大的差别，就是他们各自实现线程安全的方式。<code>Hashtable</code>是jdk1的一个遗弃的类，它把所有方法都加上<code>synchronized</code>关键字来实现线程安全。所有的方法都同步这样造成多个线程访问效率特别低。<code>Synchronized Map</code>与<code>HashTable</code>差别不大，也是在并发中作类似的操作，两者的唯一区别就是<code>Synchronized Map</code>没被遗弃，它可以通过使用<code>Collections.synchronizedMap()</code>来包装<code>Map</code>作为同步容器使用。</p></li><li><p>另一方面，<code>ConcurrentHashMap</code>的设计有点特别，表现在多个线程操作上。它不用做外的同步的情况下默认同时允许16个线程读和写这个Map容器。因为其内部的实现剥夺了锁，使它有很好的扩展性。不像<code>HashTable</code>和<code>Synchronized Map</code>，<code>ConcurrentHashMap</code>不需要锁整个Map，相反它划分了多个段(segments)，要操作哪一段才上锁那段数据。</p></li></ul><h2 id="ConcurrentHashMap实现原理"><a href="#ConcurrentHashMap实现原理" class="headerlink" title="ConcurrentHashMap实现原理"></a>ConcurrentHashMap实现原理</h2><p>ConcurrentHashMap在JDK1.7  和 JDK 1.8 的实现有很大的区别</p><p>ConcurrentHashMap底层结构是一个Segment数组，默认大小是16，每个Segment数组又可以看成一个小的HashMap，也就是说Segment数组使用链表加数组实现的。</p><h3 id="jdk-1-7的实现基于分段锁的ConcurrentHashMap"><a href="#jdk-1-7的实现基于分段锁的ConcurrentHashMap" class="headerlink" title="jdk 1.7的实现基于分段锁的ConcurrentHashMap"></a>jdk 1.7的实现基于分段锁的ConcurrentHashMap</h3><p>在JDK1.7中ConcurrentHashMap采用了<strong>数组+Segment+分段锁</strong>的方式实现。</p><ul><li><p>Segment（分段锁）</p><p>ConcurrentHashMap中的<strong>分段锁称为Segment</strong>，它即类似于HashMap的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表,同时又是一个ReentrantLock（Segment继承了ReentrantLock）。</p></li><li><p>内部结构</p><p>ConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。如下图是ConcurrentHashMap的内部结构图：</p></li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/4209232655-5de51f35bf273_articlex" alt="file"></p><p>从上面的结构我们可以了解到，ConcurrentHashMap定位一个元素的过程需要进行两次Hash操作。</p><p><strong>第一次Hash定位到Segment，第二次Hash定位到元素所在的链表的头部。</strong></p><p><strong>坏处</strong></p><p>这一种结构的带来的副作用是Hash的过程要比普通的HashMap要长</p><p><strong>好处</strong></p><p>写操作的时候可以只对元素所在的Segment进行加锁即可，不会影响到其他的Segment，这样，在最理想的情况下，ConcurrentHashMap可以最高同时支持Segment数量大小的写操作（刚好这些写操作都非常平均地分布在所有的Segment上）。</p><p>所以，通过这一种结构，ConcurrentHashMap的并发能力可以大大的提高。</p><h3 id="JDK1-8版本的CurrentHashMap的实现原理"><a href="#JDK1-8版本的CurrentHashMap的实现原理" class="headerlink" title="JDK1.8版本的CurrentHashMap的实现原理**"></a>JDK1.8版本的CurrentHashMap的实现原理**</h3><p>DK8中ConcurrentHashMap参考了JDK8 HashMap的实现，采用了<strong>数组+链表+红黑树</strong>的实现方式来设计，<strong>内部大量采用CAS操作，这里我简要介绍下CAS</strong>。</p><p>CAS是compare and swap的缩写，即我们所说的比较交换。cas是一种基于锁的操作，而且是乐观锁。在java中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加version来获取数据，性能较悲观锁有很大的提高。</p><p>CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和A的值是一样的，那么就将内存里面的值更新成B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a线程获取地址里面的值被b线程修改了，那么a线程需要自旋，到下次循环才有可能机会执行。</p><p><strong>JDK8中彻底放弃了Segment转而采用的是Node，其设计思想也不再是JDK1.7中的分段锁思想。</strong></p><p><strong>Node：保存key，value及key的hash值的数据结构。其中value和next都用volatile修饰，保证并发的可见性。</strong></p><p><strong>Java8 ConcurrentHashMap结构基本上和Java8的HashMap一样，不过保证线程安全性。</strong></p><p>在JDK8中ConcurrentHashMap的结构，由于引入了红黑树，使得ConcurrentHashMap的实现非常复杂，我们都知道，红黑树是一种性能非常好的二叉查找树，其查找性能为O（logN），但是其实现过程也非常复杂，而且可读性也非常差，Doug<br>Lea的思维能力确实不是一般人能比的，早期完全采用链表结构时Map的查找时间复杂度为O（N），JDK8中ConcurrentHashMap在链表的长度大于某个阈值的时候会将链表转换成红黑树进一步提高其查找性能。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1083488536-5de51f3800fc4_articlex" alt="file"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树。</p><p><strong>1.数据结构：</strong>取消了Segment分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。</p><p><strong>2.保证线程安全机制：</strong>JDK1.7采用segment的分段锁机制实现线程安全，其中segment继承自ReentrantLock。JDK1.8采用CAS+Synchronized保证线程安全。</p><p><strong>3.锁的粒度：</strong>原来是对需要进行数据操作的Segment加锁，现调整为对每个数组元素加锁（Node）。</p><p>**4.链表转化为红黑树:**定位结点的hash算法简化会带来弊端,Hash冲突加剧,因此在链表节点数量大于8时，会将链表转化为红黑树进行存储。</p><p><strong>5.查询时间复杂度：</strong>从原来的遍历链表O(n)，变成遍历红黑树O(logN)。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;HashMap、ConcurrentHashMap、HashTable的区别&quot;&gt;&lt;a href=&quot;#HashMap、ConcurrentHashMap、HashTable的区别&quot; class=&quot;headerlink&quot; title=&quot;HashMap、Concurre</summary>
      
    
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/categories/Collection/"/>
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/tags/Collection/"/>
    
  </entry>
  
  <entry>
    <title>2.Java集合</title>
    <link href="https://leslieaibin.github.io/2021/08/20/Collection/2.%E9%9B%86%E5%90%88[2]/"/>
    <id>https://leslieaibin.github.io/2021/08/20/Collection/2.%E9%9B%86%E5%90%88[2]/</id>
    <published>2021-08-19T16:15:42.000Z</published>
    <updated>2021-08-20T12:14:50.022Z</updated>
    
    <content type="html"><![CDATA[<h1 id="集合容器概述"><a href="#集合容器概述" class="headerlink" title="集合容器概述"></a>集合容器概述</h1><h2 id="什么是集合"><a href="#什么是集合" class="headerlink" title="什么是集合"></a>什么是集合</h2><ul><li>集合就是一个放数据的容器，准确的说是放数据对象引用的容器</li><li>集合类存放的都是对象的引用，而不是对象的本身</li><li>集合类型主要有三种： set(集)、list(列表) 和 map(映射)</li></ul><h2 id="集合的特点"><a href="#集合的特点" class="headerlink" title="集合的特点"></a>集合的特点</h2><ul><li><p>集合用于存储对象的容器，对象是用来封装数据，对象多了也需要存储集中式管理</p></li><li><p>和数组对比对象的大小是不确定的，集合的长度是可变的，数组需要提前定义大小</p></li></ul><h2 id="集合和数组的区别"><a href="#集合和数组的区别" class="headerlink" title="集合和数组的区别"></a>集合和数组的区别</h2><ul><li>数组是 固定长度的，集合可变长度的</li><li>数组可以存储基本数据类型，也可以存储引用数据类型，集合只能存储引用数据类型</li><li>数组存储的元素必须是同一个数据类型，集合存储的对象可以是不同数据类型</li></ul><h2 id="使用集合框架的好处"><a href="#使用集合框架的好处" class="headerlink" title="使用集合框架的好处"></a>使用集合框架的好处</h2><ul><li>容量自增长</li><li>提供了高性能的数据结构和算法，使编码更轻松，提高了程序速度和质量</li><li>可以方便的扩展或改写集合，提高代码复用性和可操作性</li><li>通过使用JDK自带的集合类，降低代码维护和学习新API成本</li></ul><h2 id="常用的集合类有哪些"><a href="#常用的集合类有哪些" class="headerlink" title="常用的集合类有哪些"></a>常用的集合类有哪些</h2><ul><li>Map接口和Collection接口是所有集合框架的父接口</li><li>Collection接口的子接口包括：Set接口和List接口</li><li>Map接口的实现类主要包括：HashMap、TreeMap、Hashtable、weakHashMap等</li><li>Set接口的实现类主要有：HashSet、TreeSet、LinkedHashSet等</li><li>List接口的实现类主要有： ArrayList、LinkedList、Stack以及Vector等</li></ul><h2 id="List、Map-、Set三者的区别"><a href="#List、Map-、Set三者的区别" class="headerlink" title="List、Map 、Set三者的区别"></a>List、Map 、Set三者的区别</h2><p><img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/4/13/17173551e70de4bd~tplv-t2oaga2asx-watermark.awebp" alt="在这里插入图片描述"></p><ul><li><p>Java容器分为Collection 和 Map 两大类，Collection集合的子接口有Set、List、Queue三种子接口。我们比较常用的是Set、List，Map接口不是collection的子接口。</p></li><li><p>Collection 集合主要有List 和 Set 两大接口</p><ul><li>List：一个有序的（元素存入集合的顺序和取出的顺序一致）容器，元素可以重复，可以插入多个null元素，元素都有索引。常用的实现类有ArrayList、LinkedList 和 Vector</li><li>Set：一个无序的（存入和取出顺序有可能不一致）容器，不可以存储重复元素，值允许存入一个null 元素，必须保证元素的唯一性。Set接口常用实现类 HashSet、LinkedHashSet 以及 TreeSet。</li></ul></li><li><p>Map是一个键值对集合，存储键、值和之间的映射。 Key无序，唯一；value 不要求有序，允许重复。Map没有继承于Collection接口，从Map集合中检索元素时，只要给出键对象，就会返回对应的值对象。</p><ul><li>Map 的常用实现类：HashMap、TreeMap、HashTable、LinkedHashMap、ConcurrentHashMap</li></ul></li></ul><h2 id="集合框架底层数据结构"><a href="#集合框架底层数据结构" class="headerlink" title="集合框架底层数据结构"></a>集合框架底层数据结构</h2><ul><li><p>List </p><ul><li>ArrayList：Object数组</li><li>Vector: Object数组</li><li>LinkedList：双向循环链表</li></ul></li><li><p>Set</p><ul><li>HashSet（无序，唯一）：基于HashMap实现的，底层采用HashMap来保存元素</li><li>LinkedHashSet：LinkedHashSet继承与HashSet，并且其内部是通过LinkedHashMap实现的。</li><li>TreeSet(有序，唯一)： 红黑树（自平衡的排序二叉树）</li></ul></li><li><p>Map</p><ul><li>HashMap：JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要解决哈希冲突而存在的（”拉链法”解决冲突）JDK1.8以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转换为红黑树，以减少搜索时间</li><li>LinkedHashMap：LinkedHashMap 继承自HashMap，所以它的底层也是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap在上面结构基础上，增加一条双向链表，使得上面的结构可以保持键值对的插入顺序，同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。</li><li>HashTable：数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的</li><li>TreeMap： 红黑树（自平衡的排序二叉树）</li></ul></li></ul><h2 id="那些集合类是线程安全的"><a href="#那些集合类是线程安全的" class="headerlink" title="那些集合类是线程安全的"></a>那些集合类是线程安全的</h2><ul><li>Vector：就比Arraylist 多个synchronized(线程安全)，因为效率较低，不建议使用</li><li>hashTable：就比hashMap多了个Synchronized（线程安全），不建议使用</li><li>ConcurrentHashMap：是Java5中支持高并发、高吞吐量的线程安全HashMap实现。它由Segment数组结构和HashEntry数组结构组成。Segment数组在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键-值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构；一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素；每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。（推荐使用）</li></ul><h2 id="Java集合的快速失败机制-“fail-fast”？"><a href="#Java集合的快速失败机制-“fail-fast”？" class="headerlink" title="Java集合的快速失败机制 “fail-fast”？"></a>Java集合的快速失败机制 “fail-fast”？</h2><ul><li><p>是java集合的一种错误检测机制，当多个线程对集合进行结构上的改变的操作时，有可能会产生 fail-fast 机制。</p></li><li><p>例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出 ConcurrentModificationException 异常，从而产生fail-fast机制。</p></li><li><p>原因：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。</p></li><li><p>解决办法：</p><ol><li>在遍历过程中，所有涉及到改变modCount值得地方全部加上synchronized。</li><li>使用CopyOnWriteArrayList来替换ArrayList</li></ol></li></ul><h2 id="怎样确保一个集合不能被修改"><a href="#怎样确保一个集合不能被修改" class="headerlink" title="怎样确保一个集合不能被修改"></a>怎样确保一个集合不能被修改</h2><ul><li>可以使用Collections.unmodifiableCollection(Collection c) 方法来创建一个只读集合，这样改变集合的任操作都会抛出Java.lang.UnsupportedOperationException异常</li></ul><h1 id="Collection"><a href="#Collection" class="headerlink" title="Collection"></a>Collection</h1><h2 id="List接口"><a href="#List接口" class="headerlink" title="List接口"></a>List接口</h2><h3 id="迭代器Iterator是什么"><a href="#迭代器Iterator是什么" class="headerlink" title="迭代器Iterator是什么"></a>迭代器Iterator是什么</h3><ul><li><p>Iterator接口提供遍历任何Collection的接口。我们可以从一个Collection中使用迭代器方法来获取迭代器实例。迭代器允许调用者在迭代过程中移除元素</p></li><li><p>所有Collection接继承了Iterator迭代器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Collection</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">Iterable</span>&lt;<span class="title">E</span>&gt;</span>&#123;</span><br><span class="line">   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="Iterator-怎么使用-，有什么特点"><a href="#Iterator-怎么使用-，有什么特点" class="headerlink" title="Iterator 怎么使用 ，有什么特点"></a>Iterator 怎么使用 ，有什么特点</h3><ul><li><p>Iterator使用代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">Iterator&lt;String&gt; it = list.iterator();</span><br><span class="line"><span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">    String obj = it.next();</span><br><span class="line">    Sysrtem.out.println(obj);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Iterator的特点是只能单向遍历，但是更加安全，因为他可以确保在当前遍历集合元素被更改的时候，就会抛出ConcurrentModificationException 异常。</p></li></ul><h3 id="如何边遍历边移除-Collection-中的元素"><a href="#如何边遍历边移除-Collection-中的元素" class="headerlink" title="如何边遍历边移除 Collection 中的元素"></a>如何边遍历边移除 Collection 中的元素</h3><ul><li><p>边遍历边修改Collection的正确方式是使用Iterator.remove()方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 正确的</span></span><br><span class="line">Iterator&lt;Integer&gt; it = list.iterator();</span><br><span class="line"><span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">    <span class="comment">// do something</span></span><br><span class="line">    it.romove();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 错误的</span></span><br><span class="line"><span class="keyword">for</span>(Integer i : list)&#123;</span><br><span class="line">   list.remove(i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>运行以上错误代码会报 <strong>ConcurrentModificationException 异常</strong>。这是因为当使用 foreach(for(Integer i : list)) 语句时，会自动生成一个iterator 来遍历该 list，但同时该 list 正在被 Iterator.remove() 修改。Java 一般不允许一个线程在遍历 Collection 时另一个线程修改它。</p></li></ul><h3 id="Iterator-和-ListIterator-有什么区别"><a href="#Iterator-和-ListIterator-有什么区别" class="headerlink" title="Iterator 和 ListIterator 有什么区别"></a>Iterator 和 ListIterator 有什么区别</h3><ul><li>Iterator可以遍历Set 和 List 集合，而ListIterator 只能遍历List</li><li>Iterator只能单向遍历，而ListIterator可以双向遍历（向前/先后）</li><li>LsitIterator实现Iterator接口，然后添加了一些额外的功能，比如添加一个元素，替换一个元素，获取前面或后面的元素的索引位置</li></ul><h3 id="遍历一个-List-有哪些不同的方式，每种方法的实现原理是什么，Java-中-List-遍历的最佳实践是什么"><a href="#遍历一个-List-有哪些不同的方式，每种方法的实现原理是什么，Java-中-List-遍历的最佳实践是什么" class="headerlink" title="遍历一个 List 有哪些不同的方式，每种方法的实现原理是什么，Java 中 List 遍历的最佳实践是什么"></a>遍历一个 List 有哪些不同的方式，每种方法的实现原理是什么，Java 中 List 遍历的最佳实践是什么</h3><p><strong>方式三种：</strong></p><ul><li>for循环遍历，基于计数器。在集合外部维护一个计数器，然后一次读取每个位置的元素，当读取到最后一个元素停止</li><li>迭代器遍历，Iterator。Iterator是面向对象的一个设计模式，目的设计屏蔽不同数据集合的特点，统一遍历集合接口。Java在Collection中支持Iterator模式</li><li>foreach循环遍历。foreach内部也是采用了Iterator的方式实现，使用时不需要显示声明Iterator或计数器。优点：代码简洁，缺点是只能做简单的遍历，不能在遍历过程中操作数据集合（删除，替换）</li></ul><p><strong>最佳实践：Java Collections 框架中提供了一个 RandomAccess 接口，用来标记 List 实现是否支持 Random Access。</strong></p><ul><li>推荐做法，支持Random Access的列表可用for循环遍历，否则建议使用Iterator 或 foreach遍历</li><li>如果一个数据集合实现了该接口，就意味着它支持 Random Access，按位置读取元素的平均时间复杂度为 O(1)，如ArrayList。</li><li>如果没有实现该接口，表示不支持 Random Access，如LinkedList。</li></ul><h3 id="说一下ArrayList的优缺点"><a href="#说一下ArrayList的优缺点" class="headerlink" title="说一下ArrayList的优缺点"></a>说一下ArrayList的优缺点</h3><ul><li>ArrayList的优点如下<ul><li>ArrayList底层是以数组实现的，是一种随机访问模式。ArrayList实现了RandomAccess接口，因此查找的时候非常快</li><li>ArrayList在顺序添加一个元素的时候非常方便。</li></ul></li><li>ArrayList的缺点<ul><li>删除元素的时候，需要做一次元素复制操作。如果要复制的元素很多，那么就会比较耗费性能</li><li>插入元素的时候也需要做一次元素复制，缺点同上</li></ul></li><li>ArrayList比较适合顺序添加，随机访问的场景</li></ul><h3 id="如何实现数组和List之间的转换"><a href="#如何实现数组和List之间的转换" class="headerlink" title="如何实现数组和List之间的转换"></a>如何实现数组和List之间的转换</h3><ul><li>数组转List: Arrays.asList(array)进行转换</li><li>List转换数组：使用 List 自带的 toArray() 方法</li></ul><h3 id="ArrayList-和-LinkedList的区别是什么"><a href="#ArrayList-和-LinkedList的区别是什么" class="headerlink" title="ArrayList 和 LinkedList的区别是什么"></a>ArrayList 和 LinkedList的区别是什么</h3><ul><li>数据结构实现：ArrayList 是动态数组的数据结构实现，而 LinkedList 是双向链表的数据结构实现。</li><li>随机访问效率：ArrayList 比 LinkedList 在随机访问的时候效率要高，因为 LinkedList 是线性的数据存储方式，所以需要移动指针从前往后依次查找</li><li>增加和删除效率：在非首尾的增加和删除操作，LinkedList 要比 ArrayList 效率要高，因为 ArrayList 增删操作要影响数组内的其他数据的下标。</li><li>内存空间占用：LinkedList 比 ArrayList 更占内存，因为 LinkedList 的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素。</li><li>线程安全：ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全；</li><li>综合来说，在需要频繁读取集合中的元素时，更推荐使用 ArrayList，而在插入和删除操作较多时，更推荐使用 LinkedList。</li><li>LinkedList 的双向链表也叫双链表，是链表的一种，它的每个数据结点中都有两个指针，分别指向直接后继和直接前驱。所以，从双向链表中的任意一个结点开始，都可以很方便地访问它的前驱结点和后继结点。</li></ul><h3 id="ArrayList-和-Vector-的区别是什么"><a href="#ArrayList-和-Vector-的区别是什么" class="headerlink" title="ArrayList 和 Vector 的区别是什么"></a>ArrayList 和 Vector 的区别是什么</h3><ul><li><p>这两个类都实现了 List 接口（List 接口继承了 Collection 接口），他们都是有序集合</p><ul><li>线程安全：Vector 使用了 Synchronized 来实现线程同步，是线程安全的，而 ArrayList 是非线程安全的。</li><li>性能：ArrayList 在性能方面要优于 Vector。</li><li>扩容：ArrayList 和 Vector 都会根据实际的需要动态的调整容量，只不过在 Vector 扩容每次会增加 1 倍，而 ArrayList 只会增加 50%。</li></ul></li><li><p>Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。</p></li><li><p>Arraylist不是同步的，所以在不需要保证线程安全时时建议使用Arraylist。</p></li></ul><h3 id="插入数据时，ArrayList、LinkedList、Vector谁速度较快？阐述-ArrayList、Vector、LinkedList-的存储性能和特性？"><a href="#插入数据时，ArrayList、LinkedList、Vector谁速度较快？阐述-ArrayList、Vector、LinkedList-的存储性能和特性？" class="headerlink" title="插入数据时，ArrayList、LinkedList、Vector谁速度较快？阐述 ArrayList、Vector、LinkedList 的存储性能和特性？"></a>插入数据时，ArrayList、LinkedList、Vector谁速度较快？阐述 ArrayList、Vector、LinkedList 的存储性能和特性？</h3><ul><li>ArrayList和Vector 底层的实现都是使用数组方式存储数据。数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢。</li><li>Vector 中的方法由于加了 synchronized 修饰，因此 <strong>Vector</strong> <strong>是线程安全容器，但性能上较ArrayList差</strong>。</li><li>LinkedList 使用双向链表实现存储，按序号索引数据需要进行前向或后向遍历，但插入数据时只需要记录当前项的前后项即可，所以 <strong>LinkedList</strong> <strong>插入速度较快</strong>。</li></ul><h3 id="多线程场景下如何使用ArrayList"><a href="#多线程场景下如何使用ArrayList" class="headerlink" title="多线程场景下如何使用ArrayList"></a>多线程场景下如何使用ArrayList</h3><ul><li>ArrayList不是线程安全的，如果遇到多线程场景，可以通过Collections 的 synchronizedList 方法将其转换成线程安全的容器在使用</li></ul><h3 id="List-和-Set-的区别"><a href="#List-和-Set-的区别" class="headerlink" title="List 和 Set 的区别"></a>List 和 Set 的区别</h3><ul><li>List，Set 都是继承自Collection接口</li><li>List：一个有序（元素存入集合的顺序和取出的顺序一致）容器，元素可以重复，可以插入多个null元素，元素都有索引。常用的实现类有 ArrayList、LinkedList 和 Vector。</li><li>Set：一个无序（存入和取出顺序有可能不一致）容器，不可以存储重复元素，只允许存入一个null元素，必须保证元素唯一性。Set 接口常用实现类是 HashSet、LinkedHashSet 以及 TreeSet。</li><li>另外 List 支持for循环，也就是通过下标来遍历，也可以用迭代器，但是set只能用迭代，因为他无序，无法用下标来取得想要的值。</li><li>Set和List对比<ul><li>Set：检索元素效率低下，删除和插入效率高，插入和删除不会引起元素位置改变。</li><li>List：和数组类似，List可以动态增长，查找元素效率高，插入删除元素效率低，因为会引起其他元素位置改变</li></ul></li></ul><h2 id="Set接口"><a href="#Set接口" class="headerlink" title="Set接口"></a>Set接口</h2><h3 id="说下HashSet的实现原理"><a href="#说下HashSet的实现原理" class="headerlink" title="说下HashSet的实现原理"></a>说下HashSet的实现原理</h3><ul><li>HashSet是基于HashMap实现的，HashSet的值存放于HashMap的key上，HashMap的value统一为present，因此HashSet的实现比较简单，相关 HashSet 的操作，基本上都是直接调用底层 HashMap 的相关方法来完成，HashSet 不允许重复的值。</li></ul><h3 id="HashSet如何检查重复？HashSet是如何保证数据不可重复的？"><a href="#HashSet如何检查重复？HashSet是如何保证数据不可重复的？" class="headerlink" title="HashSet如何检查重复？HashSet是如何保证数据不可重复的？"></a>HashSet如何检查重复？HashSet是如何保证数据不可重复的？</h3><ul><li><p>向HashSet中add()元素时，判断元素是否存在的依据，不仅要比较hash值，同时还要结合equals方法比较。</p></li><li><p>HashSet中的add()方法会使用HashMap()的putf()方法</p></li><li><p>HashMap 的 key 是唯一的，由源码可以看出 HashSet 添加进去的值就是作为HashMap 的key，并且在HashMap中如果K/V相同时，会用新的V覆盖掉旧的V，然后返回旧的V。所以不会重复（ HashMap 比较key是否相等是先比较hashcode 再比较equals ）。</p></li></ul><h3 id="hashCode（）与equals（）的相关规定："><a href="#hashCode（）与equals（）的相关规定：" class="headerlink" title="hashCode（）与equals（）的相关规定："></a><strong>hashCode（）与equals（）的相关规定</strong>：</h3><ol><li>如果两个对象相等，则hashcode一定也是相同的<ul><li>hashCode是jdk根据对象的地址或者字符串或者数字算出来的int类型的数值</li></ul></li><li>两个对象相等,对两个equals方法返回true</li><li>两个对象有相同的hashcode值，它们也不一定是相等的</li><li>综上，equals方法被覆盖过，则hashCode方法也必须被覆盖</li><li>hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）</li></ol><h3 id="和-equals-的区别"><a href="#和-equals-的区别" class="headerlink" title="== 和 equals 的区别"></a>== 和 equals 的区别</h3><ul><li>==是判断两个变量或实例是不是指向同一个内存空间 equals是判断两个变量或实例指向的内存空间值是不是相同的</li><li>== 是指对内存地址进行比较 equals()是对字符串</li></ul><h3 id="HashSet-与-HashMap的区别"><a href="#HashSet-与-HashMap的区别" class="headerlink" title="HashSet 与 HashMap的区别"></a>HashSet 与 HashMap的区别</h3><table><thead><tr><th align="center">HashMap</th><th align="center">HashSet</th></tr></thead><tbody><tr><td align="center">实现了Map接口</td><td align="center">实现Set接口</td></tr><tr><td align="center">存储键值对</td><td align="center">仅存储对象</td></tr><tr><td align="center">调用put（）向map中添加元素</td><td align="center">调用add（）方法向Set中添加元素</td></tr><tr><td align="center">HashMap使用键（Key）计算Hashcode</td><td align="center">HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性，如果两个对象不同的话，那么返回false</td></tr><tr><td align="center">HashMap相对于HashSet较快，因为它是使用唯一的键获取对象</td><td align="center">HashSet较HashMap来说比较慢</td></tr></tbody></table><h1 id="Map接口"><a href="#Map接口" class="headerlink" title="Map接口"></a>Map接口</h1><h2 id="什么是Hash算法"><a href="#什么是Hash算法" class="headerlink" title="什么是Hash算法"></a>什么是Hash算法</h2><p>哈希算法是指把任意长度的二进制映射为固定长度的较小的二进制值，这个较小的二进制值叫做哈希值</p><h2 id="什么是链表"><a href="#什么是链表" class="headerlink" title="什么是链表"></a>什么是链表</h2><ul><li>链表是可以将物理地址上不连续的数据连接起来，通过指针来对物理地址进行操作，实现增删改查等功能</li><li>链表大致分为单链表和双向链表<ul><li>单链表：每个节点包含两部分，一部分存放数据变量data，另一部分是指向下一个节点的next指针</li><li>双向链表：除了包含单链表的部分，还增加的pre前一个节点的指针</li></ul></li><li>链表的优点：<ul><li>插入删除速度快（因为next指针指向其下一个节点，通过改变指针的指向可以方便的增加删除元素）</li><li>内存利用率高，不会浪费内存（可以使用内存中细小的不连续空间（大于node节点的大小），并且在需要空间的时间才创建空间）</li><li>大小没有固定，拓展很灵活</li></ul></li><li>链表的缺点<ul><li>不能随机查找，必须从第一个开始遍历，查找效率低</li></ul></li></ul><h2 id="HashMap的实现原理"><a href="#HashMap的实现原理" class="headerlink" title="HashMap的实现原理"></a>HashMap的实现原理</h2><ul><li>HashMap：HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是他不保证该顺序恒久不变</li><li>HashMap的数据结构：在Java编程语言中，最基本的结构就是两种，一个是数组，另一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个”链表散列”的数据结构，即数组和链表的结合体</li><li>HashMap 基于 Hash 算法实现的<ul><li>当我们往HashMap中put元素时，利用key的hashCode重新hash计算出当前对象的元素在数组中的下标</li><li>存储时，如果出现hash值相同的key，此时有两种情况<ul><li>如果key相同，则覆盖原始值</li><li>如果key不同（出现冲突），则将当前的key-value放入链表中</li></ul></li><li>获取时，直接找到hash值对应的下标，再进一步判断key是否相同，从而找到对应值</li><li>理解了以上过程就不难明白HashMap是如何解决hash冲突的问题，核心就是使用了数组的存储方式，然后将冲突的key的对象放入链表中，一旦发现冲突就在链表中做进一步的对比。</li></ul></li><li>需要注意Jdk 1.8中对HashMap的实现做了优化，当链表中的节点数据超过八个之后，该链表会转为红黑树来提高查询效率，从原来的O(n)到O(logn)</li></ul><h2 id="HashMap在JDK1-7和JDK1-8中有哪些不同？-HashMap的底层实现"><a href="#HashMap在JDK1-7和JDK1-8中有哪些不同？-HashMap的底层实现" class="headerlink" title="HashMap在JDK1.7和JDK1.8中有哪些不同？ HashMap的底层实现"></a>HashMap在JDK1.7和JDK1.8中有哪些不同？ HashMap的底层实现</h2><p>在Java中，保存数据有两种比较简单的数据结构：数组和链表。</p><p>数组的特点：寻址容易，插入和删除困难</p><p>链表的特点：寻址困难，但插入和删除容易</p><p>所以我们将数组和链表结合在一起，发挥两者各自的优势，使用一种叫做拉链法的方式可以解决哈希冲突</p><ul><li><p><strong>HashMap JDK1.8之前</strong></p><p>JDK1.8之前采用的是拉链法。拉链法：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表当中即可。</p></li><li><p><strong>HashMap JDK1.8之后</strong></p><p>相比于之前的版本，jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。</p></li><li><p><strong>JDK1.7 VS JDK1.8比较</strong></p><p>JDK1.8主要解决或优化了一些问题：</p><ol><li>resize扩容优化</li><li>引入了红黑树，目的是避免单条链表过长而影响查询效率，红黑树算法</li><li>解决了多线程死循环问题，但仍是非线程安全，多线程可能会造成数据丢失</li></ol></li></ul><h2 id="什么是红黑树"><a href="#什么是红黑树" class="headerlink" title="什么是红黑树"></a>什么是红黑树</h2><p>说道红黑树先讲什么是二叉树： 二叉树简单来说就是每一个节上可以关联两个子节点</p><p><strong>红黑树</strong></p><p>红黑树是一种特殊的二叉查找树。红黑树的每个节点都有存储位表示节点的颜色，可以是红或黑</p><p>红黑树的每个结点是黑色或者红色。当是不管怎么样他的根结点是黑色。每个叶子结点（叶子结点代表终结、结尾的节点）也是黑色 [注意：这里叶子结点，是指为空(NIL或NULL)的叶子结点！]</p><p>如果一个结点是红色的，则它的子结点必须是黑色的。</p><p>每个结点到叶子结点NIL所经过的黑色结点的个数一样的。[确保没有一条路径会比其他路径长出俩倍，所以红黑树是相对接近平衡的二叉树的！]</p><p>红黑树的基本操作是<strong>添加、删除</strong>。在对红黑树进行添加或删除之后，都会用到旋转方法。为什么呢？道理很简单，添加或删除红黑树中的结点之后，红黑树的结构就发生了变化，可能不满足上面三条性质，也就不再是一颗红黑树了，而是一颗普通的树。而通过旋转和变色，可以使这颗树重新成为红黑树。简单点说，旋转和变色的目的是让树保持红黑树的特性。</p><h2 id="HashMap的put方法的具体流程？"><a href="#HashMap的put方法的具体流程？" class="headerlink" title="HashMap的put方法的具体流程？"></a>HashMap的put方法的具体流程？</h2><ul><li>当我们put的时候，首先计算 <code>key</code>的<code>hash</code>值，这里调用了 <code>hash</code>方法，<code>hash</code>方法实际是让<code>key.hashCode()</code>与<code>key.hashCode()&gt;&gt;&gt;16</code>进行异或操作，高16bit补0，一个数和0异或不变，所以 hash 函数大概的作用就是：<strong>高16bit不变，低16bit和高16bit做了一个异或，目的是减少碰撞</strong>。按照函数注释，因为bucket数组大小是2的幂，计算下标<code>index = (table.length - 1) &amp; hash</code>，如果不做 hash 处理，相当于散列生效的只有几个低 bit 位，为了减少散列的碰撞，设计者综合考虑了速度、作用、质量之后，使用高16bit和低16bit异或来简单处理减少碰撞，而且JDK8中用了复杂度 O（logn）的树结构来提升碰撞下的性能。</li></ul><h2 id="HashMap的扩容操作是怎么实现的？"><a href="#HashMap的扩容操作是怎么实现的？" class="headerlink" title="HashMap的扩容操作是怎么实现的？"></a>HashMap的扩容操作是怎么实现的？</h2><ul><li><p>在jdk1.8中，resize方法是在hashmap中的键值对大于阀值时或者初始化时，就调用resize方法进行扩容；</p></li><li><p>每次扩展的时候，都是扩展2倍</p></li><li><p>扩展后Node对象的位置要么是原位置，要么移动到原偏移量两倍的位置</p></li><li><p>在putVal()中，我们看到在这个函数里面使用到了2次resize()方法，resize()方法表示的在进行第一次初始化时会对其进行扩容，或者当该数组的实际大小大于其临界值值(第一次为12),这个时候在扩容的同时也会伴随的桶上面的元素进行重新分发，这也是JDK1.8版本的一个优化的地方，在1.7中，扩容之后需要重新去计算其Hash值，根据Hash值对其进行分发，但在1.8版本中，则是根据在同一个桶的位置中进行判断(e.hash &amp; oldCap)是否为0，重新进行hash分配后，该元素的位置要么停留在原始位置，要么移动到原始位置+增加的数组大小这个位置上</p></li></ul><h2 id="HashMap是怎么解决哈希冲突的？"><a href="#HashMap是怎么解决哈希冲突的？" class="headerlink" title="HashMap是怎么解决哈希冲突的？"></a>HashMap是怎么解决哈希冲突的？</h2><ul><li>Hash，一般翻译为“散列”，也有直接音译为“哈希”的， Hash就是指使用哈希算法是指把任意长度的二进制映射为固定长度的较小的二进制值，这个较小的二进制值叫做哈希值。</li><li>hash冲突：当两个不同的输入值，根据同一散列函数计算出相同的散列值的现象，我们就把他叫做哈希碰撞</li></ul><p><strong>总结</strong></p><p>简单总结一下HashMap是使用了哪些方法来有效解决哈希冲突的：</p><ul><li>链表法就是将相同hash值的对象组织成一个链表放在hash值对应的槽位；</li><li>开放地址法是通过一个探测算法，当某个槽位已经被占据的情况下继续查找下一个可以使用的槽位。</li></ul><h2 id="能否使用任何类作为Map的Key"><a href="#能否使用任何类作为Map的Key" class="headerlink" title="能否使用任何类作为Map的Key"></a>能否使用任何类作为Map的Key</h2><p>可以使用任何类作为Map的Key，然而在使用之前需要考虑一下几点：</p><ul><li>如果类重写了equals()方法，也应该重写hashCode()方法</li><li>类的所有实例需要遵循与euqals()和hashCode()相关的规则</li><li>如果一个类没有使用equals，不应该在hashCode()中使用它</li><li>用户自定义 Key 类最佳实践是使之为不可变的，这样 hashCode() 值可以被缓存起来，拥有更好的性能。不可变的类也可以确保 hashCode() 和 equals() 在未来不会改变，这样就会解决与可变相关的问题了。</li></ul><h2 id="为什么HashMap中String、Integer这样的包装类适合作为K？"><a href="#为什么HashMap中String、Integer这样的包装类适合作为K？" class="headerlink" title="为什么HashMap中String、Integer这样的包装类适合作为K？"></a>为什么HashMap中String、Integer这样的包装类适合作为K？</h2><ul><li>答：String、Integer等包装类的特性能够保证Hash值的不可更改性和计算准确性，能够有效的减少Hash碰撞的几率<ul><li>都是final类型，即不可变性，保证key的不可更改性，不会存在获取hash值不同的情况</li><li>内部已重写了<code>equals()</code>、<code>hashCode()</code>等方法，遵守了HashMap内部的规范（不清楚可以去上面看看putValue的过程），不容易出现Hash值计算错误的情况；</li></ul></li></ul><h2 id="如果使用Object-作为HashMap的Key，应该怎么办"><a href="#如果使用Object-作为HashMap的Key，应该怎么办" class="headerlink" title="如果使用Object 作为HashMap的Key，应该怎么办"></a>如果使用Object 作为HashMap的Key，应该怎么办</h2><p>答：重写<code>hashCode()</code>和<code>equals()</code>方法</p><p><strong>重写<code>hashCode()</code>是因为需要计算存储数据的存储位置</strong>，需要注意不要试图从散列码计算中排除掉一个对象的关键部分来提高性能，这样虽然能更快但可能会导致更多的Hash碰撞；</p><p><strong>重写<code>equals()</code>方法</strong>，需要遵守自反性、对称性、传递性、一致性以及对于任何非null的引用值x，x.equals(null)必须返回false的这几个特性，<strong>目的是为了保证key在哈希表中的唯一性</strong>；</p><h2 id="HashMap为什么不直接使用hashCode-处理后的哈希值直接作为table的下标？"><a href="#HashMap为什么不直接使用hashCode-处理后的哈希值直接作为table的下标？" class="headerlink" title="HashMap为什么不直接使用hashCode()处理后的哈希值直接作为table的下标？"></a>HashMap为什么不直接使用hashCode()处理后的哈希值直接作为table的下标？</h2><ul><li>答：<code>hashCode()</code>方法返回的是int整数类型，其范围为-(2 ^ 31)<del>(2 ^ 31 - 1)，约有40亿个映射空间，而HashMap的容量范围是在16（初始化默认值）</del>2 ^ 30，HashMap通常情况下是取不到最大值的，并且设备上也难以提供这么多的存储空间，从而导致通过<code>hashCode()</code>计算出的哈希值可能不在数组大小范围内，进而无法匹配存储位置；</li><li><strong>那怎么解决呢？</strong><ol><li>HashMap自己实现了自己的<code>hash()</code>方法，通过两次扰动使得它自己的哈希值高低位自行进行异或运算，降低哈希碰撞概率也使得数据分布更平均；</li><li>在保证数组长度为2的幂次方的时候，使用<code>hash()</code>运算之后的值与运算（&amp;）（数组长度 - 1）来获取数组下标的方式进行存储，这样一来是比取余操作更加有效率，二来也是因为只有当数组长度为2的幂次方时，h&amp;(length-1)才等价于h%length，三来解决了“哈希值与数组大小范围不匹配”的问题；</li></ol></li></ul><h2 id="HashMap-的长度为什么是2的幂次方"><a href="#HashMap-的长度为什么是2的幂次方" class="headerlink" title="HashMap 的长度为什么是2的幂次方"></a>HashMap 的长度为什么是2的幂次方</h2><ul><li>为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀，每个链表/红黑树长度大致相同。这个实现就是把数据存到哪个链表/红黑树中的算法。</li><li><strong>这个算法应该如何设计呢？</strong><ul><li>我们首先可能会想到采用%取余的操作来实现。但是，重点来了：“取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&amp;)操作（也就是说 hash%length==hash&amp;(length-1)的前提是 length 是2的 n 次方；）。” 并且 采用二进制位操作 &amp;，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是2的幂次方。</li></ul></li><li><strong>那为什么是两次扰动呢？</strong><ul><li>答：这样就是加大哈希值低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性&amp;均匀性，最终减少Hash冲突，两次就够了，已经达到了高位低位同时参与运算的目的；</li></ul></li></ul><h2 id="HashMap-与-HashTable-有什么区别？"><a href="#HashMap-与-HashTable-有什么区别？" class="headerlink" title="HashMap 与 HashTable 有什么区别？"></a>HashMap 与 HashTable 有什么区别？</h2><ol><li><p><strong>线程安全</strong>： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过 <code>synchronized</code> 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap ）；</p></li><li><p><strong>效率</strong>： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它；（如果你要保证线程安全的话就使用 ConcurrentHashMap ）；</p></li><li><p><strong>对Null key 和Null value的支持</strong>： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛NullPointerException。</p></li><li><p>初始容量大小和每次扩充容量大小的不同</p><p> ：</p><ol><li>创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。</li><li>创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小。也就是说 HashMap 总是使用2的幂作为哈希表的大小，后面会介绍到为什么是2的幂次方。</li></ol></li><li><p><strong>底层数据结构</strong>： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。</p></li><li><p>推荐使用：在 Hashtable 的类注释可以看到，Hashtable 是保留类不建议使用，推荐在单线程环境下使用 HashMap 替代，如果需要多线程使用则用 ConcurrentHashMap 替代。</p></li></ol><h2 id="HashMap-和-ConcurrentHashMap-的区别"><a href="#HashMap-和-ConcurrentHashMap-的区别" class="headerlink" title="HashMap 和 ConcurrentHashMap 的区别"></a>HashMap 和 ConcurrentHashMap 的区别</h2><ol><li>ConcurrentHashMap对整个桶数组进行了分割分段(Segment)，然后在每一个分段上都用lock锁进行保护，相对于HashTable的synchronized锁的粒度更精细了一些，并发性能更好，而HashMap没有锁机制，不是线程安全的。（JDK1.8之后ConcurrentHashMap启用了一种全新的方式实现,利用CAS算法。）</li><li>HashMap的键值对允许有null，但是ConCurrentHashMap都不允许。</li></ol><h2 id="ConcurrentHashMap-和-Hashtable-的区别？"><a href="#ConcurrentHashMap-和-Hashtable-的区别？" class="headerlink" title="ConcurrentHashMap 和 Hashtable 的区别？"></a>ConcurrentHashMap 和 Hashtable 的区别？</h2><ul><li>ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。<ul><li><strong>底层数据结构</strong>： JDK1.7的 ConcurrentHashMap 底层采用 <strong>分段的数组+链表</strong> 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 <strong>数组+链表</strong> 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；</li><li>实现线程安全的方式</li><li><strong>在JDK1.7的时候，ConcurrentHashMap（分段锁）</strong> 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。（默认分配16个Segment，比Hashtable效率提高16倍。） <strong>到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化）</strong> 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；</li><li>② <strong>Hashtable(同一把锁)</strong> :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。</li></ul></li></ul><h2 id="ConcurrentHashMap-底层具体实现知道吗？实现原理是什么？"><a href="#ConcurrentHashMap-底层具体实现知道吗？实现原理是什么？" class="headerlink" title="ConcurrentHashMap 底层具体实现知道吗？实现原理是什么？"></a>ConcurrentHashMap 底层具体实现知道吗？实现原理是什么？</h2><p><strong>JDK1.7</strong></p><ul><li><p>首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。</p></li><li><p>在JDK1.7中，ConcurrentHashMap采用Segment + HashEntry的方式进行实现，结构如下：</p></li><li><p>一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。</p><p><img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/4/13/171735524c5089b8~tplv-t2oaga2asx-watermark.awebp" alt="在这里插入图片描述"></p></li><li><p>该类包含两个静态内部类 HashEntry 和 Segment ；前者用来封装映射表的键值对，后者用来充当锁的角色；</p><p>Segment 是一种可重入的锁 ReentrantLock，每个 Segment 守护一个HashEntry 数组里得元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 锁。</p></li></ul><p><strong>JDK1.8</strong></p><ul><li>在<strong>JDK1.8中，放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现</strong>，synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。</li></ul><h1 id="辅助工具类"><a href="#辅助工具类" class="headerlink" title="辅助工具类"></a>辅助工具类</h1><h2 id="Array-和-ArrayList-有何区别？"><a href="#Array-和-ArrayList-有何区别？" class="headerlink" title="Array 和 ArrayList 有何区别？"></a>Array 和 ArrayList 有何区别？</h2><ul><li>Array 可以存储基本数据类型和对象，ArrayList 只能存储对象。</li><li>Array 是指定固定大小的，而 ArrayList 大小是自动扩展的。</li><li>Array 内置方法没有 ArrayList 多，比如 addAll、removeAll、iteration 等方法只有 ArrayList 有。</li></ul><h2 id="如何实现-Array-和-List-之间的转换？"><a href="#如何实现-Array-和-List-之间的转换？" class="headerlink" title="如何实现 Array 和 List 之间的转换？"></a>如何实现 Array 和 List 之间的转换？</h2><ul><li>Array 转 List： Arrays. asList(array) ；</li><li>List 转 Array：List 的 toArray() 方法。</li></ul><h2 id="comparable-和-comparator的区别？"><a href="#comparable-和-comparator的区别？" class="headerlink" title="comparable 和 comparator的区别？"></a>comparable 和 comparator的区别？</h2><ul><li><p>comparable接口实际上是出自java.lang包，它有一个 compareTo(Object obj)方法用来排序</p></li><li><p>comparator接口实际上是出自 java.util 包，它有一个compare(Object obj1, Object obj2)方法用来排序</p></li><li><p>一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo方法或compare方法，当我们需要对某一个集合实现两种排序方式，比如一个song对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo方法和使用自制的Comparator方法或者以两个Comparator来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的Collections.sort().</p></li></ul><h2 id="Collection-和-Collections-有什么区别？"><a href="#Collection-和-Collections-有什么区别？" class="headerlink" title="Collection 和 Collections 有什么区别？"></a>Collection 和 Collections 有什么区别？</h2><ul><li>java.util.Collection 是一个集合接口（集合类的一个顶级接口）。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式，其直接继承接口有List与Set。</li><li>Collections则是集合类的一个工具类/帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。</li></ul><h2 id="TreeMap-和-TreeSet-在排序时如何比较元素？Collections-工具类中的-sort-方法如何比较元素？"><a href="#TreeMap-和-TreeSet-在排序时如何比较元素？Collections-工具类中的-sort-方法如何比较元素？" class="headerlink" title="TreeMap 和 TreeSet 在排序时如何比较元素？Collections 工具类中的 sort()方法如何比较元素？"></a>TreeMap 和 TreeSet 在排序时如何比较元素？Collections 工具类中的 sort()方法如何比较元素？</h2><ul><li>TreeSet 要求存放的对象所属的类必须实现 Comparable 接口，该接口提供了比较元素的 compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap 要求存放的键值对映射的键必须实现 Comparable 接口从而根据键对元素进 行排 序。</li><li>Collections 工具类的 sort 方法有两种重载的形式，</li><li>第一种要求传入的待排序容器中存放的对象比较实现 Comparable 接口以实现元素的比较；</li></ul><p>？</p><ul><li><p>comparable接口实际上是出自java.lang包，它有一个 compareTo(Object obj)方法用来排序</p></li><li><p>comparator接口实际上是出自 java.util 包，它有一个compare(Object obj1, Object obj2)方法用来排序</p></li><li><p>一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo方法或compare方法，当我们需要对某一个集合实现两种排序方式，比如一个song对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo方法和使用自制的Comparator方法或者以两个Comparator来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的Collections.sort().</p></li></ul><h2 id="Collection-和-Collections-有什么区别？-1"><a href="#Collection-和-Collections-有什么区别？-1" class="headerlink" title="Collection 和 Collections 有什么区别？"></a>Collection 和 Collections 有什么区别？</h2><ul><li>java.util.Collection 是一个集合接口（集合类的一个顶级接口）。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式，其直接继承接口有List与Set。</li><li>Collections则是集合类的一个工具类/帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。</li></ul><h2 id="TreeMap-和-TreeSet-在排序时如何比较元素？Collections-工具类中的-sort-方法如何比较元素？-1"><a href="#TreeMap-和-TreeSet-在排序时如何比较元素？Collections-工具类中的-sort-方法如何比较元素？-1" class="headerlink" title="TreeMap 和 TreeSet 在排序时如何比较元素？Collections 工具类中的 sort()方法如何比较元素？"></a>TreeMap 和 TreeSet 在排序时如何比较元素？Collections 工具类中的 sort()方法如何比较元素？</h2><ul><li>TreeSet 要求存放的对象所属的类必须实现 Comparable 接口，该接口提供了比较元素的 compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap 要求存放的键值对映射的键必须实现 Comparable 接口从而根据键对元素进 行排 序。</li><li>Collections 工具类的 sort 方法有两种重载的形式，</li><li>第一种要求传入的待排序容器中存放的对象比较实现 Comparable 接口以实现元素的比较；</li><li>第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是Comparator 接口的子类型（需要重写 compare 方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java 中对函数式编程的支持）。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;集合容器概述&quot;&gt;&lt;a href=&quot;#集合容器概述&quot; class=&quot;headerlink&quot; title=&quot;集合容器概述&quot;&gt;&lt;/a&gt;集合容器概述&lt;/h1&gt;&lt;h2 id=&quot;什么是集合&quot;&gt;&lt;a href=&quot;#什么是集合&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/categories/Collection/"/>
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/tags/Collection/"/>
    
  </entry>
  
  <entry>
    <title>3.计算机网络 —— 传输层</title>
    <link href="https://leslieaibin.github.io/2021/07/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/3.%E4%BC%A0%E8%BE%93%E5%B1%82/"/>
    <id>https://leslieaibin.github.io/2021/07/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/3.%E4%BC%A0%E8%BE%93%E5%B1%82/</id>
    <published>2021-07-04T01:15:42.000Z</published>
    <updated>2021-07-04T11:58:43.423Z</updated>
    
    <content type="html"><![CDATA[<h1 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h1><h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1614160878-FiFlkq-image.png" alt="image.png"></p><p>三次握手是TCP连接的建立过程。在握手之前，主动打开连接的客户端结束CLOSE阶段，被动打开的服务器也结束CLOSE阶段，并进入LISTEN阶段。随后进入三次握手阶段：</p><ol><li>首先客户端向服务器发送一个SYN包，并等待服务器确认，其中：<ul><li>标志位为SYN，表示请求建立连接。</li><li>序号为Seq = x (x 一般为1)</li><li>随后客户端进入SYN-SENT阶段</li></ul></li><li>服务器接收到客户端发来的SYN包后，对该包进行确认后结束LISTEN阶段，并返回一段TCP报文，其中：<ul><li>标志位为SYN和ACK，表示确认客户端的报文Seq序号有效，服务器能正常接收客户端发送的数据，并同意创建新连接。</li><li>序号为Seq = y</li><li>确认号为ACK = x + 1, 表示收到客户端的序号Seq并将其值加1 作为自己确认号Ack的值，随后服务器端进入SYN-RECV阶段。</li></ul></li><li>客户端接收到发送的SYN+ACK包后，明确了从客户端到服务器的数据传输是正常的，从而结束SYN-SENT阶段。并返回最后一段报文。其中：<ul><li>标志位为ACK，表示确认收到服务器端同意连接的信号</li><li>序号为Seq = x + 1，表示收到服务器端的确认号ACK，并将其作为自己的序号值</li><li>确认号为ACK = y + 1，表示收到服务器端序号Seq， 并将其值加1作为自己的确认号ACK的值</li><li>随后客户端进入到ESTABLISHED</li></ul></li></ol><p>当服务器端收到来自客户端确认收到服务器数据的报文后，得知从服务器到客户端的数据传输是正常的，从而结束SYN-RECV阶段，进入ESTABLISHED阶段，从而完成三次握手。</p><h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210704172933433.png" alt="image-20210704172933433"></p><p>四次挥手即TCP连接的释放，这里假设客户端主动释放连接。在挥手之前主动释放连接的客户端结束ESTABLISHED阶段，随后开始四次挥手：</p><ol><li>首先客户端向服务器发送一段TCP报文表明其想要释放TCP连接，其中：<ul><li>标记位为FIN，表示请求释放连接；</li><li>序号为Seq = u;</li><li>随后客户端进入FIN-WAIT-1阶段，即半关闭阶段，并且停止向服务器端发送通信数据。</li></ul></li><li>服务器接收到客户端请求断开连接的FIN报文后，结束ESTABLISHED阶段，进入CLOSE-WAIT阶段并返回一段TCP报文，其中：<ul><li>标记位为ACK，表示接收到客户端释放连接的请求；</li><li>序号为Seq = v;</li><li>确认号为ACK = u + 1，表示是收到客户端报文的基础上，将其序号值加1作为本段报文确认号ACK的值</li><li>随后服务器开始准备释放服务器端到客户端方向上的连接</li></ul></li></ol><p>客户端收到服务器发送过来的TCP报文后，确认服务器已经收到了客户端连接释放的请求，随后客户端结束FIN-WAIT-1阶段，进入FIN-WAIT-2阶段</p><ol start="3"><li><p>服务器端在发送ACK确认报文后，服务器端会将遗留的待传数据传送给客户端，待传输完成后经过CLOSE-WAIT阶段，便做好了释放服务器端到客户端的连接准备，再向客户端发出一段TCP报文，其中：</p><ul><li>标记位为FIN和ACK，表示已经准备好释放连接了。</li><li>序号为Seq = w；</li><li>确认号ACK = u + 1，表示是在收到客户端报文的基础上，将其序号 Seq 的值加 1 作为本段报文确认号 Ack 的值。</li></ul><p>随后服务器端结束CLOSE-WAIT阶段，进入LAST-ACK阶段。并且停止向客户端发送数据。</p></li><li><p>客户端收到从服务器发来的 TCP 报文，确认了服务器已经做好释放连接的准备，于是结束 FIN-WAIT-2 阶段，进入 TIME-WAIT 阶段，并向服务器发送一段报文，其中：</p><ul><li>标记位为ACK，表示接收到服务器准备好释放连接的信号</li><li>序号为Seq = u + 1,表示是在收到服务器报文的基础上，将其确认号ACK值作为本段序号的值</li><li>确认号为ACK = w + 1，表示已经收到服务器报文的基础上，将其序号Seq的值作为本段报文确认号的值。</li></ul><p>随后客户端开始在TIME-WAIT阶段等待2MSL。服务器端收到从客户端发出的TCP报文之后结束LAST-ACK阶段，进入CLOSED阶段。由此正式确认关闭服务器到客户端方向上的连接。客户端等待完 2 MSL 之后，结束 TIME-WAIT 阶段，进入 CLOSED 阶段，由此完成「四次挥手」。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;传输层&quot;&gt;&lt;a href=&quot;#传输层&quot; class=&quot;headerlink&quot; title=&quot;传输层&quot;&gt;&lt;/a&gt;传输层&lt;/h1&gt;&lt;h2 id=&quot;三次握手&quot;&gt;&lt;a href=&quot;#三次握手&quot; class=&quot;headerlink&quot; title=&quot;三次握手&quot;&gt;&lt;/a&gt;三次握</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://leslieaibin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="计算机网络" scheme="https://leslieaibin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>2.计算机网络 —— 应用层</title>
    <link href="https://leslieaibin.github.io/2021/07/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/2.%E5%BA%94%E7%94%A8%E5%B1%82/"/>
    <id>https://leslieaibin.github.io/2021/07/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/2.%E5%BA%94%E7%94%A8%E5%B1%82/</id>
    <published>2021-07-04T01:15:42.000Z</published>
    <updated>2021-07-04T11:58:40.382Z</updated>
    
    <content type="html"><![CDATA[<h1 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h1><h2 id="HTTP头部包含那些信息"><a href="#HTTP头部包含那些信息" class="headerlink" title="HTTP头部包含那些信息"></a>HTTP头部包含那些信息</h2><p>HTTP头部本质上是一个传递额外重要信息的键值对。主要分为：<strong>通用头部、请求头部、响应头部、实体头部</strong></p><h3 id="通用头部"><a href="#通用头部" class="headerlink" title="通用头部"></a>通用头部</h3><table><thead><tr><th>协议头</th><th>说明</th><th>举例</th></tr></thead><tbody><tr><td>Cache-Control</td><td>用来指定当前的请求/回复中是否使用缓存机制</td><td>Cache-Control:no-store</td></tr><tr><td>Connection</td><td>客户端（浏览器）想要优先使用的连接类型</td><td>Connetion: keep-alive(Upgrade)</td></tr><tr><td>Date</td><td>报文创建时间</td><td>Date：Dec,26 2015 17:30:00 GMT</td></tr><tr><td>Trailer</td><td>会实现说明在报文主体后记录那些首部字段，该首部字段可以使用在HTTP/1.1版本分块传输编码时</td><td>Trailer:Expiress</td></tr><tr><td>Transfer-Encoding</td><td>用来改变报文格式</td><td>Transfer-Encoding: chunked</td></tr><tr><td>Upgrade</td><td>要求服务器升级到一个高版本协议</td><td>Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11</td></tr><tr><td>Via</td><td>告诉服务器，这个请求是由哪些代理发出的</td><td>Via: 1.0 fred, 1.1 <a href="http://itbilu.com.com/">itbilu.com.com</a> (Apache/1.1)</td></tr><tr><td>Warning</td><td>一个一般性的警告，表示在实体内容中可能存在错误</td><td>Warning: 199 Miscellaneous warning</td></tr></tbody></table><h3 id="请求头部"><a href="#请求头部" class="headerlink" title="请求头部"></a>请求头部</h3><table><thead><tr><th>协议头</th><th>说明</th><th>举例</th></tr></thead><tbody><tr><td>Accept</td><td>告诉服务器自己允许哪些媒体类型</td><td>Accept: text/plain</td></tr><tr><td>Accept-Charset</td><td>浏览器申明可接受的字符集</td><td>Accept-Charset: utf-8</td></tr><tr><td>Accept-Encoding</td><td>浏览器申明自己接收的编码方法</td><td>Accept-Encoding: gzip, deflate</td></tr><tr><td>Accept-Language</td><td>浏览器可接受的响应内容语言列表</td><td>Accept-Language: en-US</td></tr><tr><td>Authorization</td><td>用于表示 HTTP 协议中需要认证资源的认证信息</td><td></td></tr><tr><td>Expect</td><td>表示客户端要求服务器做出特定的行为</td><td>Expect: 100-continue</td></tr><tr><td>From</td><td>发起此请求的用户的邮件地址</td><td>From: <a href="mailto:&#117;&#115;&#101;&#114;&#64;&#x69;&#116;&#98;&#105;&#108;&#x75;&#46;&#x63;&#x6f;&#109;">&#117;&#115;&#101;&#114;&#64;&#x69;&#116;&#98;&#105;&#108;&#x75;&#46;&#x63;&#x6f;&#109;</a></td></tr><tr><td>Host</td><td>表示服务器的域名以及服务器所监听的端口号</td><td>Host: <a href="http://www.itbilu.com/">www.itbilu.com:80</a></td></tr><tr><td>If-XXX</td><td>条件请求</td><td>If-Modified-Since: Dec, 26 Dec 2015 17:30:00 GMT</td></tr><tr><td>Max-Forwards</td><td>限制该消息可被代理及网关转发的次数</td><td>Max-Forwards: 10</td></tr><tr><td>Range</td><td>表示请求某个实体的一部分，字节偏移以 0 开始</td><td>Range: bytes=500-999</td></tr><tr><td>Referer</td><td>表示浏览器所访问的前一个页面，可以认为是之前访问页面的链接将浏览器带到了当前页面</td><td>Referer: <a href="http://itbilu.com/nodejs">http://itbilu.com/nodejs</a></td></tr><tr><td>User-Agent</td><td>浏览器的身份标识字符串</td><td>User-Agent: Mozilla/……</td></tr></tbody></table><h3 id="响应头部"><a href="#响应头部" class="headerlink" title="响应头部"></a>响应头部</h3><table><thead><tr><th>协议头</th><th>说明</th><th>举例</th></tr></thead><tbody><tr><td>Accept-Ranges</td><td>字段的值表示可用于定义范围的单位</td><td>Accept-Ranges: bytes</td></tr><tr><td>Age</td><td>创建响应的时间</td><td>Age：5744337</td></tr><tr><td>ETag</td><td>唯一标识分配的资源</td><td>Etag：W/“585cd998-7c0f”</td></tr><tr><td>Location</td><td>表示重定向后的 URL</td><td>Location: <a href="http://www.zcmhi.com/archives/94.html">http://www.zcmhi.com/archives/94.html</a></td></tr><tr><td>Retry-After</td><td>告知客户端多久后再发送请求</td><td>Retry-After: 120</td></tr><tr><td>Server</td><td>告知客户端服务器信息</td><td>Server: Apache/1.3.27 (Unix) (Red-Hat/Linux)</td></tr><tr><td>Vary</td><td>缓存控制</td><td>Vary: Origin</td></tr></tbody></table><h3 id="实体头部"><a href="#实体头部" class="headerlink" title="实体头部"></a>实体头部</h3><table><thead><tr><th>协议头</th><th>说明</th><th>举例</th></tr></thead><tbody><tr><td>Allow</td><td>对某网络资源的有效的请求行为，不允许则返回405</td><td>Allow: GET, HEAD</td></tr><tr><td>Content-encoding</td><td>返回内容的编码方式</td><td>Content-Encoding: gzip</td></tr><tr><td>Content-Length</td><td>返回内容的字节长度</td><td>Content-Length: 348</td></tr><tr><td>Content-Language</td><td>响应体的语言</td><td>Content-Language: en,zh</td></tr><tr><td>Content-Location</td><td>请求资源可替代的备用的另一地址</td><td>Content-Location: /index.htm</td></tr><tr><td>Content-MD5</td><td>返回资源的MD5校验值</td><td>Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ==</td></tr><tr><td>Content-Range</td><td>在整个返回体中本部分的字节位置</td><td>Content-Range: bytes 21010-47021/47022</td></tr><tr><td>Content-Type</td><td>返回内容的MIME类型</td><td>Content-Type: text/html; charset=utf-8</td></tr><tr><td>Expires</td><td>Expires</td><td>Expires: Thu, 01 Dec 2010 16:00:00 GMT</td></tr><tr><td>Last-Modified</td><td>请求资源的最后修改时间</td><td>Last-Modified: Tue, 15 Nov 2010 12:45:26 GMT</td></tr></tbody></table><h2 id="Keep-Alive-和非-Keep-Alive区别，对服务性能有影响么"><a href="#Keep-Alive-和非-Keep-Alive区别，对服务性能有影响么" class="headerlink" title="Keep-Alive 和非 Keep-Alive区别，对服务性能有影响么"></a>Keep-Alive 和非 Keep-Alive区别，对服务性能有影响么</h2><p>在早期的<strong>HTTP/1.0</strong>中，浏览器每次发起请求都要与服务器创建一个新的TCP连接，服务器完成请求立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。然而创建和关闭连接的过程需要<strong>消耗资源和时间</strong>，为了减少资源消耗，缩短响应时间，就需要重用连接。在HTTP/1.1版本中默认使用持久连接，在此之前的HTTP版本的默认连接都是使用非持久连接，如果想要在旧版本的HTTP协议上维持持久连接，则需要指定<code>connection</code>的首部字段的值为Keep-Alive来告诉对方这个请求响应完成后不要关闭，下次咱们还用这几个请求继续交流：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210610235948369.png" alt="image-20210610235948369"></p><p>对于非 Keep=Alive 来说，必须为每一个请求的对象建立和维护一个全新的连接。对于每一个这样的连接，客户机和服务器都要分配 TCP 的缓冲区和变量，这给服务器带来的严重的负担，因为一台 Web 服务器可能同时服务于数以百计的客户机请求。在 Keep-Alive 方式下，服务器在响应后保持该 TCP 连接打开，在同一个客户机与服务器之间的后续请求和响应报文可通过相同的连接进行传送。甚至位于同一台服务器的多个 Web 页面在从该服务器发送给同一个客户机时，可以在单个持久 TCP 连接上进行。</p><p>然而，Keep-Alive 并不是没有缺点的，当长时间的保持 TCP 连接时容易<strong>导致系统资源被无效占用</strong>，若对 Keep-Alive 模式配置不当，将有可能比非 Keep-Alive 模式带来的损失更大。因此，我们需要正确地设置 keep-alive timeout 参数，当 TCP 连接在传送完最后一个 HTTP 响应，该连接会保持 keepalive_timeout 秒，之后就开始关闭这个链接。</p><h2 id="HTTP-长连接短连接使用场景是什么"><a href="#HTTP-长连接短连接使用场景是什么" class="headerlink" title="HTTP 长连接短连接使用场景是什么"></a>HTTP 长连接短连接使用场景是什么</h2><p><strong>长连接：</strong>多用于操作频繁，点对点的通讯，而且客户端连接数目较少的情况。例如即时通讯、网络游戏等。</p><p><strong>短连接：</strong>用户数目较多的Web网站的 HTTP 服务一般用短连接。例如京东，淘宝这样的大型网站一般客户端数量达到千万级甚至上亿，若采用长连接势必会使得服务端大量的资源被无效占用，所以一般使用的是短连接。</p><h2 id="HTTP方法"><a href="#HTTP方法" class="headerlink" title="HTTP方法"></a>HTTP方法</h2><p>http/1.0定义了三种请求方法： <strong>GET、POST和HEAD方法</strong></p><p>http/1.1增加了六种请求方法：<strong>OPTIONS、PUT、PATCH、DELETE、TRACE和CONNECT方法</strong></p><ul><li><p><strong>GET</strong></p><p>请求指定的页面信息，并返回具体内容，通常只用于读取数据</p></li><li><p><strong>HEAD</strong></p><p>类似于GET请求，只不过返回的响应中没有具体的内容，用于获取报头</p></li><li><p><strong>POST</strong></p><p>向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立或已有资源的更改。</p></li><li><p><strong>PUT</strong></p><p>替换指定的资源，没有的话就新增</p></li><li><p><strong>DELETE</strong></p><p>请求服务器删除URL标识的资源数据</p></li><li><p><strong>CONNECT</strong></p><p>将服务器作为代理，让服务器代替用户进行访问</p></li><li><p><strong>OPTIONS</strong></p><p>向服务发送该方法，会返回对指定资源所支持的HTTP请求方法</p></li><li><p><strong>TRACE</strong></p><p>回显服务器收到的请求数据，即服务器返回自己收到的数据，主要用于测试和诊断</p></li><li><p><strong>PATCH</strong></p><p>是对PUT方法的补充，用来对已知资源进行局部更新。</p></li></ul><h2 id="GET和POST的区别"><a href="#GET和POST的区别" class="headerlink" title="GET和POST的区别"></a>GET和POST的区别</h2><ul><li>get提交的数据会放在URL之后，并且请求参数会被完整的保留在浏览器的记录里，由于参数直接暴露在URL中，可能会存在安全问题，因此往往用于获取资源信息。而PSOT参数放在请求主体中，并且参数不会被保留，相较于get方法，post方法更安全，主要用于修改服务器上的资源。</li><li>get请求只支持URL编码，post请求支持多种编码格式</li><li>get只支持ASCII字符格式的参数，而post方法没有限制</li><li>get提交的数据大小有限制（这里所说的限制是针对浏览器而言），而POST方法的数据没限制</li><li>get方法需要使用Request.QueryString 来去的变量的值，而post方式通过Request.From来获取。</li><li>get方法产生一个TCP数据包，post方法产生两个（并不是所有的浏览器都产生两个）</li></ul><p>对于GET方式的请求，浏览器会把http header和data一并发送出去，服务端响应200，请求成功。</p><p>对于POST方式的请求，浏览器会先发送http header给服务端，告诉服务端等一下会有数据过来，服务端响应100 continue，告诉浏览器我已经准备接收数据，浏览器再post发送一个data给服务端，服务端响应200，请求成功。</p><h2 id="GET的长度限制是多少？"><a href="#GET的长度限制是多少？" class="headerlink" title="GET的长度限制是多少？"></a>GET的长度限制是多少？</h2><p>URL构成：协议 + :// + 认证信息 + @ + 域名 or IP地址 + 端口号 + 资源路径 + ? + 查询字符串 + # + 片段标识符;</p><p>所以这里说整个URL 的长度，就是指包含上述所有组成部分在内的总长度，数据部分就是指查询字符串。</p><p>HTTP中的GET方法是通过URL传递数据的，而URL本身并没有对数据的长度进行限制，<strong>真正限制GET长度的是浏览器</strong>，例如IE浏览器对URL的最大限制为2000多字符，大概2KB左右。像 Chrome, FireFox 等浏览器能支持的 URL 字符数更多，其中 FireFox 中 URL 最大长度限制为 65536 个字符，Chrome 浏览器中 URL 最大长度限制为 8182 个字符。并且这个长度不是只针对数据部分，而是针对整个 URL 而言，在这之中，不同的服务器同样影响 URL 的最大长度限制。因此对于特定的浏览器，GET的长度限制不同。</p><p>由于 POST 方法请求参数在请求主体中，理论上讲<strong>，post 方法是没有大小限制的，而真正起限制</strong></p><h2 id="HTTP-与-HTTPs-的工作方式【建立连接的过程】"><a href="#HTTP-与-HTTPs-的工作方式【建立连接的过程】" class="headerlink" title="HTTP 与 HTTPs 的工作方式【建立连接的过程】"></a>HTTP 与 HTTPs 的工作方式【建立连接的过程】</h2><ul><li>HTTP</li></ul><p><strong>HTTP（Hyper Text Transfer Protocol: 超文本传输协议）</strong>是一种简单的请求—响应协议， 被用于在Web浏览器和网站服务之间传递消息。HTTP使用Tcp(而不是UDP)作为它的支撑运输层协议。其默认工作在TCP协议80端口，HTTP客户端发起一个与服务器的TCP连接，一旦连接建立。客户机从套接字接口发送HTTP请求报文和接收HTTP响应报文。类似的，服务器也是从套接字接口接收HTTP请求报文和发送HTTP响应报文。其通信内容以明文的方式发送，不通过任何方式的数据加密。当通信结束时，客户端与服务端关闭连接。</p><ul><li>HTTPS</li></ul><p>HTTPS（Hyper Text Transfer Protocol over Secure Socket Layer）是以安全为目标的 HTTP 协议，在 HTTP 的基础上通过传输加密和身份认证的方式保证了传输过程的安全性。其工作流程如下：</p><p>① 客户端发起一个 HTTPS 请求，并连接到服务器的 443 端口，发送的信息主要包括自身所支持的算法列表和密钥长度等；</p><p>② 服务端将自身所支持的所有加密算法与客户端的算法列表进行对比并选择一种支持的加密算法，然后将它和其它密钥组件一同发送给客户端。</p><p>③ 服务器向客户端发送一个包含数字证书的报文，该数字证书中包含证书的颁发机构、过期时间、服务端的公钥等信息。</p><p>④ 最后服务端发送一个完成报文通知客户端 SSL 的第一阶段已经协商完成。</p><p>⑤ SSL 第一次协商完成后，客户端发送一个回应报文，报文中包含一个客户端生成的随机密码串，称为 pre_master_secre，并且该报文是经过证书中的公钥加密过的。</p><p>⑥ 紧接着客户端会发送一个报文提示服务端在此之后的报文是采用pre_master_secre 加密的。</p><p>⑦ 客户端向服务端发送一个 finish 报文，这次握手中包含第一次握手至今所有报文的整体校验值，最终协商是否完成取决于服务端能否成功解密。</p><p>⑧ 服务端同样发送与第 ⑥ 步中相同作用的报文，已让客户端进行确认，最后发送 finish 报文告诉客户端自己能够正确解密报文。</p><p>当服务端和客户端的 finish 报文交换完成之后，SSL 连接就算建立完成了，之后就进行和 HTTP 相同的通信过程，唯一不同的是在 HTTP 通信过程中并不是采用明文传输，而是采用对称加密的方式，其中对称密钥已经在 SSL 的建立过程中协商好了。</p><p>HTTP:默认用TCP协议的80端口（可以改），通信内容明文传输，不处理<br>HTTPS:</p><p>请求：443端口，支持算法，密钥长度<br>理解：两网友约定明天出去玩，玩什么呢？爬山，游泳，游乐园选一个吧<br>响应：选择一种，将其密钥组件一起发给客户端<br>理解：我们去游乐园吧<br>响应：数字证书<br>理解：为了证明我是个合法公民。给你看看我的身份证，身份证是XX公安局发的，身份证号是XX,10年后过期<br>响应：协商完成<br>理解：OK，我同意去游乐园<br>生成随机密码串，并使用证书公钥加密<br>理解：为了互相证明我们是协商的网友，每个句尾加个“喵”<br>请求：尝试使用加密串加密<br>理解：我们试试，我是客户端喵<br>响应：发送finish结束<br>理解：我说完了你试试<br>响应：和客户端相同进行加密发送<br>理解：服务端喵</p><h2 id="HTTPS-和-HTTP-的区别"><a href="#HTTPS-和-HTTP-的区别" class="headerlink" title="HTTPS 和 HTTP 的区别"></a>HTTPS 和 HTTP 的区别</h2><ul><li>http协议以明文方式发送内容，数据都是未加密的，安全性较差。https数据传输过程是加密的，安全性较好。</li><li>http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80端口，后者是443端口</li><li>https协议需要到数字认证机构（Certificate Authority, CA）申请证书，一般需要一定的费用。</li><li>http页面响应比https快，主要因为HTTP使用三次握手建立连接，客户端和服务器需要握手三次，而HTTPS除了TCP的3次握手，还需要经历一个SSL协商过程。</li></ul><p>SSL(Secure Sockets Layer 安全套接层),及其继任者传输层安全(Transport Layer Security，TLS)是为网络通信提供安全及数据完整性的一种安全协议。如今被广泛使用，如网页，电子邮件，互联网传真，即时消息和语音在IP电话（VoIP）。其中网站是通过使用TLS来保护WEB浏览器与服务器之间的通信安全。</p><h2 id="HTTPS的加密方式"><a href="#HTTPS的加密方式" class="headerlink" title="HTTPS的加密方式"></a>HTTPS的加密方式</h2><p>https采用对称加密和非对称假期相结合的方式，首先使用SSL/TLS协议进行加密传输，为了弥补非对称加密的缺点，https采用证书来进一步加强非对称加密的安全性，通过非对称加密，客户端和服务端协商好之后进行通信传输的对称秘钥，后续的所有信息都通过该对称秘钥进行加密解密，完成整个https的流程。</p><h2 id="HTTP-是不保存状态的协议-如何保存用户状态"><a href="#HTTP-是不保存状态的协议-如何保存用户状态" class="headerlink" title="HTTP 是不保存状态的协议,如何保存用户状态"></a>HTTP 是不保存状态的协议,如何保存用户状态</h2><p>假定某个特定的客户机在短时间内两次请求同一个对象，服务器并不会因为刚刚为该用户提供了该对象不再做出反应，而是重新发送该对象，就像该服务器已经完全忘记不就之前所做过的是一样。因为一个HTTP服务器并不保存关于客户机的任何信息，所以我们说http是一个无状态协议。</p><ul><li><p>基于Session实现的会话保持</p><p>在客户端第一次向服务器发送HTTP请求后，服务器会创建一个Session对象并将客户端的身份信息以键值对的形式存储下来，然后分配一个会话标识（Sessionld）客户端，这个会话标识一般保存在客户端Cookie中，之后每次该浏览器发送http请求都会带上Cookie中的Sessionld到服务器，服务器根据会话标识就可以将之前的状态信息与会话联系起来，从而实现会话保持。</p><p>优点：安全性高，因为状态信息保存在服务端</p><p>缺点：由于大型网站往往采用分布式服务器，浏览器发送的http请求一般要先通过负载均衡器才能到达具体的后台服务器，倘若同一个浏览器两次 HTTP 请求分别落在不同的服务器上时，基于 Session 的方法就不能实现会话保持了。</p><p><strong>【解决方法：采用中间件，例如 Redis，我们通过将 Session 的信息存储在 Redis 中，使得每个服务器都可以访问到之前的状态信息】</strong></p></li><li><p>基于Cookie实现的会话保持</p><p>当服务器发送响应消息时，在http响应头中设置Set-Cookie字段，用来存储客户端的状态信息。客户端解析出http响应头中的字段信息，并根据其生命周期创建不同的Cookie，这样一来每次浏览器发送http请求的时候都会带上Cookie字段，从而实现状态保持。基于 Cookie 的会话保持与基于 Session 实现的会话保持最主要的区别是前者完全将会话状态信息存储在浏览器 Cookie 中。</p><p>优点：服务器不用保存状态信息， 减轻服务器存储压力，同时便于服务端做水平拓展。</p><p>缺点：该方式不够安全，因为状态信息存储在客户端，这意味着不能在会话中保存机密数据。除此之外，浏览器每次发起 HTTP 请求时都需要发送额外的 Cookie 到服务器端，会占用更多带宽。</p></li></ul><h2 id="状态码"><a href="#状态码" class="headerlink" title="状态码"></a>状态码</h2><p>HTTP状态码由三个十进制数字组成，第一个数字定义了状态码的类型，后两个并没有起到分类作用。HTTP状态码共有5中类型。</p><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul><li><p>1xx:</p><p>指示信息–表示请求正在处理</p></li><li><p>2xx:</p><p>成功–表示请求已被成功处理完毕</p></li><li><p>3xx:</p><p>重定向–要完成的请求需要进行附加操作</p></li><li><p>4xx:</p><p>客户端错误–请求有语法错误或者请求无法实现，服务器无法处理请求</p></li><li><p>5xx：</p><p>服务器端错误–服务器处理请求出现错误</p></li></ul><h3 id="相应的HTTP状态码列表"><a href="#相应的HTTP状态码列表" class="headerlink" title="相应的HTTP状态码列表"></a>相应的HTTP状态码列表</h3><ul><li><p>100： Continue</p><p>继续，客户端继续处理请求。</p></li><li><p>101：Switching Protocol</p><p>切换协议，服务器根据客户端的请求切换到更高的协议</p></li><li><p>200：OK</p><p>请求成功。请求所希望的响应头或数据体将随此响应返回</p></li><li><p>201：Created</p><p>请求以实现，并且有一个新的资源已经依据需求而建立</p></li><li><p>202： Accepted</p><p>请求已接受，已经接受请求但还未处理完成</p></li><li><p>203：Non-Authoritative Information</p><p>非授权信息，请求成功。但返回的meta信息不再原始的服务器中，而是一个副本。</p></li><li><p>204： No Content</p><p>无内容，服务器成功处理了请求，但不需要返回任何实体内容</p></li><li><p>205：Reset Content </p><p>重置内容，与204类似，不同点是返回此状态码的响应要求请求者重置文档视图</p></li><li><p>206：Partial Content</p><p>部分内容。服务器成功处理了部分Get请求。</p></li><li><p>300：Multiple Choices</p><p> 多种选择。被请求的资源有一系列可供选择的回馈信息，用户或浏览器能够自行选择一个首选地址进行重定向</p></li><li><p>301：Moved Permanently</p><p>永久移动。请求的资源已被永久地移动到新 URI，返回信息会包含新的 URI，浏览器会自动定向到新 URI</p></li><li><p>302：Found</p><p> 临时移动。与 301 类似。但资源只是临时被移动，客户端应继续使用原有URI</p></li><li><p>303： See Other</p><p>查看其它地址。与301类似。使用GET和POST请求查看</p></li><li><p>304： Not Modified</p><p>未修改。如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码</p></li><li><p>305：Use Proxy</p><p>使用代理。被请求的资源必须通过指定的代理才能被访问</p></li><li><p>306： Unused</p><p> 在最新版的规范中，306状态码已经不再被使用</p></li><li><p>307： Temporary Redirect</p><p>临时重定向。请求的资源现在临时从不同的URI 响应请求，与302类似</p></li><li><p>400：Bad Request</p><p>客户端请求的语法错误，服务器无法理解；请求的参数有误</p></li><li><p>401：Unauthorized</p><p>当前请求需要用户验证</p></li><li><p>402： Payment Required</p><p>该状态码是为了将来可能的需求而预留的</p></li><li><p>403： Forbidden</p><p> 服务器已经理解请求，但是拒绝执行它</p></li><li><p>404：Not Found</p><p>请求失败，请求所希望得到的资源未被在服务器上发现</p></li><li><p>405： Method Not Allowed</p><p>客户端请求中的方法被禁止</p></li><li><p>406：Not Acceptable</p><p>请求的资源的内容特性无法满足请求头中的条件，因而无法生成响应实体</p></li><li><p>407：Proxy Authentication Required</p><p>与401响应类似，只不过客户端必须在代理服务器上进行身份验证</p></li><li><p>408： Request Time-out</p><p>请求超时。服务器等待客户端发送的请求时间过长，超时</p></li><li><p>409：Conflict</p><p>由于和被请求的资源的当前状态之间存在冲突，请求无法完成</p></li><li><p>410： Gone</p><p>被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址</p></li><li><p>411： Length Required</p><p>服务器拒绝在没有定义 Content-Length 头的情况下接受请求</p></li><li><p>412： Precondition Failed</p><p>客户端请求信息的先决条件错误</p></li><li><p>413：Request Entity Too Large</p><p>服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围</p></li><li><p>414：Request-URI Too Large</p><p>请求的 URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务</p></li><li><p>415：Unsupported Media Type</p><p> 服务器无法处理请求附带的媒体格式</p></li><li><p>416：Requested range not satisfiable</p><p>客户端请求的范围无效</p></li><li><p>417：Expectation Failed</p><p>服务器无法满足Expect的请求头信息</p></li><li><p>500：Internal Server</p><p> 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理</p></li><li><p>501：Not Implemented</p><p>服务器不支持当前请求所需要的某个功能</p></li><li><p>502：Bad Gateway</p><p>作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到无效的响应</p></li><li><p>503：Service Unavailable</p><p>由于临时的服务器维护或者过载，服务器当前无法处理请求，一段时间后可能恢复正常</p></li><li><p>504： Gateway Time-out</p><p>充当网关或代理的服务器，未及时从远端服务器获取请求</p></li><li><p>505：HTTP Version not supported</p><p>服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本</p></li></ul><p>200 请求成功</p><p>204 请求成功但无内容返回</p><p>206 范围请求成功</p><p>301 永久重定向； 30(2|3|7)临时重定向，语义和实现有略微区别；</p><p>304 带if-modified-since 请求首部的条件请求，条件没有满足</p><p>400 语法错误（前端挨打）</p><p>401 需要认证信息</p><p>403 拒绝访问</p><p>404 找不到资源</p><p>412 除if-modified-since 以外的条件请求，条件未满足</p><p>500 服务器错误（后端挨打）</p><p>503 服务器宕机了（DevOps or IT 挨打）</p><h2 id="HTTP-1-1-和-HTTP-1-0-的区别"><a href="#HTTP-1-1-和-HTTP-1-0-的区别" class="headerlink" title="HTTP/1.1 和 HTTP/1.0 的区别"></a>HTTP/1.1 和 HTTP/1.0 的区别</h2><ul><li><p><strong>长链接</strong></p><p>HTTP/1.0默认浏览器和服务器之间保持短暂连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成后立即断开TCP连接。HTTP/1.1版本的默认使用的是持久连接，其支持在同一个TCP请求中传送多个HTTP请求和响应。此之前的HTTP版本的默认连接都是使用非持久连接，如果想要在旧版的HTTP协议维持持久连接，则需要指定Connection的首部字段的值为Keep-alive.</p></li><li><p><strong>缓存处理</strong></p><p>1.1请求头中增加了一些和缓存的相关的字段，比如IF-MATCH，可以更加灵活的控制缓存策略。</p><p>HTTP缓存</p><p>访问一个网站的时候，浏览器会向服务器请求很多资源，比如css、js这些静态文件，如果每次请求都要让服务器发送所有资源，请求多了会对服务器造成很大的压力</p><p>HTTP为了解决这个问题，就引入了缓存，缓存有两种策略：</p><p>1、强缓存：每次请求资源的时候会先去缓存里找，如果有就直接用，没有才去向服务器请求资源</p><p>2、对比缓存：每次请求资源的时候先发个消息和服务器确认一下，如果服务器返回304，说明缓存可以用，浏览器就会去缓存里寻找资源</p></li><li><p><strong>节约带宽</strong></p><p>1.0默认把资源相关的整个对象都发给客户端，但是可能客户端不需要所有的信息，这就浪费了带宽资源，1.1的请求头引入了Range头域，可以只请求部分资源，比如断点下载的时候可以用Range</p></li><li><p><strong>错误通知的管理</strong></p><p>1.1增加了一些错误的状态响应码（24个），比如410表示请求的资源已经被永远删除</p></li><li><p>Host<strong>请求头</strong></p><p>1.0的时候每台服务器都绑定唯一的IP地址，后面出现了虚拟主机，一个服务器可以有多个虚拟主机，一起共享同一个IP地址，所以为了区分不同虚拟主机，1.1添加了host请求头部</p></li></ul><h2 id="HTTP-1-X-和-HTTP-2-0-的区别"><a href="#HTTP-1-X-和-HTTP-2-0-的区别" class="headerlink" title="HTTP/1.X 和 HTTP/2.0 的区别"></a>HTTP/1.X 和 HTTP/2.0 的区别</h2><ul><li><p><strong>二进制传送</strong></p><p>之前的版本数据都是用文本传输，因为文本有多种格式，所以不能很好地适应所有的场景，2.0传送的是二进制，相当于统一了格式</p></li><li><p><strong>多路复用</strong></p><p>1.1虽然默认复用TCP连接，但是每个请求时串行执行的，如果前面的请求超时，后面的请求智能等待（也就是线头阻塞）2.0的时候每个请求有自己的ID，多个请求可以在同一TCP连接上并行执行，不会相互影响。</p></li><li><p><strong>header压缩</strong></p><p>每次进行HTTP请求响应的时候，头部里很多的字段都是重复的，在2.0中，将字段记录到一张表中，头部只需要存放字段对应的编码就行，用的时候只需要拿着编号去表里查找就行，减少传输的数据量。</p></li><li><p><strong>服务器推送</strong></p><p>服务器会在客户端没发起请求的时候会主动推送一些需要的资源，比如客户端请求一个html文件，服务器发送完之后会把和这个html相关的静态文件也发送给客户端，当客户端准备向服务器请求静态文件的时候，就可以直接缓存中获取，就不需要在发起请求了。</p></li></ul><h2 id="HTTP-3-了解吗"><a href="#HTTP-3-了解吗" class="headerlink" title="HTTP/3 了解吗"></a>HTTP/3 了解吗</h2><p><strong>HTTP2.0存在的问题</strong></p><p>我们知道，传统Web平台的数据传输都基于TCP协议，而TCP协议在创建之前不可以避免的需要三次握手，如果需要提高数据交互的安全性，即增加传输层安全协议（TLS），还会增加更多的握手次数。HTTP从1.0到2.0，其传输层都基于TCP协议的。即使是带来了巨大性能提升的HTTP2，也无法完全解决TCP协议存在的固有问题。此外，HTTP/2 多路复用只是减少了连接数，其队头的拥塞问题并没有完全解决，倘若 TCP 丢包率过大，则 HTTP/2 的表现将不如 HTTP/1.1。</p><p><strong>QUIC协议</strong></p><p>QUIC（Quick UDP Internet COnnections)，直译为快速UDP网络连接，是谷歌制定的一种基于UDP的低延迟传输协议。其主要目的是解决采用传输层TCP协议存在的问题，同时满足传输层和应用层对多连接，低延迟等的需求。该协议融合了TCP，TLS，HTTP2等协议的特性，并基于 UDP传输。该协议带来的主要提升有：</p><p>低延迟连接。当客户端第一次连接服务器时，QUIC 只需要 1 RTT（Round-Trid Time）延迟就可以建立安全可靠的连接（采用 TLS 1.3 版本），相比于 TCP + TLS 的 3 次 RTT 要更加快捷。之后，客户端可以在本地缓存加密的认证信息，当再次与服务器建立连接时可以实现 0 RTT 的连接建立延迟。</p><p>QUIC 复用了 HTTP/2 协议的多路复用功能，由于 QUIC 基于 UDP，所以也避免了 HTTP/2存在的队头阻塞问题。</p><p>基于 UDP 协议的 QUIC 运行在用户域而不是系统内核，这使得 QUIC 协议可以快速的更新和部署，从而很好地解决了 TPC 协议部署及更新的困难。</p><p>QUIC 的报文是经过加密和认证的，除了少量的报文，其它所有的 QUIC 报文头部都经过了认证，报文主体经过了加密。只要有攻击者篡改 QUIC 报文，接收端都能及时发现。</p><p>具有向前纠错机制，每个数据包携带了除了本身内容外的部分其他数据包的内容，使得在出现少量丢包的情况下，尽量地减少其它包的重传次数，其通过牺牲单个包所携带的有效数据大小换来更少的重传次数，这在丢包数量较小的场景下能够带来一定程度的性能提升。</p><p><strong>HTTP3</strong></p><p>HTTP3是在QUIC基础上发展起来的，其底层使用UDP进行数据传输，上层仍然使用HTTP2，在UDP与HTTP2之间存在一个QUIC层，其中TLS加密过程在该层进行处理。HTTP3主要有以下几个特点：</p><p>① 使用 UDP 作为传输层进行通信；</p><p>② 在 UDP 之上的 QUIC 协议保证了 HTTP/3 的安全性。QUIC 在建立连接的过程中就完成了 TLS 加密握手；</p><p>③ 建立连接快，正常只需要 1 RTT 即可建立连接。如果有缓存之前的会话信息，则直接验证和建立连接，此过程 0 RTT。建立连接时，也可以带有少量业务数据；</p><p>④ 不和具体底层连接绑定，QUIC 为每个连接的两端分别分配了一个唯一 ID，上层连接只认这对逻辑 ID。网络切换或者断连时，只需要继续发送数据包即可完成连接的建立；</p><p>⑤ 使用 QPACK 进行头部压缩，因为 在 HTTP/2 中的 HPACK 要求传输过程有序，这会导致队头阻塞，而 QPACK 不存在这个问题。</p><p>最后我们使用一张图来清晰的表示出 HTTP 协议的发展变化：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210703151748265.png" alt="image-20210703151748265"></p><h2 id="DNS-的作用和原理"><a href="#DNS-的作用和原理" class="headerlink" title="DNS 的作用和原理"></a>DNS 的作用和原理</h2><p><code>DNS（Domain Name System)</code>是域名系统的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，用于TCP/IP网络。</p><p><strong>DNS的作用</strong></p><p>通常我们有两种方式识别主机：通过主机名或者IP地址。人们喜欢便于记忆的主机名表示，而路由器则喜欢定长的、有层次结构的IP地址。为了满足这些不同的偏好，我们需要一种能够进行主机名到IP地址转换的目录服务，域名系统作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网。</p><p><strong>DNS域名解析原理</strong></p><p>DNS采用了分布式的设计方案，其域名空间采用一种树形的层次结构：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210703153043428.png" alt="image-20210703153043428"></p><p>上图展示了 DNS 服务器的部分层次结构，从上到下依次为根域名服务器、顶级域名服务器和权威域名服务器。其实根域名服务器在因特网上有13个，大部分位于北美洲。第二层为顶级域服务器，这些服务器负责顶级域名（如 com、org、net、edu）和所有国家的顶级域名（如uk、fr、ca 和 jp）。在第三层为权威 DNS 服务器，因特网上具有公共可访问主机（例如 Web 服务器和邮件服务器）的每个组织机构必须提供公共可访问的 DNS 记录，这些记录由组织机构的权威 DNS 服务器负责保存，这些记录将这些主机的名称映射为 IP 地址。</p><p>除此之外，还有一类重要的 DNS 服务器，叫做本地 DNS 服务器。本地 DNS 服务器严格来说不在 DNS 服务器的层次结构中，但它对 DNS 层次结构是很重要的。一般来说，每个网络服务提供商（ISP） 都有一台本地 DNS 服务器。当主机与某个 ISP 相连时，该 ISP 提供一台主机的 IP 地址，该主机具有一台或多台其本地 DNS 服务器的 IP 地址。主机的本地 DNS 服务器通常和主机距离较近，当主机发起 DNS 请求时，该请求被发送到本地 DNS 服务器，它起着代理的作用，并将该请求转发到 DNS 服务器层次结构中。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210703154357430.png" alt="image-20210703154357430"></p><p>以一个例子了解DNS的工作原理，假设主机A（IP地址为abc.xyz.edu.)想知道主机B的IP地址（def.mn.edu）。</p><ul><li><p>主机A首先向它的本地DNS服务器发送一个DNS查询报文。该查询报文含有被转换的主机名def.mn.edu。</p></li><li><p>本地DNS服务器将该报文转发到根DNS服务器，</p></li><li><p>根DNS服务器注意到查询的ip地址前缀为edu后向本地DNS服务器返回负责edu的顶级域名服务器的IP地址列表。</p></li><li><p>该本地DNS服务器则再次向这些顶级域名服务器发送查询报文。该顶级域名服务器注意到mn.edu的前缀，并用权威域名服务器的ip地址进行相应。</p></li><li><p>通常情况下，顶级域名服务器并不总是知道每台主机的权威 DNS 服务器的 IP 地址，而只知道中间的某个服务器，该中间 DNS 服务器依次能找到用于相应主机的 IP 地址，我们假设中间经历了权威服务器 ① 和 ②，最后找到了负责 def.mn.edu 的权威 DNS 服务器 ③，之后，本地 DNS 服务器直接向该服务器发送查询报文从而获得主机 B 的IP 地址。</p></li></ul><p>IP 地址的查询其实经历了两种查询方式，分别是递归查询和迭代查询。</p><p><strong>递归查询：</strong></p><p>如果主机所询问的本地域名服务器不知道被查询域名的ip地址，那么本地域名服务器就以DNS客户端的身份，向其他域名服务器鸡血发出查询请求报文，即替主机继续查询，而不是让主机自己进行下一步查询。</p><p><strong>迭代查询:</strong></p><p>当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地服务器下一步应该找哪个域名服务器进行查询，然后让本地服务器进行后续的查询</p><h2 id="DNS为什么用UDP"><a href="#DNS为什么用UDP" class="headerlink" title="DNS为什么用UDP"></a>DNS为什么用UDP</h2><p>DNS既使用TCP又使用UDP</p><ul><li>当进行区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用TCP，因为数据同步传送数据量比一个请求和应答的数据量要多，而TCP允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的TCP。</li><li>当客户端向DNS服务器查询域名（域名解析）的时候，一般返回的内容不会超过UDP报文的最大长度，即512字节。用UDP传输时，不需要经过TCP三次握手的过程，从而大大提高了响应速度，但这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。</li></ul><h2 id="socket-套接字有哪些"><a href="#socket-套接字有哪些" class="headerlink" title="socket() 套接字有哪些"></a>socket() 套接字有哪些</h2><p>套接字（Socket）是对网络中不同主机上的应用进程之间进行双向通信的端点的抽象，网络进程通信的一端就是一个套接字，不同主机上的进程便是通过套接字发送报文来进行通信。例如 TCP 用主机的 IP 地址 + 端口号作为 TCP 连接的端点，这个端点就叫做套接字。</p><p>套接字主要有以下三种类型：</p><ul><li><p>流套接字（SOCK_STREAM）：流套接字基于 TCP 传输协议，主要用于提供面向连接、可靠的数据传输服务。由于 TCP 协议的特点，使用流套接字进行通信时能够保证数据无差错、无重复传送，并按顺序接收，通信双方不需要在程序中进行相应的处理。</p></li><li><p>数据报套接字（SOCK_DGRAM）：和流套接字不同，数据报套接字基于 UDP 传输协议，对应于无连接的 UDP 服务应用。该服务并不能保证数据传输的可靠性，也无法保证对端能够顺序接收到数据。此外，通信两端不需建立长时间的连接关系，当 UDP 客户端发送一个数据给服务器后，其可以通过同一个套接字给另一个服务器发送数据。当用 UDP 套接字时，丢包等问题需要在程序中进行处理。</p></li><li><p>原始套接字（SOCK_RAW）：由于流套接字和数据报套接字只能读取 TCP 和 UDP 协议的数据，当需要传送非传输层数据包（例如 Ping 命令时用的 ICMP 协议数据包）或者遇到操作系统无法处理的数据包时，此时就需要建立原始套接字来发送。</p></li></ul><h2 id="URI（统一资源标识符）和-URL（统一资源定位符）之间的区别"><a href="#URI（统一资源标识符）和-URL（统一资源定位符）之间的区别" class="headerlink" title="URI（统一资源标识符）和 URL（统一资源定位符）之间的区别"></a>URI（统一资源标识符）和 URL（统一资源定位符）之间的区别</h2><p>URL，即统一资源定位符 (Uniform Resource Locator )，URL 其实就是我们平时上网时输入的网址，它标识一个互联网资源，并指定对其进行操作或获取该资源的方法。</p><p>从定义即可看出，URL 是 URI 的一个子集，两者都定义了资源是什么，而 URL 还定义了如何能访问到该资源。URI 是一种语义上的抽象概念，可以是绝对的，也可以是相对的，而URL则必须提供足够的信息来定位，是绝对的。简单地说，只要能唯一标识资源的就是 URI，在 URI 的基础上给出其资源的访问方式的就是 URL。</p><h2 id="用户输入网址到显示对应页面的全过程"><a href="#用户输入网址到显示对应页面的全过程" class="headerlink" title="用户输入网址到显示对应页面的全过程"></a>用户输入网址到显示对应页面的全过程</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210703185939090.png" alt="image-20210703185939090"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;应用层&quot;&gt;&lt;a href=&quot;#应用层&quot; class=&quot;headerlink&quot; title=&quot;应用层&quot;&gt;&lt;/a&gt;应用层&lt;/h1&gt;&lt;h2 id=&quot;HTTP头部包含那些信息&quot;&gt;&lt;a href=&quot;#HTTP头部包含那些信息&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://leslieaibin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="计算机网络" scheme="https://leslieaibin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Redis缓存穿透，雪崩</title>
    <link href="https://leslieaibin.github.io/2021/07/04/Redis/Redis%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81redis%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E9%97%AE%E9%A2%98/"/>
    <id>https://leslieaibin.github.io/2021/07/04/Redis/Redis%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81redis%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E9%97%AE%E9%A2%98/</id>
    <published>2021-07-04T01:15:42.000Z</published>
    <updated>2021-08-21T06:39:57.963Z</updated>
    
    <content type="html"><![CDATA[<h1 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h1><h2 id="什么是缓存雪崩"><a href="#什么是缓存雪崩" class="headerlink" title="什么是缓存雪崩"></a>什么是缓存雪崩</h2><p>由于</p><ul><li>设置缓存时，key都采用了相同expire</li><li>更新策略</li><li>数据热点</li><li>缓存服务宕机</li></ul><p>等原因，可能导致缓存数据同一时刻大规模不可用，或者都更新</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ul><li>更新策略在时间上做到比较均匀</li><li>使用的热数据尽量分散到不同的机器上</li><li>多台机器做主从复制或者多副本，实现高可用</li><li>实现熔断限流机制，对系统进行负载能力控制</li></ul><p>在原有失效时间基础上增加一个随机值，比如1~5分钟的随机，这样每个缓存的过期时间重复率就会降低，集体失效概率也会大大降低。</p><h1 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h1><h2 id="什么是缓存穿透"><a href="#什么是缓存穿透" class="headerlink" title="什么是缓存穿透"></a>什么是缓存穿透</h2><p>大量并发查询不存在的KEY，导致都直接将压力透传给数据库</p><p>为什么多次透传？不存在一直为空。需要注意让缓存能够区分KEY不存在和查询到一个空值</p><p>例如：访问<strong>id=-1</strong>的数据。可能出现绕过Redis依然频繁访问数据库，称为缓存穿透，多出现在查询为null的情况不被缓存时。</p><h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><ul><li>缓存空值的KEY，这样第一次不存在也会被加载会记录，下次拿到有这个KEY</li><li>Bloom过滤或RoaringBitmap判断Key是否存在</li></ul><p>最常见的布隆过滤器，将多有可能存在的数据哈希到一个足够大的Bitmap中，一个一定不存在的数据会被这个Bitmap拦截掉，从而避免了对底层存储系统的查询压力</p><ul><li>完全以缓存为准，</li><li>使用 延迟异步加载 的策略2，这样就不会触发更新。</li></ul><p>更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过5min。</p><h1 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h1><p>击穿是针对某一个Key缓存，而雪崩是很多key</p><p>某个Key失效时，正好有大量并发请求访问该Key</p><p>通常使用缓存 + 过期时间的策略来帮助我们加速接口的访问速度，减少了后端负载，同时保证功能的更新，一般情况下这个种模式已经基本满足要求了</p><p>但如下问题若同时出现，可能对系统致命：</p><ul><li>为热点key，访问量非常大</li><li>缓存的构建是需要时间（可能是个复杂过程，例如复杂SQL、多次I/O、多个接口依赖）</li></ul><p>于是就会导致： 在缓存失效瞬间，有大量线程构建缓存，导致后端负载加剧，甚至可能让系统崩溃。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210821140221116.png" alt="image-20210821140221116"></p><h2 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h2><p>所有问题就在限制处理线程的数量，即KEY的更新操作添加全局互斥锁。</p><h3 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h3><p>在缓存失效时（判断拿出来的值为空），不是立即去load db，而是</p><ul><li>先使用缓存工具的某些带成功操作返回值的操作（Redis的SETNX）去set一个mutex key</li><li>当操作返回成功时，再load db的操作并回设缓存；否则，就重试整个get缓存的方法。</li></ul><h1 id="缓存并发"><a href="#缓存并发" class="headerlink" title="缓存并发"></a>缓存并发</h1><p>这里的并发指的是多个redis的client同时set<br>key引起的并发问题。其实redis自身就是单线程操作，多个client并发操作，按照先到先执行的原则，先到的先执行，其余的阻塞。当然，另外的解决方案是把redis.set操作放在队列中使其串行化，必须的一个一个执行。</p><h1 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h1><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。</p><p>这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p><p>解决思路：</p><p>1、直接写个缓存刷新页面，上线时手工操作下；</p><p>2、数据量不大，可以在项目启动的时候自动进行加载；</p><p>目的就是在系统上线前，将数据加载到缓存中。</p><h1 id="如何预防缓存雪崩"><a href="#如何预防缓存雪崩" class="headerlink" title="如何预防缓存雪崩"></a>如何预防缓存雪崩</h1><p>在缓存的时候给过期时间在加上一个随机值，这样就会大幅度减少缓存在同一时间过期</p><p>对于“Redis挂掉了，请求全部走数据库”这种情况，我们可以有以下的思路</p><ul><li>事发前：万一Redis的高可用（采用主从架构），尽量避免Redis挂掉这种情况</li><li>事发中：万一Redis真的挂了，可以设置本地缓存（ehcache) + 限流（hystrix)，尽量避免数据库被干掉</li><li>事发后：redis持久化，重启后自动从磁盘加载数据，快速恢复缓存数据</li></ul><ol><li><p>缓存的高可用性</p><p>缓存层设计成高可用，防止缓存大面积故障。即使个别节点，个别机器，甚至是机房宕机，依然可以提供服务，例如Redis Sentinel  和 Redis Cluster 都实现了高可用。</p></li><li><p>缓存降级</p><p>可以利用ehcache等本地缓存，但主要还是对源服务访问进行限流、资源隔离、降级等</p><p>当访问量剧增、服务出现问题仍然需要保证服务还是可用的。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级，这里会涉及到运维的配合。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;缓存雪崩&quot;&gt;&lt;a href=&quot;#缓存雪崩&quot; class=&quot;headerlink&quot; title=&quot;缓存雪崩&quot;&gt;&lt;/a&gt;缓存雪崩&lt;/h1&gt;&lt;h2 id=&quot;什么是缓存雪崩&quot;&gt;&lt;a href=&quot;#什么是缓存雪崩&quot; class=&quot;headerlink&quot; title=&quot;什么是</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>HTTP1.0 1.1 2.0</title>
    <link href="https://leslieaibin.github.io/2021/07/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/5.Http1.0%201.1%202.0.3.0/"/>
    <id>https://leslieaibin.github.io/2021/07/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/5.Http1.0%201.1%202.0.3.0/</id>
    <published>2021-07-04T01:15:42.000Z</published>
    <updated>2021-09-07T07:29:16.602Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HTTP1-0"><a href="#HTTP1-0" class="headerlink" title="HTTP1.0"></a>HTTP1.0</h1><p>1.0的HTTP版本，是一种无状态，无连接的应用层协议。HTTP1.0 规定浏览器和服务器保持短暂的连接</p><p>浏览器每次请求都需要与服务器建立一个TCP连接，服务器处理完成以后立即断开TCP连接（无连接），服务器也不跟踪每个客户端，也不记录过去的请求（无状态）</p><p>这种无状态性可以借助cookie/session机制来做身份认证和状态记录</p><h2 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h2><p>无法复用连接</p><p>每次发送请求，都需要进行一次TCP连接，而TCP的连接释放过程又是比较费事的，这种无连接的特性会使得网络的利用率变低</p><h2 id="对头阻塞（head-of-line-blocking"><a href="#对头阻塞（head-of-line-blocking" class="headerlink" title="对头阻塞（head of line blocking)"></a>对头阻塞（head of line blocking)</h2><p>由于HTTP1.0规定下一个请求必须在前一个响应到达之前才能发送，假设前一个请求响应一直不到达，那么下一个请求就不发送，后面的请求就阻塞了。</p><h1 id="HTTP1-1"><a href="#HTTP1-1" class="headerlink" title="HTTP1.1"></a>HTTP1.1</h1><p>HTTP1.1继承了HTTP1.0的简单，克服了HTTP1.0性能上的问题</p><h2 id="长链接"><a href="#长链接" class="headerlink" title="长链接"></a>长链接</h2><p>HTTP1.1增加了Conection字段，通过设置keep-Alive保持HTTP连接不断，避免每次客户端与服务器请求都要重复建立释放TCP连接。提高了网络利用率。</p><p>如果客户端向关闭HTTP连接，可以在请求头中携带Conection:false来告知服务器关闭请求</p><h2 id="管道化（pipelining）——-尴尬的假并行传输"><a href="#管道化（pipelining）——-尴尬的假并行传输" class="headerlink" title="管道化（pipelining）—— 尴尬的假并行传输"></a>管道化（pipelining）—— 尴尬的假并行传输</h2><p>HTTP1.1支持请求管道化（piplining）。</p><p>基于HTTP1.1的长链接，使得请求管线化成为可能。管线化使得请求能够“并行”传输</p><p>例如：</p><p>假如响应的主体是一个html页面，页面中包含了很多img，这个时候keep-alive就有了很大作用。能够“并行”发送多个请求。（注意，这里的“并行”并不是意义上的并行传输）</p><p>也就是说，HTTP管道化可以让我们先进先出队列从客户端（请求队列）迁移到服务端（响应队列）</p><p>如果，客户端同时发了两个请求分别获取html和css，假如说服务器的css资源先准备就绪，服务器也会先发送html，在发送css，换句话说，只有等到html响应的资源完全传输完毕后，css响应的资源才开始传输，不允许同时存在两个并行的响应。</p><p>可见，HTTP1.1还是无法解决队头阻塞（head of line blocking）的问题。同时“管道化”技术存在各种各样的问题，所以很多浏览器要么根本不支持它，要么直接默认关闭，并且开启的条件很苛刻……而且好像实际也没有什么用处。</p><h2 id="真并行传输——浏览器优化策略"><a href="#真并行传输——浏览器优化策略" class="headerlink" title="真并行传输——浏览器优化策略"></a>真并行传输——浏览器优化策略</h2><p>HTTP1.1支持管道化，但是服务器也不许进行逐个响应的送回，这个是很大的一个缺陷。实际上，现阶段浏览器厂商采取了另一种做法，他允许我们打开多个TCP的会话，也就是说，其实是不同的TCP连接上的HTTP请求和相应。这才是真正的并行!</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210907143928590.png" alt="image-20210907143928590"></p><p>实际情况：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210907144015353.png" alt="image-20210907144015353"></p><h2 id="缓存处理-—-强缓存、协商缓存，启发式缓存-新增"><a href="#缓存处理-—-强缓存、协商缓存，启发式缓存-新增" class="headerlink" title="缓存处理 — 强缓存、协商缓存，启发式缓存(新增)"></a><strong>缓存处理 — 强缓存、协商缓存，启发式缓存(新增)</strong></h2><p>此外，HTTP1.1还加入了缓存处理(强缓存和协商缓存)，新的字段如cache-control，支持断点传输，以及增加了Host字段(使得一个服务器能够用来创建多个Web站点)</p><h1 id="HTTP2-0"><a href="#HTTP2-0" class="headerlink" title="HTTP2.0"></a>HTTP2.0</h1><h2 id="二进制分帧"><a href="#二进制分帧" class="headerlink" title="二进制分帧"></a>二进制分帧</h2><p>HTTP2.0通过在应用层和传输层之间增加一个二进制分层帧，突破了HTTP1.1的性能限制，改进传输性能。</p><h2 id="多路复用（链接共享）——-真并行传输"><a href="#多路复用（链接共享）——-真并行传输" class="headerlink" title="多路复用（链接共享）—— 真并行传输"></a>多路复用（链接共享）—— 真并行传输</h2><ul><li>流(stream)：已建立连接上的双向字节流。</li><li>消息：与逻辑消息对应的完整的一系列数据帧。</li><li>帧(frame)：HTTP2.0通信的最小单位，每个帧包含头部，至少也会标识出当前所属的流(stream_id)</li></ul><p>所有HTTP2.0通信都在一个TCP链接完成，这个链接可以承载任意流量的双向数据流</p><p>每个数据流以消息的形式发送，而消息由一或多个帧组成。这些帧可以乱序发送，然后再根据每个帧头部的流标识（Stream_id)重新封装</p><p>多路复用（连接共享）可能会导致关键字被阻塞，HTTP2.0里每个 数据流都可以设置优先级和依赖，优先级高的数据流会被服务器优先处理和返回客户端，数据流还可以依赖其他的子数据流。</p><p>可见，HTTP2.0实现了真正的并行传输，它能够在一个TCP上进行任意数量的HTTP请求，而这个强大的功能基于”二级制分帧”的特性</p><h2 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a><strong>头部压缩</strong></h2><p>在HTTP1.X中，头部元数据都是以纯文本的形式发送的，通常会给每个请求增加500-8000字节的负荷。</p><p>比如cookie，默认情况下，浏览器会在每次请求的时候，把cookie附在header上面发给服务器。</p><p>HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header_files表，既避免重复header的传输，又减少了需要传输的大小。</p><p>高效的压缩算法可以很大的压缩header，减少发送包的数量从而降低延迟。</p><h2 id="服务器推送"><a href="#服务器推送" class="headerlink" title="服务器推送"></a>服务器推送</h2><p>服务器除了最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确的需求。</p><h1 id="HTTP3-0"><a href="#HTTP3-0" class="headerlink" title="HTTP3.0"></a>HTTP3.0</h1><p>Google搞了一个基于UDP协议的QUIC协议，并且使用在了HTTP/3上， HTTP/3之前的名称为HTTP-over-QUIC。</p><p>早期Quic协议，存在IETF和Google两个版本，直到它被证实命名为HTTP3.0</p><p><strong>IETF的QUIC工作小组创造了QUIC传输协议。QUIC是一个使用UDP来替代TCP的协议。最初的时候，Google开始助力QUIC，其后QUIC更多地被叫做“HTTP/2-encrypted-over-UDP “。</strong></p><p><strong>社区中的人们已经使用非正式名称如iQUIC和gQUIC来指代这些不同版本的协议，以将QUIC协议与IETF和Google分开(因为它们在细节上差异很大)。通过“iQUIC”发送HTTP的协议被称为“HQ”(HTTP-over-QUIC)很长一段时间。</strong></p><p><strong>2018年11月7日，Litespeed的Dmitri宣布他们和Facebook已经成功地完成了两个HTTP/3实现之间的第一次互操作。Mike Bihop在该主题的HTTPBIS会话中的后续介绍可以在这里看到。会议结束时达成共识称新名称是HTTP/3!</strong></p><h2 id="0-RTT-—-QUIC协议相比HTTP2-0的最大优势"><a href="#0-RTT-—-QUIC协议相比HTTP2-0的最大优势" class="headerlink" title="0-RTT — QUIC协议相比HTTP2.0的最大优势"></a><strong>0-RTT — QUIC协议相比HTTP2.0的最大优势</strong></h2><p>缓存当前会话的上下文，下次恢复会话的时候，只需要将之前的缓存传递给服务器，验证通过，就可以进行传输了。</p><p>0-RTT建连可以说是QUIC相比HTTP2最大的性能优势。</p><p>什么是0-RTT建连?</p><ul><li>传输层0-RTT就能建立连接</li><li>加密层0-RTT就能建立加密连接</li></ul><h2 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h2><p>QUIC基于UDP，一个连接上的多个stream之间没有依赖，即使丢包，只需要重发丢失的包即可，不需要重传整个连接。</p><h2 id="更好的移动端表现"><a href="#更好的移动端表现" class="headerlink" title="更好的移动端表现"></a><strong>更好的移动端表现</strong></h2><p>QUIC在移动端的表现比TCP好，因为TCP是基于IP识别连接，而QUIC是通过ID识别链接。 无论网络环境如何变化，只要ID不便，就能迅速重新连上。</p><h2 id="加密认证的根文-—-武装到牙齿"><a href="#加密认证的根文-—-武装到牙齿" class="headerlink" title="加密认证的根文 — 武装到牙齿"></a><strong>加密认证的根文 — 武装到牙齿</strong></h2><p>TCP协议头没有经过任何加密和认证，在传输过程中很容易被中间网络设备篡改、注入和窃听。</p><p>QUIC的packet可以说武装到了牙齿，除了个别报文，比如PUBLIC_RESET和CHLO，所有报文头部都是经过认证的，报文Body都是经过加密的。</p><p>所以只要对 QUIC 做任何更改，接收端都能及时发现，有效地降低了安全风险。</p><h2 id="向前纠错机制"><a href="#向前纠错机制" class="headerlink" title="向前纠错机制"></a><strong>向前纠错机制</strong></h2><p>QUIC协议有一个非常独特的特性，称为向前纠错(Foward Error Connec，FEC)，每个数据包除了它本身的内容之外还包括了其他数据包的数据，因此少量的丢包可以通过其他包的冗余数据直接组装而无需重传。</p><p>向前纠错牺牲了每个数据包可以发送数据的上限，但是带来的提升大于丢包导致的数据重传，因为数据重传将会消耗更多的时间(包括确认数据包丢失，请求重传，等待新数据包等步骤的时间消耗)。</p><p>例如：</p><ul><li>我总共发送三个包，协议会算出这个三个包的异或值并单独发出一个校验包，也就是总共发出了四个包。</li><li>当其中出现了非校验包丢失的情况，可以通过另外三个包计算出丢失的数据包的内容。</li><li>当然这种技术只能使用在丢失一个包的情况下，如果出现丢失多个包，就不能使用纠错机制了，只能使用重传的方式了。、</li></ul><h1 id="HTTP-与-HTTPS-区别"><a href="#HTTP-与-HTTPS-区别" class="headerlink" title="HTTP 与 HTTPS 区别"></a>HTTP 与 HTTPS 区别</h1><ul><li>HTTP 明文传输，数据都是未加密的，安全性较差，HTTPS（SSL+HTTP） 数据传输过程是加密的，安全性较好。</li><li>使用 HTTPS 协议需要到 CA（Certificate Authority，数字证书认证机构） 申请证书，一般免费证书较少，因而需要一定费用。证书颁发机构如：Symantec、Comodo、GoDaddy 和 GlobalSign 等。</li><li>HTTP 页面响应速度比 HTTPS 快，主要是因为 HTTP 使用 TCP 三次握手建立连接，客户端和服务器需要交换 3 个包，而 HTTPS除了 TCP 的三个包，还要加上 ssl 握手需要的 9 个包，所以一共是 12 个包。</li><li>http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443。</li><li>HTTPS 其实就是建构在 SSL/TLS 之上的 HTTP 协议，所以，要比较 HTTPS 比 HTTP 要更耗费服务器资源。</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h1><p><strong>HTTP 1.0</strong></p><ul><li>无状态，无连接</li><li>短连接：每次发送请求都要重新建立tcp请求，即三次握手，非常浪费性能</li><li>无host头域，也就是http请求头里的host，</li><li>不允许断点续传，而且不能只传输对象的一部分，要求传输整个对象</li></ul><p><strong>HTTP 1.1</strong></p><ul><li>长连接，流水线，使用connection:keep-alive使用长连接</li><li>请求管道化</li><li>增加缓存处理(新的字段如cache-control)</li><li>增加Host字段，支持断点传输等</li><li>由于长连接会给服务器造成压力</li></ul><p><strong>HTTP 2.0</strong></p><ul><li>二进制分帧</li><li>头部压缩，双方各自维护一个header的索引表，使得不需要直接发送值，通过发送key缩减头部大小</li><li>多路复用(或连接共享)，使用多个stream，每个stream又分帧传输，使得一个tcp连接能够处理多个http请求</li><li>服务器推送(Sever push)</li></ul><p><strong>HTTP 3.0</strong></p><ul><li>基于google的QUIC协议，而quic协议是使用udp实现的</li><li>减少了tcp三次握手时间，以及tls握手时间</li><li>解决了http 2.0中前一个stream丢包导致后一个stream被阻塞的问题</li><li>优化了重传策略，重传包和原包的编号不同，降低后续重传计算的消耗</li><li>连接迁移，不再用tcp四元组确定一个连接，而是用一个64位随机数来确定这个连接</li><li>更合适的流量控制</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;HTTP1-0&quot;&gt;&lt;a href=&quot;#HTTP1-0&quot; class=&quot;headerlink&quot; title=&quot;HTTP1.0&quot;&gt;&lt;/a&gt;HTTP1.0&lt;/h1&gt;&lt;p&gt;1.0的HTTP版本，是一种无状态，无连接的应用层协议。HTTP1.0 规定浏览器和服务器保持短暂的</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://leslieaibin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="计算机网络" scheme="https://leslieaibin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>1.计算机网络 —— 协议层次以及服务</title>
    <link href="https://leslieaibin.github.io/2021/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1.%E5%8D%8F%E8%AE%AE%E5%B1%82%E6%AC%A1%E4%BB%A5%E5%8F%8A%E5%AE%83%E4%BB%AC%E7%9A%84%E6%9C%8D%E5%8A%A1%E7%B1%BB%E5%9E%8B/"/>
    <id>https://leslieaibin.github.io/2021/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1.%E5%8D%8F%E8%AE%AE%E5%B1%82%E6%AC%A1%E4%BB%A5%E5%8F%8A%E5%AE%83%E4%BB%AC%E7%9A%84%E6%9C%8D%E5%8A%A1%E7%B1%BB%E5%9E%8B/</id>
    <published>2021-06-09T01:15:42.000Z</published>
    <updated>2021-07-04T11:58:42.204Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OSI七层模型"><a href="#OSI七层模型" class="headerlink" title="OSI七层模型"></a>OSI七层模型</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1612150605-NindRH-image.png" alt="image.png"></p><p>OSI模型全称为<code>开放式通信系统互连参考模型</code>，是国际标准化（ISO）提出的一个视图使各种计算机在世界范围内互连为网络的标准框架。OSI将计算机网络体系结构划分为七层，每一层实现各自的功能和协议，并完成与相邻层的接口通信。OSI的服务定义详细说明了各层所提供的服务。某一层的服务就是该层及其下各层的一种能力，它通过接口提供给更高的一层。</p><h2 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h2><p>应用层位于OSI参考模型的第七层，其作用是<strong>通过应用程序间的交互来完成特定的网络应用。</strong>该层协议定义了应用进程之间的交互规则，通过不同的应用层协议为不同的网络应用提供服务。例如域名系统DNS，支持万维网应用的HTTP协议，电子邮件系统采用SMTP协议等。在应用层交互的数据单位我们称之为报文。</p><h2 id="表示层"><a href="#表示层" class="headerlink" title="表示层"></a>表示层</h2><p>表示层的作用是使<strong>通信的应用程序能够解释交换数据的含义</strong>，其位于OSI参考模型的第六层，向上为应用层提供服务，向下接受来自会话层的服务。该层提供的服务只要包括数据压缩，数据加密以及数据描述。这使得应用程序不必担心在各台计算机中表示和存储的内部格式差异。</p><h2 id="会话层"><a href="#会话层" class="headerlink" title="会话层"></a>会话层</h2><p>会话层就是<strong>负责建立、管理和终止表示层实体之间的通信会话。</strong>该层提供了数据交换的定界和同步功能，包括了建立检查点和恢复方案的方法。</p><h2 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h2><p><strong>传输层的主要任务是为了两台主机进程之间的通信提供服务。</strong>应用程序利用该服务传送应用层报文，该服务并不针对某一特定的应用，多种应用可以使用同一传输层服务。由于一台主机可同时运行多个线程，因此传输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面的传输层的服务，分用和复用相反，是传输层把收到的信息分别交付上面应用层中的相应进程。</p><h2 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h2><p>两台计算机之间传送数据时其通信链路往往不止一条，所传输的信息甚至可能经过很多通信子网。网络层的主要任务就是<strong>选择合适的网间路由和交换节点，确保数据按时成功传送。</strong>在发送数据时，网络层把传输层产生的报文或用户数据报封装成分组和包向下传输到数据链路层。在网络层使用的协议是无连接的网际协议（Internet Protocol）和许多路由协议，因此我们通常把该层简单地称为 IP 层。</p><h2 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h2><p>数据链路层通常也叫做链路层，在物理层和网络层之间。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层协议。在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息。通过控制信息我们可以知道一个帧的起止比特位置，此外，也能使接收端检测出所收到的帧有无差错，如果发现差错，数据链路层能够简单的丢弃掉这个帧，以避免继续占用网络资源。</p><h2 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h2><p>作为 OSI 参考模型中最低的一层，物理层的作用是实现计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。<strong>使其上面的数据链路层不必考虑网络的具体传输介质是什么。</strong>该层的主要任务是确定与传输媒体的接口的一些特性（机械特性、电气特性、功能特性，过程特性）。</p><h1 id="TCP-IP四层模型"><a href="#TCP-IP四层模型" class="headerlink" title="TCP/IP四层模型"></a>TCP/IP四层模型</h1><p>OSI七层模型在提出时的出发点是基于标准化的考虑，而没有考虑到具体的时长需求，使得该模型结构复杂，部分功能冗余，因而完全实现OSI参考模型的系统不多。而TCP/IP参考模型直接面向时长需求，实现起来比较容易，因此在一经提出便得到广泛的应用。基于TCP/IP的参考模型将协议分成四个层次，如上图所示，分别为：<code>网络互连层</code>、<code>网际互联层</code>、<code>传输层</code>、<code>应用层</code>。</p><h2 id="应用层-1"><a href="#应用层-1" class="headerlink" title="应用层"></a>应用层</h2><p>TCP/IP模型将OSI参考模型中的会话层、表示层和应用层的功能合并到一个应用层实现，通过不同的应用层协议为不同的应用提供服务。例如：FTP、Telnet、DNS、SMTP等。</p><h2 id="传输层-1"><a href="#传输层-1" class="headerlink" title="传输层"></a>传输层</h2><p>该层对应于OSI参考模型的传输层，为上层实体提供源端到对端主机的通信功能。传输层定义了两个主要协议：<code>传输控制协议（TCP Transmission Control Protocol）</code> 和<code>用户数据报协议（UDP User Data Protocol）</code> 。其中面向连接的TCP协议保证的数据传输可靠性，面向无连接的UDP协议能够实现数据包简单、快速的传输。</p><h2 id="网际互联层"><a href="#网际互联层" class="headerlink" title="网际互联层"></a>网际互联层</h2><p>网际互联层对应OSI参考模型的网络层，主要负责相同或不同网络中计算机之间的通信。在网际互联层，IP协议提供的是一个不可靠、无连接的数据报传递服务。该协议实现两个基本功能：寻址和分段。根据数据报头中的目的地址将数据传送到目的地址，在这个过程中IP负责选择传送路线。除了 IP 协议外，该层另外两个主要协议是<code>互联网组管理协议（IGMP）和互联网控制报文协议（ICMP）。</code></p><h2 id="网络接入层"><a href="#网络接入层" class="headerlink" title="网络接入层"></a>网络接入层</h2><p>网络接入层的功能对应于 OSI 参考模型中的物理层和数据链路层，它负责监视数据在主机和网络之间的交换。事实上，TCP/IP 并未真正描述这一层的实现，而由参与互连的各网络使用自己的物理层和数据链路层协议，然后与 TCP/IP 的网络接入层进行连接，因此具体的实现方法将随着网络类型的不同而有所差异。</p><h1 id="TCP-IP五层参考模型"><a href="#TCP-IP五层参考模型" class="headerlink" title="TCP/IP五层参考模型"></a>TCP/IP五层参考模型</h1><p>五层体系的协议结构是综合了 OSI 和 TCP/IP 优点的一种协议，包括：</p><ul><li>应用层</li><li>传输层</li><li>网络层</li><li>数据链路层</li><li>物理层。</li></ul><p>其中应用层对应 OSI 的上三层，下四层和 OSI 相同。五层协议的体系结构只是为介绍网络原理而设计的，实际应用还是 TCP/IP 四层体系结构。</p><h1 id="OSI模型与TCP-IP的异同比较"><a href="#OSI模型与TCP-IP的异同比较" class="headerlink" title="OSI模型与TCP/IP的异同比较"></a>OSI模型与TCP/IP的异同比较</h1><h2 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h2><ul><li>OSI参考模型与TCP/IP参考模型都采用了层次结构</li><li>都能够提供面向连接和无连接两种通信服务机制</li></ul><p><strong>面向无连接：</strong></p><ul><li><strong>面向无连接</strong>是通信技术之一。是指通信双方不需要事先建立一条通信线路，而是把每个带有目的地址的包（报文分组）送到线路上，由系统自主选定路线进行传输。邮政系统是一个无连接的模式，天罗地网式的选择路线，天女散花式的传播形式；<strong>IP、UDP协议就是一种无连接协议。</strong></li></ul><p><strong>面向连接：</strong></p><ul><li>Connection－oriented 面向连接：<strong>一种网络协议,依赖发送方和接收器之间的显示通信和阻塞以管理双方的数据传输.网络系统需要在两台计算机之间发送数据之前先建立连接的一种特性。面向连接网络类似于电话系统，在开始通信前必须先进行一次呼叫和应答。</strong>TCP协议就是一种面向连接服务的协议,电话系统是一个面向连接的模式。</li></ul><h2 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h2><ul><li>OSI采用的七层模型；TCP/IP是四层结构</li><li>TCP/IP参考模型没有对网络接口层进行细分，只是一些概念性的描述；OSI参考模型对服务和协议做了明确的区分。</li><li>OSI先有模型，后有协议规范，适合于描述各种网络；TCP/IP是先有协议集然后建立模型，不适用于非TCP/IP网络。</li><li>TCP/IP一开始就提出面向连接和无连接，而OSI一开始只强调面向连接服务，直到很晚才开始制定无连接的服务标准。</li><li>OSI参考模型虽然被看好，但将网络划分为七层，实现起来较困难；相反，TCP/IP参考模型虽然很多不尽人意的地方，但作为一种简化的分层结构还是比较成功的。</li></ul><h1 id="OSI和TCP-IP协议之间的对应关系"><a href="#OSI和TCP-IP协议之间的对应关系" class="headerlink" title="OSI和TCP/IP协议之间的对应关系"></a>OSI和TCP/IP协议之间的对应关系</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210608153545012.png" alt="image-20210608153545012"></p><h1 id="为什么TCP-IP去除了表示层和会话层"><a href="#为什么TCP-IP去除了表示层和会话层" class="headerlink" title="为什么TCP/IP去除了表示层和会话层"></a>为什么TCP/IP去除了表示层和会话层</h1><p>OSI参考模式在提出时，他们的理想是非常好的，但实际上，由于会话层、表示层、应用层都是在应用程序内部实现的，最终产出的是一个应用数据包，而应用程序之间是几乎无法实现代码的抽象共享的，这也就造成 OSI 设想中的应用程序维度的分层是无法实现的，例如，我们几乎不会认为数据的压缩、加密算法算是一种协议，而会话的概念则更为抽象，难以用协议来进行描述，所以在后来的 TCP/IP 协议框架的设计中，便将表示层和会话层与应用层整合在一起，让整个过程更为清晰明了。</p><h1 id="数据如何在各层之间传输——数据的封装过程"><a href="#数据如何在各层之间传输——数据的封装过程" class="headerlink" title="数据如何在各层之间传输——数据的封装过程"></a>数据如何在各层之间传输——数据的封装过程</h1><p>在发送主机端，一个应用层报文被传送到运输层。在最简单的情况下，运输层收取到报文并附上附加信息，该首部将被接收端的运输层使用。应用层报文和运输层首部信息一道构成了运输层报文段。附加的信息可能包括：允许接收端运输层向上向适当的应用程序交付报文的信息以及差错检测位信息。该信息让接收端能够判断报文中的比特是否在途中已被改变。运输层则向网络层传递该报文段，网络层增加了如源和目的端系统地址等网络层首部信息，生成了网络层数据报。该数据报接下来被传递给链路层，在数据链路层数据包添加发送端 MAC 地址和接收端 MAC 地址后被封装成数据帧，在物理层数据帧被封装成比特流，之后通过传输介质传送到对端。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;OSI七层模型&quot;&gt;&lt;a href=&quot;#OSI七层模型&quot; class=&quot;headerlink&quot; title=&quot;OSI七层模型&quot;&gt;&lt;/a&gt;OSI七层模型&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http://test-1874253.oss-cn-beijing.aliyu</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://leslieaibin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="计算机网络" scheme="https://leslieaibin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>16.JVM —— 垃圾回收器</title>
    <link href="https://leslieaibin.github.io/2021/06/05/JVM/16.%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/"/>
    <id>https://leslieaibin.github.io/2021/06/05/JVM/16.%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/</id>
    <published>2021-06-05T01:15:42.000Z</published>
    <updated>2021-06-09T06:54:15.727Z</updated>
    
    <content type="html"><![CDATA[<h1 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h1><h2 id="GC分类与性能指标"><a href="#GC分类与性能指标" class="headerlink" title="GC分类与性能指标"></a>GC分类与性能指标</h2><p>垃圾收集器没有在规范中进行过多的规定，可以由不同的厂商，不用版本的JVM来实现。</p><p>由于JDK的版本处于高速迭代过程中，因此Java发展至今已经衍生了众多的GC版本。</p><p>从不同角度分析垃圾收集器，可以将GC分为不同的类型。</p><p>Java不同版本新特性</p><ul><li>语法层面：Lambda表达式、switch、自动拆箱装箱、enum</li><li>API层面：Stream API、新的日期时间、OPtional、String、集合框架</li><li>底层优化：JVM优化、GC的变化、元空间、静态域、字符串常量池位置变化</li></ul><h3 id="垃圾收集器分类"><a href="#垃圾收集器分类" class="headerlink" title="垃圾收集器分类"></a>垃圾收集器分类</h3><h4 id="按线程数分"><a href="#按线程数分" class="headerlink" title="按线程数分"></a>按线程数分</h4><p>按线程数分（垃圾回收线程数），可以分为<code>串行垃圾回收器</code>和<code>并行垃圾回收器</code></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713083030867.png" alt="image-20200713083030867"></p><p>串行回收指的是在同一时间段内只允许有一个CPU用于执行垃圾回收操作，此时工作线程被暂停，直至垃圾收集工作结束。</p><ul><li>在诸如单CPU处理器或者较小的应用内存等硬件平台不是特别优越的场合，串行回收器的性能可以远超并行回收器和并发回收器。所以，串行回收器默认被应用在客户端的Client模式下的JVM中。</li><li>在并发能力比较强的CPU上，并行回收器产生的停顿时间要短于串行回收器。</li></ul><p>和串行回收相反，并行收集可以运行多个CPU同时执行垃圾回收，因此提升了应用的吞吐量，不过并行回收仍然与串行回收一样，采用独占式，使用了”STW”机制。</p><h4 id="按工作模式分"><a href="#按工作模式分" class="headerlink" title="按工作模式分"></a>按工作模式分</h4><p>按照工作模式分，可以分为<code>并发式垃圾回收器</code>和<code>独占式垃圾回收器</code>。</p><ul><li>并发式垃圾回收器与应用线程交替工作，以尽可能减少应用程序的停顿时间。</li><li>独占式垃圾回收器（Stop the world）一旦运行，就停止应用程序的所有用户线程，知道垃圾回收过程完全结束。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713083443486.png" alt="image-20200713083443486"></p><h4 id="按碎片处理方式分"><a href="#按碎片处理方式分" class="headerlink" title="按碎片处理方式分"></a>按碎片处理方式分</h4><p>按碎片处理方式分，分为<code>压缩式垃圾回收器</code>和<code>非压缩式垃圾回收器</code></p><ul><li>压缩式垃圾回收器会在回收完成后，对存活对象进行压缩整理，消除回收后的碎片</li><li>非压缩式的垃圾回收器不进行这步操作</li></ul><p>按照工作的区间分，又可分为年轻代垃圾回收器和老年垃圾回收器。</p><h3 id="评估GC的性能指标"><a href="#评估GC的性能指标" class="headerlink" title="评估GC的性能指标"></a>评估GC的性能指标</h3><ul><li><strong>吞吐量：</strong> 运行用户代码的时间占总运行时间的比例（总运行时间 = 程序的运行时间 + 内存回收的时间）</li><li><strong>垃圾收集开销：</strong> 吞吐量的补数，垃圾收集所用时间与总运行时间的比例</li><li><strong>暂停时间：</strong>执行垃圾收集时，程序的工作线程被暂停的时间</li><li><strong>收集频率：</strong>相对于应用程序的执行，收集操作发生的频率</li><li><strong>内存占用：</strong>Java堆区所占的内存大小</li><li><strong>快速：</strong>一个对象从诞生到被回收所经历的时间</li></ul><p>吞吐量、暂停时间、内存占用这三者共同努力构成一个”不可能三角”。三者总体的表现会随着技术进步而越来越好。一款优秀的垃圾收集器最多同时满足其中两项。这三项里，暂停时间的重要性日益凸显。随着硬件发展，内存占用多些越来越能容忍，硬件性能的提升也有助于降低收集器运行时对应用程序的影响，即提高吞吐量。而内存的扩大，对延迟反而带来了负面效果。</p><p>简单来说，主要抓住两点：</p><ul><li>吞吐量</li><li>暂停时间</li></ul><h3 id="性能指标：吞吐量"><a href="#性能指标：吞吐量" class="headerlink" title="性能指标：吞吐量"></a>性能指标：吞吐量</h3><p>吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）</p><p>比如：虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%</p><p>这种情况下，应用程序能容忍较高的暂停时间，因此，高吞吐量的应用程序有更长的时间基准，快速响应是不必考虑的</p><p>吞吐量优先，意味着在单位时间内，STW的时间最短：0.2+0.2=0.4</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713084726176.png" alt="image-20200713084726176"></p><h3 id="性能指标：暂停时间"><a href="#性能指标：暂停时间" class="headerlink" title="性能指标：暂停时间"></a>性能指标：暂停时间</h3><p>“暂停时间”是指一个时间段内应用程序线程暂停，让GC线程执行的状态</p><p>例如，GC期间100ms的暂停时间意味着在这期间内没有应用程序线程时活动的。暂停时间优先，意味着尽可能让单次STW的时间最短：0.1+0.1 + 0.1+ 0.1+ 0.1=0.5</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713085306400.png" alt="image-20200713085306400"></p><h3 id="吞吐量VS暂停时间"><a href="#吞吐量VS暂停时间" class="headerlink" title="吞吐量VS暂停时间"></a>吞吐量VS暂停时间</h3><p>高吞吐量较好因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。直觉上，吞吐量越高程序运行越快。</p><p>不幸的是”高吞吐量”和”低暂停时间”是一对相互竞争的目标（矛盾）。</p><p><strong>因为如果选择以吞吐量优先，那么必然需要降低内存回收的执行频率，但是这样会导致GC需要更长的暂停时间来执行内存回收。</strong></p><p>相反的，如果选择以低延迟优先为原则，那么为了降低每次执行内存回收时的暂停时间，也只能频繁地执行内存回收，但这又引起了年轻代内存的缩减和导致程序吞吐量的下降。</p><p>在设计（或使用）GC算法时，我们必须确定我们的目标：一个GC算法只可能针对两个目标之一（即只专注于较大吞吐量或最小暂停时间），或尝试找到一个二者的折衷。</p><p>现在标准：<strong>在最大吞吐量优先的情况下，降低停顿时间</strong></p><h2 id="不同的垃圾回收器概述"><a href="#不同的垃圾回收器概述" class="headerlink" title="不同的垃圾回收器概述"></a>不同的垃圾回收器概述</h2><p>垃圾收集机制是Java的招牌能力，极大地提高了开发效率。这当然也是面试的热点。</p><p>那么，Java常见的垃圾收集器有哪些？</p><blockquote><p>GC垃圾收集器和JVM一脉相承的，它是和JVM进行搭配使用，在不同的使用场景对应的收集器也是有区别的</p></blockquote><h3 id="垃圾回收器发展史"><a href="#垃圾回收器发展史" class="headerlink" title="垃圾回收器发展史"></a>垃圾回收器发展史</h3><p>有了虚拟机，就一定需要手机垃圾的机制，这就是Garbage Collection，对应的产品我们称为Garbage Collector。</p><ul><li>1999年随JDK1.3.1一起来的是串行方式的serialGc，它是第一款GC。ParNew垃圾收集器是Serial收集器的多线程版本</li><li>2002年2月26日，Parallel GC和Concurrent Mark Sweep GC跟随JDK1.4.2一起发布·</li><li>Parallel GC在JDK6之后成为HotSpot默认GC。</li><li>2012年，在JDK1.7u4版本中，G1可用。</li><li>2017年，JDK9中G1变成默认的垃圾收集器，以替代CMS。</li><li>2018年3月，JDK10中G1垃圾回收器的并行完整垃圾回收，实现并行性来改善最坏情况下的延迟。</li><li>2018年9月，JDK11发布。引入Epsilon 垃圾回收器，又被称为 “No-Op(无操作)“ 回收器。同时，引入ZGC：可伸缩的低延迟垃圾回收器（Experimental）</li><li>2019年3月，JDK12发布。增强G1，自动返回未用堆内存给操作系统。同时，引入Shenandoah GC：低停顿时间的GC（Experimental）。·2019年9月，JDK13发布。增强zGC，自动返回未用堆内存给操作系统。</li><li>2020年3月，JDK14发布。删除cMs垃圾回收器。扩展zGC在macos和Windows上的应用</li></ul><h3 id="7种经典的垃圾收集器"><a href="#7种经典的垃圾收集器" class="headerlink" title="7种经典的垃圾收集器"></a>7种经典的垃圾收集器</h3><ul><li>串行回收器：Serial、Serial old</li><li>并行回收器：ParNew、Parallel Scavenge、Parallel old</li><li>并发回收器：CMS、G1</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713093551365.png" alt="image-20200713093551365"></p><h3 id="7款经典收集器与垃圾分代之间的关系"><a href="#7款经典收集器与垃圾分代之间的关系" class="headerlink" title="7款经典收集器与垃圾分代之间的关系"></a>7款经典收集器与垃圾分代之间的关系</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713093757644.png" alt="image-20200713093757644"></p><p>新生代收集器：Serial、ParNew、Paralle1 Scavenge；</p><p>老年代收集器：Serial old、Parallel old、CMS；</p><p>整堆收集器：G1；</p><h3 id="垃圾收集器的组和关系"><a href="#垃圾收集器的组和关系" class="headerlink" title="垃圾收集器的组和关系"></a>垃圾收集器的组和关系</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713094745366.png" alt="image-20200713094745366"></p><ul><li>两个收集器间有连线，表明他们可以搭配使用：<ul><li>Serial——Serial old</li><li>Serial——CMS</li><li>ParNew——Serial old</li><li>ParNew——CMS</li><li>Parallel Scavenge——Serial Old</li><li>Parallel Scavenge——Parallel</li><li>G1</li></ul></li><li>其中Serial o1d作为CMs出现”Concurrent Mode Failure”失败的后备预案。</li><li>（红色虚线）由于维护和兼容性测试的成本，在JDK 8时将Serial+CMS、ParNew+Serial old这两个组合声明为废弃（JEP173），并在JDK9中完全取消了这些组合的支持（JEP214），即：移除。</li><li>（绿色虚线）JDK14中：弃用Paralle1 Scavenge和Serialold GC组合（JEP366）</li><li>（青色虚线）JDK14中：删除CMS垃圾回收器（JEP363）</li></ul><p>为什么要有很多收集器，一个不够么？因为Java的使用场景很多，移动端，服务器等。所以就需要针对不同的场景，提供不同垃圾收集器，提高垃圾收集的性能。</p><p>虽然我们会对各个收集器进行比较，但并非为了挑选一个最好的收集器出来。没有一种放之四海皆准、任何场景下都适用的完美收集器存在，更加没有万能的收集器。所以我们选择的只是对具体应用最合适的收集器。</p><h2 id="Serial回收器：串行回收"><a href="#Serial回收器：串行回收" class="headerlink" title="Serial回收器：串行回收"></a>Serial回收器：串行回收</h2><p>Serial收集器是最基本、历史最悠久的垃圾收集器了。JDK1.3之前回收新生代唯一的选择。</p><p>Serial收集器作为HotSpot中client模式下的默认新生代垃圾收集器。</p><p>Serial收集器采用复制算法、串行回收和”stop-the-World”机制的方式执行内存回收。</p><p>除了年轻代之外，Serial收集器还提供用于执行老年代垃圾收集的Serial old收集器。Serial old收集器同样也采用了串行回收和”stop the World”机制，只不过内存回收算法使用的是标记-压缩算法。</p><ul><li>Serial old是运行在Client模式下默认的老年代的垃圾回收器</li><li>Serial 0ld在Server模式下主要有两个用途：<ul><li>与新生代的Parallel scavenge配合使用</li><li>作为老年代CMS收集器的后备垃圾收集方案</li></ul></li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713100703799.png" alt="image-20200713100703799"></p><p>这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束（Stop The World）</p><p>优势：简单而高效（与其他收集器的单线程比），对于限定单个cPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。</p><p>运行在client模式下的虚拟机是个不错的选择。</p><p>在用户的桌面应用场景中，可用内存一般不大（几十MB至一两百MB），可以在较短时间内完成垃圾收集（几十ms至一百多ms），只要不频繁发生，使用串行回收器是可以接受的。</p><p>在HotSpot虚拟机中，使用-XX：+UseSerialGC参数可以指定年轻代和老年代都使用串行收集器。</p><p>等价于新生代用Serial GC，且老年代用Serial old GC</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这种垃圾收集器大家了解，现在已经不用串行的了。而且在限定单核cpu才可以用。现在都不是单核的了。</p><p>对于交互较强的应用而言，这种垃圾收集器是不能接受的。一般在Java web应用程序中是不会采用串行垃圾收集器的。</p><h2 id="ParNew回收器：并行回收"><a href="#ParNew回收器：并行回收" class="headerlink" title="ParNew回收器：并行回收"></a>ParNew回收器：并行回收</h2><p>如果说serialGC是年轻代中的单线程垃圾收集器，那么ParNew收集器则是serial收集器的多线程版本。</p><ul><li>Par是Parallel的缩写，New：只能处理的是新生代</li></ul><p>ParNew 收集器除了采用并行回收的方式执行内存回收外，两款垃圾收集器之间几乎没有任何区别。ParNew收集器在年轻代中同样也是采用复制算法、”stop-the-World”机制。</p><p>ParNew 是很多JVM运行在Server模式下新生代的默认垃圾收集器。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713102030127.png" alt="image-20200713102030127"></p><ul><li>对于新生代，回收次数频繁，使用并行方式高效。</li><li>对于老年代，回收次数少，使用串行方式节省资源。（CPU并行需要切换线程，串行可以省去切换线程的资源）</li></ul><p>由于ParNew收集器是基于并行回收，那么是否可以断定ParNew收集器的回收效率在任何场景下都会比serial收集器更高效？</p><p>因为除Serial外，目前只有ParNew GC能与CMS收集器配合工作</p><p>在程序中，开发人员可以通过选项”-XX：+UseParNewGC”手动指定使用ParNew收集器执行内存回收任务。它表示年轻代使用并行收集器，不影响老年代。</p><p>-XX:ParallelGCThreads限制线程数量，默认开启和CPU数据相同的线程数。</p><h2 id="Parallel回收器：吞吐量优先"><a href="#Parallel回收器：吞吐量优先" class="headerlink" title="Parallel回收器：吞吐量优先"></a>Parallel回收器：吞吐量优先</h2><p>HotSpot的年轻代中除了拥有ParNew收集器是基于并行回收的以外，Parallel Scavenge收集器同样也采用了复制算法、并行回收和”Stop the World”机制。</p><p>那么Parallel 收集器的出现是否多此一举？</p><ul><li>和ParNew收集器不同，ParallelScavenge收集器的目标则是达到一个可控制的吞吐量（Throughput），它也被称为吞吐量优先的垃圾收集器。</li><li>自适应调节策略也是Parallel Scavenge与ParNew一个重要区别。</li></ul><p>高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。因此，常见在服务器环境中使用。例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序。</p><p>Parallel收集器在JDK1.6时提供了用于执行老年代垃圾收集的Parallel old收集器，用来代替老年代的serialold收集器</p><p>Parallel old收集器采用了标记-压缩算法，但同样也是基于并行回收和”stop-the-World”机制。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713110359441.png" alt="image-20200713110359441"></p><p>在程序吞吐量优先的应用场景中，IParalle1收集器和Parallel old收集器的组合，在server模式下的内存回收性能很不错。在Java8中，默认是此垃圾收集器。</p><h3 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h3><p>-XX：+UseParallelGC 手动指定年轻代使用Paralle1并行收集器执行内存回收任务。</p><p>-XX：+UseParalleloldcc 手动指定老年代都是使用并行回收收集器。</p><ul><li>分别适用于新生代和老年代。默认jdk8是开启的。</li><li>上面两个参数，默认开启一个，另一个也会被开启。（互相激活）</li></ul><p>-XX:ParallelGcrhreads设置年轻代并行收集器的线程数。一般地，最好与CPU数量相等，以避免过多的线程数影响垃圾收集性能。</p><p>在默认情况下，当CPU数量小于8个，ParallelGcThreads的值等于CPU数量。</p><p>当CPU数量大于8个，ParallelGCThreads的值等于3+[5*CPU Count]/8]</p><p>-XX:MaxGCPauseMillis 设置垃圾收集器最大停顿时间（即STw的时间）。单位是毫秒。</p><p>为了尽可能地把停顿时间控制在MaxGCPauseMi11s以内，收集器在工作时会调整Java堆大小或者其他一些参数。<br>对于用户来讲，停顿时间越短体验越好。但是在服务器端，我们注重高并发，整体的吞吐量。所以服务器端适合Parallel，进行控制。该参数使用需谨慎。</p><p>-XX:GCTimeRatio垃圾收集时间占总时间的比例（=1/（N+1））。用于衡量吞吐量的大小。</p><p>取值范围（0，100）。默认值99，也就是垃圾回收时间不超过1。</p><p>与前一个-xx:MaxGCPauseMillis参数有一定矛盾性。暂停时间越长，Radio参数就容易超过设定的比例。</p><p>-XX:+UseAdaptivesizepplicy 设置Parallel scavenge收集器具有自适应调节策略</p><p>在这种模式下，年轻代的大小、Eden和Survivor的比例、晋升老年代的对象年龄等参数会被自动调整，已达到在堆大小、吞吐量和停顿时间之间的平衡点。</p><p>在手动调优比较困难的场合，可以直接使用这种自适应的方式，仅指定虚拟机的最大堆、目标的吞吐量（GCTimeRatio）和停顿时间（MaxGCPauseMil1s），让虚拟机自己完成调优工作。</p><h2 id="CMS回收器：低延迟"><a href="#CMS回收器：低延迟" class="headerlink" title="CMS回收器：低延迟"></a>CMS回收器：低延迟</h2><p>在JDK1.5时期，Hotspot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器：CMS（Concurrent-Mark-Sweep）收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，<strong>它第一次实现了让垃圾收集线程与用户线程同时工作</strong>。</p><p>CMS收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间。停顿时间越短（低延迟）就越适合与用户交互的程序，良好的响应速度能提升用户体验。</p><p>目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。</p><p>CMS的垃圾收集算法采用标记-清除算法，并且也会”stop-the-world”</p><p>不幸的是，CMS作为老年代的收集器，却无法与JDK1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。</p><p>在G1出现之前，CMS使用还是非常广泛的。一直到今天，仍然有很多系统使用CMS GC。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713205154007.png" alt="image-20200713205154007"></p><p>CMS整个过程比之前的收集器要复杂，整个过程分为4个主要阶段，即<strong>初始标记阶段、并发标记阶段、重新标记阶段和并发清除阶段</strong>。(涉及STW的阶段主要是：初始标记 和 重新标记)</p><ul><li><strong>初始标记</strong>（Initial-Mark）阶段：在这个阶段中，程序中所有的工作线程都将会因为“stop-the-world”机制而出现短暂的暂停，这个阶段的主要任务仅仅只是<strong>标记出GCRoots能直接关联到的对象</strong>。一旦标记完成之后就会恢复之前被暂停的所有应用线程。由于直接关联对象比较小，所以这里的速度非常快。</li><li><strong>并发标记</strong>（Concurrent-Mark）阶段：从Gc Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行。</li><li><strong>重新标记</strong>（Remark）阶段：由于在并发标记阶段中，程序的工作线程会和垃圾收集线程同时运行或者交叉运行，因此为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段的时间短。</li><li><strong>并发清除</strong>（Concurrent-Sweep）阶段：此阶段清理删除掉标记阶段判断的已经死亡的对象，释放内存空间。由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的</li></ul><p>尽管CMS收集器采用的是并发回收（非独占式），但是在其初始化标记和再次标记这两个阶段中仍然需要执行“Stop-the-World”机制暂停程序中的工作线程，不过暂停时间并不会太长，因此可以说明目前所有的垃圾收集器都做不到完全不需要“stop-the-World”，只是尽可能地缩短暂停时间。</p><p>由于最耗费时间的并发标记与并发清除阶段都不需要暂停工作，所以整体的回收是低停顿的。</p><p>另外，由于在垃圾收集阶段用户线程没有中断，所以在CMS回收过程中，还应该确保应用程序用户线程有足够的内存可用。因此，CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，而是当堆内存使用率达到某一阈值时，便开始进行回收，以确保应用程序在CMS工作过程中依然有足够的空间支持应用程序运行。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”<br>失败，这时虚拟机将启动后备预案：临时启用Serial old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。</p><p>CMS收集器的垃圾收集算法采用的是<strong>标记清除算法</strong>，这意味着每次执行完内存回收后，由于被执行内存回收的无用对象所占用的内存空间极有可能是不连续的一些内存块，不可避免地将会产生一些内存碎片。那么CMS在为新对象分配内存空间时，将无法使用指针碰撞（Bump the Pointer）技术，而只能够选择空闲列表（Free List）执行内存分配。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713212230352.png" alt="image-20200713212230352"></p><h3 id="CMS为什么不使用标记整理算法？"><a href="#CMS为什么不使用标记整理算法？" class="headerlink" title="CMS为什么不使用标记整理算法？"></a>CMS为什么不使用标记整理算法？</h3><p>答案其实很简答，因为当并发清除的时候，用Compact整理内存的话，原来的用户线程使用的内存还怎么用呢？要保证用户线程能继续执行，前提的它运行的资源不受影响嘛。Mark Compact更适合“stop the world”<br>这种场景下使用</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>并发收集</li><li>低延迟</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li><p>会产生内存碎片，导致并发清除后，用户线程可用的空间不足。在无法分配大对象的情况下，不得不提前触发FullGC。</p></li><li><p>CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。</p></li><li><p>CMS收集器无法处理浮动垃圾。可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。在并发标记阶段由于程序的工作线程和垃圾收集线程是同时运行或者交叉运行的，那么在并发标记阶段如果产生新的垃圾对象，CMS将无法对这些垃圾对象进行标记，最终会导致这些新产生的垃圾对象没有被及时回收，从而只能在下一次执行GC时释放这些之前未被回收的内存空间。</p></li></ul><h3 id="设置的参数"><a href="#设置的参数" class="headerlink" title="设置的参数"></a>设置的参数</h3><ul><li>-XX：+UseConcMarkSweepGC手动指定使用CMS收集器执行内存回收任务。</li></ul><p>开启该参数后会自动将-xx：+UseParNewGC打开。即：ParNew（Young区用）+CMS（01d区用）+Serial old的组合。</p><ul><li>-XX:CMSInitiatingoccupanyFraction 设置堆内存使用率的阈值，一旦达到该阈值，便开始进行回收。</li></ul><p>JDK5及以前版本的默认值为68，即当老年代的空间使用率达到68%时，会执行一次cMs回收。JDK6及以上版本默认值为92%</p><p>如果内存增长缓慢，则可以设置一个稍大的值，大的阀值可以有效降低CMS的触发频率，减少老年代回收的次数可以较为明显地改善应用程序性能。反之，如果应用程序内存使用率增长很快，则应该降低这个阈值，以避免频繁触发老年代串行收集器。因此通过该选项便可以有效降低Ful1Gc的执行次数。</p><ul><li>-XX：+UseCMSCompactAtFullCollection用于指定在执行完Ful1</li></ul><p>GC后对内存空间进行压缩整理，以此避免内存碎片的产生。不过由于内存压缩整理过程无法并发执行，所带来的问题就是停顿时间变得更长了。</p><ul><li><p>-XX:CMSFullGCsBeforecompaction 设置在执行多少次Ful1GC后对内存空间进行压缩整理。</p></li><li><p>-XX:ParallelcMSThreads 设置cMs的线程数量。</p></li></ul><p>CMs默认启动的线程数是（Paralle1GCThreads+3）/4，ParallelGCThreads是年轻代并行收集器的线程数。当CPU资源比较紧张时，受到CMS收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>HotSpot有这么多的垃圾回收器，那么如果有人问，Serial GC、Parallel GC、Concurrent Mark Sweep GC这三个GC有什么不同呢？</p><p>请记住以下口令：</p><ul><li>如果你想要最小化地使用内存和并行开销，请选Serial GC；</li><li>如果你想要最大化应用程序的吞吐量，请选Parallel GC；</li><li>如果你想要最小化GC的中断或停顿时间，请选CMS GC。</li></ul><h3 id="JDK后续版本中CMS的变化"><a href="#JDK后续版本中CMS的变化" class="headerlink" title="JDK后续版本中CMS的变化"></a>JDK后续版本中CMS的变化</h3><p><strong>JDK9新特性</strong>：CMS被标记为eprecate了（JEP291）&gt;如果对JDK9及以上版本的HotSpot虚拟机使用参数-XX：<br>+UseConcMarkSweepGC来开启CMS收集器的话，用户会收到一个警告信息，提示CMS未来将会被废弃。</p><p>JDK14新特性：删除CMs垃圾回收器（JEP363）移除了CMS垃圾收集器，如果在JDK14中使用<br>XX：+UseConcMarkSweepGC的话，JVM不会报错，只是给出一个warning信息，但是不会exit。JVM会自动回退以默认GC方式启动JVM</p><h2 id="G1回收器：区域化分代式"><a href="#G1回收器：区域化分代式" class="headerlink" title="G1回收器：区域化分代式"></a>G1回收器：区域化分代式</h2><h3 id="既然我们已经有了前面几个强大的GC，为什么还要发布Garbage-First（G1）？"><a href="#既然我们已经有了前面几个强大的GC，为什么还要发布Garbage-First（G1）？" class="headerlink" title="既然我们已经有了前面几个强大的GC，为什么还要发布Garbage First（G1）？"></a>既然我们已经有了前面几个强大的GC，为什么还要发布Garbage First（G1）？</h3><p>原因就在于应用程序所应对的业务越来越庞大、复杂，用户越来越多，没有GC就不能保证应用程序正常进行，而经常造成STW的GC又跟不上实际的需求，所以才会不断地尝试对GC进行优化。G1（Garbage-First）垃圾回收器是在Java7 update4之后引入的一个新的垃圾回收器，是当今收集器技术发展的最前沿成果之一。</p><p>与此同时，为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间（pause time），同时兼顾良好的吞吐量。</p><p><strong>官方给G1设定的目标是在延迟可控的情况下获得尽可能高的吞吐量，所以才担当起“全功能收集器”的重任与期望</strong>。</p><h3 id="为什么名字叫-Garbage-First-G1-呢？"><a href="#为什么名字叫-Garbage-First-G1-呢？" class="headerlink" title="为什么名字叫 Garbage First(G1)呢？"></a>为什么名字叫 Garbage First(G1)呢？</h3><p>因为G1是一个并行回收器，它把堆内存分割为很多不相关的区域（Region）（物理上不连续的）。使用不同的Region来表示Eden、幸存者0区，幸存者1区，老年代等。</p><p>G1 GC有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。</p><p>由于这种方式的侧重点在于回收垃圾最大量的区间（Region），所以我们给G1一个名字：垃圾优先（Garbage First）。</p><p>G1（Garbage-First）是一款面向服务端应用的垃圾收集器，主要针对配备多核CPU及大容量内存的机器，以极高概率满足GC停顿时间的同时，还兼具高吞吐量的性能特征。</p><p>在JDK1.7版本正式启用，移除了Experimenta1的标识，是JDK9以后的默认垃圾回收器，取代了CMS回收器以及Paralle1+Parallel old组合。被orac1e官方称为“全功能的垃圾收集器”。</p><p>与此同时，CMS已经在JDK9中被标记为废弃（deprecated）。在jdk8中还不是默认的垃圾回收器，需要使用-xx：+UseG1GC来启用。</p><h3 id="G1垃圾收集器的优点"><a href="#G1垃圾收集器的优点" class="headerlink" title="G1垃圾收集器的优点"></a>G1垃圾收集器的优点</h3><p>与其他GC收集器相比，G1使用了全新的分区算法，其特点如下所示：</p><p><strong>并行与并发</strong></p><ul><li>并行性：G1在回收期间，可以有多个GC线程同时工作，有效利用多核计算能力。此时用户线程STW</li><li>并发性：G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会在整个回收阶段发生完全阻塞应用程序的情况</li></ul><p><strong>分代收集</strong></p><ul><li>从分代上看，G1依然属于分代型垃圾回收器，它会区分年轻代和老年代，年轻代依然有Eden区和Survivor区。但从堆的结构上看，它不要求整个Eden区、年轻代或者老年代都是连续的，也不再坚持固定大小和固定数量。</li><li>将堆空间分为若干个区域（Region），这些区域中包含了逻辑上的年轻代和老年代。</li><li>和之前的各类回收器不同，它同时兼顾年轻代和老年代。对比其他回收器，或者工作在年轻代，或者工作在老年代；</li></ul><p>G1所谓的分代，已经不是下面这样的了</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713215105293.png" alt="image-20200713215105293"></p><p>而是这样的一个区域</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713215133839.png" alt="image-20200713215133839"></p><p><strong>空间整合</strong></p><ul><li>CMS：“标记-清除”算法、内存碎片、若干次Gc后进行一次碎片整理</li><li>G1将内存划分为一个个的region。内存的回收是以region作为基本单位的。Region之间是复制算法，但整体上实际可看作是标记-压缩（Mark-Compact）算法，两种算法都可以避免内存碎片。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。尤其是当Java堆非常大的时候，G1的优势更加明显。</li></ul><p><strong>可预测的停顿时间模型（即：软实时soft real-time）</strong><br>这是G1相对于CMS的另一大优势，G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。</p><ul><li>由于分区的原因，G1可以只选取部分区域进行内存回收，这样缩小了回收的范围，因此对于全局停顿情况的发生也能得到较好的控制。</li><li>G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。</li><li>相比于CMSGC，G1未必能做到CMS在最好情况下的延时停顿，但是最差情况要好很多。</li></ul><h3 id="G1垃圾收集器的缺点"><a href="#G1垃圾收集器的缺点" class="headerlink" title="G1垃圾收集器的缺点"></a>G1垃圾收集器的缺点</h3><p>相较于CMS，G1还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用（Footprint）还是程序运行时的额外执行负载（overload）都要比CMS要高。</p><p>从经验上来说，在小内存应用上CMS的表现大概率会优于G1，而G1在大内存应用上则发挥其优势。平衡点在6-8GB之间。</p><h3 id="G1参数设置"><a href="#G1参数设置" class="headerlink" title="G1参数设置"></a>G1参数设置</h3><ul><li>-XX:+UseG1GC：手动指定使用G1垃圾收集器执行内存回收任务</li><li>-XX:G1HeapRegionSize设置每个Region的大小。值是2的幂，范围是1MB到32MB之间，目标是根据最小的Java堆大小划分出约2048个区域。默认是堆内存的1/2000。</li><li>-XX:MaxGCPauseMillis 设置期望达到的最大Gc停顿时间指标（JVM会尽力实现，但不保证达到）。默认值是200ms</li><li>-XX:+ParallelGcThread 设置STW工作线程数的值。最多设置为8</li><li>-XX:ConcGCThreads 设置并发标记的线程数。将n设置为并行垃圾回收线程数（ParallelGcThreads）的1/4左右。</li><li>-XX:InitiatingHeapoccupancyPercent 设置触发并发Gc周期的Java堆占用率阈值。超过此值，就触发GC。默认值是45。</li></ul><h3 id="G1收集器的常见操作步骤"><a href="#G1收集器的常见操作步骤" class="headerlink" title="G1收集器的常见操作步骤"></a>G1收集器的常见操作步骤</h3><p>G1的设计原则就是简化JVM性能调优，开发人员只需要简单的三步即可完成调优：</p><ul><li>第一步：开启G1垃圾收集器</li><li>第二步：设置堆的最大内存</li><li>第三步：设置最大的停顿时间</li></ul><p>G1中提供了三种垃圾回收模式：YoungGC、Mixed GC和Fu11GC，在不同的条件下被触发。</p><h3 id="G1收集器的适用场景"><a href="#G1收集器的适用场景" class="headerlink" title="G1收集器的适用场景"></a>G1收集器的适用场景</h3><p>面向服务端应用，针对具有大内存、多处理器的机器。（在普通大小的堆里表现并不惊喜）</p><p>最主要的应用是需要低GC延迟，并具有大堆的应用程序提供解决方案；</p><p>如：在堆大小约6GB或更大时，可预测的暂停时间可以低于e.5秒；（G1通过每次只清理一部分而不是全部的Region的增量式清理来保证每次Gc停顿时间不会过长）。<br>用来替换掉JDK1.5中的CMS收集器；在下面的情况时，使用61可能比CMS好：</p><ul><li>超过5e%的Java堆被活动数据占用；</li><li>对象分配频率或年代提升频率变化很大；</li><li>GC停顿时间过长（长于e.5至1秒）</li></ul><p>HotSpot垃圾收集器里，除了61以外，其他的垃圾收集器使用内置的JVM线程执行Gc的多线程操作，而G1GC可以采用应用线程承担后台运行的GC工作，即当JVM的GC线程处理速度慢时，系统会调用应用程序线程帮助加速垃圾回收过程。</p><h3 id="分区Region：化整为零"><a href="#分区Region：化整为零" class="headerlink" title="分区Region：化整为零"></a>分区Region：化整为零</h3><p>使用G1收集器时，它将整个Java堆划分成约2048个大小相同的独立Region块，每个Region块大小根据堆空间的实际大小而定，整体被控制在1MB到32MB之间，且为2的N次幂，即1MB，2MB，4MB，8MB，16MB，32MB。可以通过</p><p>XX:G1HeapRegionsize设定。所有的Region大小相同，且在JVM生命周期内不会被改变。</p><p>虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。通过Region的动态分配方式实现逻辑上的连续。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713223244886.png" alt="image-20200713223244886"></p><p>一个region有可能属于Eden，Survivor或者old/Tenured内存区域。但是一个region只可能属于一个角色。图中的E表示该region属于Eden内存区域，s表示属于survivor内存区域，o表示属于01d内存区域。图中空白的表示未使用的内存空间。</p><p>G1垃圾收集器还增加了一种新的内存区域，叫做Humongous内存区域，如图中的H块。主要用于存储大对象，如果超过1.5个region，就放到H。</p><p><strong>设置H的原因：</strong>对于堆中的对象，默认直接会被分配到老年代，但是如果它是一个短期存在的大对象就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放大对象。如果一个H区装不下一个大对象，那么G1会寻找连续的H区来存储。为了能找到连续的H区，有时候不得不启动Fu11Gc。G1的大多数行为都把H区作为老年代的一部分来看待。</p><p>每个Region都是通过指针碰撞来分配空间</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713223509993.png" alt="image-20200713223509993"></p><h3 id="G1垃圾回收器的回收过程"><a href="#G1垃圾回收器的回收过程" class="headerlink" title="G1垃圾回收器的回收过程"></a>G1垃圾回收器的回收过程</h3><p>G1GC的垃圾回收过程主要包括如下三个环节：</p><ul><li>年轻代GC（Young GC）</li><li>老年代并发标记过程（Concurrent Marking）</li><li>混合回收（Mixed GC）</li></ul><p>（如果需要，单线程、独占式、高强度的Fu11GC还是继续存在的。它针对GC的评估失败提供了一种失败保护机制，即强力回收。）</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713224113996.png" alt="image-20200713224113996"></p><p>顺时针，young gc-&gt;young gc+concurrent mark-&gt;Mixed GC顺序，进行垃圾回收。</p><p>应用程序分配内存，当年轻代的Eden区用尽时开始年轻代回收过程；G1的年轻代收集阶段是一个并行的独占式收集器。在年轻代回收期，G1GC暂停所有应用程序线程，启动多线程执行年轻代回收。然后从年轻代区间移动存活对象到Survivor区间或者老年区间，也有可能是两个区间都会涉及。</p><p>当堆内存使用达到一定值（默认45%）时，开始老年代并发标记过程。</p><p>标记完成马上开始混合回收过程。对于一个混合回收期，G1GC从老年区间移动存活对象到空闲区间，这些空闲区间也就成为了老年代的一部分。和年轻代不同，老年代的G1回收器和其他GC不同，G1的老年代回收器不需要整个老年代被回收，一次只需要扫描/回收一小部分老年代的Region就可以了。同时，这个老年代Region是和年轻代一起被回收的。</p><p>举个例子：一个Web服务器，Java进程最大堆内存为4G，每分钟响应1500个请求，每45秒钟会新分配大约2G的内存。G1会每45秒钟进行一次年轻代回收，每31个小时整个堆的使用率会达到45%，会开始老年代并发标记过程，标记完成后开始四到五次的混合回收。</p><h3 id="Remembered-Set（记忆集）"><a href="#Remembered-Set（记忆集）" class="headerlink" title="Remembered Set（记忆集）"></a>Remembered Set（记忆集）</h3><p>一个对象被不同区域引用的问题</p><p>一个Region不可能是孤立的，一个Region中的对象可能被其他任意Region中对象引用，判断对象存活时，是否需要扫描整个Java堆才能保证准确？</p><p>在其他的分代收集器，也存在这样的问题（而G1更突出）回收新生代也不得不同时扫描老年代？这样的话会降低MinorGC的效率；</p><p><strong>解决方法：</strong></p><p>无论G1还是其他分代收集器，JVM都是使用Remembered Set来避免全局扫描：</p><p>每个Region都有一个对应的Remembered Set；每次Reference类型数据写操作时，都会产生一个Write Barrier暂时中断操作；</p><p>然后检查将要写入的引用指向的对象是否和该Reference类型数据在不同的Region（其他收集器：检查老年代对象是否引用了新生代对象）；如果不同，通过cardTable把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中；当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set；就可以保证不进行全局扫描，也不会有遗漏。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713224716715.png" alt="image-20200713224716715"></p><h3 id="G1回收过程-年轻代GC"><a href="#G1回收过程-年轻代GC" class="headerlink" title="G1回收过程-年轻代GC"></a>G1回收过程-年轻代GC</h3><p>JVM启动时，G1先准备好Eden区，程序在运行过程中不断创建对象到Eden区，当Eden空间耗尽时，G1会启动一次年轻代垃圾回收过程。</p><p>YGC时，首先G1停止应用程序的执行（stop-The-Wor1d），G1创建回收集（Collection Set），回收集是指需要被回收的内存分段的集合，年轻代回收过程的回收集包含年轻代Eden区和Survivor区所有的内存分段。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713225100632.png" alt="image-20200713225100632"></p><p>然后开始如下回收过程：</p><ul><li>第一阶段，扫描根</li></ul><p>根是指static变量指向的对象，正在执行的方法调用链条上的局部变量等。根引用连同RSet记录的外部引用作为扫描存活对象的入口。</p><ul><li>第二阶段，更新RSet</li></ul><p>处理dirty card queue（见备注）中的card，更新RSet。此阶段完成后，RSet可以准确的反映老年代对所在的内存分段中对象的引用。</p><ul><li>第三阶段，处理RSet</li></ul><p>识别被老年代对象指向的Eden中的对象，这些被指向的Eden中的对象被认为是存活的对象。</p><ul><li>第四阶段，复制对象。</li></ul><p>此阶段，对象树被遍历，Eden区内存段中存活的对象会被复制到Survivor区中空的内存分段，Survivor区内存段中存活的对象如果年龄未达阈值，年龄会加1，达到阀值会被会被复制到o1d区中空的内存分段。如果Survivor空间不够，Eden空间的部分数据会直接晋升到老年代空间。</p><ul><li>第五阶段，处理引用</li></ul><p>处理Soft，Weak，Phantom，Final，JNI Weak 等引用。最终Eden空间的数据为空，GC停止工作，而目标内存中的对象都是连续存储的，没有碎片，所以复制过程可以达到内存整理的效果，减少碎片。</p><h3 id="G1回收过程-并发标记过程"><a href="#G1回收过程-并发标记过程" class="headerlink" title="G1回收过程-并发标记过程"></a>G1回收过程-并发标记过程</h3><ul><li>初始标记阶段：标记从根节点直接可达的对象。这个阶段是sTw的，并且会触发一次年轻代GC。</li><li>根区域扫描（Root Region Scanning）：G1 Gc扫描survivor区直接可达的老年代区域对象，并标记被引用的对象。这一过程必须在youngGC之前完成。</li><li>并发标记（Concurrent Marking）：在整个堆中进行并发标记（和应用程序并发执行），此过程可能被youngGC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那这个区域会被立即回收。同时，并发标记过程中，会计算每个区域的对象活性（区域中存活对象的比例）。</li><li>再次标记（Remark）：由于应用程序持续进行，需要修正上一次的标记结果。是STW的。G1中采用了比CMS更快的初始快照算法：snapshot-at-the-beginning（SATB）。</li><li>独占清理（cleanup，STW）：计算各个区域的存活对象和GC回收比例，并进行排序，识别可以混合回收的区域。为下阶段做铺垫。是sTw的。这个阶段并不会实际上去做垃圾的收集</li><li>并发清理阶段：识别并清理完全空闲的区域。</li></ul><h3 id="G1回收过程-混合回收"><a href="#G1回收过程-混合回收" class="headerlink" title="G1回收过程 - 混合回收"></a>G1回收过程 - 混合回收</h3><p>当越来越多的对象晋升到老年代o1d region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即Mixed GC，该算法并不是一个old GC，除了回收整个Young Region，还会回收一部分的old Region。这里需要注意：<strong>是一部分老年代，而不是全部老年代</strong>。可以选择哪些o1d Region进行收集，从而可以对垃圾回收的耗时时间进行控制。也要注意的是Mixed GC并不是Full GC。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200713225810871.png" alt="image-20200713225810871"></p><p>并发标记结束以后，老年代中百分百为垃圾的内存分段被回收了，部分为垃圾的内存分段被计算了出来。默认情况下，这些老年代的内存分段会分8次（可以通过-XX:G1MixedGCCountTarget设置）被回收</p><p>混合回收的回收集（Collection Set）包括八分之一的老年代内存分段，Eden区内存分段，Survivor区内存分段。混合回收的算法和年轻代回收的算法完全一样，只是回收集多了老年代的内存分段。具体过程请参考上面的年轻代回收过程。</p><p>由于老年代中的内存分段默认分8次回收，G1会优先回收垃圾多的内存分段。垃圾占内存分段比例越高的，越会被先回收。并且有一个阈值会决定内存分段是否被回收，</p><p>XX:G1MixedGCLiveThresholdPercent，默认为65%，意思是垃圾占内存分段比例要达到65%才会被回收。如果垃圾占比太低，意味着存活的对象占比高，在复制的时候会花费更多的时间。</p><p>混合回收并不一定要进行8次。有一个阈值-XX:G1HeapWastePercent，默认值为1e%，意思是允许整个堆内存中有10%的空间被浪费，意味着如果发现可以回收的垃圾占堆内存的比例低于1e%，则不再进行混合回收。因为GC会花费很多的时间但是回收到的内存却很少。</p><h3 id="G1回收可选的过程4-Full-GC"><a href="#G1回收可选的过程4-Full-GC" class="headerlink" title="G1回收可选的过程4 - Full GC"></a>G1回收可选的过程4 - Full GC</h3><p>G1的初衷就是要避免Fu11GC的出现。但是如果上述方式不能正常工作，G1会停止应用程序的执行（stop-The-world），使用单线程的内存回收算法进行垃圾回收，性能会非常差，应用程序停顿时间会很长。</p><p>要避免Fu11GC的发生，一旦发生需要进行调整。什么时候会发生Ful1GC呢？比如堆内存太小，当G1在复制存活对象的时候没有空的内存分段可用，则会回退到ful1gc，这种情况可以通过增大内存解决。<br>导致61Fu11GC的原因可能有两个：</p><ul><li>EVacuation的时候没有足够的to-space来存放晋升的对象；</li><li>并发处理过程完成之前空间耗尽。</li></ul><h3 id="G1回收的优化建议"><a href="#G1回收的优化建议" class="headerlink" title="G1回收的优化建议"></a>G1回收的优化建议</h3><p> 从oracle官方透露出来的信息可获知，回收阶段（Evacuation）其实本也有想过设计成与用户程序一起并发执行，但这件事情做起来比较复杂，考虑到G1只是回一部分Region，停顿时间是用户可控制的，所以并不迫切去实现，而选择把这个特性放到了G1之后出现的低延迟垃圾收集器（即ZGC）中。另外，还考虑到G1不是仅仅面向低延迟，停顿用户线程能够最大幅度提高垃圾收集效率，为了保证吞吐量所以才选择了完全暂停用户线程的实现方案。</p><p>年轻代大小</p><ul><li>避免使用-Xmn或-XX:NewRatio等相关选项显式设置年轻代大小</li><li>固定年轻代的大小会覆盖</li></ul><p>暂停时间目标暂停时间目标不要太过严苛</p><ul><li>G1 GC的吞吐量目标是90%的应用程序时间和10%的垃圾回收时间</li><li>评估G1GC的吞吐量时，暂停时间目标不要太严苛。目标太过严苛表示你愿意承受更多的垃圾回收开销，而这些会直接影响到吞吐量。</li></ul><h2 id="垃圾回收器总结"><a href="#垃圾回收器总结" class="headerlink" title="垃圾回收器总结"></a>垃圾回收器总结</h2><p>截止JDK1.8，一共有7款不同的垃圾收集器。每一款的垃圾收集器都有不同的特点，在具体使用的时候，需要根据具体的情况选用不同的垃圾收集器。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714075738203.png" alt="image-20200714075738203"></p><p>GC发展阶段：Seria l=&gt; Parallel（并行）=&gt; CMS（并发）=&gt; G1 =&gt; ZGC</p><p>不同厂商、不同版本的虚拟机实现差距比较大。HotSpot虚拟机在JDK7/8后所有收集器及组合如下图</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714080151020.png" alt="image-20200714080151020"></p><h3 id="怎么选择垃圾回收器"><a href="#怎么选择垃圾回收器" class="headerlink" title="怎么选择垃圾回收器"></a>怎么选择垃圾回收器</h3><p>Java垃圾收集器的配置对于JVM优化来说是一个很重要的选择，选择合适的垃圾收集器可以让JVM的性能有一个很大的提升。怎么选择垃圾收集器？</p><ul><li>优先调整堆的大小让JVM自适应完成。</li><li>如果内存小于100M，使用串行收集器</li><li>如果是单核、单机程序，并且没有停顿时间的要求，串行收集器</li><li>如果是多CPU、需要高吞吐量、允许停顿时间超过1秒，选择并行或者JVM自己选择</li><li>如果是多CPU、追求低停顿时间，需快速响应（比如延迟不能超过1秒，如互联网应用），使用并发收集器</li><li>官方推荐G1，性能高。现在互联网的项目，基本都是使用G1。</li></ul><p>最后需要明确一个观点：</p><ul><li>没有最好的收集器，更没有万能的收集</li><li>调优永远是针对特定场景、特定需求，不存在一劳永逸的收集器</li></ul><h3 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h3><p>对于垃圾收集，面试官可以循序渐进从理论、实践各种角度深入，也未必是要求面试者什么都懂。但如果你懂得原理，一定会成为面试中的加分项。<br>这里较通用、基础性的部分如下：</p><p>垃圾收集的算法有哪些？如何判断一个对象是否可以回收？</p><p>垃圾收集器工作的基本流程。</p><p>另外，大家需要多关注垃圾回收器这一章的各种常用的参数</p><h2 id="GC日志分析"><a href="#GC日志分析" class="headerlink" title="GC日志分析"></a>GC日志分析</h2><p>通过阅读Gc日志，我们可以了解Java虚拟机内存分配与回收策略。<br>内存分配与垃圾回收的参数列表</p><ul><li>-XX:+PrintGc输出GC日志。类似：-verbose:gc</li><li>-XX:+PrintGcDetails输出Gc的详细日志</li><li>-XX:+PrintGcTimestamps 输出Gc的时间戳（以基准时间的形式）</li><li>-XX:+PrintGCDatestamps 输出Gc的时间戳（以日期的形式，如2013-05-04T21：53：59.234+0800）</li><li>-XX:+PrintHeapAtGC在进行Gc的前后打印出堆的信息</li><li>-Xloggc:../logs/gc.1og日志文件的输出路径</li></ul><h3 id="verbose-gc"><a href="#verbose-gc" class="headerlink" title="verbose:gc"></a>verbose:gc</h3><p>打开GC日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-verbose:gc</span><br></pre></td></tr></table></figure><p>这个只会显示总的GC堆的变化，如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714081610474.png" alt="image-20200714081610474"></p><p>参数解析</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714081622526.png" alt="image-20200714081622526"></p><h3 id="PrintGCDetails"><a href="#PrintGCDetails" class="headerlink" title="PrintGCDetails"></a>PrintGCDetails</h3><p>打开GC日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-verbose:gc -XX:+PrintGCDetails</span><br></pre></td></tr></table></figure><p>输入信息如下</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714081909309.png" alt="image-20200714081909309"></p><p>参数解析</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714081925767.png" alt="image-20200714081925767"></p><h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><ul><li>[GC”和”[Fu11GC”说明了这次垃圾收集的停顿类型，如果有”Fu11”则说明GC发生了”stop The World”</li><li>使用Seria1收集器在新生代的名字是Default New Generation，因此显示的是”[DefNew”</li><li>使用ParNew收集器在新生代的名字会变成”[ParNew”，意思是”Parallel New Generation”</li><li>使用Paralle1 scavenge收集器在新生代的名字是”[PSYoungGen”</li><li>老年代的收集和新生代道理一样，名字也是收集器决定的</li><li>使用G1收集器的话，会显示为”garbage-first heap”</li></ul><p>Allocation Failure表明本次引起GC的原因是因为在年轻代中没有足够的空间能够存储新的数据了。</p><p>[PSYoungGen：5986K-&gt;696K（8704K）]5986K-&gt;704K（9216K）中括号内：GC回收前年轻代大小，回收后大小，（年轻代总大小）括号外：GC回收前年轻代和老年代大小，回收后大小，（年轻代和老年代总大小）</p><p>user代表用户态回收耗时，sys内核态回收耗时，rea实际耗时。由于多核的原因，时间总和可能会超过rea1时间</p><h3 id="Young-GC图片"><a href="#Young-GC图片" class="headerlink" title="Young GC图片"></a>Young GC图片</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714082555688.png" alt="image-20200714082555688"></p><h3 id="FullGC图片、"><a href="#FullGC图片、" class="headerlink" title="FullGC图片、"></a>FullGC图片、</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714082714690.png" alt="image-20200714082714690"></p><h3 id="GC回收举例"><a href="#GC回收举例" class="headerlink" title="GC回收举例"></a>GC回收举例</h3><p>我们编写一个程序，用来说明GC收集的过程</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * GC垃圾收集过程</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: 陌溪</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span>: 2020-07-14-8:35</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GCUseTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> Integer _1MB = <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">byte</span> [] allocation1, allocation2, allocation3, allocation4;</span><br><span class="line">        allocation1 = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">2</span> *_1MB];</span><br><span class="line">        allocation2 = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">2</span> *_1MB];</span><br><span class="line">        allocation3 = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">2</span> *_1MB];</span><br><span class="line">        allocation4 = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span> *_1MB];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们设置JVM启动参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Xms10m -Xmx10m -XX:+PrintGCDetails</span><br></pre></td></tr></table></figure><p>首先我们会将3个2M的数组存放到Eden区，然后后面4M的数组来了后，将无法存储，因为Eden区只剩下2M的剩余空间了，那么将会进行一次Young GC操作，将原来Eden区的内容，存放到Survivor区，但是Survivor区也存放不下，那么就会直接晋级存入Old 区</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714083332238.png" alt="image-20200714083332238"></p><p>然后我们将4M对象存入到Eden区中</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714083526790.png" alt="image-20200714083526790"></p><p>可以用一些工具去分析这些GC日志</p><p>常用的日志分析工具有：GCViewer、GCEasy、GCHisto、GCLogViewer、Hpjmeter、garbagecat等</p><p><strong>GCViewer</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714084921184.png" alt="image-20200714084921184"></p><p><strong>GC easy</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714084726824.png" alt="image-20200714084726824"></p><h2 id="垃圾回收器的新发展"><a href="#垃圾回收器的新发展" class="headerlink" title="垃圾回收器的新发展"></a>垃圾回收器的新发展</h2><p>GC仍然处于飞速发展之中，目前的默认选项G1GC在不断的进行改进，很多我们原来认为的缺点，例如串行的Fu11GC、Card Table扫描的低效等，都已经被大幅改进，例如，JDK10以后，Fu11GC已经是并行运行，在很多场景下，其表现还略优于ParallelGC的并行Ful1GC实现。</p><p>即使是SerialGC，虽然比较古老，但是简单的设计和实现未必就是过时的，它本身的开销，不管是GC相关数据结构的开销，还是线程的开销，都是非常小的，所以随着云计算的兴起，在serverless等新的应用场景下，Serial Gc找到了新的舞台。</p><p>比较不幸的是CMSGC，因为其算法的理论缺陷等原因，虽然现在还有非常大的用户群体，但在JDK9中已经被标记为废弃，并在JDK14版本中移除</p><p>Epsilon:A No-Op GarbageCollector（Epsilon垃圾回收器，”No-Op（无操作）”回收器）<a href="http://openidk.iava.net/iep">http://openidk.iava.net/iep</a> s/318</p><p>ZGC:A Scalable Low-Latency Garbage Collector（Experimental）（ZGC：可伸缩的低延迟垃圾回收器，处于实验性阶段）</p><p>现在G1回收器已成为默认回收器好几年了。我们还看到了引入了两个新的收集器：ZGC（JDK11出现）和Shenandoah（Open JDK12）</p><blockquote><p>主打特点：低停顿时间</p></blockquote><h3 id="Open-JDK12的Shenandoash-GC"><a href="#Open-JDK12的Shenandoash-GC" class="headerlink" title="Open JDK12的Shenandoash GC"></a>Open JDK12的Shenandoash GC</h3><p>Open JDK12的shenandoash GC：低停顿时间的GC（实验性）</p><p>Shenandoah，无疑是众多GC中最孤独的一个。是第一款不由oracle公司团队领导开发的Hotspot垃圾收集器。不可避免的受到官方的排挤。比如号称openJDK和OracleJDk没有区别的Oracle公司仍拒绝在oracleJDK12中支持Shenandoah。</p><p>Shenandoah垃圾回收器最初由RedHat进行的一项垃圾收集器研究项目Pauseless GC的实现，旨在针对JVM上的内存回收实现低停顿的需求。在2014年贡献给OpenJDK。</p><p>Red Hat研发Shenandoah团队对外宣称，Shenandoah垃圾回收器的暂停时间与堆大小无关，这意味着无论将堆设置为200MB还是200GB，99.9%的目标都可以把垃圾收集的停顿时间限制在十毫秒以内。不过实际使用性能将取决于实际工作堆的大小和工作负载。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714090608807.png" alt="image-20200714090608807"></p><p>这是RedHat在2016年发表的论文数据，测试内容是使用Es对200GB的维基百科数据进行索引。从结果看：</p><blockquote><p>停顿时间比其他几款收集器确实有了质的飞跃，但也未实现最大停顿时间控制在十毫秒以内的目标。<br>而吞吐量方面出现了明显的下降，总运行时间是所有测试收集器里最长的。</p></blockquote><p>总结</p><ul><li>shenandoah Gc的弱项：高运行负担下的吞吐量下降。</li><li>shenandoah GC的强项：低延迟时间。</li></ul><h3 id="革命性的ZGC"><a href="#革命性的ZGC" class="headerlink" title="革命性的ZGC"></a>革命性的ZGC</h3><p>zGC与shenandoah目标高度相似，在尽可能对吞吐量影响不大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停颇时间限制在十毫秒以内的低延迟。</p><p>《深入理解Java虚拟机》一书中这样定义zGC：2GC收集器是一款基于Region内存布局的，（暂时）不设分代的，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-压缩算法的，以低延迟为首要目标的一款垃圾收集器。</p><p>ZGC的工作过程可以分为4个阶段：<strong>并发标记 - 并发预备重分配 - 并发重分配 - 并发重映射</strong> 等。</p><p>ZGC几乎在所有地方并发执行的，除了初始标记的是STw的。所以停顿时间几乎就耗费在初始标记上，这部分的实际时间是非常少的。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714091201073.png" alt="image-20200714091201073"></p><p>停顿时间对比</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714091401511.png" alt="image-20200714091401511"></p><p>虽然ZGC还在试验状态，没有完成所有特性，但此时性能已经相当亮眼，用“令人震惊、革命性”来形容，不为过。<br>未来将在服务端、大内存、低延迟应用的首选垃圾收集器。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714093243028.png" alt="image-20200714093243028"></p><p>JDK14之前，2GC仅Linux才支持。</p><p>尽管许多使用zGc的用户都使用类Linux的环境，但在Windows和macos上，人们也需要zGC进行开发部署和测试。许多桌面应用也可以从ZGC中受益。因此，2GC特性被移植到了Windows和macos上。</p><p>现在mac或Windows上也能使用zGC了，示例如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:+UnlockExperimentalVMOptions-XX：+UseZGC</span><br></pre></td></tr></table></figure><h3 id="AliGC"><a href="#AliGC" class="headerlink" title="AliGC"></a>AliGC</h3><p>AliGC是阿里巴巴JVM团队基于G1算法，面向大堆（LargeHeap）应用场景。指定场景下的对比：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20200714093604012.png" alt="image-20200714093604012"></p><p>当然，其它厂商也提供了各种别具一格的GC实现，例如比较有名的低延迟GC Zing</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;垃圾回收器&quot;&gt;&lt;a href=&quot;#垃圾回收器&quot; class=&quot;headerlink&quot; title=&quot;垃圾回收器&quot;&gt;&lt;/a&gt;垃圾回收器&lt;/h1&gt;&lt;h2 id=&quot;GC分类与性能指标&quot;&gt;&lt;a href=&quot;#GC分类与性能指标&quot; class=&quot;headerlink&quot; ti</summary>
      
    
    
    
    <category term="JVM" scheme="https://leslieaibin.github.io/categories/JVM/"/>
    
    
    <category term="JVM" scheme="https://leslieaibin.github.io/tags/JVM/"/>
    
  </entry>
  
</feed>
