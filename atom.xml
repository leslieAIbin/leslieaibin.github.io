<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mr.Ai</title>
  
  <subtitle>春暖花开去见你</subtitle>
  <link href="https://leslieaibin.github.io/atom.xml" rel="self"/>
  
  <link href="https://leslieaibin.github.io/"/>
  <updated>2021-09-30T08:44:26.803Z</updated>
  <id>https://leslieaibin.github.io/</id>
  
  <author>
    <name>Leslie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis分布式限流</title>
    <link href="https://leslieaibin.github.io/2021/09/30/Redis/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81/"/>
    <id>https://leslieaibin.github.io/2021/09/30/Redis/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81/</id>
    <published>2021-09-30T01:15:42.000Z</published>
    <updated>2021-09-30T08:44:26.803Z</updated>
    
    <content type="html"><![CDATA[<p>由于互联网公司的流量巨大，系统上线会做一个流量峰值的评估，尤其是像各种秒杀促销活动，为了保证系统不被巨大的流量压垮，会在系统流量到达一定阈值时，拒绝掉一部分流量。</p><p>限流会导致用户在短时间内（这个时间段是毫秒级的）系统不可用，一般我们衡量系统处理能力的指标是每秒的<code>QPS</code>或者<code>TPS</code>，假设系统每秒的流量阈值是1000，理论上一秒内有第1001个请求进来时，那么这个请求就会被限流。</p><h1 id="限流方案"><a href="#限流方案" class="headerlink" title="限流方案"></a>限流方案</h1><h2 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h2><p>Java内部可以通过原子类计数器<code>AtomicInteger</code>、<code>Semaphore</code>信号量来做简单的限流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 限流的个数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> maxCount = <span class="number">10</span>;</span><br><span class="line"><span class="comment">// 指定时间内</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> interval = <span class="number">60</span>;</span><br><span class="line"><span class="comment">// 原子类计数器</span></span><br><span class="line"><span class="keyword">private</span> AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"><span class="comment">// 起始时间</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> startTime = System.currentTimeMills();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">limit</span><span class="params">(<span class="keyword">int</span> maxCount, <span class="keyword">int</span> interval)</span> </span>&#123;</span><br><span class="line">    atomicInteger.addAndGet(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (atomicInteger.get() == <span class="number">1</span>) &#123;</span><br><span class="line">        startTime = System.currentTimeMillis();</span><br><span class="line">        atomicInteger.addAndGet(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 超过了间隔时间，直接重新开始计数</span></span><br><span class="line">    <span class="keyword">if</span> (System.currentTimeMillis() - startTime &gt; interval * <span class="number">1000</span>) &#123;</span><br><span class="line">        startTime = System.currentTimeMillis();</span><br><span class="line">        atomicInteger.set(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 还在间隔时间内,check有没有超过限流的个数</span></span><br><span class="line">    <span class="keyword">if</span> (atomicInteger.get() &gt; maxCount) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h2><p>漏桶算法思路很简单，我们把水比做请求，漏桶比做是系统处理能力极限，水先进入到漏桶里，漏桶里的水按一定速率流出，当流出速率小于流入的速率时，由于漏桶容量有限，后续进入的水直接溢出（拒绝请求），以此实现限流。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210930162736284.png" alt="image-20210930162736284"></p><h2 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h2><p>令牌桶算法的原理也比较简单，可以理解成医院的挂号看病，只要拿到号以后才可以进行诊病。</p><p>系统会维护 一个令牌（token）桶，以一个恒定的速度往桶里放入令牌（token），这时如果有请求进来想要被处理，则需要先从桶里获取一个令牌（token）, 当桶里没有令牌（token）可取时，则该请求将被拒绝服务。令牌桶算法通过控制桶的容量，发放令牌的速率，来达到对请求的限制。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210930163437254.png" alt="image-20210930163437254"></p><h2 id="Redis-Lua"><a href="#Redis-Lua" class="headerlink" title="Redis + Lua"></a>Redis + Lua</h2><p>个人理解，<code>Lua</code>脚本和 <code>MySQL</code>数据库的存储过程比较相似，他们执行一组命令，所有命令的执行要么全部成功或者失败，以此达到原子性。也可以把<code>Lua</code>脚本理解为，一段具有业务逻辑的代码块。</p><p>而<code>Lua</code>本身就是一种编程语言，虽然<code>redis</code> 官方没有直接提供限流相应的<code>API</code>，但却支持了 <code>Lua</code> 脚本的功能，可以使用它实现复杂的令牌桶或漏桶算法，也是分布式系统中实现限流的主要方式之一。</p><p>相比<code>Redis</code>事务，<code>Lua脚本</code>的优点：</p><ul><li>减少网络开销：使用<code>Lua</code>脚本，无需向<code>Redis</code> 发送多次请求，执行一次即可，减少网络传输</li><li>原子操作：<code>Redis</code> 将整个<code>Lua</code>脚本作为一个命令执行，原子，无需担心并发</li><li>复用：<code>Lua</code>脚本一旦执行，会永久保存 <code>Redis</code> 中,，其他客户端可复用</li></ul><p><code>Lua</code>脚本大致逻辑如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">-- 获取调用脚本时传入的第一个key值（用作限流的 key）</span><br><span class="line">local key = KEYS[<span class="number">1</span>]</span><br><span class="line">-- 获取调用脚本时传入的第一个参数值（限流大小）</span><br><span class="line">local limit = tonumber(ARGV[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">-- 获取当前流量大小</span><br><span class="line">local curentLimit = tonumber(redis.call(<span class="string">&#x27;get&#x27;</span>, key) or <span class="string">&quot;0&quot;</span>)</span><br><span class="line"></span><br><span class="line">-- 是否超出限流</span><br><span class="line"><span class="keyword">if</span> curentLimit + <span class="number">1</span> &gt; limit then</span><br><span class="line">    -- 返回(拒绝)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    -- 没有超出 value + <span class="number">1</span></span><br><span class="line">    redis.call(<span class="string">&quot;INCRBY&quot;</span>, key, <span class="number">1</span>)</span><br><span class="line">    -- 设置过期时间</span><br><span class="line">    redis.call(<span class="string">&quot;EXPIRE&quot;</span>, key, <span class="number">2</span>)</span><br><span class="line">    -- 返回(放行)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure><ul><li>通过<code>KEYS[1]</code> 获取传入的key参数</li><li>通过<code>ARGV[1]</code>获取传入的<code>limit</code>参数</li><li><code>redis.call</code>方法，从缓存中<code>get</code>和<code>key</code>相关的值，如果为<code>null</code>那么就返回0</li><li>接着判断缓存中记录的数值是否会大于限制大小，如果超出表示该被限流，返回0</li><li>如果未超过，那么该key的缓存值+1，并设置过期时间为1秒钟以后，并返回缓存值+1</li></ul><p>这种方式是本文推荐的方案，具体实现会在后边做细说。</p><h2 id="网关层限流"><a href="#网关层限流" class="headerlink" title="网关层限流"></a>网关层限流</h2><p>限流常在网关这一层做，比如<code>Nginx</code>、<code>Openresty</code>、<code>kong</code>、<code>zuul</code>、<code>Spring Cloud Gateway</code>等，而像<code>spring cloud - gateway</code>网关限流底层实现原理，就是基于<code>Redis + Lua</code>，通过内置<code>Lua</code>限流脚本的方式。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/640" alt="图片"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;由于互联网公司的流量巨大，系统上线会做一个流量峰值的评估，尤其是像各种秒杀促销活动，为了保证系统不被巨大的流量压垮，会在系统流量到达一定阈值时，拒绝掉一部分流量。&lt;/p&gt;
&lt;p&gt;限流会导致用户在短时间内（这个时间段是毫秒级的）系统不可用，一般我们衡量系统处理能力的指标是每秒</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>3.操作系统-IO模型</title>
    <link href="https://leslieaibin.github.io/2021/09/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3.IO%E6%A8%A1%E5%9E%8B/"/>
    <id>https://leslieaibin.github.io/2021/09/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3.IO%E6%A8%A1%E5%9E%8B/</id>
    <published>2021-09-29T16:15:42.000Z</published>
    <updated>2021-09-30T08:47:28.525Z</updated>
    
    <content type="html"><![CDATA[<h1 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927141630387.png" alt="image-20210927141630387"></p><p>IO (Input/Output，输入/输出)即数据的读取（接收）或写入（发送）操作，通常用户进程中的一个完整IO分为两阶段：用户进程空间&lt;–&gt;内核空间、内核空间&lt;–&gt;设备空间（磁盘、网络等）。IO有内存IO、网络IO和磁盘IO三种，通常我们说的IO指的是后两者。</p><p>LINUX中进程无法直接操作I/O设备，其必须通过系统调用请求kernel来协助完成I/O动作；内核会为每个I/O设备维护一个缓冲区。</p><p>对于一个输入操作来说，进程IO系统调用后，内核会先看缓冲区中有没有相应的缓存数据，没有的话再到设备中读取，因为设备IO一般速度较慢，需要等待；内核缓冲区有数据则直接复制到进程空间。</p><p>所以，对于一个网络输入操作通常包括两个不同阶段：</p><ul><li><p>等待网络数据到达网卡→读取到内核缓冲区，数据准备好；</p></li><li><p>从内核缓冲区复制数据到进程空间。</p><p><strong>从TCP发送数据的流程说起</strong></p></li></ul><p>要深入的理解各种IO模型，那么必须先了解下产生各种IO的原因是什么，要知道这其中的本质问题那么我们就必须要知一条消息是如何从过一个人发送到另外一个人的；</p><p>以两个应用程序通讯为例，我们来了解一下当“A”向”B” 发送一条消息，简单来说会经过如下流程：</p><p><strong>第一步</strong>：应用A把消息发送到 TCP发送缓冲区。</p><p><strong>第二步：</strong> TCP发送缓冲区再把消息发送出去，经过网络传递后，消息会发送到B服务器的TCP接收缓冲区。</p><p><strong>第三步：</strong>B再从TCP接收缓冲区去读取属于自己的数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-5311954c22d15ca91e47ab52168b7ada_720w.jpg" alt="img"></p><p>根据上图我们基本上了解消息发送要经过 应用A、应用A对应服务器的TCP发送缓冲区、经过网络传输后消息发送到了应用B对应服务器TCP接收缓冲区、然后最终B应用读取到消息。</p><p>《UNIX网络编程》说得很清楚，5种IO模型分别是阻塞IO模型、非阻塞IO模型、IO复用模型、信号驱动的IO模型、异步IO模型；前4种为同步IO操作，只有异步IO模型是异步IO操作。</p><h2 id="阻塞IO"><a href="#阻塞IO" class="headerlink" title="阻塞IO"></a>阻塞IO</h2><p><strong>思考一个问题：</strong></p><p>因为应用之间发送消息是间断性的，也就是说在上图中TCP缓冲区还没有接收到属于应用B该读取的消息时，那么此时应用B向TCP缓冲区发起读取申请，TCP接收缓冲区是应该马上告诉应用B 现在没有你的数据，还是说让应用B在这里等着，直到有数据再把数据交给应用B。</p><p>把这个问题应用到第一个步骤也是一样，应用A在向TCP发送缓冲区发送数据时，如果TCP发送缓冲区已经满了，那么是告诉应用A现在没空间了，还是让应用A等待着，等TCP发送缓冲区有空间了再把应用A的数据访拷贝到发送缓冲区。</p><p><strong>什么是阻塞IO</strong></p><p>阻塞IO就是当应用B发起读取数据申请时，在内核数据没有准备好之前，应用B会一直处于等待数据状态，直到内核把数据准备好了交给应用B才结束。</p><p><strong>术语描述</strong>：在应用调用recvfrom读取数据时，其系统调用直到数据包到达且被复制到应用缓冲区中或者发送错误时才返回，在此期间一直会等待，进程从调用到返回这段时间内都是被阻塞的称为阻塞IO；</p><p><strong>流程：</strong></p><p>1、应用进程向内核发起recfrom读取数据。</p><p>2、准备数据报（应用进程阻塞）。</p><p>3、将数据从内核负责到应用空间。</p><p>4、复制完成后，返回成功提示。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927142530568.png" alt="image-20210927142530568"></p><p><strong>1、典型应用：阻塞socket、Java BIO；</strong></p><p><strong>2、特点：</strong></p><ul><li>进程阻塞挂起不消耗CPU资源，及时响应每个操作；</li><li>实现难度低、开发应用较容易；</li><li>适用并发量小的网络应用开发；</li></ul><p>不适用并发量大的应用：因为一个请求IO会阻塞进程，所以，得为每请求分配一个处理进程（线程）以及时响应，系统开销大。</p><h2 id="非阻塞IO"><a href="#非阻塞IO" class="headerlink" title="非阻塞IO"></a>非阻塞IO</h2><p>非阻塞IO就是当应用B发起读取数据申请时，如果内核数据没有准备好会即刻告诉应用B，不会让B在这里等待。</p><p><strong>术语</strong>：非阻塞IO是在应用调用recvfrom读取数据时，如果该缓冲区没有数据的话，就会直接返回一个EWOULDBLOCK错误，不会让应用一直等待中。在没有数据的时候会即刻返回错误标识，那也意味着如果应用要读取数据就需要不断的调用recvfrom请求，直到读取到它数据要的数据为止。</p><p><strong>流程：</strong></p><p>1、应用进程向内核发起recvfrom读取数据。</p><p>2、没有数据报准备好，即刻返回EWOULDBLOCK错误码。</p><p>3、应用进程向内核发起recvfrom读取数据。</p><p>4、已有数据包准备好就进行一下 步骤，否则还是返回错误码。</p><p>5、将数据从内核拷贝到用户空间。</p><p>6、完成后，返回成功提示。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927155649702.png" alt="image-20210927155649702"></p><p>1、典型应用：socket是非阻塞的方式（设置为NONBLOCK）</p><p>2、特点：</p><ul><li>进程轮询（重复）调用，消耗CPU的资源；</li><li>实现难度低、开发应用相对阻塞IO模式较难；</li><li>适用并发量较小、且不需要及时响应的网络应用开发；</li></ul><h2 id="IO复用模型"><a href="#IO复用模型" class="headerlink" title="IO复用模型"></a><strong>IO复用模型</strong></h2><p><strong>思考一个问题：</strong></p><p>我们还是把视角放到应用B从TCP缓冲区中读取数据这个环节来。如果在并发的环境下，可能会N个人向应用B发送消息，这种情况下我们的应用就必须创建多个线程去读取数据，每个线程都会自己调用recvfrom 去读取数据。那么此时情况可能如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-529734ac694c4da96ac78eeebd7deb6b_720w.jpg" alt="img"></p><p>如上图一样，并发情况下服务器很可能一瞬间会收到几十上百万的请求，这种情况下应用B就需要创建几十上百万的线程去读取数据，同时又因为应用线程是不知道什么时候会有数据读取，为了保证消息能及时读取到，那么这些线程自己必须不断的向内核发送recvfrom 请求来读取数据；</p><p>那么问题来了，这么多的线程不断调用recvfrom 请求数据，先不说服务器能不能扛得住这么多线程，就算扛得住那么很明显这种方式是不是太浪费资源了，线程是我们操作系统的宝贵资源，大量的线程用来去读取数据了，那么就意味着能做其它事情的线程就会少。</p><p>所以，有人就提出了一个思路，能不能提供一种方式，可以由一个线程监控多个网络请求（<strong>我们后面将称为fd文件描述符，linux系统把所有网络请求以一个fd来标识</strong>），这样就可以只需要一个或几个线程就可以完成数据状态询问的操作，当有数据准备就绪之后再分配对应的线程去读取数据，这么做就可以节省出大量的线程资源出来，这个就是IO复用模型的思路。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2c65fd3534e58d3a54cdeae778a31446_720w.jpg" alt="img"></p><p>正如上图，IO复用模型的思路就是系统提供了一种函数可以同时监控多个fd的操作，这个函数就是我们常说到的select、poll、epoll函数，有了这个函数后，应用线程通过调用select函数就可以同时监控多个fd，select函数监控的fd中只要有任何一个数据状态准备就绪了，select函数就会返回可读状态，这时询问线程再去通知处理数据的线程，对应线程此时再发起recvfrom请求去读取数据。</p><p><strong>术语描述：</strong>进程通过将一个或多个fd传递给select，阻塞在select操作上，select帮我们侦测多个fd是否准备就绪，当有fd准备就绪时，select返回数据可读状态，应用程序再调用recvfrom读取数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927160639013.png" alt="image-20210927160639013"></p><p>复用IO的基本思路就是通过slect或poll、epoll 来监控多fd ，来达到不必为每个fd创建一个对应的监控线程，从而减少线程资源创建的目的。</p><p>可以看到，多个进程注册IO后，只有另一个select调用进程被阻塞。</p><p>1、典型应用：select、poll、epoll三种方案，nginx都可以选择使用这三个方案;Java NIO;</p><p>2、特点：</p><ul><li>专一进程解决多个进程IO的阻塞问题，性能好；Reactor模式;</li><li>实现、开发应用难度较大；</li><li>适用高并发服务应用开发：一个进程（线程）响应多个请求；</li></ul><p>3、select、poll、epoll</p><ul><li>Linux中IO复用的实现方式主要有select、poll和epoll：</li><li>Select：注册IO、阻塞扫描，监听的IO最大连接数不能多于FD_SIZE；</li><li>Poll：原理和Select相似，没有数量限制，但IO数量大扫描线性性能下降；</li><li>Epoll ：事件驱动不阻塞，mmap实现内核与用户空间的消息传递，数量很大，Linux2.6后内核支持；</li></ul><h2 id="信号驱动IO模型"><a href="#信号驱动IO模型" class="headerlink" title="信号驱动IO模型"></a><strong>信号驱动IO模型</strong></h2><p>复用IO模型解决了一个线程可以监控多个fd的问题，但是select是采用轮询的方式来监控多个fd的，通过不断的轮询fd的可读状态来知道是否就可读的数据，而无脑的轮询就显得有点暴力，因为大部分情况下的轮询都是无效的，所以有人就想，能不能不要我总是去问你是否数据准备就绪，能不能我发出请求后等你数据准备好了就通知我，所以就衍生了信号驱动IO模型。</p><p>于是信号驱动IO不是用循环请求询问的方式去监控数据就绪状态，而是在调用sigaction时候建立一个SIGIO的信号联系，当内核数据准备好之后再通过SIGIO信号通知线程数据准备好后的可读状态，当线程收到可读状态的信号后，此时再向内核发起recvfrom读取数据的请求，因为信号驱动IO的模型下应用线程在发出信号监控后即可返回，不会阻塞，所以这样的方式下，一个应用线程也可以同时监控多个fd。</p><p>类似于下图描述：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2461c8df6a154930afb4e7c345442835_720w.jpg" alt="img"></p><p><strong>术语描述：</strong>首先开启套接口信号驱动IO功能，并通过系统调用sigaction执行一个信号处理函数，此时请求即刻返回，当数据准备就绪时，就生成对应进程的SIGIO信号，通过信号回调通知应用线程调用recvfrom来读取数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927161210407.png" alt="image-20210927161210407"></p><p> IO复用模型里面的select虽然可以监控多个fd了，但select其实现的本质上还是通过不断的轮询fd来监控数据状态， 因为大部分轮询请求其实都是无效的，所以信号驱动IO意在通过这种建立信号关联的方式，实现了发出请求后只需要等待数据就绪的通知即可，这样就可以避免大量无效的数据状态轮询操作。</p><p>特点：回调机制，实现、开发应用难度大；</p><h2 id="异步IO模型"><a href="#异步IO模型" class="headerlink" title="异步IO模型"></a><strong>异步IO模型</strong></h2><p>不管是IO复用还是信号驱动，我们要读取一个数据总是要发起两阶段的请求，第一次发送select请求，询问数据状态是否准备好，第二次发送recevform请求读取数据。</p><p><strong>思考一个问题：</strong></p><p>也许你一开始就有一个疑问，为什么我们明明是想读取数据，什么非得要先发起一个select询问数据状态的请求，然后再发起真正的读取数据请求,能不能有一种一劳永逸的方式，我只要发送一个请求我告诉内核我要读取数据，然后我就什么都不管了，然后内核去帮我去完成剩下的所有事情？</p><p>当然既然你想得出来，那么就会有人做得到，有人设计了一种方案，应用只需要向内核发送一个read 请求,告诉内核它要读取数据后即刻返回；内核收到请求后会建立一个信号联系，当数据准备就绪，内核会主动把数据从内核复制到用户空间，等所有操作都完成之后，内核会发起一个通知告诉应用，我们称这种一劳永逸的模式为异步IO模型。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-96009f54d89ade0d8c4001bc67395c57_720w.jpg" alt="img"></p><p><strong>术语描述：</strong> 应用告知内核启动某个操作，并让内核在整个操作完成之后，通知应用，这种模型与信号驱动模型的主要区别在于，信号驱动IO只是由内核通知我们合适可以开始下一个IO操作，而异步IO模型是由内核通知我们操作什么时候完成。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927161941186.png" alt="image-20210927161941186"></p><p><strong>总结：</strong>异步IO的优化思路是解决了应用程序需要先后发送询问请求、发送接收数据请求两个阶段的模式，在异步IO的模式下，只需要向内核发送一次请求就可以完成状态询问和数拷贝的所有操作。</p><h2 id="IO模型比较"><a href="#IO模型比较" class="headerlink" title="IO模型比较"></a><strong>IO模型比较</strong></h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927164055422.png" alt="image-20210927164055422"></p><h3 id="阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型"><a href="#阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型" class="headerlink" title="阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型"></a><strong>阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型</strong></h3><p>注意这里的阻塞IO调用和非阻塞IO调用不是指阻塞IO模型和非阻塞IO模型：</p><ul><li>阻塞IO调用 ：在用户进程（线程）中调用执行的时候，进程会等待该IO操作，而使得其他操作无法执行。</li><li>非阻塞IO调用：在用户进程中调用执行的时候，无论成功与否，该IO操作会立即返回，之后进程可以进行其他操作（当然如果是读取到数据，一般就接着进行数据处理）。</li></ul><p>这个直接理解就好，进程（线程）IO调用会不会阻塞进程自己。所以这里两个概念是相对调用进程本身状态来讲的。</p><p>从上面对比图片来说，阻塞IO模型是一个阻塞IO调用，而非阻塞IO模型是多个非阻塞IO调用+一个阻塞IO调用，因为多个IO检查会立即返回错误，不会阻塞进程。</p><p>而上面也说过了，非阻塞IO模型对于阻塞IO模型来说区别就是，内核数据没准备好需要进程阻塞的时候，就返回一个错误，以使得进程不被阻塞。</p><h3 id="同步IO和异步IO"><a href="#同步IO和异步IO" class="headerlink" title="同步IO和异步IO"></a><strong>同步IO和异步IO</strong></h3><ul><li>同步IO：导致请求进程阻塞，直到I/O操作完成。</li><li>异步IO：不导致请求进程阻塞。</li></ul><p>上面两个定义是《UNIX网络编程 卷1：套接字联网API》给出的。这不是很好理解，我们来扩展一下，先说说同步和异步，同步和异步关注的是双方的消息通信机制：</p><ul><li>同步：双方的动作是经过双方协调的，步调一致的。</li><li>异步：双方并不需要协调，都可以随意进行各自的操作。</li></ul><p>这里我们的双方是指，用户进程和IO设备；明确同步和异步之后，我们在上面网络输入操作例子的基础上，进行扩展定义：</p><ul><li>同步IO：用户进程发出IO调用，去获取IO设备数据，双方的数据要经过内核缓冲区同步，完全准备好后，再复制返回到用户进程。而复制返回到用户进程会导致请求进程阻塞，直到I/O操作完成。</li><li>异步IO：用户进程发出IO调用，去获取IO设备数据，并不需要同步，内核直接复制到进程，整个过程不导致请求进程阻塞。</li></ul><p>所以， 阻塞IO模型、非阻塞IO模型、IO复用模型、信号驱动的IO模型者为同步IO模型，只有异步IO模型是异步IO。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;IO&quot;&gt;&lt;a href=&quot;#IO&quot; class=&quot;headerlink&quot; title=&quot;IO&quot;&gt;&lt;/a&gt;IO&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20</summary>
      
    
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据结构</title>
    <link href="https://leslieaibin.github.io/2021/09/29/Redis/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://leslieaibin.github.io/2021/09/29/Redis/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2021-09-29T01:15:42.000Z</published>
    <updated>2021-09-30T08:44:00.941Z</updated>
    
    <content type="html"><![CDATA[<p>Redist有五种基本数据结构：<strong>string、hash、set、zset、list</strong>。这五种数据结构的底层数据结构有六种：<strong>动态字符串SDS、链表、哈希表、跳表、整数集合、压缩链表</strong></p><h1 id="底层结构"><a href="#底层结构" class="headerlink" title="底层结构"></a>底层结构</h1><p>Redis是用C语言写的，但是Redis并没有使用C的字符串表示（C是字符串是以<code>\0</code>空字符结尾的字符数组），而是自己构建了一种<strong>简单动态字符串</strong>（simple dynamic string，SDS）的抽象类型，并作为Redis的默认字符串表示</p><p>在Redis中，包含字符串值的键值对底层都是用SDS实现的</p><h2 id="动态字符串SDS"><a href="#动态字符串SDS" class="headerlink" title="动态字符串SDS"></a>动态字符串SDS</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3.0</span></span><br><span class="line">struct sdshdr &#123;</span><br><span class="line">    <span class="comment">// 记录buf数组中已使用字节的数量，即SDS所保存字符串的长度</span></span><br><span class="line">    unsigned <span class="keyword">int</span> len;</span><br><span class="line">    <span class="comment">// 记录buf数据中未使用的字节数量</span></span><br><span class="line">    unsigned <span class="keyword">int</span> free;</span><br><span class="line">    <span class="comment">// 字节数组，用于保存字符串</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.2</span></span><br><span class="line"><span class="comment">/* Note: sdshdr5 is never used, we just access the flags byte directly.</span></span><br><span class="line"><span class="comment"> * However is here to document the layout of type 5 SDS strings. */</span></span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr5 </span>&#123;</span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, and 5 msb of string length */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr8 </span>&#123;</span><br><span class="line">    uint8_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint8_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr16 </span>&#123;</span><br><span class="line">    uint16_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint16_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr32 </span>&#123;</span><br><span class="line">    uint32_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint32_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr64 </span>&#123;</span><br><span class="line">    uint64_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint64_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>3.2版本之后，会根据字符串的长度来选择对应的数据结构</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">char</span> <span class="title">sdsReqType</span><span class="params">(<span class="keyword">size_t</span> string_size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1</span>&lt;&lt;<span class="number">5</span>)  <span class="comment">// 32</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_5;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1</span>&lt;&lt;<span class="number">8</span>)  <span class="comment">// 256</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_8;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1</span>&lt;&lt;<span class="number">16</span>)   <span class="comment">// 65536 64k</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_16;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1l</span>l&lt;&lt;<span class="number">32</span>)  <span class="comment">// 4294967296 4G</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_32;</span><br><span class="line">    <span class="keyword">return</span> SDS_TYPE_64;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d245812d1e41c5~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p><code>len</code>：记录当前已使用的字节数（不包括<code>&#39;\0&#39;</code>），获取SDS长度的复杂度为O(1)</p><p><code>alloc</code>：记录当前字节数组总共分配的字节数量（不包括<code>&#39;\0&#39;</code>）</p><p><code>flags</code>：标记当前字节数组的属性，是<code>sdshdr8</code>还是<code>sdshdr16</code>等，flags值的定义可以看下面代码</p><p><code>buf</code>：字节数组，用于保存字符串，包括结尾空白字符`’\0’</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// flags值定义</span></span><br><span class="line">#define SDS_TYPE_5  0</span><br><span class="line">#define SDS_TYPE_8  1</span><br><span class="line">#define SDS_TYPE_16 2</span><br><span class="line">#define SDS_TYPE_32 3</span><br><span class="line">#define SDS_TYPE_64 4</span><br></pre></td></tr></table></figure><p>上面的字节数组的空白处表示未使用空间，是Redis优化的空间策略，给字符串的操作留有余地，保证安全提高效率</p><h2 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h2><p>链表上的节点定义如下，<code>adlist.h/listNode</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">typedef struct listNode &#123;</span><br><span class="line">    <span class="comment">// 前置节点</span></span><br><span class="line">    struct listNode *prev;</span><br><span class="line">    <span class="comment">// 后置节点</span></span><br><span class="line">    struct listNode *next;</span><br><span class="line">    <span class="comment">// 节点值</span></span><br><span class="line">    <span class="keyword">void</span> *value;</span><br><span class="line">&#125; listNode;</span><br></pre></td></tr></table></figure><p>链表的定义如下，<code>adlist.h/list</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">typedef struct list &#123;</span><br><span class="line">    <span class="comment">// 链表头节点</span></span><br><span class="line">    listNode *head;</span><br><span class="line">    <span class="comment">// 链表尾节点</span></span><br><span class="line">    listNode *tail;</span><br><span class="line">    <span class="comment">// 节点值复制函数</span></span><br><span class="line">    <span class="keyword">void</span> *(*dup)(<span class="keyword">void</span> *ptr);</span><br><span class="line">    <span class="comment">// 节点值释放函数</span></span><br><span class="line">    <span class="keyword">void</span> (*free)(<span class="keyword">void</span> *ptr);</span><br><span class="line">    <span class="comment">// 节点值对比函数</span></span><br><span class="line">    <span class="keyword">int</span> (*match)(<span class="keyword">void</span> *ptr, <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 链表所包含的节点数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> len;</span><br><span class="line">&#125; list;</span><br></pre></td></tr></table></figure><p>每个节点<code>listNode</code>可以通过<code>prev</code>和<code>next</code>指针分布指向前一个节点和后一个节点组成双端链表，同时每个链表还会有一个<code>list</code>结构为链表提供表头指针<code>head</code>、表尾指针<code>tail</code>、以及链表长度计数器<code>len</code>，还有三个用于实现多态链表的类型特定函数</p><ul><li><code>dup</code>：用于复制链表节点所保存的值</li><li><code>free</code>：用于释放链表节点所保存的值</li><li><code>match</code>：用于对比链表节点所保存的值和另一个输入值是否相等</li></ul><p> <strong>链表结构图</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318c8442f7~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p> <strong>链表特性</strong></p><ul><li>双端链表：带有指向前置节点和后置节点的指针，获取这两个节点的复杂度为O(1)</li><li>无环：表头节点的<code>prev</code>和表尾节点的<code>next</code>都指向NULL，对链表的访问以NULL结束</li><li>链表长度计数器：带有<code>len</code>属性，获取链表长度的复杂度为O(1)</li><li>多态：链表节点使用 <code>void*</code>指针保存节点值，可以保存不同类型的值</li></ul><h3 id="3-2版本后更改"><a href="#3-2版本后更改" class="headerlink" title="3.2版本后更改"></a>3.2版本后更改</h3><p>quicklist：</p><p>（1）什么是quicklist：</p><p>quicklist是一个双向链表，而且是一个基于ziplist的双向链表，quicklist的每个节点都是一个ziplist，比如，一个包含3个节点的quicklist，如果每个节点的ziplist又包含4个数据项，那么对外表现上，这个list就总共包含12个数据项。</p><p>quicklist的结构为什么这样设计呢？总结起来，大概又是一个空间和时间的折中：</p><p>双向链表便于在表的两端进行push和pop操作，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。<br>ziplist由于是一整块连续内存，所以存储效率很高。但是，它不利于修改操作，每次数据变动都会引发一次内存的realloc。特别是当ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝，进一步降低性能。<br>于是，结合了双向链表和ziplist的优点，quicklist就应运而生了。</p><p>（2）quicklist中每个ziplist长度的配置：</p><p>不过，这也带来了一个新问题：到底一个quicklist节点包含多长的ziplist合适呢？比如，同样是存储12个数据项，既可以是一个quicklist包含3个节点，而每个节点的ziplist又包含4个数据项，也可以是一个quicklist包含6个节点，而每个节点的ziplist又包含2个数据项。</p><p>这又是一个需要找平衡点的难题。我们只从存储效率上分析一下：</p><p>每个quicklist节点上的ziplist越短，则内存碎片越多。内存碎片多了，有可能在内存中产生很多无法被利用的小碎片，从而降低存储效率。这种情况的极端是每个quicklist节点上的ziplist只包含一个数据项，这就蜕化成一个普通的双向链表了。<br>每个quicklist节点上的ziplist越长，则为ziplist分配大块连续内存空间的难度就越大。有可能出现内存里有很多小块的空闲空间（它们加起来很多），但却找不到一块足够大的空闲空间分配给ziplist的情况。这同样会降低存储效率。这种情况的极端是整个quicklist只有一个节点，所有的数据项都分配在这仅有的一个节点的ziplist里面。这其实蜕化成一个ziplist了<br>可见，一个quicklist节点上的ziplist要保持一个合理的长度。那到底多长合理呢？这可能取决于具体应用场景。实际上，Redis提供了一个配置参数list-max-ziplist-size，就是为了让使用者可以来根据自己的情况进行调整。</p><p>list-max-ziplist-size -2</p><p>这个参数可以取正值，也可以取负值。</p><p>当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。</p><p>当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值，每个值含义如下：</p><p>-5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =&gt; 1024 bytes）</p><p>-4: 每个quicklist节点上的ziplist大小不能超过32 Kb。</p><p>-3: 每个quicklist节点上的ziplist大小不能超过16 Kb。</p><p>-2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值）</p><p>-1: 每个quicklist节点上的ziplist大小不能超过4 Kb。</p><h2 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h2><p>哈希表又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。字典中的每一个键都是唯一的，可以通过键查找与之关联的值，并对其修改或删除</p><p>Redis的键值对存储就是用哈希表实现的，散列（Hash）的底层实现之一也是哈希表</p><p>哈希表结构定义，<code>dict.h/dictht</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictht &#123;</span><br><span class="line">    <span class="comment">// 哈希表数组</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="comment">// 哈希表大小</span></span><br><span class="line">    unsigned <span class="keyword">long</span> size;</span><br><span class="line">    <span class="comment">// 哈希表大小掩码，用于计算索引值，等于size-1</span></span><br><span class="line">    unsigned <span class="keyword">long</span> sizemask;</span><br><span class="line">    <span class="comment">// 哈希表已有节点的数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure><p>哈希表是由数组<code>table</code>组成，<code>table</code>中每个元素都是指向<code>dict.h/dictEntry</code>结构的指针，哈希表节点的定义如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictEntry &#123;</span><br><span class="line">    <span class="comment">// 键</span></span><br><span class="line">    <span class="keyword">void</span> *key;</span><br><span class="line">    <span class="comment">// 值</span></span><br><span class="line">    union &#123;</span><br><span class="line">        <span class="keyword">void</span> *val;</span><br><span class="line">        uint64_t u64;</span><br><span class="line">        int64_t s64;</span><br><span class="line">        <span class="keyword">double</span> d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="comment">// 指向下一个哈希表节点，形成链表</span></span><br><span class="line">    struct dictEntry *next;</span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure><p>其中<code>key</code>是我们的键；<code>v</code>是键值，可以是一个指针，也可以是整数或浮点数；<code>next</code>属性是指向下一个哈希表节点的指针，可以让多个哈希值相同的键值对形成链表，解决键冲突问题</p><p>最后就是我们的字典结构，<code>dict.h/dict</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dict &#123;</span><br><span class="line">    <span class="comment">// 和类型相关的处理函数</span></span><br><span class="line">    dictType *type;</span><br><span class="line">    <span class="comment">// 私有数据</span></span><br><span class="line">    <span class="keyword">void</span> *privdata;</span><br><span class="line">    <span class="comment">// 哈希表</span></span><br><span class="line">    dictht ht[<span class="number">2</span>];</span><br><span class="line">    <span class="comment">// rehash 索引，当rehash不再进行时，值为-1</span></span><br><span class="line">    <span class="keyword">long</span> rehashidx; <span class="comment">/* rehashing not in progress if rehashidx == -1 */</span></span><br><span class="line">    <span class="comment">// 迭代器数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> iterators; <span class="comment">/* number of iterators currently running */</span></span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure><p><code>type</code>属性和<code>privdata</code>属性是针对不同类型的键值对，用于创建多类型的字典，<code>type</code>是指向<code>dictType</code>结构的指针，<code>privdata</code>则保存需要传给类型特定函数的可选参数，关于<code>dictType</code>结构和类型特定函数可以看下面代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictType &#123;</span><br><span class="line">    <span class="comment">// 计算哈希值的行数</span></span><br><span class="line">    uint64_t (*hashFunction)(<span class="keyword">const</span> <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 复制键的函数</span></span><br><span class="line">    <span class="keyword">void</span> *(*keyDup)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 复制值的函数</span></span><br><span class="line">    <span class="keyword">void</span> *(*valDup)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *obj);</span><br><span class="line">    <span class="comment">// 对比键的函数</span></span><br><span class="line">    <span class="keyword">int</span> (*keyCompare)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *key1, <span class="keyword">const</span> <span class="keyword">void</span> *key2);</span><br><span class="line">    <span class="comment">// 销毁键的函数</span></span><br><span class="line">    <span class="keyword">void</span> (*keyDestructor)(<span class="keyword">void</span> *privdata, <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 销毁值的函数</span></span><br><span class="line">    <span class="keyword">void</span> (*valDestructor)(<span class="keyword">void</span> *privdata, <span class="keyword">void</span> *obj);</span><br><span class="line">&#125; dictType;</span><br></pre></td></tr></table></figure><p><code>dict</code>的<code>ht</code>属性是两个元素的数组，包含两个<code>dictht</code>哈希表，一般字典只使用<code>ht[0]</code>哈希表，<code>ht[1]</code>哈希表会在对<code>ht[0]</code>哈希表进行<code>rehash</code>（重哈希）的时候使用，即当哈希表的键值对数量超过负载数量过多的时候，会将键值对迁移到<code>ht[1]</code>上</p><p><code>rehashidx</code>也是跟rehash相关的，rehash的操作不是瞬间完成的，<code>rehashidx</code>记录着rehash的进度，如果目前没有在进行rehash，它的值为-1</p><p>结合上面的几个结构，我们来看一下<strong>字典的结构图</strong>（没有在进行rehash）</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318d3796f5~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><p>一个普通的单链表查询一个元素的时间复杂度为O(N)，即便该单链表是有序的。使用跳跃表（SkipList）是来解决查找问题的，它是一种有序的数据结构，不属于平衡树结构，也不属于Hash结构，它通过在每个节点维持多个指向其他节点的指针，而达到快速访问节点的目的</p><p>跳跃表是有序集合（Sorted Set）的底层实现之一，如果有序集合包含的元素比较多，或者元素的成员是比较长的字符串时，Redis会使用跳跃表做有序集合的底层实现</p><p> <strong>跳跃表的定义</strong></p><p>跳跃表其实可以把它理解为<strong>多层的链表</strong>，它有如下的性质</p><ul><li><strong>多层</strong>的结构组成，每层是一个<strong>有序的链表</strong></li><li>最底层（level 1）的链表包含所有的元素</li><li>跳跃表的查找次数近似于层数，时间复杂度为O(logn)，插入、删除也为 O(logn)</li><li>跳跃表是一种随机化的数据结构(通过抛硬币来决定层数)</li></ul><p>那么如何来理解跳跃表呢，我们从最底层的包含所有元素的链表开始，给定如下的链表</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318d89eb55~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>然后我们每隔一个元素，把它放到上一层的链表当中，这里我把它叫做<strong>上浮</strong>（注意，科学的办法是<strong>抛硬币</strong>的方式，来决定元素是否上浮到上一层链表，我这里先简单每隔一个元素上浮到上一层链表，便于理解），操作完成之后的结构如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318d9e2558~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>查找元素的方法是这样，从上层开始查找，大数向右找到头，小数向左找到头，例如我要查找<code>17</code>，查询的顺序是：13 -&gt; 46  -&gt; 22 -&gt; 17；如果是查找<code>35</code>，则是 13 -&gt; 46 -&gt; 22 -&gt; 46 -&gt; 35；如果是<code>54</code>，则是 13 -&gt; 46 -&gt; 54</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318db56821~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>上面是查找元素，如果是添加元素，是通过抛硬币的方式来决定该元素会出现到多少层，也就是说它会有 1/2的概率出现第二层、1/4 的概率出现在第三层……</p><p>跳跃表节点的删除和添加都是不可预测的，很难保证跳表的索引是始终均匀的，抛硬币的方式可以让大体上是趋于均匀的</p><p>假设我们已经有了上述例子的一个跳跃表了，现在往里面添加一个元素<code>18</code>，通过抛硬币的方式来决定它会出现的层数，是正面就继续，反面就停止，假如我抛了2次硬币，第一次为正面，第二次为反面</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31ad5ebfc9~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>跳跃表的删除很简单，只要先找到要删除的节点，然后顺藤摸瓜删除每一层相同的节点就好了</p><p>跳跃表维持结构平衡的成本是比较低的，完全是依靠随机，相比二叉查找树，在多次插入删除后，需要Rebalance来重新调整结构平衡</p><p><strong>跳跃表的实现</strong></p><p>Redis的跳跃表实现是由<code>redis.h/zskiplistNode</code>和<code>redis.h/zskiplist</code>（3.2版本之后redis.h改为了server.h）两个结构定义，<code>zskiplistNode</code>定义跳跃表的节点，<code>zskiplist</code>保存跳跃表节点的相关信息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ZSETs use a specialized version of Skiplists */</span></span><br><span class="line">typedef struct zskiplistNode &#123;</span><br><span class="line">    <span class="comment">// 成员对象 （robj *obj;）</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">// 分值</span></span><br><span class="line">    <span class="keyword">double</span> score;</span><br><span class="line">    <span class="comment">// 后退指针</span></span><br><span class="line">    struct zskiplistNode *backward;</span><br><span class="line">    <span class="comment">// 层</span></span><br><span class="line">    struct zskiplistLevel &#123;</span><br><span class="line">        <span class="comment">// 前进指针</span></span><br><span class="line">        struct zskiplistNode *forward;</span><br><span class="line">        <span class="comment">// 跨度</span></span><br><span class="line">        <span class="comment">// 跨度实际上是用来计算元素排名(rank)的，在查找某个节点的过程中，将沿途访过的所有层的跨度累积起来，得到的结果就是目标节点在跳跃表中的排位</span></span><br><span class="line">        unsigned <span class="keyword">long</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br><span class="line"></span><br><span class="line">typedef struct zskiplist &#123;</span><br><span class="line">    <span class="comment">// 表头节点和表尾节点</span></span><br><span class="line">    struct zskiplistNode *header, *tail;</span><br><span class="line">    <span class="comment">// 表中节点的数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> length;</span><br><span class="line">    <span class="comment">// 表中层数最大的节点的层数</span></span><br><span class="line">    <span class="keyword">int</span> level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure><p><code>zskiplistNode</code>结构</p><ul><li><code>level</code>数组（层）：每次创建一个新的跳表节点都会根据幂次定律计算出level数组的大小，也就是次层的高度，每一层带有两个属性-<strong>前进指针</strong>和<strong>跨度</strong>，前进指针用于访问表尾方向的其他指针；跨度用于记录当前节点与前进指针所指节点的距离（指向的为NULL，阔度为0）</li><li><code>backward</code>（后退指针）：指向当前节点的前一个节点</li><li><code>score</code>（分值）：用来排序，如果分值相同看成员变量在字典序大小排序</li><li><code>obj</code>或<code>ele</code>：成员对象是一个指针，指向一个字符串对象，里面保存着一个sds；在跳表中各个节点的成员对象必须唯一，分值可以相同</li></ul><p><code>zskiplist</code>结构</p><ul><li><code>header</code>、<code>tail</code>表头节点和表尾节点</li><li><code>length</code>表中节点的数量</li><li><code>level</code>表中层数最大的节点的层数</li></ul><p>假设我们现在展示一个跳跃表，有四个节点，节点的高度分别是2、1、4、</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b0f3da89~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p><code>zskiplist</code>的头结点不是一个有效的节点，它有<strong>ZSKIPLIST_MAXLEVEL</strong>层(32层)，每层的<code>forward</code>指向该层跳跃表的第一个节点，若没有则为NULL，在Redis中，上面的跳跃表结构如下</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b46f4b67~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><ul><li>每个跳跃表节点的层数在1-32之间</li><li>一个跳跃表中，节点按照分值大小排序，多个节点的分值是可以相同的，相同时，节点按成员对象大小排序</li><li>每个节点的成员变量必须是唯一的</li></ul><h2 id="整数集合"><a href="#整数集合" class="headerlink" title="整数集合"></a>整数集合</h2><p>整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，可以保存类型为int16_t、int32_t、int64_t的整数值，并且保证集合中不会出现重复元素</p><p>整数集合是集合（Set）的底层实现之一，如果一个集合只包含整数值元素，且元素数量不多时，会使用整数集合作为底层实现</p><p><strong>整数集合的定义实现</strong></p><p>整数集合的定义为<code>inset.h/inset</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">typedef struct intset &#123;</span><br><span class="line">    <span class="comment">// 编码方式</span></span><br><span class="line">    uint32_t encoding;</span><br><span class="line">    <span class="comment">// 集合包含的元素数量</span></span><br><span class="line">    uint32_t length;</span><br><span class="line">    <span class="comment">// 保存元素的数组</span></span><br><span class="line">    int8_t contents[];</span><br><span class="line">&#125; intset;</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><ul><li><code>contents</code>数组：整数集合的每个元素在数组中按值的大小从小到大排序，且不包含重复项</li><li><code>length</code>记录整数集合的元素数量，即contents数组长度</li><li><code>encoding</code>决定contents数组的真正类型，如INTSET_ENC_INT16、INTSET_ENC_INT32、INTSET_ENC_INT64</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b471202a~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p> <strong>整数集合的升级</strong></p><p>当想要添加一个新元素到整数集合中时，并且新元素的类型比整数集合现有的所有元素的类型都要长，整数集合需要先进行升级（upgrade），才能将新元素添加到整数集合里面。每次想整数集合中添加新元素都有可能会引起升级，每次升级都需要对底层数组已有的所有元素进行类型转换</p><p>升级添加新元素：</p><ul><li>根据新元素类型，扩展整数集合底层数组的空间大小，并为新元素分配空间</li><li>把数组现有的元素都转换成新元素的类型，并将转换后的元素放到正确的位置，且要保持数组的有序性</li><li>添加新元素到底层数组</li></ul><p>整数集合的升级策略可以提升整数集合的灵活性，并尽可能的节约内存</p><p>另外，整数集合不支持降级，一旦升级，编码就会一直保持升级后的状态</p><h2 id="压缩链表"><a href="#压缩链表" class="headerlink" title="压缩链表"></a>压缩链表</h2><p>压缩列表（ziplist）是为了节约内存而设计的，是由一系列特殊编码的连续内存块组成的顺序性（sequential）数据结构，一个压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者一个整数值</p><p>压缩列表是列表（List）和散列（Hash）的底层实现之一，一个列表只包含少量列表项，并且每个列表项是小整数值或比较短的字符串，会使用压缩列表作为底层实现（在3.2版本之后是使用<code>quicklist</code>实现）</p><p><strong>压缩列表的构成</strong></p><p>一个压缩列表可以包含多个节点（entry），每个节点可以保存一个字节数组或者一个整数值</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b5614230~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>各部分组成说明如下</p><ul><li><code>zlbytes</code>：记录整个压缩列表占用的内存字节数，在压缩列表内存重分配，或者计算<code>zlend</code>的位置时使用</li><li><code>zltail</code>：记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过该偏移量，可以不用遍历整个压缩列表就可以确定表尾节点的地址</li><li><code>zllen</code>：记录压缩列表包含的节点数量，但该属性值小于UINT16_MAX（65535）时，该值就是压缩列表的节点数量，否则需要遍历整个压缩列表才能计算出真实的节点数量</li><li><code>entryX</code>：压缩列表的节点</li><li><code>zlend</code>：特殊值0xFF（十进制255），用于标记压缩列表的末端</li></ul><p><strong>压缩列表节点的构成</strong></p><p>每个压缩列表节点可以保存一个字节数字或者一个整数值，结构如下</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b502238d~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><ul><li><code>previous_entry_ength</code>：记录压缩列表前一个字节的长度</li><li><code>encoding</code>：节点的encoding保存的是节点的content的内容类型</li><li><code>content</code>：content区域用于保存节点的内容，节点内容类型和长度由encoding决定</li></ul><h2 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h2><p>上面介绍了Redis的主要底层数据结构，包括简单动态字符串（SDS）、链表、字典、跳跃表、整数集合、压缩列表。但是Redis并没有直接使用这些数据结构来构建键值对数据库，而是基于这些数据结构创建了一个对象系统，也就是我们所熟知的可API操作的Redis那些数据类型，如字符串(String)、列表(List)、散列(Hash)、集合(Set)、有序集合(Sorted Set)</p><p>根据对象的类型可以判断一个对象是否可以执行给定的命令，也可针对不同的使用场景，对象设置有多种不同的数据结构实现，从而优化对象在不同场景下的使用效率</p><table><thead><tr><th>类型</th><th>编码</th><th>BOJECT ENCODING 命令输出</th><th>对象</th></tr></thead><tbody><tr><td>REDIS_STRING</td><td>REDIS_ENCODING_INT</td><td>“int”</td><td>使用整数值实现的字符串对象</td></tr><tr><td>REDIS_STRING</td><td>REDIS_ENCODING_EMBSTR</td><td>“embstr”</td><td>使用embstr编码的简单动态字符串实现的字符串对象</td></tr><tr><td>REDIS_STRING</td><td>REDIS_ENCODING_RAW</td><td>“raw”</td><td>使用简单动态字符串实现的字符串对象</td></tr><tr><td>REDIS_LIST</td><td>REDIS_ENCODING_ZIPLIST</td><td>“ziplist”</td><td>使用压缩列表实现的列表对象</td></tr><tr><td>REDIS_LIST</td><td>REDIS_ENCODING_LINKEDLIST</td><td>‘“linkedlist’</td><td>使用双端链表实现的列表对象</td></tr><tr><td>REDIS_HASH</td><td>REDIS_ENCODING_ZIPLIST</td><td>“ziplist”</td><td>使用压缩列表实现的哈希对象</td></tr><tr><td>REDIS_HASH</td><td>REDIS_ENCODING_HT</td><td>“hashtable”</td><td>使用字典实现的哈希对象</td></tr><tr><td>REDIS_SET</td><td>REDIS_ENCODING_INTSET</td><td>“intset”</td><td>使用整数集合实现的集合对象</td></tr><tr><td>REDIS_SET</td><td>REDIS_ENCODING_HT</td><td>“hashtable”</td><td>使用字典实现的集合对象</td></tr><tr><td>REDIS_ZSET</td><td>REDIS_ENCODING_ZIPLIST</td><td>“ziplist”</td><td>使用压缩列表实现的有序集合对象</td></tr><tr><td>REDIS_ZSET</td><td>REDIS_ENCODING_SKIPLIST</td><td>“skiplist”</td><td>使用跳跃表表实现的有序集合对象</td></tr></tbody></table><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>String数据结构是最简单的数据类型。一般用于复杂的计数功能的缓存：微博数，粉丝数等。</p><p><strong>底层实现方式：动态字符串sds 或者 long</strong></p><p>String的内部存储结构一般是sds（Simple Dynamic String，可以动态扩展内存），但是如果一个String类型的value的值是数字，那么Redis内部会把它转成long类型来存储，从而减少内存的使用。</p><ul><li>确切地说，String在Redis中是用一个robj来表示的。</li><li>用来表示String的robj可能编码成3种内部表示：OBJ_ENCODING_RAW，OBJ_ENCODING_EMBSTR，OBJ_ENCODING_INT。其中前两种编码使用的是sds来存储，最后一种OBJ_ENCODING_INT编码直接把string存成了long型。</li><li>在对string进行incr, decr等操作的时候，如果它内部是OBJ_ENCODING_INT编码，那么可以直接进行加减操作；如果它内部是OBJ_ENCODING_RAW或OBJ_ENCODING_EMBSTR编码，那么Redis会先试图把sds存储的字符串转成long型，如果能转成功，再进行加减操作。</li><li>对一个内部表示成long型的string执行append, setbit, getrange这些命令，针对的仍然是string的值（即十进制表示的字符串），而不是针对内部表示的long型进行操作。比如字符串”32”，如果按照字符数组来解释，它包含两个字符，它们的ASCII码分别是0x33和0x32。当我们执行命令setbit key 7 0的时候，相当于把字符0x33变成了0x32，这样字符串的值就变成了”22”。而如果将字符串”32”按照内部的64位long型来解释，那么它是0x0000000000000020，在这个基础上执行setbit位操作，结果就完全不对了。因此，在这些命令的实现中，会把long型先转成字符串再进行相应的操作。</li></ul><h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><p>Hash特别适合用于存储对象，因为一个对象的各个属性，正好对应一个hash结构的各个field，可以方便地操作对象中的某个字段。</p><p><strong>底层实现方式：压缩列表ziplist 或者 字典dict</strong></p><p>当Hash中数据项比较少的情况下，Hash底层才用压缩列表ziplist进行存储数据，随着数据的增加，底层的ziplist就可能会转成dict，具体配置如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hash-max-ziplist-entries <span class="number">512</span></span><br><span class="line">hash-max-ziplist-value <span class="number">64</span></span><br></pre></td></tr></table></figure><p>当hash中的数据项（即filed-value对）的数目超过512时，也就是ziplist数据项超过1024的时候<br>当hash中插入的任意一个value的长度超过了64字节的时候</p><p>当满足上面两个条件其中之一的时候，Redis就使用dict字典来实现hash。</p><p>Redis的hash之所以这样设计，是因为当ziplist变得很大的时候，它有如下几个缺点：</p><ul><li><p>每次插入或修改引发的realloc操作会有更大的概率造成内存拷贝，从而降低性能。</p></li><li><p>一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。</p></li><li><p>当ziplist数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。</p></li></ul><p>总之，ziplist本来就设计为各个数据项挨在一起组成连续的内存空间，这种结构并不擅长做修改操作。一旦数据发生改动，就会引发内存realloc，可能导致内存拷贝。</p><h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>list 的实现为一个双向链表，经常被用作队列使用，支持在链表两端进行push和pop操作，时间复杂度为O(1)；同时也支持在链表中的任意位置的存取操作，但是都需要对list进行遍历，支持反向查找和遍历，时间复杂度为O(n)。</p><p>list是一个能维持数据项先后顺序的列表（各个数据项的先后顺序由插入位置决定），便于在表的两端追加和删除数据，而对于中间位置的存取具有O(N)的时间复杂度。</p><p>list 的应用场景非常多，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。可以利用lrange命令，做基于redis的分页功能。</p><ul><li><strong>Redis3.2之前的底层实现方式：压缩列表ziplist 或者 双向循环链表linkedlist</strong></li></ul><p>当list存储的数据量比较少且同时满足下面两个条件时，list就使用ziplist存储数据：</p><p>list中保存的每个元素的长度小于 64 字节；</p><p>列表中数据个数少于512个。</p><p>当不能同时满足上面两个条件的时候，list就通过双向循环链表linkedlist来实现了</p><ul><li><strong>Redis3.2及之后的底层实现方式：quicklist</strong></li></ul><p>quicklist是一个双向链表，而且是一个基于ziplist的双向链表，quicklist的每个节点都是一个ziplist，结合了双向链表和ziplist的优点</p><h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>set是一个存放不重复值的无序集合，可以做全局去重的功能，提供了判断某个元素是否在set集合内的功能，这个也是list所不能提供的。基于set可以实现交集、并集、差集的操作，计算共同喜好，全部的喜好，自己独有的喜好等功能。</p><p><strong>底层实现方式：有序整数集合intset 或者 字典dict</strong></p><p>当存储的数据同时满足下面这样两个条件的时候，Redis 就采用整数集合intset来实现set这种数据类型：</p><ul><li>存储的数据都是整数</li><li>存储的数据元素个数小于512个</li></ul><p>当不能同时满足这两个条件的时候，Redis 就使用dict来存储集合中的数据</p><h2 id="Sorted-Set"><a href="#Sorted-Set" class="headerlink" title="Sorted Set"></a>Sorted Set</h2><p>Sorted set多了一个权重参数score，集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。另外，sorted set可以用来做延时任务。最后一个应用就是可以做范围查找。</p><p><strong>底层实现方式：压缩列表ziplist 或者 zskiplistNode</strong></p><p>当存储的数据同时满足下面这两个条件的时候，Redis就使用压缩列表ziplist实现sorted set</p><ul><li>集合中每个数据的大小都要小于 64 字节</li><li>元素个数要小于 128 个，也就是ziplist数据项小于256个</li></ul><p>当不能同时满足这两个条件的时候，Redis 就使用zskiplistNode来实现sorted set。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Redist有五种基本数据结构：&lt;strong&gt;string、hash、set、zset、list&lt;/strong&gt;。这五种数据结构的底层数据结构有六种：&lt;strong&gt;动态字符串SDS、链表、哈希表、跳表、整数集合、压缩链表&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;底层</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>MQ的作用</title>
    <link href="https://leslieaibin.github.io/2021/09/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/MQ%E7%9A%84%E4%BD%9C%E7%94%A8%E6%80%BB%E7%BB%93/"/>
    <id>https://leslieaibin.github.io/2021/09/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/MQ%E7%9A%84%E4%BD%9C%E7%94%A8%E6%80%BB%E7%BB%93/</id>
    <published>2021-09-26T01:15:42.000Z</published>
    <updated>2021-10-06T10:27:41.847Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MQ的作用"><a href="#MQ的作用" class="headerlink" title="MQ的作用"></a>MQ的作用</h1><p>消息队列在大型电子商务类网站，如京东、淘宝、去哪儿等网站有着深入的应用，</p><p>队列的主要作用是消除高并发访问高峰，加快网站的响应速度。</p><p>在不使用消息队列的情况下，用户的请求数据直接写入数据库，在高并发的情况下，会对数据库造成巨大的压力，同时也使得系统响应延迟加剧。</p><p>在使用队列后，用户的请求发给队列后立即返回,</p><p>（例如: 当然不能直接给用户提示订单提交成功，京东上提示：您“您提交了订单，请等待系统确认”），</p><p>再由消息队列的消费者进程从消息队列中获取数据，异步写入数据库。</p><p>由于消息队列的服务处理速度远快于数据库，因此用户的响应延迟可得到有效改善。</p><p>图解说明:</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110300965" alt="img"></p><h2 id="消息队列说明"><a href="#消息队列说明" class="headerlink" title="消息队列说明"></a>消息队列说明</h2><p>消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题。</p><p>实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。</p><p>目前在生产环境，使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等。</p><h2 id="消息队列应用场景"><a href="#消息队列应用场景" class="headerlink" title="消息队列应用场景"></a>消息队列应用场景</h2><p>消息队列在实际应用中常用的使用场景。异步处理，应用解耦，流量削峰和消息通讯四个场景。</p><h2 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h2><p>场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种1.串行的方式；2.并行方式。</p><ul><li>串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110336376" alt="img"></p><ul><li>并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110405511" alt="img"></p><p>假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。</p><p>因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。</p><p>则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）。</p><p>小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？</p><p>引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/2018060811044171" alt="img"></p><p>按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。</p><p>注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，</p><p>因此用户的响应时间可能是50毫秒。所以基于此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。</p><h2 id="应用解耦"><a href="#应用解耦" class="headerlink" title="应用解耦"></a>应用解耦</h2><p>场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。如下图：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/2018060811050932" alt="img"></p><p>传统模式的缺点：</p><p>1） 假如库存系统无法访问，则订单减库存将失败，从而导致订单失败；</p><p>2） 订单系统与库存系统耦合；</p><p>如何解决以上问题呢？引入应用消息队列后的方案，如下图：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110546334" alt="img"></p><ul><li>订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功,请等待物流配送。</li><li>库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。</li><li>假如：在下单时库存系统不能正常使用。也不影响正常下单，</li><li>因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。</li></ul><h2 id="流量削锋"><a href="#流量削锋" class="headerlink" title="流量削锋"></a>流量削锋</h2><p>流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。</p><p>应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用容易挂掉。为解决这个问题，一般需要在应用前端加入消息队列。</p><ol><li><p>可以控制活动的人数.</p></li><li><p>可以缓解短时间内高流量压垮应用；</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110744677" alt="img"></p></li><li><p>用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面；</p></li><li><p>秒杀业务根据消息队列中的请求信息，再做后续处理。</p></li></ol><h2 id="消息通讯"><a href="#消息通讯" class="headerlink" title="消息通讯"></a>消息通讯</h2><p>消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。</p><p>点对点通讯：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608111245390" alt="img"></p><p>客户端A和客户端B使用同一队列，进行消息通讯。</p><p>聊天室通讯：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608111307382" alt="img"></p><p>客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。</p><p>以上实际是消息队列的两种消息模式，点对点或发布订阅模式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MQ的作用&quot;&gt;&lt;a href=&quot;#MQ的作用&quot; class=&quot;headerlink&quot; title=&quot;MQ的作用&quot;&gt;&lt;/a&gt;MQ的作用&lt;/h1&gt;&lt;p&gt;消息队列在大型电子商务类网站，如京东、淘宝、去哪儿等网站有着深入的应用，&lt;/p&gt;
&lt;p&gt;队列的主要作用是消除高并发访</summary>
      
    
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>07.Innodb引擎特性和日志</title>
    <link href="https://leslieaibin.github.io/2021/09/25/MySQL/07.Innodb%E5%BC%95%E6%93%8E%E7%9A%844%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%97%A5%E5%BF%97/"/>
    <id>https://leslieaibin.github.io/2021/09/25/MySQL/07.Innodb%E5%BC%95%E6%93%8E%E7%9A%844%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%97%A5%E5%BF%97/</id>
    <published>2021-09-25T12:17:42.000Z</published>
    <updated>2021-09-25T13:41:21.239Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Innodb引擎的4大特性"><a href="#Innodb引擎的4大特性" class="headerlink" title="Innodb引擎的4大特性"></a>Innodb引擎的4大特性</h1><h2 id="插入缓存（Insert-Buffer-Change-Buffer"><a href="#插入缓存（Insert-Buffer-Change-Buffer" class="headerlink" title="插入缓存（Insert Buffer/Change Buffer)"></a>插入缓存（Insert Buffer/Change Buffer)</h2><p>插入缓存之前版本叫insert buffer，现版本Change Buffer，主要提升插入性能，change buffer 是insert buffer的加强，insert buffer 只针对insert有效，change buffering 对insert、delete、update（delete + insert）、purge都有效</p><p>对于非聚聚索引来说，比如存在用户购买金额这样一个字段，索引是普通索引，每个用户的购买的金额不相同的概率比较大，这样导致可能出现购买记录的数据在数据里的排序可能是1000，3，499，35…，这种不连续的数据，一会插入这个数据页，一会插入那个数据页，这样造成的IO是很耗时的，所以出现了Insert Buffer。</p><p>Insert Buffer是怎么做的呢？mysql对于非聚集索引的插入，先去判断要插入的索引页是否已经在内存中了，如果不在，暂时不着急先把索引页加载到内存中，而是把它放到了一个Insert Buffer对象中，临时先放在这，然后等待情况，等待很多和现在情况一样的非聚集索引，再和要插入的非聚集索引页合并，比如说现在Insert Buffer中有1，99，2，100，合并之前可能要4次插入，合并之后1，2可能是一个页的，99，100可能是一个页的，这样就减少到了2次插入。这样就提升了效率和插入性能，减少了随机IO带来性能损耗。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210330151746375.png" alt="在这里插入图片描述"></p><p>综合上述，Insert Buffer 只对于非聚集索引（非唯一）的插入和更新有效，对于每一次的插入不是写到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，如果在则直接插入；若不在，则先放到Insert Buffer 中，再按照一定的频率进行合并操作，再写回disk。这样通常能将多个插入合并到一个操作中，目的还是减少了随机IO带来性能损耗。</p><p>使用插入缓冲的条件：</p><ul><li>非聚集索引</li><li>非唯一索引</li></ul><p>innodb_change_buffer设置的值有：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">all: 默认值，缓存insert, delete, purges操作</span><br><span class="line">none: 不缓存</span><br><span class="line">inserts: 缓存insert操作</span><br><span class="line">deletes: 缓存delete操作</span><br><span class="line">changes: 缓存insert和delete操作</span><br><span class="line">purges: 缓存后台执行的物理删除操作</span><br></pre></td></tr></table></figure><p>可以通过参数控制其使用的大小：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like <span class="string">&#x27;innodb_change_buffer_max_size&#x27;</span>;</span><br><span class="line">+-------------------------------+-------+</span><br><span class="line">| Variable_name                 | Value |</span><br><span class="line">+-------------------------------+-------+</span><br><span class="line">| innodb_change_buffer_max_size | <span class="number">25</span>    |</span><br><span class="line">+-------------------------------+-------+</span><br><span class="line"><span class="number">1</span> <span class="function">row in <span class="title">set</span> <span class="params">(<span class="number">0.05</span> sec)</span></span></span><br></pre></td></tr></table></figure><p>innodb_change_buffer_max_size，默认是25%，即缓冲池的1/4。最大可设置为50%。当MySQL实例中有大量的修改操作时，要考虑增大innodb_change_buffer_max_size</p><p>上面提过在一定频率下进行合并，那所谓的频率是什么条件？</p><ul><li><p>辅助索引页被读取到缓冲池中。正常的select先检查Insert Buffer是否有该非聚集索引页存在，若有则合并插入。</p></li><li><p>辅助索引页没有可用空间。空间小于1/32页的大小，则会强制合并操作。</p></li><li><p>Master Thread 每秒和每10秒的合并操作。</p></li></ul><h2 id="双写机制（Double-Write）"><a href="#双写机制（Double-Write）" class="headerlink" title="双写机制（Double Write）"></a><strong>双写机制（Double Write）</strong></h2><ol><li>doublewrite缓存位于系统表空间的存储区域，用来缓存innodb的数据页从innodb buffer pool中flush之后并写入到数据文件之前；</li><li>当操作系统或数据库进程在数据页写入磁盘的过程中崩溃，可以在doublewrite缓存中找到数据页的备份，用来执行crash恢复；</li><li>数据页写入到doublewrite缓存的动作所需要的io消耗要小于写入到数据文件的消耗，因为此写入操作会以一次大的连续块的方式写入<img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210330151850245.png" alt="在这里插入图片描述"></li></ol><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-8dc0d0503cc0075578d896ae71ed1609_720w.jpg" alt="img"></p><p>根据上图知道：</p><ol><li><ol><li><p>内存中doublewrite buffer大小2M；物理磁盘上共享表空间中连续的128个页，也就是2个区（extent）大小同样为2M；</p></li><li><p>对缓冲池脏页进行刷新时，不是直接写磁盘。</p></li><li><ol><li>第一步：通过memcpy()函数将脏页先复制到内存中的doublewrite buffer；</li><li>第二步：通过doublewrite分两次，每次1M顺序的写入共享表空间的物理磁盘上。这个过程中，doublewrite页是连续的，因此这个过程是顺序的，所以开销并不大；</li><li>第三步：完成doublewrite页的写入后，再将doublewrite buffer中的页写入各个表空间文件中，此时写入是离散的，可能会较慢；</li><li>如果操作系统在第三步的过程中发生了崩溃，在恢复过程中，可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件中，再应用重做日志；</li></ol></li></ol></li></ol><h2 id="自适应hash索引ahi"><a href="#自适应hash索引ahi" class="headerlink" title="自适应hash索引ahi"></a>自适应hash索引ahi</h2><ol><li>innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，此索引成为热数据，建立hash索引以提升查询速度，此建立是自动建立哈希索引，故称为自适应哈希索引（adaptive hash index）；</li><li>自适应哈希索引会占用innodb buffer pool；</li><li>只适合搜索等值（=）的查询，对于范围查找等操作，是不能使用的；</li></ol><h2 id="预读"><a href="#预读" class="headerlink" title="预读"></a>预读</h2><p>预读（read-ahead)操作是一种IO操作，用于异步将磁盘的页读取到buffer pool中，预料这些页会马上被读取到。预读请求的所有页集中在一个范围内。InnoDB使用两种预读算法：</p><ol><li><p>两种预读算法来提高性能：</p></li><li><ol><li>线性预读：以extent为单位，将下一个extent提前读取到buffer pool中；</li><li>随机预读：以extent中的page为单位，将当前extent中的剩余的page提前读取到buffer pool中；</li></ol></li><li><p>线性预读一个重要参数：innodb_read_ahead_threshold，控制什么时间（访问extent中多少页的阈值）触发预读；</p></li><li><ol><li>默认：56，范围：0～64，值越高，访问模式检查越严格；</li><li>没有该变量之前，当访问到extent最后一个page时，innodb会决定是否将下一个extent放入到buffer pool中；</li></ol></li><li><p>随机预读说明：</p></li><li><ol><li>当同一个extent的一些page在buffer pool中发现时，innodb会将extent中剩余page一并读取到buffer pool中；</li><li>随机预读给innodb code带来一些不必要的复杂性，性能上也不稳定，在5.5版本已经废弃，如果启用，需要修改变量：innodb_random_read_ahead为ON；</li></ol></li></ol><h1 id="mysql三大日志-binlog、redo-log和undo-log"><a href="#mysql三大日志-binlog、redo-log和undo-log" class="headerlink" title="mysql三大日志-binlog、redo log和undo log"></a>mysql三大日志-binlog、redo log和undo log</h1><h2 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h2><p><code>binlog </code>用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。 <code>binlog </code>是 <code>mysql</code>的逻辑日志，并且由 <code>Server </code>层进行记录，使用任何存储引擎的 <code>mysql </code>数据库都会记录 <code>binlog </code>日志。</p><ul><li><strong>逻辑日志</strong>： 可以简单理解为记录的就是sql语句 。</li><li><strong>物理日志</strong>： <code>mysql </code>数据最终是保存在数据页中的，物理日志记录的就是数据页变更 </li></ul><p><code>binlog </code>是通过追加的方式进行写入的，可以通过 <code>max_binlog_size </code>参数设置每个 <code>binlog</code><br>文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。</p><h3 id="binlog使用场景"><a href="#binlog使用场景" class="headerlink" title="binlog使用场景"></a>binlog使用场景</h3><p>在实际应用中， <code>binlog </code>的主要使用场景有两个，分别是 <strong>主从复制</strong> 和 <strong>数据恢复</strong> 。</p><ol><li><strong>主从复制</strong> ：在 <code>Master </code>端开启 <code>binlog </code>，然后将 <code>binlog </code>发送到各个 <code>Slave </code>端， <code>Slave </code>端重放 <code>binlog </code>从而达到主从数据一致。</li><li><strong>数据恢复</strong> ：通过使用 <code>mysqlbinlog </code>工具来恢复数据。</li></ol><h3 id="binlog刷盘时机"><a href="#binlog刷盘时机" class="headerlink" title="binlog刷盘时机"></a>binlog刷盘时机</h3><p>对于 <code>InnoDB </code>存储引擎而言，只有在事务提交时才会记录 <code>biglog </code>，此时记录还在内存中，那么 <code>biglog</code><br>是什么时候刷到磁盘中的呢？ <code>mysql </code>通过 <code>sync_binlog </code>参数控制 <code>biglog </code>的刷盘时机，取值范围是 <code>0-N</code><br>：</p><ul><li>0：不去强制要求，由系统自行判断何时写入磁盘；</li><li>1：每次 <code>commit </code>的时候都要将 <code>binlog </code>写入磁盘；</li><li>N：每N个事务，才会将 <code>binlog </code>写入磁盘。</li></ul><p>从上面可以看出， <code>sync_binlog </code>最安全的是设置是 <code>1 </code>，这也是 <code>MySQL 5.7.7</code><br>之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。</p><h3 id="binlog日志格式"><a href="#binlog日志格式" class="headerlink" title="binlog日志格式"></a>binlog日志格式</h3><p><code>binlog </code>日志有三种格式，分别为 <code>STATMENT </code>、 <code>ROW </code>和 <code>MIXED </code>。</p><blockquote><p>在 <code>MySQL 5.7.7 </code>之前，默认的格式是 <code>STATEMENT </code>， <code>MySQL 5.7.7 </code>之后，默认值是 <code>ROW </code>。日志格式通过 <code>binlog-format </code>指定。</p></blockquote><ul><li><p><code>STATMENT </code>： 基于<code>SQL</code>语句的复制( <code>statement-based replication, SBR </code>)，每一条会修改数据的sql语句会记录到 <code>binlog </code>中 。</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">* 优点： 不需要记录每一行的变化，减少了` binlog ` 日志量，节约了 ` IO ` , 从而提高了性能； </span><br><span class="line">* 缺点： 在某些情况下会导致主从数据不一致，比如执行` sysdate() ` 、 ` slepp() ` 等 。 </span><br></pre></td></tr></table></figure></li><li><p><code>ROW </code>： 基于行的复制(<code>row-based replication, RBR</code>)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了 。</p><ul><li>优点： 不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题 ；</li><li>缺点： 会产生大量的日志，尤其是<code>alter table</code>的时候会让日志暴涨</li></ul></li><li><p><code>MIXED </code>： 基于<code>STATMENT</code>和 <code>ROW </code>两种模式的混合复制( <code>mixed-based replication, MBR </code>)，一般的复制使用 <code>STATEMENT </code>模式保存 <code>binlog </code>，对于 <code>STATEMENT </code>模式无法复制的操作使用 <code>ROW </code>模式保存 <code>binlog</code></p></li></ul><h2 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h2><h3 id="为什么需要redo-log"><a href="#为什么需要redo-log" class="headerlink" title="为什么需要redo log"></a>为什么需要redo log</h3><p>我们都知道，事务的四大特性里面有一个是 <strong>持久性</strong> ，具体来说就是<br><strong>只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态</strong> 。那么 <code>mysql</code><br>是如何保证一致性的呢？最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：</p><ol><li>因为 <code>Innodb </code>是以 <code>页 </code>为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！</li><li>一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！</li></ol><p>因此 <code>mysql </code>设计了 <code>redo log </code>， <strong>具体来说就是只记录事务对数据页做了哪些修改</strong><br>，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)</p><h3 id="redo-log基本概念"><a href="#redo-log基本概念" class="headerlink" title="redo log基本概念"></a>redo log基本概念</h3><p><code>redo log </code>包括两部分：一个是内存中的日志缓冲( <code>redo log buffer </code>)，另一个是磁盘上的日志文件( <code>redo log file</code>)。 <code>mysql </code>每执行一条 <code>DML </code>语句，先将记录写入 <code>redo log buffer </code><br>，后续某个时间点再一次性将多个操作记录写到 <code>redo log file </code>。这种 <strong>先写日志，再写磁盘</strong> 的技术就是 <code>MySQL</code><br>里经常说到的 <code>WAL(Write-Ahead Logging) </code>技术。</p><p>在计算机操作系统中，用户空间( <code>user space </code>)下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间( <code>kernel space</code>)缓冲区( <code>OS Buffer </code>)。因此， <code>redo log buffer </code>写入 <code>redo log file </code>实际上是先写入 <code>OS Buffer </code>，然后再通过系统调用 <code>fsync() </code>将其刷到 <code>redo log file </code><br>中，过程如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000023827701" alt="img"></p><p><code>mysql </code>支持三种将 <code>redo log buffer </code>写入 <code>redo log file </code>的时机，可以通过 <code>innodb_flush_log_at_trx_commit</code> 参数配置，各参数值含义如下：</p><table><thead><tr><th>参数值</th><th>含义</th></tr></thead><tbody><tr><td>0（延迟写）</td><td>事务提交时不会将 <code>redo log buffer </code>中日志写入到 <code>os buffer </code>，而是每秒写入 <code>os buffer </code>并调用 <code>fsync() </code>写入到 <code>redo log file </code>中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。</td></tr><tr><td>1（实时写，实时刷）</td><td>事务每次提交都会将 <code>redo log buffer </code>中的日志写入 <code>os buffer </code>并调用 <code>fsync() </code>刷到 <code>redo log file </code>中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。</td></tr><tr><td>2（实时写，延迟刷）</td><td>每次提交都仅写入到 <code>os buffer </code>，然后是每秒调用 <code>fsync() </code>将 <code>os buffer </code>中的日志写入到 <code>redo log file </code>。</td></tr></tbody></table><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000023827700" alt="img"></p><h3 id="redo-log记录形式"><a href="#redo-log记录形式" class="headerlink" title="redo log记录形式"></a>redo log记录形式</h3><p>前面说过， <code>redo log </code>实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此 <code>redo log</code><br>实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000023827699" alt="img"></p><p>同时我们很容易得知， 在innodb中，既有<code>redo log</code>需要刷盘，还有 <code>数据页 </code>也需要刷盘， <code>redo log </code>存在的意义主要就是降低对 <code>数据页 </code>刷盘的要求 <strong>。在上图中， <code>write pos </code>表示 <code>redo log </code>当前记录的 <code>LSN</code> (逻辑序列号)位置， <code>check point </code>表示</strong> 数据页更改记录** 刷盘后对应 <code>redo log </code>所处的 <code>LSN </code>(逻辑序列号)位置。 <code>write pos </code>到 <code>check point </code>之间的部分是 <code>redo log </code>空着的部分，用于记录新的记录；<code>check point</code>到 <code>write pos </code>之间是 <code>redo log </code>待落盘的数据页更改记录。当 <code>write pos </code>追上 <code>check point </code>时，会先推动 <code>check point </code>向前移动，空出位置再记录新的日志。</p><p>启动 <code>innodb </code>的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。因为 <code>redo log </code>记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如 <code>binlog </code>)要快很多。 重启 <code>innodb </code>时，首先会检查磁盘中数据页的 <code>LSN </code>，如果数据页的 <code>LSN </code>小于日志中的 <code>LSN </code>，则会从 <code>checkpoint </code>开始恢复。 还有一种情况，在宕机前正处于<br><code>checkpoint </code>的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的 <code>LSN </code>大于日志中的 <code>LSN</code><br>，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。</p><h3 id="redo-log与binlog区别"><a href="#redo-log与binlog区别" class="headerlink" title="redo log与binlog区别"></a>redo log与binlog区别</h3><table><thead><tr><th></th><th>redo log</th><th>binlog</th></tr></thead><tbody><tr><td>文件大小</td><td><code>redo log </code>的大小是固定的。</td><td><code>binlog </code>可通过配置参数 <code>max_binlog_size </code>设置每个<code>binlog</code>文件的大小。</td></tr><tr><td>实现方式</td><td><code>redo log </code>是 <code>InnoDB </code>引擎层实现的，并不是所有引擎都有。</td><td><code>binlog </code>是 <code>Server</code> 层实现的，所有引擎都可以使用 <code>binlog </code>日志</td></tr><tr><td>记录方式</td><td>redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。</td><td>binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上</td></tr><tr><td>适用场景</td><td><code>redo log </code>适用于崩溃恢复(crash-safe)</td><td><code>binlog </code>适用于主从复制和数据恢复</td></tr></tbody></table><p>由 <code>binlog </code>和 <code>redo log </code>的区别可知： <code>binlog </code>日志只用于归档，只依靠 <code>binlog </code>是没有 <code>crash-safe</code>能力的。但只有 <code>redo log </code>也不行，因为 <code>redo log </code>是 <code>InnoDB </code><br>特有的，且日志上的记录落盘后会被覆盖掉。因此需要 <code>binlog </code>和 <code>redo log</code><br>二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。</p><h2 id="redo-log是什么，为什么需要redo-log"><a href="#redo-log是什么，为什么需要redo-log" class="headerlink" title="redo log是什么，为什么需要redo log"></a>redo log是什么，为什么需要redo log</h2><ul><li>redo log 是<strong>重做日志</strong>。</li><li>它记录了<strong>数据页</strong>上的改动。</li><li>它指<strong>事务</strong>中修改了的数据，将会备份存储。</li><li>发生数据库服务器宕机、或者脏页未写入磁盘，可以通过redo log恢复。</li><li>它是<strong>Innodb存储</strong>引擎独有的</li></ul><h3 id="为什么需要-redo-log？"><a href="#为什么需要-redo-log？" class="headerlink" title="为什么需要 redo log？"></a>为什么需要 redo log？</h3><ul><li>redo log主要用于MySQL异常重启后的一种数据恢复手段，确保了数据的一致性。</li><li>其实是为了配合MySQL的WAL机制。因为MySQL进行更新操作，为了能够快速响应，所以采用了异步写回磁盘的技术，写入内存后就</li><li>返回。但是这样，会存在<strong>crash后</strong>内存数据丢失的隐患，而redo log具备crash safe的能力。</li></ul><h2 id="什么是WAL技术-好处是什么"><a href="#什么是WAL技术-好处是什么" class="headerlink" title="什么是WAL技术, 好处是什么."></a>什么是WAL技术, 好处是什么.</h2><ul><li>WAL，中文全称是Write-Ahead Logging，它的关键点就是日志先写内存，再写磁盘。MySQL执行更新操作后，<strong>在真正把数据写入到磁盘前，先记录日志</strong>。</li><li>好处是不用每一次操作都实时把数据写盘，就算crash后也可以通过redo log恢复，所以能够实现快速响应SQL语句。</li></ul><h2 id="redo-log的写入方式"><a href="#redo-log的写入方式" class="headerlink" title="redo log的写入方式"></a>redo log的写入方式</h2><p>redo log包括两部分内容，分别是内存中的<strong>日志缓冲</strong>(redo log buffer)和磁盘上的<strong>日志文件</strong>(redo log file)。</p><p>mysql每执行一条DML语句，会先把记录写入<strong>redo log buffer</strong>，后续某个时间点再一次性将多个操作记录写到<strong>redo log file</strong>。这种先写日志，再写磁盘的技术，就是<strong>WAL</strong>。</p><p>在计算机操作系统中，用户空间(user space)下的缓冲区数据，一般是无法直接写入磁盘的，必须经过操作系统内核空间缓冲区(即OS Buffer)。</p><ul><li>日志最开始会写入位于存储引擎Innodb的redo log buffer，这个是在用户空间完成的。</li><li>然后再将日志保存到操作系统内核空间的缓冲区(OS buffer)中。</li><li>最后，通过系统调用<code>fsync()</code>，从<strong>OS buffer</strong>写入到磁盘上的<strong>redo log file</strong>中，完成写入操作。这个写入磁盘的操作，就叫做<strong>刷盘</strong>。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925213720105.png" alt="image-20210925213720105"></p><p>我们可以发现，redo log buffer写入到redo log file，是经过OS buffer中转的。其实可以通过参数<code>innodb_flush_log_at_trx_commit</code>进行配置，参数值含义如下：</p><ul><li>0：称为<strong>延迟写</strong>，事务提交时不会将redo log buffer中日志写入到OS buffer，而是每秒写入OS buffer并调用写入到redo log file中。</li><li>1：称为<strong>实时写</strong>，实时刷”，事务每次提交都会将redo log buffer中的日志写入OS buffer并保存到redo log file中。</li><li>2：称为<strong>实时写，延迟刷</strong>。每次事务提交写入到OS buffer，然后是每秒将日志写入到redo log file。</li></ul><h2 id="Redo-log的执行流程"><a href="#Redo-log的执行流程" class="headerlink" title="Redo log的执行流程"></a>Redo log的执行流程</h2><p>我们来看下Redo log的执行流程，假设执行的SQL如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update T set a &#x3D;1 where id &#x3D;666</span><br></pre></td></tr></table></figure><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925213741905.png" alt="image-20210925213741905"></p><p>redo log的执行流程</p><ol><li>MySQL客户端将请求语句<code>update T set a =1 where id =666</code>，发往MySQL Server层。</li><li>MySQL Server 层接收到SQL请求后，对其进行分析、优化、执行等处理工作，将生成的SQL执行计划发到InnoDb存储引擎层执行。</li><li>InnoDb存储引擎层将<strong>a修改为1</strong>的这个操作记录到内存中。</li><li>记录到内存以后会修改redo log 的记录，会在添加一行记录，其内容是<strong>需要在哪个数据页上做什么修改</strong>。</li><li>此后，将事务的状态设置为prepare ，说明已经准备好提交事务了。</li><li>等到MySQL Server层处理完事务以后，会将事务的状态设置为<strong>commit</strong>，也就是提交该事务。</li><li>在收到事务提交的请求以后，<strong>redo log</strong>会把刚才写入内存中的操作记录写入到磁盘中，从而完成整个日志的记录过程。</li></ol><p>默认状态时先写入 磁盘redolog 再进行事务commit</p><h2 id="redo-log-为什么可以保证crash-safe机制呢？"><a href="#redo-log-为什么可以保证crash-safe机制呢？" class="headerlink" title="redo log 为什么可以保证crash safe机制呢？"></a>redo log 为什么可以保证crash safe机制呢？</h2><ul><li>因为redo log每次更新操作完成后，就一定会写入的，如果<strong>写入失败</strong>，说明此次操作失败，事务也不可能提交。</li><li>redo log内部结构是基于页的，记录了这个页的字段值变化，只要crash后读取redo log进行重放，就可以恢复数据。</li></ul><h2 id="binlog的概念是什么-起到什么作用-可以保证crash-safe吗"><a href="#binlog的概念是什么-起到什么作用-可以保证crash-safe吗" class="headerlink" title="binlog的概念是什么, 起到什么作用, 可以保证crash-safe吗?"></a>binlog的概念是什么, 起到什么作用, 可以保证crash-safe吗?</h2><ul><li>bin log是归档日志，属于MySQL Server层的日志。可以实现<strong>主从复制</strong>和<strong>数据恢复</strong>两个作用。</li><li>当需要<strong>恢复数据</strong>时，可以取出某个时间范围内的bin log进行重放恢复。</li><li>但是bin log不可以做crash safe，因为crash之前，bin log<strong>可能没有写入完全</strong>MySQL就挂了。所以需要配合<strong>redo log</strong>才可以进行crash safe。</li></ul><h2 id="binlog和redolog的不同点有哪些"><a href="#binlog和redolog的不同点有哪些" class="headerlink" title="binlog和redolog的不同点有哪些?"></a>binlog和redolog的不同点有哪些?</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925210728980.png" alt="image-20210925210728980"></p><h2 id="执行器和innoDB在执行update语句时候的流程是什么样的"><a href="#执行器和innoDB在执行update语句时候的流程是什么样的" class="headerlink" title="执行器和innoDB在执行update语句时候的流程是什么样的?"></a>执行器和innoDB在执行update语句时候的流程是什么样的?</h2><ul><li>执行器在优化器选择了索引后，会调用InnoDB读接口，读取要更新的行到内存中</li><li>执行SQL操作后，更新到内存，然后写redo log，写bin log，此时即为完成。</li><li>后续InnoDB会在合适的时候把此次操作的结果写回到磁盘。</li></ul><h2 id="如果数据库误操作-如何执行数据恢复"><a href="#如果数据库误操作-如何执行数据恢复" class="headerlink" title="如果数据库误操作, 如何执行数据恢复?"></a>如果数据库误操作, 如何执行数据恢复?</h2><p>数据库在某个时候误操作，就可以找到距离误操作最近的时间节点的bin log，重放到临时数据库里，然后选择误删的数据节点，恢复到线上数据库。</p><h2 id="什么是MySQL两阶段提交-为什么需要两阶段提交"><a href="#什么是MySQL两阶段提交-为什么需要两阶段提交" class="headerlink" title="什么是MySQL两阶段提交, 为什么需要两阶段提交?"></a>什么是MySQL两阶段提交, 为什么需要两阶段提交?</h2><p>其实所谓的两阶段就是把一个事务分成两个阶段来提交。</p><p>两阶段提交</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925211124058.png" alt="image-20210925211124058"></p><p>两阶段提交主要有三步曲：</p><ol><li>redo log在写入后，进入prepare状态</li><li>执行器写入bin log</li><li>进入commit状态，事务可以提交。</li></ol><p><strong>为什么需要两阶段提交呢?</strong></p><ul><li>如果不用两阶段提交的话，可能会出现这样情况：bin log写入之前，机器crash导致需要重启。重启后redo log继续重放crash之前的操作，而当bin log后续需要作为备份恢复时，会出现数据不一致的情况。</li><li>如果是bin log commit之前crash，那么重启后，发现redo log是prepare状态且bin log完整（bin log写入成功后，redo log会有bin log的标记），就会自动commit，让存储引擎提交事务。</li><li>两阶段提交就是为了保证redo log和binlog数据的安全一致性。只有在这两个日志文件逻辑上高度一致了。你才能放心的使用redo log帮你将数据库中的状态恢复成crash之前的状态，使用binlog实现数据备份、恢复、以及主从复制。</li></ul><h2 id="如果不是两阶段提交-先写redo-log和先写bin-log两种情况各会遇到什么问题"><a href="#如果不是两阶段提交-先写redo-log和先写bin-log两种情况各会遇到什么问题" class="headerlink" title="如果不是两阶段提交, 先写redo log和先写bin log两种情况各会遇到什么问题?"></a>如果不是两阶段提交, 先写redo log和先写bin log两种情况各会遇到什么问题?</h2><ul><li>先写redo log，crash后bin log备份恢复时少了一次更新，与当前数据不一致。</li><li>先写bin log，crash后，由于redo log没写入，事务无效，所以后续bin log备份恢复时，数据不一致。</li></ul><h2 id="binlog刷盘机制"><a href="#binlog刷盘机制" class="headerlink" title="binlog刷盘机制"></a>binlog刷盘机制</h2><p>所有未提交的事务产生的binlog，都会被先记录到binlog的缓存中。等该事务提交时，再将缓存中的数据写入binlog日志文件中。缓存的大小由参数<code>binlog_chache_size</code>控制。</p><p>binlog什么时候刷新到磁盘呢？由参数<code>sync_binlog</code>控制</p><ul><li>当<code>sync_binlog</code>为0时，表示MySQL不控制binlog的刷新，而是由系统自行判断何时写入磁盘。选这种策略，一旦操作系统宕机，缓存中的binlog就会丢失。</li><li><code>sync_binlog</code>为N时，每N个事务，才会将binlog写入磁盘。。</li><li>当<code>sync_binlog</code>为1时，则表示每次commit，都将binlog 写入磁盘。</li></ul><p>来看一个比较完整的流程图吧：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925213845996.png" alt="image-20210925213845996"></p><h2 id="说说Redo-log的记录方式"><a href="#说说Redo-log的记录方式" class="headerlink" title="说说Redo log的记录方式"></a>说说Redo log的记录方式</h2><p>redo log的大小是固定。它采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。如下图（图片来源网络）：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/640" alt="图片">redo log 循环写入</p><p>redo log buffer(内存中)是由首尾相连的四个文件组成的，它们分别是：ib_logfile_1、ib_logfile_2、ib_logfile_3、ib_logfile_4。</p><blockquote><ul><li>write pos表示当前写入记录位置(写入磁盘的数据页的逻辑序列位置)</li><li>check point表示刷盘(写入磁盘)后对应的位置。</li><li>write pos到check point之间的部分用来记录新日志，也就是留给新记录的空间。</li><li>check point到write pos之间是待刷盘的记录，如果不刷盘会被新记录覆盖。</li></ul></blockquote><p>有了 redo log，当数据库发生宕机重启后，可通过 redo log将未落盘的数据（check point之后的数据）恢复，保证已经提交的事务记录不会丢失，这种能力称为<strong>crash-safe</strong>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Innodb引擎的4大特性&quot;&gt;&lt;a href=&quot;#Innodb引擎的4大特性&quot; class=&quot;headerlink&quot; title=&quot;Innodb引擎的4大特性&quot;&gt;&lt;/a&gt;Innodb引擎的4大特性&lt;/h1&gt;&lt;h2 id=&quot;插入缓存（Insert-Buffer-Ch</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>12.ThreadLocal 分析</title>
    <link href="https://leslieaibin.github.io/2021/09/24/Thread/12.ThreadLocal%E5%88%86%E6%9E%90/"/>
    <id>https://leslieaibin.github.io/2021/09/24/Thread/12.ThreadLocal%E5%88%86%E6%9E%90/</id>
    <published>2021-09-24T02:15:42.000Z</published>
    <updated>2021-09-24T06:36:35.263Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ThreadLocal的数据结构"><a href="#ThreadLocal的数据结构" class="headerlink" title="ThreadLocal的数据结构"></a>ThreadLocal的数据结构</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/2.png" alt="img"></p><p><code>Thread</code>类有一个类型为<code>ThreadLocal.ThreadLocalMap</code>的实例变量<code>threadLocals</code>，也就是说每个线程有一个自己的<code>ThreadLocalMap</code>。</p><p><code>ThreadLocalMap</code>有自己的独立实现，可以简单地将它的<code>key</code>视作<code>ThreadLocal</code>，<code>value</code>为代码中放入的值（实际上<code>key</code>并不是<code>ThreadLocal</code>本身，而是它的一个<strong>弱引用</strong>）。</p><p>每个线程在往<code>ThreadLocal</code>里放值的时候，都会往自己的<code>ThreadLocalMap</code>里存，读也是以<code>ThreadLocal</code>作为引用，在自己的<code>map</code>里找对应的<code>key</code>，从而实现了<strong>线程隔离</strong>。</p><p><code>ThreadLocalMap</code>有点类似<code>HashMap</code>的结构，只是<code>HashMap</code>是由<strong>数组+链表</strong>实现的，而<code>ThreadLocalMap</code>中并没有<strong>链表</strong>结构。</p><p>我们还要注意<code>Entry</code>， 它的<code>key</code>是<code>ThreadLocal&lt;?&gt; k</code> ，继承自<code>WeakReference</code>， 也就是我们常说的弱引用类型。</p><h1 id="GC-之后-key-是否为-null？"><a href="#GC-之后-key-是否为-null？" class="headerlink" title="GC 之后 key 是否为 null？"></a>GC 之后 key 是否为 null？</h1><p>回应开头的那个问题， <code>ThreadLocal</code> 的<code>key</code>是弱引用，那么在<code>ThreadLocal.get()</code>的时候,发生<code>GC</code>之后，<code>key</code>是否是<code>null</code>？</p><p>为了搞清楚这个问题，我们需要搞清楚<code>Java</code>的<strong>四种引用类型</strong>：</p><ul><li><strong>强引用</strong>：我们常常 new 出来的对象就是强引用类型，只要强引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足的时候</li><li><strong>软引用</strong>：使用 SoftReference 修饰的对象被称为软引用，软引用指向的对象在内存要溢出的时候被回收</li><li><strong>弱引用</strong>：使用 WeakReference 修饰的对象被称为弱引用，只要发生垃圾回收，若这个对象只被弱引用指向，那么就会被回收</li><li><strong>虚引用</strong>：虚引用是最弱的引用，在 Java 中使用 PhantomReference 进行定义。虚引用中唯一的作用就是用队列接收对象即将死亡的通知</li></ul><p>在<code>GC</code>之后，<code>key</code>就会被回收。其实是不对的，因为题目说的是在做 <code>ThreadLocal.get()</code> 操作，证明其实还是有<strong>强引用</strong>存在的，所以 <code>key</code> 并不为 <code>null</code>，如下图所示，<code>ThreadLocal</code>的<strong>强引用</strong>仍然是存在的。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/5.png" alt="image.png"></p><p>如果我们的<strong>强引用</strong>不存在的话，那么 <code>key</code> 就会被回收，也就是会出现我们 <code>value</code> 没被回收，<code>key</code> 被回收，导致 <code>value</code> 永远存在，出现内存泄漏。</p><h1 id="ThreadLocal-set-方法源码"><a href="#ThreadLocal-set-方法源码" class="headerlink" title="ThreadLocal.set() 方法源码"></a>ThreadLocal.set() 方法源码</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/6.png" alt="img"></p><p><code>ThreadLocal</code>中的<code>set</code>方法原理如上图所示，很简单，主要是判断<code>ThreadLocalMap</code>是否存在，然后使用<code>ThreadLocal</code>中的<code>set</code>方法进行数据处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(T value)</span> </span>&#123;</span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    <span class="keyword">if</span> (map != <span class="keyword">null</span>)</span><br><span class="line">        map.set(<span class="keyword">this</span>, value);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        createMap(t, value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createMap</span><span class="params">(Thread t, T firstValue)</span> </span>&#123;</span><br><span class="line">    t.threadLocals = <span class="keyword">new</span> ThreadLocalMap(<span class="keyword">this</span>, firstValue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="ThreadLocalMap-Hash算法"><a href="#ThreadLocalMap-Hash算法" class="headerlink" title="ThreadLocalMap Hash算法"></a>ThreadLocalMap Hash算法</h1><p>既然是<code>Map</code>结构，那么<code>ThreadLocalMap</code>当然也要实现自己的<code>hash</code>算法来解决散列表数组冲突问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = key.threadLocalHashCode &amp; (len - <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p><code>ThreadLocalMap</code>中<code>hash</code>算法很简单，这里<code>i</code>就是当前 key 在散列表中对应的数组下标位置。</p><p>这里最关键的就是<code>threadLocalHashCode</code>值的计算，<code>ThreadLocal</code>中有一个属性为<code>HASH_INCREMENT = 0x61c88647</code></p><p>每当创建一个<code>ThreadLocal</code>对象，这个<code>ThreadLocal.nextHashCode</code> 这个值就会增长 <code>0x61c88647</code> 。</p><p>这个值很特殊，它是<strong>斐波那契数</strong> 也叫 <strong>黄金分割数</strong>。<code>hash</code>增量为 这个数字，带来的好处就是 <code>hash</code> <strong>分布非常均匀</strong>。</p><h1 id="ThreadLocalMap-Hash-冲突"><a href="#ThreadLocalMap-Hash-冲突" class="headerlink" title="ThreadLocalMap Hash 冲突"></a>ThreadLocalMap Hash 冲突</h1><p><strong>注明：</strong> 下面所有示例图中，<strong>绿色块</strong><code>Entry</code>代表<strong>正常数据</strong>，<strong>灰色块</strong>代表<code>Entry</code>的<code>key</code>值为<code>null</code>，<strong>已被垃圾回收</strong>。<strong>白色块</strong>表示<code>Entry</code>为<code>null</code>。</p><p>虽然<code>ThreadLocalMap</code>中使用了<strong>黄金分割数来</strong>作为<code>hash</code>计算因子，大大减少了<code>Hash</code>冲突的概率，但是仍然会存在冲突。</p><p><code>HashMap</code>中解决冲突的方法是在数组上构造一个<strong>链表</strong>结构，冲突的数据挂载到链表上，如果链表长度超过一定数量则会转化成<strong>红黑树</strong>。</p><p>而 <code>ThreadLocalMap</code> 中并没有链表结构，所以这里不能使用 <code>HashMap</code> 解决冲突的方式了。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/7.png" alt="img"></p><p>如上图所示，如果我们插入一个<code>value=27</code>的数据，通过 <code>hash</code> 计算后应该落入第 4 个槽位中，而槽位 4 已经有了 <code>Entry</code> 数据。</p><p>此时就会线性向后查找，一直找到 <code>Entry</code> 为 <code>null</code> 的槽位才会停止查找，将当前元素放入此槽位中。当然迭代过程中还有其他的情况，比如遇到了 <code>Entry</code> 不为 <code>null</code> 且 <code>key</code> 值相等的情况，还有 <code>Entry</code> 中的 <code>key</code> 值为 <code>null</code> 的情况等等都会有不同的处理，后面会一一详细讲解。</p><p>这里还画了一个<code>Entry</code>中的<code>key</code>为<code>null</code>的数据（<strong>Entry=2 的灰色块数据</strong>），因为<code>key</code>值是<strong>弱引用</strong>类型，所以会有这种数据存在。在<code>set</code>过程中，如果遇到了<code>key</code>过期的<code>Entry</code>数据，实际上是会进行一轮<strong>探测式清理</strong>操作的，具体操作方式后面会讲到。</p><h1 id="ThreadLocalMap-set-详解"><a href="#ThreadLocalMap-set-详解" class="headerlink" title="ThreadLocalMap.set()详解"></a>ThreadLocalMap.set()详解</h1><p>往<code>ThreadLocalMap</code>中<code>set</code>数据（<strong>新增</strong>或者<strong>更新</strong>数据）分为好几种情况，针对不同的情况我们画图来说说明。</p><ul><li><p>通过<code>hash</code>计算后的槽位对应的<code>Entry</code>数据为空：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/9.png" alt="img"></p><p>这里直接将数据放到该槽位即可。</p></li><li><p>槽位数据不为空，<code>key</code>值与当前<code>ThreadLocal</code>通过<code>hash</code>计算获取的<code>key</code>值一致：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/10.png" alt="img"></p><p>这里直接更新该槽位的数据。</p></li><li><p>槽位数据不为空，往后遍历过程中，在找到<code>Entry</code>为<code>null</code>的槽位之前，没有遇到<code>key</code>过期的<code>Entry</code>：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/11.png" alt="img"></p><p>遍历散列数组，线性往后查找，如果找到<code>Entry</code>为<code>null</code>的槽位，则将数据放入该槽位中，或者往后遍历过程中，遇到了<strong>key 值相等</strong>的数据，直接更新即可</p></li><li><p>槽位数据不为空，往后遍历过程中，在找到<code>Entry</code>为<code>null</code>的槽位之前，遇到<code>key</code>过期的<code>Entry</code>，如下图，往后遍历过程中，一到了<code>index=7</code>的槽位数据<code>Entry</code>的<code>key=null</code>：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/12.png" alt="img"></p></li></ul><p>散列数组下标为 7 位置对应的<code>Entry</code>数据<code>key</code>为<code>null</code>，表明此数据<code>key</code>值已经被垃圾回收掉了，此时就会执行<code>replaceStaleEntry()</code>方法，该方法含义是<strong>替换过期数据的逻辑</strong>，以<strong>index=7</strong>位起点开始遍历，进行探测式数据清理工作。</p><p>初始化探测式清理过期数据扫描的开始位置：<code>slotToExpunge = staleSlot = 7</code></p><p>以当前<code>staleSlot</code>开始 向前迭代查找，找其他过期的数据，然后更新过期数据起始扫描下标<code>slotToExpunge</code>。<code>for</code>循环迭代，直到碰到<code>Entry</code>为<code>null</code>结束。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/13.png" alt="img"></p><p>上面向前迭代的操作是为了更新探测清理过期数据的起始下标<code>slotToExpunge</code>的值，这个值在后面会讲解，它是用来判断当前过期槽位<code>staleSlot</code>之前是否还有过期元素。</p><p>接着开始以<code>staleSlot</code>位置(index=7)向后迭代，<strong>如果找到了相同 key 值的 Entry 数据：</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/14.png" alt="img"></p><p>从当前节点<code>staleSlot</code>向后查找<code>key</code>值相等的<code>Entry</code>元素，找到后更新<code>Entry</code>的值并交换<code>staleSlot</code>元素的位置(<code>staleSlot</code>位置为过期元素)，更新<code>Entry</code>数据，然后开始进行过期<code>Entry</code>的清理工作，如下图所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/view.png" alt="img">向后遍历过程中，如果没有找到相同 key 值的 Entry 数据：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/15.png" alt="img"></p><p>从当前节点<code>staleSlot</code>向后查找<code>key</code>值相等的<code>Entry</code>元素，直到<code>Entry</code>为<code>null</code>则停止寻找。通过上图可知，此时<code>table</code>中没有<code>key</code>值相同的<code>Entry</code>。</p><p>创建新的<code>Entry</code>，替换<code>table[stableSlot]</code>位置：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16.png" alt="img"></p><p>替换完成后也是进行过期元素清理工作，清理工作主要是有两个方法：<code>expungeStaleEntry()</code>和<code>cleanSomeSlots()</code>，具体细节后面会讲到，请继续往后看。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(ThreadLocal&lt;?&gt; key, Object value)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line">    <span class="keyword">int</span> i = key.threadLocalHashCode &amp; (len-<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Entry e = tab[i];</span><br><span class="line">         e != <span class="keyword">null</span>;</span><br><span class="line">         e = tab[i = nextIndex(i, len)]) &#123;</span><br><span class="line">        ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (k == key) &#123;</span><br><span class="line">            e.value = value;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">            replaceStaleEntry(key, value, i);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tab[i] = <span class="keyword">new</span> Entry(key, value);</span><br><span class="line">    <span class="keyword">int</span> sz = ++size;</span><br><span class="line">    <span class="keyword">if</span> (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)</span><br><span class="line">        rehash();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里会通过<code>key</code>来计算在散列表中的对应位置，然后以当前<code>key</code>对应的桶的位置向后查找，找到可以使用的桶。</p><p>什么情况下桶才是可以使用的呢？</p><ol><li><code>k = key</code> 说明是替换操作，可以使用</li><li>碰到一个过期的桶，执行替换逻辑，占用过期桶</li><li>查找过程中，碰到桶中<code>Entry=null</code>的情况，直接使用</li></ol><p>接着就是执行<code>for</code>循环遍历，向后查找，我们先看下<code>nextIndex()</code>、<code>prevIndex()</code>方法实现：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/17.png" alt="img"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nextIndex</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ((i + <span class="number">1</span> &lt; len) ? i + <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">prevIndex</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ((i - <span class="number">1</span> &gt;= <span class="number">0</span>) ? i - <span class="number">1</span> : len - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li>遍历当前<code>key</code>值对应的桶中<code>Entry</code>数据为空，这说明散列数组这里没有数据冲突，跳出<code>for</code>循环，直接<code>set</code>数据到对应的桶中</li><li>如果<code>key</code>值对应的桶中<code>Entry</code>数据不为空<ul><li>如果<code>k = key</code>，说明当前<code>set</code>操作是一个替换操作，做替换逻辑，直接返回 </li><li>如果<code>key = null</code>，说明当前桶位置的<code>Entry</code>是过期数据，执行<code>replaceStaleEntry()</code>方法(核心方法)，然后返回</li></ul></li><li><code>for</code>循环执行完毕，继续往下执行说明向后迭代的过程中遇到了<code>entry</code>为<code>null</code>的情况 -<ul><li>在<code>Entry</code>为<code>null</code>的桶中创建一个新的<code>Entry</code>对象 </li><li>执行<code>++size</code>操作</li></ul></li><li>调用<code>cleanSomeSlots()</code>做一次启发式清理工作，清理散列数组中<code>Entry</code>的<code>key</code>过期的数据<ul><li>如果清理工作完成后，未清理到任何数据，且<code>size</code>超过了阈值(数组长度的 2/3)，进行<code>rehash()</code>操作</li><li>rehash()<code>中会先进行一轮探测式清理，清理过期</code>key`，清理完成后如果<strong>size &gt;= threshold - threshold / 4</strong>，就会执行真正的扩容逻辑(扩容逻辑往后看)</li></ul></li></ol><p>接着重点看下<code>replaceStaleEntry()</code>方法，<code>replaceStaleEntry()</code>方法提供替换过期数据的功能，我们可以对应上面<strong>第四种情况</strong>的原理图来再回顾下，具体代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">replaceStaleEntry</span><span class="params">(ThreadLocal&lt;?&gt; key, Object value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       <span class="keyword">int</span> staleSlot)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line">    Entry e;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> slotToExpunge = staleSlot;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = prevIndex(staleSlot, len);</span><br><span class="line">         (e = tab[i]) != <span class="keyword">null</span>;</span><br><span class="line">         i = prevIndex(i, len))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (e.get() == <span class="keyword">null</span>)</span><br><span class="line">            slotToExpunge = i;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = nextIndex(staleSlot, len);</span><br><span class="line">         (e = tab[i]) != <span class="keyword">null</span>;</span><br><span class="line">         i = nextIndex(i, len)) &#123;</span><br><span class="line"></span><br><span class="line">        ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (k == key) &#123;</span><br><span class="line">            e.value = value;</span><br><span class="line"></span><br><span class="line">            tab[i] = tab[staleSlot];</span><br><span class="line">            tab[staleSlot] = e;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (slotToExpunge == staleSlot)</span><br><span class="line">                slotToExpunge = i;</span><br><span class="line">            cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span> &amp;&amp; slotToExpunge == staleSlot)</span><br><span class="line">            slotToExpunge = i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tab[staleSlot].value = <span class="keyword">null</span>;</span><br><span class="line">    tab[staleSlot] = <span class="keyword">new</span> Entry(key, value);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (slotToExpunge != staleSlot)</span><br><span class="line">        cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>slotToExpunge<code>表示开始探测式清理过期数据的开始下标，默认从当前的</code>staleSlot<code>开始。以当前的</code>staleSlot<code>开始，向前迭代查找，找到没有过期的数据，</code>for<code>循环一直碰到</code>Entry<code>为</code>null<code>才会结束。如果向前找到了过期数据，更新探测清理过期数据的开始下标为 i，即</code>slotToExpunge=i</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = prevIndex(staleSlot, len);</span><br><span class="line">     (e = tab[i]) != <span class="keyword">null</span>;</span><br><span class="line">     i = prevIndex(i, len))&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e.get() == <span class="keyword">null</span>)&#123;</span><br><span class="line">        slotToExpunge = i;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着开始从<code>staleSlot</code>向后查找，也是碰到<code>Entry</code>为<code>null</code>的桶结束。 如果迭代过程中，<strong>碰到 k == key</strong>，这说明这里是替换逻辑，替换新数据并且交换当前<code>staleSlot</code>位置。如果<code>slotToExpunge == staleSlot</code>，这说明<code>replaceStaleEntry()</code>一开始向前查找过期数据时并未找到过期的<code>Entry</code>数据，接着向后查找过程中也未发现过期数据，修改开始探测式清理过期数据的下标为当前循环的 index，即<code>slotToExpunge = i</code>。最后调用<code>cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</code>进行启发式过期数据清理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (k == key) &#123;</span><br><span class="line">    e.value = value;</span><br><span class="line"></span><br><span class="line">    tab[i] = tab[staleSlot];</span><br><span class="line">    tab[staleSlot] = e;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (slotToExpunge == staleSlot)</span><br><span class="line">        slotToExpunge = i;</span><br><span class="line"></span><br><span class="line">    cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p><code>cleanSomeSlots()</code>和<code>expungeStaleEntry()</code>方法后面都会细讲，这两个是和清理相关的方法，一个是过期<code>key</code>相关<code>Entry</code>的启发式清理(<code>Heuristically scan</code>)，另一个是过期<code>key</code>相关<code>Entry</code>的探测式清理。</p><p><strong>如果 k != key</strong>则会接着往下走，<code>k == null</code>说明当前遍历的<code>Entry</code>是一个过期数据，<code>slotToExpunge == staleSlot</code>说明，一开始的向前查找数据并未找到过期的<code>Entry</code>。如果条件成立，则更新<code>slotToExpunge</code> 为当前位置，这个前提是前驱节点扫描时未发现过期数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (k == <span class="keyword">null</span> &amp;&amp; slotToExpunge == staleSlot)</span><br><span class="line">    slotToExpunge = i;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>往后迭代的过程中如果没有找到<code>k == key</code>的数据，且碰到<code>Entry</code>为<code>null</code>的数据，则结束当前的迭代操作。此时说明这里是一个添加的逻辑，将新的数据添加到<code>table[staleSlot]</code> 对应的<code>slot</code>中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tab[staleSlot].value = <span class="keyword">null</span>;</span><br><span class="line">tab[staleSlot] = <span class="keyword">new</span> Entry(key, value);Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>最后判断除了<code>staleSlot</code>以外，还发现了其他过期的<code>slot</code>数据，就要开启清理数据的逻辑：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (slotToExpunge != staleSlot)</span><br><span class="line">    cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</span><br></pre></td></tr></table></figure><h1 id="ThreadLocalMap过期-key-的探测式清理流程"><a href="#ThreadLocalMap过期-key-的探测式清理流程" class="headerlink" title="ThreadLocalMap过期 key 的探测式清理流程"></a><code>ThreadLocalMap</code>过期 key 的探测式清理流程</h1><p>我们先讲下探测式清理，也就是<code>expungeStaleEntry</code>方法，遍历散列数组，从开始位置向后探测清理过期数据，将过期数据的<code>Entry</code>设置为<code>null</code>，沿途中碰到未过期的数据则将此数据<code>rehash</code>后重新在<code>table</code>数组中定位，如果定位的位置已经有了数据，则会将未过期的数据放到最靠近此位置的<code>Entry=null</code>的桶中，使<code>rehash</code>后的<code>Entry</code>数据距离正确的桶的位置更近一些。操作逻辑如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/18.png" alt="img"></p><p>如上图，<code>set(27)</code> 经过 hash 计算后应该落到<code>index=4</code>的桶中，由于<code>index=4</code>桶已经有了数据，所以往后迭代最终数据放入到<code>index=7</code>的桶中，放入后一段时间后<code>index=5</code>中的<code>Entry</code>数据<code>key</code>变为了<code>null</code></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/19.png" alt="img"></p><p>如果再有其他数据<code>set</code>到<code>map</code>中，就会触发<strong>探测式清理</strong>操作。</p><p>如上图，执行<strong>探测式清理</strong>后，<code>index=5</code>的数据被清理掉，继续往后迭代，到<code>index=7</code>的元素时，经过<code>rehash</code>后发现该元素正确的<code>index=4</code>，而此位置已经已经有了数据，往后查找离<code>index=4</code>最近的<code>Entry=null</code>的节点(刚被探测式清理掉的数据：index=5)，找到后移动<code>index= 7</code>的数据到<code>index=5</code>中，此时桶的位置离正确的位置<code>index=4</code>更近了。</p><p>经过一轮探测式清理后，<code>key</code>过期的数据会被清理掉，没过期的数据经过<code>rehash</code>重定位后所处的桶位置理论上更接近<code>i= key.hashCode &amp; (tab.len - 1)</code>的位置。这种优化会提高整个散列表查询性能。</p><p>接着看下<code>expungeStaleEntry()</code>具体流程，我们还是以先原理图后源码讲解的方式来一步步梳理：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20.png" alt="img"></p><p>我们假设<code>expungeStaleEntry(3)</code> 来调用此方法，如上图所示，我们可以看到<code>ThreadLocalMap</code>中<code>table</code>的数据情况，接着执行清理操作：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/21.png" alt="img"></p><p>第一步是清空当前<code>staleSlot</code>位置的数据，<code>index=3</code>位置的<code>Entry</code>变成了<code>null</code>。然后接着往后探测：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/22.png" alt="img"></p><p>执行完第二步后，index=4 的元素挪到 index=3 的槽位中。</p><p>继续往后迭代检查，碰到正常数据，计算该数据位置是否偏移，如果被偏移，则重新计算<code>slot</code>位置，目的是让正常数据尽可能存放在正确位置或离正确位置更近的位置</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/23.png" alt="img"></p><p>在往后迭代的过程中碰到空的槽位，终止探测，这样一轮探测式清理工作就完成了，接着我们继续看看具体<strong>实现源代码</strong>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">expungeStaleEntry</span><span class="params">(<span class="keyword">int</span> staleSlot)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line"></span><br><span class="line">    tab[staleSlot].value = <span class="keyword">null</span>;</span><br><span class="line">    tab[staleSlot] = <span class="keyword">null</span>;</span><br><span class="line">    size--;</span><br><span class="line"></span><br><span class="line">    Entry e;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = nextIndex(staleSlot, len);</span><br><span class="line">         (e = tab[i]) != <span class="keyword">null</span>;</span><br><span class="line">         i = nextIndex(i, len)) &#123;</span><br><span class="line">        ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">            e.value = <span class="keyword">null</span>;</span><br><span class="line">            tab[i] = <span class="keyword">null</span>;</span><br><span class="line">            size--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">int</span> h = k.threadLocalHashCode &amp; (len - <span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span> (h != i) &#123;</span><br><span class="line">                tab[i] = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">while</span> (tab[h] != <span class="keyword">null</span>)</span><br><span class="line">                    h = nextIndex(h, len);</span><br><span class="line">                tab[h] = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>这里我们还是以<code>staleSlot=3</code> 来做示例说明，首先是将<code>tab[staleSlot]</code>槽位的数据清空，然后设置<code>size--</code> 接着以<code>staleSlot</code>位置往后迭代，如果遇到<code>k==null</code>的过期数据，也是清空该槽位数据，然后<code>size--</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">    e.value = <span class="keyword">null</span>;</span><br><span class="line">    tab[i] = <span class="keyword">null</span>;</span><br><span class="line">    size--;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>如果<code>key</code>没有过期，重新计算当前<code>key</code>的下标位置是不是当前槽位下标位置，如果不是，那么说明产生了<code>hash</code>冲突，此时以新计算出来正确的槽位位置往后迭代，找到最近一个可以存放<code>entry</code>的位置。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> h = k.threadLocalHashCode &amp; (len - <span class="number">1</span>);</span><br><span class="line"><span class="keyword">if</span> (h != i) &#123;</span><br><span class="line">    tab[i] = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (tab[h] != <span class="keyword">null</span>)</span><br><span class="line">        h = nextIndex(h, len);</span><br><span class="line"></span><br><span class="line">    tab[h] = e;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>这里是处理正常的产生<code>Hash</code>冲突的数据，经过迭代后，有过<code>Hash</code>冲突数据的<code>Entry</code>位置会更靠近正确位置，这样的话，查询的时候 效率才会更高。</p><h1 id="ThreadLocalMap扩容机制"><a href="#ThreadLocalMap扩容机制" class="headerlink" title="ThreadLocalMap扩容机制"></a><code>ThreadLocalMap</code>扩容机制</h1><p>在<code>ThreadLocalMap.set()</code>方法的最后，如果执行完启发式清理工作后，未清理到任何数据，且当前散列数组中<code>Entry</code>的数量已经达到了列表的扩容阈值<code>(len*2/3)</code>，就开始执行<code>rehash()</code>逻辑：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)</span><br><span class="line">    rehash();Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>接着看下<code>rehash()</code>具体实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">rehash</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    expungeStaleEntries();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (size &gt;= threshold - threshold / <span class="number">4</span>)</span><br><span class="line">        resize();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">expungeStaleEntries</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; len; j++) &#123;</span><br><span class="line">        Entry e = tab[j];</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span> &amp;&amp; e.get() == <span class="keyword">null</span>)</span><br><span class="line">            expungeStaleEntry(j);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>这里首先是会进行探测式清理工作，从<code>table</code>的起始位置往后清理，上面有分析清理的详细流程。清理完成之后，<code>table</code>中可能有一些<code>key</code>为<code>null</code>的<code>Entry</code>数据被清理掉，所以此时通过判断<code>size &gt;= threshold - threshold / 4</code> 也就是<code>size &gt;= threshold* 3/4</code> 来决定是否扩容。</p><p>我们还记得上面进行<code>rehash()</code>的阈值是<code>size &gt;= threshold</code>，所以当面试官套路我们<code>ThreadLocalMap</code>扩容机制的时候 我们一定要说清楚这两个步骤：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/24.png" alt="img"></p><p>接着看看具体的<code>resize()</code>方法，为了方便演示，我们以<code>oldTab.len=8</code>来举例：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/25.png" alt="img"></p><p>扩容后的<code>tab</code>的大小为<code>oldLen * 2</code>，然后遍历老的散列表，重新计算<code>hash</code>位置，然后放到新的<code>tab</code>数组中，如果出现<code>hash</code>冲突则往后寻找最近的<code>entry</code>为<code>null</code>的槽位，遍历完成之后，<code>oldTab</code>中所有的<code>entry</code>数据都已经放入到新的<code>tab</code>中了。重新计算<code>tab</code>下次扩容的<strong>阈值</strong>，具体代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">resize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Entry[] oldTab = table;</span><br><span class="line">    <span class="keyword">int</span> oldLen = oldTab.length;</span><br><span class="line">    <span class="keyword">int</span> newLen = oldLen * <span class="number">2</span>;</span><br><span class="line">    Entry[] newTab = <span class="keyword">new</span> Entry[newLen];</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldLen; ++j) &#123;</span><br><span class="line">        Entry e = oldTab[j];</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">            ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line">            <span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">                e.value = <span class="keyword">null</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">int</span> h = k.threadLocalHashCode &amp; (newLen - <span class="number">1</span>);</span><br><span class="line">                <span class="keyword">while</span> (newTab[h] != <span class="keyword">null</span>)</span><br><span class="line">                    h = nextIndex(h, newLen);</span><br><span class="line">                newTab[h] = e;</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    setThreshold(newLen);</span><br><span class="line">    size = count;</span><br><span class="line">    table = newTab;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="ThreadLocalMap-get-详解"><a href="#ThreadLocalMap-get-详解" class="headerlink" title="ThreadLocalMap.get()详解"></a><code>ThreadLocalMap.get()</code>详解</h1><ul><li>通过查找<code>key</code>值计算出散列表中<code>slot</code>位置，然后该<code>slot</code>位置中的<code>Entry.key</code>和查找的<code>key</code>一致，则直接返回：</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/26.png" alt="img"></p><ul><li><code>slot</code>位置中的<code>Entry.key</code>和要查找的<code>key</code>不一致：</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/27.png" alt="img"></p><p>我们以<code>get(ThreadLocal1)</code>为例，通过<code>hash</code>计算后，正确的<code>slot</code>位置应该是 4，而<code>index=4</code>的槽位已经有了数据，且<code>key</code>值不等于<code>ThreadLocal1</code>，所以需要继续往后迭代查找。</p><p>迭代到<code>index=5</code>的数据时，此时<code>Entry.key=null</code>，触发一次探测式数据回收操作，执行<code>expungeStaleEntry()</code>方法，执行完后，<code>index 5,8</code>的数据都会被回收，而<code>index 6,7</code>的数据都会前移，此时继续往后迭代，到<code>index = 6</code>的时候即找到了<code>key</code>值相等的<code>Entry</code>数据，如下图所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/28.png" alt="img"></p><p> <code>ThreadLocalMap.get()</code>源码详解</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Entry <span class="title">getEntry</span><span class="params">(ThreadLocal&lt;?&gt; key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = key.threadLocalHashCode &amp; (table.length - <span class="number">1</span>);</span><br><span class="line">    Entry e = table[i];</span><br><span class="line">    <span class="keyword">if</span> (e != <span class="keyword">null</span> &amp;&amp; e.get() == key)</span><br><span class="line">        <span class="keyword">return</span> e;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> getEntryAfterMiss(key, i, e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> Entry <span class="title">getEntryAfterMiss</span><span class="params">(ThreadLocal&lt;?&gt; key, <span class="keyword">int</span> i, Entry e)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">        ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line">        <span class="keyword">if</span> (k == key)</span><br><span class="line">            <span class="keyword">return</span> e;</span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span>)</span><br><span class="line">            expungeStaleEntry(i);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            i = nextIndex(i, len);</span><br><span class="line">        e = tab[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="ThreadLocalMap过期-key-的启发式清理流程"><a href="#ThreadLocalMap过期-key-的启发式清理流程" class="headerlink" title="ThreadLocalMap过期 key 的启发式清理流程"></a><code>ThreadLocalMap</code>过期 key 的启发式清理流程</h1><p>上面多次提及到<code>ThreadLocalMap</code>过期可以的两种清理方式：<strong>探测式清理(expungeStaleEntry())\</strong>、<strong>启发式清理(cleanSomeSlots())</strong></p><p>探测式清理是以当前<code>Entry</code> 往后清理，遇到值为<code>null</code>则结束清理，属于<strong>线性探测清理</strong>。</p><p>而启发式清理被作者定义为：<strong>Heuristically scan some cells looking for stale entries</strong>.</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/29.png" alt="img"></p><p>具体代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">cleanSomeSlots</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> removed = <span class="keyword">false</span>;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        i = nextIndex(i, len);</span><br><span class="line">        Entry e = tab[i];</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span> &amp;&amp; e.get() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            n = len;</span><br><span class="line">            removed = <span class="keyword">true</span>;</span><br><span class="line">            i = expungeStaleEntry(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> ( (n &gt;&gt;&gt;= <span class="number">1</span>) != <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> removed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ThreadLocal的数据结构&quot;&gt;&lt;a href=&quot;#ThreadLocal的数据结构&quot; class=&quot;headerlink&quot; title=&quot;ThreadLocal的数据结构&quot;&gt;&lt;/a&gt;ThreadLocal的数据结构&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http</summary>
      
    
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>5.ConcurrentHashMap详解</title>
    <link href="https://leslieaibin.github.io/2021/09/24/Collection/5.ConcurrentHashMap%E8%AF%A6%E8%A7%A3/"/>
    <id>https://leslieaibin.github.io/2021/09/24/Collection/5.ConcurrentHashMap%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-09-23T16:15:42.000Z</published>
    <updated>2021-09-24T11:30:43.664Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ConcurrentHashMap跟HashMap，HashTable的对比"><a href="#ConcurrentHashMap跟HashMap，HashTable的对比" class="headerlink" title="ConcurrentHashMap跟HashMap，HashTable的对比"></a><strong>ConcurrentHashMap跟HashMap，HashTable的对比</strong></h2><p>　我们都知道HashMap不是线程安全的，所以在处理并发的时候会出现问题。</p><p>　而HashTable虽然是线程安全的，但是是通过整个来加锁的方式，当一个线程在写操作的时候，另外的线程则不能进行读写。</p><p>　而ConcurrentHashMap则可以支持并发的读写。跟1.7版本相比，1.8版本又有了很大的变化，已经抛弃了Segment的概念，虽然源码里面还保留了，也只是为了兼容性的考虑。</p><h2 id="ConcurrentHashMap原理概览"><a href="#ConcurrentHashMap原理概览" class="headerlink" title="ConcurrentHashMap原理概览"></a><strong>ConcurrentHashMap原理概览</strong></h2><p>在ConcurrentHashMap中通过一个Node&lt;K,V&gt;[]数组来保存添加到map中的键值对，而在同一个数组位置是通过链表和红黑树的形式来保存的。但是这个数组只有在第一次添加元素的时候才会初始化，否则只是初始化一个ConcurrentHashMap对象的话，只是设定了一个sizeCtl变量，这个变量用来判断对象的一些状态和是否需要扩容，后面会详细解释。</p><p>　　第一次添加元素的时候，默认初期长度为16，当往map中继续添加元素的时候，通过hash值跟数组长度取与来决定放在数组的哪个位置，如果出现放在同一个位置的时候，优先以链表的形式存放，在同一个位置的个数又达到了8个以上，如果数组的长度还小于64的时候，则会扩容数组。如果数组的长度大于等于64了的话，在会将该节点的链表转换成树。</p><p>　　通过扩容数组的方式来把这些节点给分散开。然后将这些元素复制到扩容后的新的数组中，同一个链表中的元素通过hash值的数组长度位来区分，是还是放在原来的位置还是放到扩容的长度的相同位置去 。在扩容完成之后，如果某个节点的是树，同时现在该节点的个数又小于等于6个了，则会将该树转为链表。</p><p>　　取元素的时候，相对来说比较简单，通过计算hash来确定该元素在数组的哪个位置，然后在通过遍历链表或树来判断key和key的hash，取出value值。</p><p>　　往ConcurrentHashMap中添加元素的时候，里面的数据以数组的形式存放的样子大概是这样的：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/979960-20180401205241081-2070730856.png" alt="img"></p><p>　　这个时候因为数组的长度才为16，则不会转化为树，而是会进行扩容。</p><p>　　扩容后数组大概是这样的：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/979960-20180401210643538-263913441.png" alt="img"></p><p>需要注意的是，扩容之后的长度不是32，扩容后的长度在后面细说。</p><p>如果数组扩张后长度达到64了，且继续在某个节点的后面添加元素达到8个以上的时候，则会出现转化为红黑树的情况。</p><p>转化之后大概是这样：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/979960-20180401211320795-401540659.png" alt="img"></p><h2 id="ConcurrentHashMap几个重要概念"><a href="#ConcurrentHashMap几个重要概念" class="headerlink" title="ConcurrentHashMap几个重要概念"></a>ConcurrentHashMap几个重要概念</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CAPACITY = <span class="number">16</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MOVED     = -<span class="number">1</span>; <span class="comment">// 表示正在转移</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEBIN   = -<span class="number">2</span>; <span class="comment">// 表示已经转换成树</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RESERVED  = -<span class="number">3</span>; <span class="comment">// hash for transient reservations</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> HASH_BITS = <span class="number">0x7fffffff</span>; <span class="comment">// usable bits of normal node hash</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">volatile</span> Node&lt;K,V&gt;[] table;<span class="comment">//默认没初始化的数组，用来保存元素</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> Node&lt;K,V&gt;[] nextTable;<span class="comment">//转移的时候用的数组</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 用来控制表初始化和扩容的，默认值为0，当在初始化的时候指定了大小，这会将这个大小保存在sizeCtl中，大小为数组的0.75</span></span><br><span class="line"><span class="comment">     * 当为负的时候，说明表正在初始化或扩张，</span></span><br><span class="line"><span class="comment">     *     -1表示初始化</span></span><br><span class="line"><span class="comment">     *     -(1+n) n:表示活动的扩张线程</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> <span class="keyword">int</span> sizeCtl;</span><br></pre></td></tr></table></figure><p><strong>几个重要的类</strong></p><p>Node&lt;K,V&gt;,这是构成每个元素的基本类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> hash;    <span class="comment">//key的hash值</span></span><br><span class="line">        <span class="keyword">final</span> K key;       <span class="comment">//key</span></span><br><span class="line">        <span class="keyword">volatile</span> V val;    <span class="comment">//value</span></span><br><span class="line">        <span class="keyword">volatile</span> Node&lt;K,V&gt; next; <span class="comment">//表示链表中的下一个节点</span></span><br><span class="line"></span><br><span class="line">        Node(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">            <span class="keyword">this</span>.hash = hash;</span><br><span class="line">            <span class="keyword">this</span>.key = key;</span><br><span class="line">            <span class="keyword">this</span>.val = val;</span><br><span class="line">            <span class="keyword">this</span>.next = next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> K <span class="title">getKey</span><span class="params">()</span>       </span>&#123; <span class="keyword">return</span> key; &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">getValue</span><span class="params">()</span>     </span>&#123; <span class="keyword">return</span> val; &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span>   </span>&#123; <span class="keyword">return</span> key.hashCode() ^ val.hashCode(); &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p> TreeNode，构造树的节点</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        TreeNode&lt;K,V&gt; parent;  <span class="comment">// red-black tree links</span></span><br><span class="line">        TreeNode&lt;K,V&gt; left;</span><br><span class="line">        TreeNode&lt;K,V&gt; right;</span><br><span class="line">        TreeNode&lt;K,V&gt; prev;    <span class="comment">// needed to unlink next upon deletion</span></span><br><span class="line">        <span class="keyword">boolean</span> red;</span><br><span class="line"></span><br><span class="line">        TreeNode(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next,</span><br><span class="line">                 TreeNode&lt;K,V&gt; parent) &#123;</span><br><span class="line">            <span class="keyword">super</span>(hash, key, val, next);</span><br><span class="line">            <span class="keyword">this</span>.parent = parent;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>TreeBin 用作树的头结点，只存储root和first节点，不存储节点的key、value值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeBin</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        TreeNode&lt;K,V&gt; root;</span><br><span class="line">        <span class="keyword">volatile</span> TreeNode&lt;K,V&gt; first;</span><br><span class="line">        <span class="keyword">volatile</span> Thread waiter;</span><br><span class="line">        <span class="keyword">volatile</span> <span class="keyword">int</span> lockState;</span><br><span class="line">        <span class="comment">// values for lockState</span></span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> WRITER = <span class="number">1</span>; <span class="comment">// set while holding write lock</span></span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> WAITER = <span class="number">2</span>; <span class="comment">// set when waiting for write lock</span></span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> READER = <span class="number">4</span>; <span class="comment">// increment value for setting read lock</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ForwardingNode在转移的时候放在头部的节点，是一个空节点</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ForwardingNode</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Node&lt;K,V&gt;[] nextTable;</span><br><span class="line">        ForwardingNode(Node&lt;K,V&gt;[] tab) &#123;</span><br><span class="line">            <span class="keyword">super</span>(MOVED, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">            <span class="keyword">this</span>.nextTable = tab;</span><br><span class="line">        &#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="ConcurrentHashMap的初始化"><a href="#ConcurrentHashMap的初始化" class="headerlink" title="ConcurrentHashMap的初始化"></a><strong>ConcurrentHashMap的初始化</strong></h2><p>构造方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//空的构造</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMapDebug</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//如果在实例化对象的时候指定了容量，则初始化sizeCtl</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMapDebug</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">        <span class="keyword">int</span> cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; <span class="number">1</span>)) ?</span><br><span class="line">                   MAXIMUM_CAPACITY :</span><br><span class="line">                   tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; <span class="number">1</span>) + <span class="number">1</span>));</span><br><span class="line">        <span class="keyword">this</span>.sizeCtl = cap;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//当出入一个Map的时候，先设定sizeCtl为默认容量，在添加元素</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMapDebug</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sizeCtl = DEFAULT_CAPACITY;</span><br><span class="line">        putAll(m);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>可以看到，在任何一个构造方法中，都没有对存储Map元素Node的table变量进行初始化。而是在第一次put操作的时候在进行初始化。</p><p>下面来看看数组的初始化方法initTable</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 初始化数组table，</span></span><br><span class="line"><span class="comment">* 如果sizeCtl小于0，说明别的数组正在进行初始化，则让出执行权</span></span><br><span class="line"><span class="comment">* 如果sizeCtl大于0的话，则初始化一个大小为sizeCtl的数组</span></span><br><span class="line"><span class="comment">* 否则的话初始化一个默认大小(16)的数组</span></span><br><span class="line"><span class="comment">* 然后设置sizeCtl的值为数组长度的3/4</span></span><br><span class="line"><span class="comment">ConcurrentHashMap的put操作详解*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Node&lt;K,V&gt;[] initTable() &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; <span class="keyword">int</span> sc;</span><br><span class="line">    <span class="keyword">while</span> ((tab = table) == <span class="keyword">null</span> || tab.length == <span class="number">0</span>) &#123;    <span class="comment">//第一次put的时候，table还没被初始化，进入while</span></span><br><span class="line">        <span class="keyword">if</span> ((sc = sizeCtl) &lt; <span class="number">0</span>)                            <span class="comment">//sizeCtl初始值为0，当小于0的时候表示在别的线程在初始化表或扩展表</span></span><br><span class="line">            Thread.yield(); <span class="comment">// lost initialization race; just spin</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc, -<span class="number">1</span>)) &#123;    <span class="comment">//SIZECTL：表示当前对象的内存偏移量ConcurrentHashMap的put操作详解，sc表示期望值，-1表示要替换的值，设定为-1表示要初始化表了</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || tab.length == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">int</span> n = (sc &gt; <span class="number">0</span>) ? sc : DEFAULT_CAPACITY;        <span class="comment">//指定了大小的时候就创建指定大小的Node数组，否则创建指定大小(16)的Node数组</span></span><br><span class="line">                    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node&lt;?,?&gt;[n];</span><br><span class="line">                    table = tab = nt;</span><br><span class="line">                    sc = n - (n &gt;&gt;&gt; <span class="number">2</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                sizeCtl = sc;            <span class="comment">//初始化后，sizeCtl长度为数组长度的3/4</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> tab;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ConcurrentHashMap的put操作详解"><a href="#ConcurrentHashMap的put操作详解" class="headerlink" title="ConcurrentHashMap的put操作详解"></a>ConcurrentHashMap的put操作详解</h2><p>下面看看put方法的源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">*    单纯的额调用putVal方法，并且putVal的第三个参数设置为false</span></span><br><span class="line"><span class="comment">*  当设置为false的时候表示这个value一定会设置</span></span><br><span class="line"><span class="comment">*  true的时候，只有当这个key的value为空的时候才会设置</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> putVal(key, value, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再来看putVal</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 当添加一对键值对的时候，首先会去判断保存这些键值对的数组是不是初始化了，</span></span><br><span class="line"><span class="comment">     * 如果没有的话就初始化数组</span></span><br><span class="line"><span class="comment">     *  然后通过计算hash值来确定放在数组的哪个位置</span></span><br><span class="line"><span class="comment">     * 如果这个位置为空则直接添加，如果不为空的话，则取出这个节点来</span></span><br><span class="line"><span class="comment">     * 如果取出来的节点的hash值是MOVED(-1)的话，则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程也去帮助复制</span></span><br><span class="line"><span class="comment">     * 最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过synchronized来加锁，进行添加操作</span></span><br><span class="line"><span class="comment">     *    然后判断当前取出的节点位置存放的是链表还是树</span></span><br><span class="line"><span class="comment">     *    如果是链表的话，则遍历整个链表，直到取出来的节点的key来个要放的key进行比较，如果key相等，并且key的hash值也相等的话，</span></span><br><span class="line"><span class="comment">     *          则说明是同一个key，则覆盖掉value，否则的话则添加到链表的末尾</span></span><br><span class="line"><span class="comment">     *    如果是树的话，则调用putTreeVal方法把这个元素添加到树中去</span></span><br><span class="line"><span class="comment">     *  最后在添加完成之后，会判断在该节点处共有多少个节点（注意是添加前的个数），如果达到8个以上了的话，</span></span><br><span class="line"><span class="comment">     *  则调用treeifyBin方法来尝试将处的链表转为树，或者扩容数组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(K key, V value, <span class="keyword">boolean</span> onlyIfAbsent)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="keyword">null</span> || value == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();<span class="comment">//K,V都不能为空，否则的话跑出异常</span></span><br><span class="line">        <span class="keyword">int</span> hash = spread(key.hashCode());    <span class="comment">//取得key的hash值</span></span><br><span class="line">        <span class="keyword">int</span> binCount = <span class="number">0</span>;    <span class="comment">//用来计算在这个节点总共有多少个元素，用来控制扩容或者转移为树</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;K,V&gt;[] tab = table;;) &#123;    <span class="comment">//</span></span><br><span class="line">            Node&lt;K,V&gt; f; <span class="keyword">int</span> n, i, fh;</span><br><span class="line">            <span class="keyword">if</span> (tab == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)    </span><br><span class="line">                tab = initTable();    <span class="comment">//第一次put的时候table没有初始化，则初始化table</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((f = tabAt(tab, i = (n - <span class="number">1</span>) &amp; hash)) == <span class="keyword">null</span>) &#123;    <span class="comment">//通过哈希计算出一个表中的位置因为n是数组的长度，所以(n-1)&amp;hash肯定不会出现数组越界</span></span><br><span class="line">                <span class="keyword">if</span> (casTabAt(tab, i, <span class="keyword">null</span>,        <span class="comment">//如果这个位置没有元素的话，则通过cas的方式尝试添加，注意这个时候是没有加锁的</span></span><br><span class="line">                             <span class="keyword">new</span> Node&lt;K,V&gt;(hash, key, value, <span class="keyword">null</span>)))        <span class="comment">//创建一个Node添加到数组中区，null表示的是下一个节点为空</span></span><br><span class="line">                    <span class="keyword">break</span>;                   <span class="comment">// no lock when adding to empty bin</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 如果检测到某个节点的hash值是MOVED，则表示正在进行数组扩张的数据复制阶段，</span></span><br><span class="line"><span class="comment">             * 则当前线程也会参与去复制，通过允许多线程复制的功能，一次来减少数组的复制所带来的性能损失</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((fh = f.hash) == MOVED)    </span><br><span class="line">                tab = helpTransfer(tab, f);</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                 * 如果在这个位置有元素的话，就采用synchronized的方式加锁，</span></span><br><span class="line"><span class="comment">                 *     如果是链表的话(hash大于0)，就对这个链表的所有元素进行遍历，</span></span><br><span class="line"><span class="comment">                 *         如果找到了key和key的hash值都一样的节点，则把它的值替换到</span></span><br><span class="line"><span class="comment">                 *         如果没找到的话，则添加在链表的最后面</span></span><br><span class="line"><span class="comment">                 *  否则，是树的话，则调用putTreeVal方法添加到树中去</span></span><br><span class="line"><span class="comment">                 *  </span></span><br><span class="line"><span class="comment">                 *  在添加完之后，会对该节点上关联的的数目进行判断，</span></span><br><span class="line"><span class="comment">                 *  如果在8个以上的话，则会调用treeifyBin方法，来尝试转化为树，或者是扩容</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                V oldVal = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">synchronized</span> (f) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (tabAt(tab, i) == f) &#123;        <span class="comment">//再次取出要存储的位置的元素，跟前面取出来的比较</span></span><br><span class="line">                        <span class="keyword">if</span> (fh &gt;= <span class="number">0</span>) &#123;                <span class="comment">//取出来的元素的hash值大于0，当转换为树之后，hash值为-2</span></span><br><span class="line">                            binCount = <span class="number">1</span>;            </span><br><span class="line">                            <span class="keyword">for</span> (Node&lt;K,V&gt; e = f;; ++binCount) &#123;    <span class="comment">//遍历这个链表</span></span><br><span class="line">                                K ek;</span><br><span class="line">                                <span class="keyword">if</span> (e.hash == hash &amp;&amp;        <span class="comment">//要存的元素的hash，key跟要存储的位置的节点的相同的时候，替换掉该节点的value即可</span></span><br><span class="line">                                    ((ek = e.key) == key ||</span><br><span class="line">                                     (ek != <span class="keyword">null</span> &amp;&amp; key.equals(ek)))) &#123;</span><br><span class="line">                                    oldVal = e.val;</span><br><span class="line">                                    <span class="keyword">if</span> (!onlyIfAbsent)        <span class="comment">//当使用putIfAbsent的时候，只有在这个key没有设置值得时候才设置</span></span><br><span class="line">                                        e.val = value;</span><br><span class="line">                                    <span class="keyword">break</span>;</span><br><span class="line">                                &#125;</span><br><span class="line">                                Node&lt;K,V&gt; pred = e;</span><br><span class="line">                                <span class="keyword">if</span> ((e = e.next) == <span class="keyword">null</span>) &#123;    <span class="comment">//如果不是同样的hash，同样的key的时候，则判断该节点的下一个节点是否为空，</span></span><br><span class="line">                                    pred.next = <span class="keyword">new</span> Node&lt;K,V&gt;(hash, key,        <span class="comment">//为空的话把这个要加入的节点设置为当前节点的下一个节点</span></span><br><span class="line">                                                              value, <span class="keyword">null</span>);</span><br><span class="line">                                    <span class="keyword">break</span>;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span> <span class="keyword">if</span> (f <span class="keyword">instanceof</span> TreeBin) &#123;    <span class="comment">//表示已经转化成红黑树类型了</span></span><br><span class="line">                            Node&lt;K,V&gt; p;</span><br><span class="line">                            binCount = <span class="number">2</span>;</span><br><span class="line">                            <span class="keyword">if</span> ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,    <span class="comment">//调用putTreeVal方法，将该元素添加到树中去</span></span><br><span class="line">                                                           value)) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                                oldVal = p.val;</span><br><span class="line">                                <span class="keyword">if</span> (!onlyIfAbsent)</span><br><span class="line">                                    p.val = value;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (binCount != <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD)    <span class="comment">//当在同一个节点的数目达到8个的时候，则扩张数组或将给节点的数据转为tree</span></span><br><span class="line">                        treeifyBin(tab, i);    </span><br><span class="line">                    <span class="keyword">if</span> (oldVal != <span class="keyword">null</span>)</span><br><span class="line">                        <span class="keyword">return</span> oldVal;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        addCount(<span class="number">1L</span>, binCount);    <span class="comment">//计数</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="ConcurrentHashMap的扩容详解"><a href="#ConcurrentHashMap的扩容详解" class="headerlink" title="ConcurrentHashMap的扩容详解"></a><strong>ConcurrentHashMap的扩容详解</strong></h2><p>在put方法的详解中，我们可以看到，在同一个节点的个数超过8个的时候，会调用treeifyBin方法来看看是扩容还是转化为一棵树</p><p>同时在每次添加完元素的addCount方法中，也会判断当前数组中的元素是否达到了sizeCtl的量，如果达到了的话，则会进入transfer方法去扩容</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Replaces all linked nodes in bin at given index unless table is</span></span><br><span class="line"><span class="comment">     * too small, in which case resizes instead.</span></span><br><span class="line"><span class="comment">     * 当数组长度小于64的时候，扩张数组长度一倍，否则的话把链表转为树</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">treeifyBin</span><span class="params">(Node&lt;K,V&gt;[] tab, <span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">        Node&lt;K,V&gt; b; <span class="keyword">int</span> n, sc;</span><br><span class="line">        <span class="keyword">if</span> (tab != <span class="keyword">null</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;treeifyBin方\t==&gt;数组长：&quot;</span>+tab.length);</span><br><span class="line">            <span class="keyword">if</span> ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY)    <span class="comment">//MIN_TREEIFY_CAPACITY 64</span></span><br><span class="line">                tryPresize(n &lt;&lt; <span class="number">1</span>);        <span class="comment">// 数组扩容</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((b = tabAt(tab, index)) != <span class="keyword">null</span> &amp;&amp; b.hash &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (b) &#123;    <span class="comment">//使用synchronized同步器，将该节点出的链表转为树</span></span><br><span class="line">                    <span class="keyword">if</span> (tabAt(tab, index) == b) &#123;</span><br><span class="line">                        TreeNode&lt;K,V&gt; hd = <span class="keyword">null</span>, tl = <span class="keyword">null</span>;    <span class="comment">//hd：树的头(head)</span></span><br><span class="line">                        <span class="keyword">for</span> (Node&lt;K,V&gt; e = b; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line">                            TreeNode&lt;K,V&gt; p =</span><br><span class="line">                                <span class="keyword">new</span> TreeNode&lt;K,V&gt;(e.hash, e.key, e.val,</span><br><span class="line">                                                  <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">                            <span class="keyword">if</span> ((p.prev = tl) == <span class="keyword">null</span>)        <span class="comment">//把Node组成的链表，转化为TreeNode的链表，头结点任然放在相同的位置</span></span><br><span class="line">                                hd = p;    <span class="comment">//设置head</span></span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                tl.next = p;</span><br><span class="line">                            tl = p;</span><br><span class="line">                        &#125;</span><br><span class="line">                        setTabAt(tab, index, <span class="keyword">new</span> TreeBin&lt;K,V&gt;(hd));<span class="comment">//把TreeNode的链表放入容器TreeBin中</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>可以看到当需要扩容的时候，调用的时候tryPresize方法，看看trePresize的源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 扩容表为指可以容纳指定个数的大小（总是2的N次方）</span></span><br><span class="line"><span class="comment">     * 假设原来的数组长度为16，则在调用tryPresize的时候，size参数的值为16&lt;&lt;1(32)，此时sizeCtl的值为12</span></span><br><span class="line"><span class="comment">     * 计算出来c的值为64,则要扩容到sizeCtl≥为止</span></span><br><span class="line"><span class="comment">     *  第一次扩容之后 数组长：32 sizeCtl：24</span></span><br><span class="line"><span class="comment">     *  第二次扩容之后 数组长：64 sizeCtl：48</span></span><br><span class="line"><span class="comment">     *  第二次扩容之后 数组长：128 sizeCtl：94 --&gt; 这个时候才会退出扩容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">tryPresize</span><span class="params">(<span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * MAXIMUM_CAPACITY = 1 &lt;&lt; 30</span></span><br><span class="line"><span class="comment">             * 如果给定的大小大于等于数组容量的一半，则直接使用最大容量，</span></span><br><span class="line"><span class="comment">             * 否则使用tableSizeFor算出来</span></span><br><span class="line"><span class="comment">             * 后面table一直要扩容到这个值小于等于sizeCtrl(数组长度的3/4)才退出扩容</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">        <span class="keyword">int</span> c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; <span class="number">1</span>)) ? MAXIMUM_CAPACITY :</span><br><span class="line">            tableSizeFor(size + (size &gt;&gt;&gt; <span class="number">1</span>) + <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">int</span> sc;</span><br><span class="line">        <span class="keyword">while</span> ((sc = sizeCtl) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            Node&lt;K,V&gt;[] tab = table; <span class="keyword">int</span> n;</span><br><span class="line"><span class="comment">//            printTable(tab);    调试用的</span></span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 如果数组table还没有被初始化，则初始化一个大小为sizeCtrl和刚刚算出来的c中较大的一个大小的数组</span></span><br><span class="line"><span class="comment">             * 初始化的时候，设置sizeCtrl为-1，初始化完成之后把sizeCtrl设置为数组长度的3/4</span></span><br><span class="line"><span class="comment">             * 为什么要在扩张的地方来初始化数组呢？这是因为如果第一次put的时候不是put单个元素，</span></span><br><span class="line"><span class="comment">             * 而是调用putAll方法直接put一个map的话，在putALl方法中没有调用initTable方法去初始化table，</span></span><br><span class="line"><span class="comment">             * 而是直接调用了tryPresize方法，所以这里需要做一个是不是需要初始化table的判断</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">if</span> (tab == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>) &#123;</span><br><span class="line">                n = (sc &gt; c) ? sc : c;</span><br><span class="line">                <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc, -<span class="number">1</span>)) &#123;    <span class="comment">//初始化tab的时候，把sizeCtl设为-1</span></span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="keyword">if</span> (table == tab) &#123;</span><br><span class="line">                            <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">                            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node&lt;?,?&gt;[n];</span><br><span class="line">                            table = nt;</span><br><span class="line">                            sc = n - (n &gt;&gt;&gt; <span class="number">2</span>);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                        sizeCtl = sc;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 一直扩容到的c小于等于sizeCtl或者数组长度大于最大长度的时候，则退出</span></span><br><span class="line"><span class="comment">             * 所以在一次扩容之后，不是原来长度的两倍，而是2的n次方倍</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;    <span class="comment">//退出扩张</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (tab == table) &#123;</span><br><span class="line">                <span class="keyword">int</span> rs = resizeStamp(n);</span><br><span class="line">                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                 * 如果正在扩容Table的话，则帮助扩容</span></span><br><span class="line"><span class="comment">                 * 否则的话，开始新的扩容</span></span><br><span class="line"><span class="comment">                 * 在transfer操作，将第一个参数的table中的元素，移动到第二个元素的table中去，</span></span><br><span class="line"><span class="comment">                 * 虽然此时第二个参数设置的是null，但是，在transfer方法中，当第二个参数为null的时候，</span></span><br><span class="line"><span class="comment">                 * 会创建一个两倍大小的table</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="keyword">if</span> (sc &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                    Node&lt;K,V&gt;[] nt;</span><br><span class="line">                    <span class="keyword">if</span> ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + <span class="number">1</span> ||</span><br><span class="line">                        sc == rs + MAX_RESIZERS || (nt = nextTable) == <span class="keyword">null</span> ||</span><br><span class="line">                        transferIndex &lt;= <span class="number">0</span>)</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="comment">/*</span></span><br><span class="line"><span class="comment">                     * transfer的线程数加一,该线程将进行transfer的帮忙</span></span><br><span class="line"><span class="comment">                     * 在transfer的时候，sc表示在transfer工作的线程数</span></span><br><span class="line"><span class="comment">                     */</span></span><br><span class="line">                    <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc, sc + <span class="number">1</span>))</span><br><span class="line">                        transfer(tab, nt);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                 * 没有在初始化或扩容，则开始扩容</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc,</span><br><span class="line">                                             (rs &lt;&lt; RESIZE_STAMP_SHIFT) + <span class="number">2</span>)) &#123;</span><br><span class="line">                        transfer(tab, <span class="keyword">null</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>在tryPresize方法中，并没有加锁，允许多个线程进入，如果数组正在扩张，则当前线程也去帮助扩容。</p><p>数组扩容的主要方法就是transfer方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Moves and/or copies the nodes in each bin to new table. See</span></span><br><span class="line"><span class="comment">     * above for explanation.</span></span><br><span class="line"><span class="comment">     * 把数组中的节点复制到新的数组的相同位置，或者移动到扩张部分的相同位置</span></span><br><span class="line"><span class="comment">     * 在这里首先会计算一个步长，表示一个线程处理的数组长度，用来控制对CPU的使用，</span></span><br><span class="line"><span class="comment">     * 每个CPU最少处理16个长度的数组元素,也就是说，如果一个数组的长度只有16，那只有一个线程会对其进行扩容的复制移动操作</span></span><br><span class="line"><span class="comment">     * 扩容的时候会一直遍历，知道复制完所有节点，每处理一个节点的时候会在链表的头部设置一个fwd节点，这样其他线程就会跳过他，</span></span><br><span class="line"><span class="comment">     * 复制后在新数组中的链表不是绝对的反序的</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = tab.length, stride;</span><br><span class="line">        <span class="keyword">if</span> ((stride = (NCPU &gt; <span class="number">1</span>) ? (n &gt;&gt;&gt; <span class="number">3</span>) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)    <span class="comment">//MIN_TRANSFER_STRIDE 用来控制不要占用太多CPU</span></span><br><span class="line">            stride = MIN_TRANSFER_STRIDE; <span class="comment">// subdivide range    //MIN_TRANSFER_STRIDE=16</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 如果复制的目标nextTab为null的话，则初始化一个table两倍长的nextTab</span></span><br><span class="line"><span class="comment">         * 此时nextTable被设置值了(在初始情况下是为null的)</span></span><br><span class="line"><span class="comment">         * 因为如果有一个线程开始了表的扩张的时候，其他线程也会进来帮忙扩张，</span></span><br><span class="line"><span class="comment">         * 而只是第一个开始扩张的线程需要初始化下目标数组</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (nextTab == <span class="keyword">null</span>) &#123;            <span class="comment">// initiating</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">                Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node&lt;?,?&gt;[n &lt;&lt; <span class="number">1</span>];</span><br><span class="line">                nextTab = nt;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Throwable ex) &#123;      <span class="comment">// try to cope with OOME</span></span><br><span class="line">                sizeCtl = Integer.MAX_VALUE;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            nextTable = nextTab;</span><br><span class="line">            transferIndex = n;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> nextn = nextTab.length;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 创建一个fwd节点，这个是用来控制并发的，当一个节点为空或已经被转移之后，就设置为fwd节点</span></span><br><span class="line"><span class="comment">         * 这是一个空的标志节点</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        ForwardingNode&lt;K,V&gt; fwd = <span class="keyword">new</span> ForwardingNode&lt;K,V&gt;(nextTab);</span><br><span class="line">        <span class="keyword">boolean</span> advance = <span class="keyword">true</span>;    <span class="comment">//是否继续向前查找的标志位</span></span><br><span class="line">        <span class="keyword">boolean</span> finishing = <span class="keyword">false</span>; <span class="comment">// to ensure sweep(清扫) before committing nextTab,在完成之前重新在扫描一遍数组，看看有没完成的没</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, bound = <span class="number">0</span>;;) &#123;</span><br><span class="line">            Node&lt;K,V&gt; f; <span class="keyword">int</span> fh;</span><br><span class="line">            <span class="keyword">while</span> (advance) &#123;</span><br><span class="line">                <span class="keyword">int</span> nextIndex, nextBound;</span><br><span class="line">                <span class="keyword">if</span> (--i &gt;= bound || finishing) &#123;</span><br><span class="line">                    advance = <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> ((nextIndex = transferIndex) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    i = -<span class="number">1</span>;</span><br><span class="line">                    advance = <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (U.compareAndSwapInt</span><br><span class="line">                         (<span class="keyword">this</span>, TRANSFERINDEX, nextIndex,</span><br><span class="line">                          nextBound = (nextIndex &gt; stride ?</span><br><span class="line">                                       nextIndex - stride : <span class="number">0</span>))) &#123;</span><br><span class="line">                    bound = nextBound;</span><br><span class="line">                    i = nextIndex - <span class="number">1</span>;</span><br><span class="line">                    advance = <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; <span class="number">0</span> || i &gt;= n || i + n &gt;= nextn) &#123;</span><br><span class="line">                <span class="keyword">int</span> sc;</span><br><span class="line">                <span class="keyword">if</span> (finishing) &#123;        <span class="comment">//已经完成转移</span></span><br><span class="line">                    nextTable = <span class="keyword">null</span>;</span><br><span class="line">                    table = nextTab;</span><br><span class="line">                    sizeCtl = (n &lt;&lt; <span class="number">1</span>) - (n &gt;&gt;&gt; <span class="number">1</span>);    <span class="comment">//设置sizeCtl为扩容后的0.75</span></span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc = sizeCtl, sc - <span class="number">1</span>)) &#123;</span><br><span class="line">                    <span class="keyword">if</span> ((sc - <span class="number">2</span>) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) &#123;</span><br><span class="line">                            <span class="keyword">return</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    finishing = advance = <span class="keyword">true</span>;</span><br><span class="line">                    i = n; <span class="comment">// recheck before commit</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((f = tabAt(tab, i)) == <span class="keyword">null</span>)            <span class="comment">//数组中把null的元素设置为ForwardingNode节点(hash值为MOVED[-1])</span></span><br><span class="line">                advance = casTabAt(tab, i, <span class="keyword">null</span>, fwd);</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((fh = f.hash) == MOVED)</span><br><span class="line">                advance = <span class="keyword">true</span>; <span class="comment">// already processed</span></span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (f) &#123;                <span class="comment">//加锁操作</span></span><br><span class="line">                    <span class="keyword">if</span> (tabAt(tab, i) == f) &#123;</span><br><span class="line">                        Node&lt;K,V&gt; ln, hn;</span><br><span class="line">                        <span class="keyword">if</span> (fh &gt;= <span class="number">0</span>) &#123;        <span class="comment">//该节点的hash值大于等于0，说明是一个Node节点</span></span><br><span class="line">                                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                                 * 因为n的值为数组的长度，且是power(2,x)的，所以，在&amp;操作的结果只可能是0或者n</span></span><br><span class="line"><span class="comment">                                 * 根据这个规则</span></span><br><span class="line"><span class="comment">                                 *         0--&gt;  放在新表的相同位置</span></span><br><span class="line"><span class="comment">                                 *         n--&gt;  放在新表的（n+原来位置）</span></span><br><span class="line"><span class="comment">                                 */</span></span><br><span class="line">                            <span class="keyword">int</span> runBit = fh &amp; n; </span><br><span class="line">                            Node&lt;K,V&gt; lastRun = f;</span><br><span class="line">                            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                             * lastRun 表示的是需要复制的最后一个节点</span></span><br><span class="line"><span class="comment">                             * 每当新节点的hash&amp;n -&gt; b 发生变化的时候，就把runBit设置为这个结果b</span></span><br><span class="line"><span class="comment">                             * 这样for循环之后，runBit的值就是最后不变的hash&amp;n的值</span></span><br><span class="line"><span class="comment">                             * 而lastRun的值就是最后一次导致hash&amp;n 发生变化的节点(假设为p节点)</span></span><br><span class="line"><span class="comment">                             * 为什么要这么做呢？因为p节点后面的节点的hash&amp;n 值跟p节点是一样的，</span></span><br><span class="line"><span class="comment">                             * 所以在复制到新的table的时候，它肯定还是跟p节点在同一个位置</span></span><br><span class="line"><span class="comment">                             * 在复制完p节点之后，p节点的next节点还是指向它原来的节点，就不需要进行复制了，自己就被带过去了</span></span><br><span class="line"><span class="comment">                             * 这也就导致了一个问题就是复制后的链表的顺序并不一定是原来的倒序</span></span><br><span class="line"><span class="comment">                             */</span></span><br><span class="line">                            <span class="keyword">for</span> (Node&lt;K,V&gt; p = f.next; p != <span class="keyword">null</span>; p = p.next) &#123;</span><br><span class="line">                                <span class="keyword">int</span> b = p.hash &amp; n;    <span class="comment">//n的值为扩张前的数组的长度</span></span><br><span class="line">                                <span class="keyword">if</span> (b != runBit) &#123;</span><br><span class="line">                                    runBit = b;</span><br><span class="line">                                    lastRun = p;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">if</span> (runBit == <span class="number">0</span>) &#123;</span><br><span class="line">                                ln = lastRun;</span><br><span class="line">                                hn = <span class="keyword">null</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">else</span> &#123;</span><br><span class="line">                                hn = lastRun;</span><br><span class="line">                                ln = <span class="keyword">null</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                             * 构造两个链表，顺序大部分和原来是反的</span></span><br><span class="line"><span class="comment">                             * 分别放到原来的位置和新增加的长度的相同位置(i/n+i)</span></span><br><span class="line"><span class="comment">                             */</span></span><br><span class="line">                            <span class="keyword">for</span> (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123;</span><br><span class="line">                                <span class="keyword">int</span> ph = p.hash; K pk = p.key; V pv = p.val;</span><br><span class="line">                                <span class="keyword">if</span> ((ph &amp; n) == <span class="number">0</span>)</span><br><span class="line">                                        <span class="comment">/*</span></span><br><span class="line"><span class="comment">                                         * 假设runBit的值为0，</span></span><br><span class="line"><span class="comment">                                         * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同为0的节点)设置到旧的table的第一个hash计算后为0的节点下一个节点</span></span><br><span class="line"><span class="comment">                                         * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点</span></span><br><span class="line"><span class="comment">                                         */</span></span><br><span class="line">                                    ln = <span class="keyword">new</span> Node&lt;K,V&gt;(ph, pk, pv, ln);</span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line">                                        <span class="comment">/*</span></span><br><span class="line"><span class="comment">                                         * 假设runBit的值不为0，</span></span><br><span class="line"><span class="comment">                                         * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同不为0的节点)设置到旧的table的第一个hash计算后不为0的节点下一个节点</span></span><br><span class="line"><span class="comment">                                         * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点</span></span><br><span class="line"><span class="comment">                                         */</span></span><br><span class="line">                                    hn = <span class="keyword">new</span> Node&lt;K,V&gt;(ph, pk, pv, hn);    </span><br><span class="line">                            &#125;</span><br><span class="line">                            setTabAt(nextTab, i, ln);    </span><br><span class="line">                            setTabAt(nextTab, i + n, hn);</span><br><span class="line">                            setTabAt(tab, i, fwd);</span><br><span class="line">                            advance = <span class="keyword">true</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span> <span class="keyword">if</span> (f <span class="keyword">instanceof</span> TreeBin) &#123;    <span class="comment">//否则的话是一个树节点</span></span><br><span class="line">                            TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;</span><br><span class="line">                            TreeNode&lt;K,V&gt; lo = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                            TreeNode&lt;K,V&gt; hi = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                            <span class="keyword">int</span> lc = <span class="number">0</span>, hc = <span class="number">0</span>;</span><br><span class="line">                            <span class="keyword">for</span> (Node&lt;K,V&gt; e = t.first; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line">                                <span class="keyword">int</span> h = e.hash;</span><br><span class="line">                                TreeNode&lt;K,V&gt; p = <span class="keyword">new</span> TreeNode&lt;K,V&gt;</span><br><span class="line">                                    (h, e.key, e.val, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">                                <span class="keyword">if</span> ((h &amp; n) == <span class="number">0</span>) &#123;</span><br><span class="line">                                    <span class="keyword">if</span> ((p.prev = loTail) == <span class="keyword">null</span>)</span><br><span class="line">                                        lo = p;</span><br><span class="line">                                    <span class="keyword">else</span></span><br><span class="line">                                        loTail.next = p;</span><br><span class="line">                                    loTail = p;</span><br><span class="line">                                    ++lc;</span><br><span class="line">                                &#125;</span><br><span class="line">                                <span class="keyword">else</span> &#123;</span><br><span class="line">                                    <span class="keyword">if</span> ((p.prev = hiTail) == <span class="keyword">null</span>)</span><br><span class="line">                                        hi = p;</span><br><span class="line">                                    <span class="keyword">else</span></span><br><span class="line">                                        hiTail.next = p;</span><br><span class="line">                                    hiTail = p;</span><br><span class="line">                                    ++hc;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                             * 在复制完树节点之后，判断该节点处构成的树还有几个节点，</span></span><br><span class="line"><span class="comment">                             * 如果≤6个的话，就转回为一个链表</span></span><br><span class="line"><span class="comment">                             */</span></span><br><span class="line">                            ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :</span><br><span class="line">                                (hc != <span class="number">0</span>) ? <span class="keyword">new</span> TreeBin&lt;K,V&gt;(lo) : t;</span><br><span class="line">                            hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :</span><br><span class="line">                                (lc != <span class="number">0</span>) ? <span class="keyword">new</span> TreeBin&lt;K,V&gt;(hi) : t;</span><br><span class="line">                            setTabAt(nextTab, i, ln);</span><br><span class="line">                            setTabAt(nextTab, i + n, hn);</span><br><span class="line">                            setTabAt(tab, i, fwd);</span><br><span class="line">                            advance = <span class="keyword">true</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>到这里，ConcurrentHashMap的put操作和扩容都介绍的差不多了，</p><p>下面的两点一定要注意：</p><ul><li><p>复制之后的新链表不是旧链表的绝对倒序。</p></li><li><p>在扩容的时候每个线程都有处理的步长，最少为16，在这个步长范围内的数组节点只有自己一个线程来处理</p></li></ul><h2 id="ConcurrentHashMap的get操作详解"><a href="#ConcurrentHashMap的get操作详解" class="headerlink" title="ConcurrentHashMap的get操作详解"></a><strong>ConcurrentHashMap的get操作详解</strong></h2><p>相比put操作，get操作就显得很简单了。废话少说，直接上源码分析。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 相比put方法，get就很单纯了，支持并发操作，</span></span><br><span class="line"><span class="comment">     * 当key为null的时候回抛出NullPointerException的异常</span></span><br><span class="line"><span class="comment">     * get操作通过首先计算key的hash值来确定该元素放在数组的哪个位置</span></span><br><span class="line"><span class="comment">     * 然后遍历该位置的所有节点</span></span><br><span class="line"><span class="comment">     * 如果不存在的话返回null</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; <span class="keyword">int</span> n, eh; K ek;</span><br><span class="line">        <span class="keyword">int</span> h = spread(key.hashCode());</span><br><span class="line">        <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">            (e = tabAt(tab, (n - <span class="number">1</span>) &amp; h)) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> ((eh = e.hash) == h) &#123;</span><br><span class="line">                <span class="keyword">if</span> ((ek = e.key) == key || (ek != <span class="keyword">null</span> &amp;&amp; key.equals(ek)))</span><br><span class="line">                    <span class="keyword">return</span> e.val;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (eh &lt; <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span> (p = e.find(h, key)) != <span class="keyword">null</span> ? p.val : <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (e.hash == h &amp;&amp;</span><br><span class="line">                    ((ek = e.key) == key || (ek != <span class="keyword">null</span> &amp;&amp; key.equals(ek))))</span><br><span class="line">                    <span class="keyword">return</span> e.val;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>前面分析了下ConcurrentHashMap的源码，那么，对于一个映射集合来说，ConcurrentHashMap是如果来做到并发安全，又是如何做到高效的并发的呢？</p><p>首先是读操作，从源码中可以看出来，在get操作中，根本没有使用同步机制，也没有使用unsafe方法，所以读操作是支持并发操作的。</p><p>那么写操作呢？</p><p>分析这个之前，先看看什么情况下会引起数组的扩容，扩容是通过transfer方法来进行的。而调用transfer方法的只有trePresize、helpTransfer和addCount三个方法。</p><p>这三个方法又是分别在什么情况下进行调用的呢？</p><p>tryPresize是在treeIfybin和putAll方法中调用，treeIfybin主要是在put添加元素完之后，判断该数组节点相关元素是不是已经超过8个的时候，如果超过则会调用这个方法来扩容数组或者把链表转为树。</p><p>helpTransfer是在当一个线程要对table中元素进行操作的时候，如果检测到节点的HASH值为MOVED的时候，就会调用helpTransfer方法，在helpTransfer中再调用transfer方法来帮助完成数组的扩容</p><p>addCount是在当对数组进行操作，使得数组中存储的元素个数发生了变化的时候会调用的方法。</p><p>　　</p><p><strong>所以引起数组扩容的情况如下</strong>：</p><p>只有在往map中添加元素的时候，在某一个节点的数目已经超过了8个，同时数组的长度又小于64的时候，才会触发数组的扩容。</p><p>当数组中元素达到了sizeCtl的数量的时候，则会调用transfer方法来进行扩容</p><p>　　</p><p><strong>那么在扩容的时候，可以不可以对数组进行读写操作呢？</strong></p><p>事实上是可以的。当在进行数组扩容的时候，如果当前节点还没有被处理（也就是说还没有设置为fwd节点），那就可以进行设置操作。</p><p>如果该节点已经被处理了，则当前线程也会加入到扩容的操作中去。</p><p>　　</p><p><strong>那么，多个线程又是如何同步处理的呢？</strong></p><p>在ConcurrentHashMap中，同步处理主要是通过Synchronized和unsafe两种方式来完成的。</p><p>在取得sizeCtl、某个位置的Node的时候，使用的都是unsafe的方法，来达到并发安全的目的</p><p>当需要在某个位置设置节点的时候，则会通过Synchronized的同步机制来锁定该位置的节点。</p><p>在数组扩容的时候，则通过处理的步长和fwd节点来达到并发安全的目的，通过设置hash值为MOVED</p><p>当把某个位置的节点复制到扩张后的table的时候，也通过Synchronized的同步机制来保证现程安全</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ConcurrentHashMap跟HashMap，HashTable的对比&quot;&gt;&lt;a href=&quot;#ConcurrentHashMap跟HashMap，HashTable的对比&quot; class=&quot;headerlink&quot; title=&quot;ConcurrentHashMa</summary>
      
    
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/categories/Collection/"/>
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/tags/Collection/"/>
    
  </entry>
  
  <entry>
    <title>06.MySQL的主从复制</title>
    <link href="https://leslieaibin.github.io/2021/09/21/MySQL/06.MySQL%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    <id>https://leslieaibin.github.io/2021/09/21/MySQL/06.MySQL%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</id>
    <published>2021-09-21T12:17:42.000Z</published>
    <updated>2021-09-21T08:38:02.552Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL-BinLog"><a href="#MySQL-BinLog" class="headerlink" title="MySQL BinLog"></a>MySQL BinLog</h1><p>MySQL 的 Binlog 日志是一种二进制格式的日志，Binlog记录所有的DDL和DML语句（除了数据查询语句Select， show 等），以Event的形式记录，同时记录语句执行时间。</p><p>BInlog的 主要作用有两种：</p><ul><li><p>数据恢复：</p><p>因为Binlog详细记录所有修改数据的SQL，当某一个时刻的数据误操作而导致出问题，或者数据库当局数据丢失，那么可以根据binlog回放历史数据</p></li><li><p>主从复制</p><p>想做多级备份的业务，可以去监听当前写库的Binlog日志，同步写库的所有更改</p></li></ul><p>Binlog包括两类文件</p><ul><li>二进制日志索引文件（.index）：记录所有的二进制文件</li><li>二进制日志文件(.00000*)：记录所有DDL和DML语句事件</li></ul><p>Binlog日志功能默认是开启的，线上情况下的Binlog日志的增长速度是很快的，在MySQL配置文件<code>my.cnf</code> 中提供一些参数来对 Binlog 进行设置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">设置此参数表示启用binlog功能，并制定二进制日志的存储目录</span><br><span class="line">log-<span class="built_in">bin</span>=/home/mysql/binlog/</span><br><span class="line"></span><br><span class="line"><span class="comment">#mysql-bin.*日志文件最大字节（单位：字节）</span></span><br><span class="line"><span class="comment">#设置最大100MB</span></span><br><span class="line">max_binlog_size=<span class="number">104857600</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#设置了只保留7天BINLOG（单位：天）</span></span><br><span class="line">expire_logs_days = <span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#binlog日志只记录指定库的更新</span></span><br><span class="line"><span class="comment">#binlog-do-db=db_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#binlog日志不记录指定库的更新</span></span><br><span class="line"><span class="comment">#binlog-ignore-db=db_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#写缓冲多少次，刷一次磁盘，默认0</span></span><br><span class="line">sync_binlog=<span class="number">0</span></span><br></pre></td></tr></table></figure><p><strong>max_binlog_size</strong> ：Binlog 最大和默认值是 1G，该设置并不能严格控制 Binlog 的大小，尤其是 Binlog 比较靠近最大值而又遇到一个比较大事务时，为了保证事务的完整性不可能做切换日志的动作，只能将该事务的所有 SQL 都记录进当前日志直到事务结束。所以真实文件有时候会大于 max_binlog_size 设定值。</p><p><strong>expire_logs_days</strong> ：Binlog 过期删除不是服务定时执行，是需要借助事件触发才执行，事件包括：</p><ul><li>服务器重启</li><li>服务器被更新</li><li>日志达到了最大日志长度 <code>max_binlog_size</code></li><li>日志被刷新</li></ul><p>二进制日志由配置文件的 <code>log-bin</code> 选项负责启用，MySQL 服务器将在数据根目录创建两个新文件<code>mysql-bin.000001</code> 和 <code>mysql-bin.index</code>，若配置选项没有给出文件名，MySQL 将使用主机名称命名这两个文件，其中 <code>.index</code> 文件包含一份全体日志文件的清单。</p><p><strong>sync_binlog</strong>：这个参数决定了 Binlog 日志的更新频率。默认 0 ，表示该操作由操作系统根据自身负载自行决定多久写一次磁盘。</p><p>sync_binlog = 1 表示每一条事务提交都会立刻写盘。sync_binlog=n 表示 n 个事务提交才会写盘。</p><p>根据 MySQL 文档，写 Binlog 的时机是：SQL transaction 执行完，但任何相关的 Locks 还未释放或事务还未最终 commit 前。这样保证了 Binlog 记录的操作时序与数据库实际的数据变更顺序一致。</p><h1 id="MySQL主从复制"><a href="#MySQL主从复制" class="headerlink" title="MySQL主从复制"></a>MySQL主从复制</h1><p>Binlog 日志主要作用是数据恢复和主从复制。本身就是二进制格式的日志文件，网络传输无需进行协议转换。MySQL集群的高可用，负载均衡，读写分类等功能都是基于Binlog来实现的</p><h2 id="MySQL主从复制主流架构模型"><a href="#MySQL主从复制主流架构模型" class="headerlink" title="MySQL主从复制主流架构模型"></a>MySQL主从复制主流架构模型</h2><p>我们基于 Binlog 可以复制出一台 MySQL 服务器，也可以复制出多台，取决于我们想实现什么功能。主流的系统架构有如下几种方式：</p><h3 id="一主一从-一主多从"><a href="#一主一从-一主多从" class="headerlink" title="一主一从 / 一主多从"></a>一主一从 / 一主多从</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mx9n5wj30lu0mwgne.jpg" alt="1"></p><p>一主一从和一主多从是最常见的主从架构方式，一般实现主从配置或者读写分离都可以采用这种架构。</p><p>如果是一主多从的模式，当 Slave 增加到一定数量时，Slave 对 Master 的负载以及网络带宽都会成为一个严重的问题。</p><h3 id="多主一从"><a href="#多主一从" class="headerlink" title="多主一从"></a>多主一从</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mt1km7j30m80l4407.jpg" alt="1"></p><p>MySQL 5.7 开始支持多主一从的模式，将多个库的数据备份到一个库中存储。</p><h3 id="双主复制"><a href="#双主复制" class="headerlink" title="双主复制"></a>双主复制</h3><p>理论上跟主从一样，但是两个MySQL服务器互做对方的从，任何一方有变更，都会复制对方的数据到自己的数据库。双主适用于写压力比较大的业务场景，或者 DBA 做维护需要主从切换的场景，通过双主架构避免了重复搭建从库的麻烦。（主从相互授权连接，读取对方binlog日志并更新到本地数据库的过程；只要对方数据改变，自己就跟着改变）</p><h3 id="级联复制"><a href="#级联复制" class="headerlink" title="级联复制"></a>级联复制</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mr6mxzj30z60hg40u.jpg" alt="1"></p><p>级联模式下因为涉及到的 slave 节点很多，所以如果都连在 master 上对主服务器的压力肯定是不小的。所以部分 slave 节点连接到它上一级的从节点上。这样就缓解了主服务器的压力。</p><p>级联复制解决了一主多从场景下多个从库复制对主库的压力，带来的弊端就是数据同步延迟比较大。</p><h2 id="MySQL-主从复制原理"><a href="#MySQL-主从复制原理" class="headerlink" title="MySQL 主从复制原理"></a>MySQL 主从复制原理</h2><p>MySQL 主从复制涉及到三个线程：</p><ul><li>一个在主节点的线程：<code>log dump thread</code></li><li>从库会生成两个线程：一个 I/O 线程，一个 SQL 线程</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1ms5ezhj312s0imtb5.jpg" alt="4"></p><p>主库会生成一个 log dump 线程,用来给从库 I/O 线程传 Binlog 数据。</p><p>从库的 I/O 线程会去请求主库的 Binlog，并将得到的 Binlog 写到本地的 relay log (中继日志)文件中。</p><p>SQL 线程,会读取 relay log 文件中的日志，并解析成 SQL 语句逐一执行。</p><h5 id="主节点-log-dump-线程"><a href="#主节点-log-dump-线程" class="headerlink" title="主节点 log dump 线程"></a>主节点 log dump 线程</h5><p>当从节点连接主节点时，主节点会为其创建一个 log dump 线程，用于发送和读取 Binlog 的内容。在读取 Binlog 中的操作时，log dump 线程会对主节点上的 Binlog 加锁；当读取完成发送给从节点之前，锁会被释放。<strong>主节点会为自己的每一个从节点创建一个 log dump 线程</strong>。</p><h5 id="从节点I-O线程"><a href="#从节点I-O线程" class="headerlink" title="从节点I/O线程"></a>从节点I/O线程</h5><p>当从节点上执行<code>start slave</code>命令之后，从节点会创建一个 I/O 线程用来连接主节点，请求主库中更新的Binlog。I/O 线程接收到主节点的 log dump 进程发来的更新之后，保存在本地 relay-log（中继日志）中。</p><h5 id="relay-log"><a href="#relay-log" class="headerlink" title="relay log"></a>relay log</h5><p>这里又引申出一个新的日志概念。MySQL 进行主主复制或主从复制的时候会在要复制的服务器下面产生相应的 relay log。</p><p>relay log 是怎么产生的呢？</p><p>从服务器 I/O 线程将主服务器的 Binlog 日志读取过来，解析到各类 Events 之后记录到从服务器本地文件，这个文件就被称为 relay log。然后 SQL 线程会读取 relay log 日志的内容并应用到从服务器，从而使从服务器和主服务器的数据保持一致。中继日志充当缓冲区，这样 master 就不必等待 slave 执行完成才发送下一个事件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt;  show variables like &#39;%relay%&#39;;</span><br><span class="line">+---------------------------+------------------------------------------------------------+</span><br><span class="line">| Variable_name             | Value                                                      |</span><br><span class="line">+---------------------------+------------------------------------------------------------+</span><br><span class="line">| max_relay_log_size        | 0                                                          |</span><br><span class="line">| relay_log                 | yangyuedeMacBook-Pro-relay-bin                             |</span><br><span class="line">| relay_log_basename        | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;yangyuedeMacBook-Pro-relay-bin       |</span><br><span class="line">| relay_log_index           | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;yangyuedeMacBook-Pro-relay-bin.index |</span><br><span class="line">| relay_log_info_file       | relay-log.info                                             |</span><br><span class="line">| relay_log_info_repository | TABLE                                                      |</span><br><span class="line">| relay_log_purge           | ON                                                         |</span><br><span class="line">| relay_log_recovery        | OFF                                                        |</span><br><span class="line">| relay_log_space_limit     | 0                                                          |</span><br><span class="line">| sync_relay_log            | 10000                                                      |</span><br><span class="line">| sync_relay_log_info       | 10000                                                      |</span><br><span class="line">+---------------------------+------------------------------------------------------------+</span><br><span class="line">11 rows in set (0.03 sec)</span><br></pre></td></tr></table></figure><p><strong>max_relay_log_size</strong></p><p>标记 relay log 允许的最大值，如果该值为 0，则默认值为 max_binlog_size(1G)；如果不为 0，则max_relay_log_size 则为最大的 relay_log 文件大小。</p><p><strong>relay_log_purge</strong></p><p>是否自动清空不再需要中继日志时。默认值为1(启用)。</p><p><strong>relay_log_recovery</strong></p><p>当 slave 从库宕机后，假如 relay log 损坏了，导致一部分中继日志没有处理，则自动放弃所有未执行的 relay log，并且重新从 master 上获取日志，这样就保证了 relay log 的完整性。默认情况下该功能是关闭的，将 relay_log_recovery 的值设置为 1 时，可在 slave 从库上开启该功能，建议开启。</p><p><strong>relay_log_space_limit</strong></p><p>防止中继日志写满磁盘，这里设置中继日志最大限额。但此设置存在主库崩溃，从库中继日志不全的情况，不到万不得已，<strong>不推荐使用。</strong></p><p><strong>sync_relay_log</strong></p><p>这个参数和 Binlog 中的 <code>sync_binlog</code>作用相同。当设置为 1 时，slave 的 I/O 线程每次接收到 master 发送过来的 Binlog 日志都要写入系统缓冲区，然后刷入 relay log 中继日志里，这样是最安全的，因为在崩溃的时候，你最多会丢失一个事务，但会造成磁盘的大量 I/O。</p><p>当设置为 0 时，并不是马上就刷入中继日志里，而是由操作系统决定何时来写入，虽然安全性降低了，但减少了大量的磁盘 I/O 操作。这个值默认是 0，可动态修改，建议采用默认值。</p><p><strong>sync_relay_log_info</strong></p><p>当设置为 1 时，slave 的 I/O 线程每次接收到 master 发送过来的 Binlog 日志都要写入系统缓冲区，然后刷入 relay-log.info 里，这样是最安全的，因为在崩溃的时候，你最多会丢失一个事务，但会造成磁盘的大量 I/O。当设置为 0 时，并不是马上就刷入 relay-log.info 里，而是由操作系统决定何时来写入，虽然安全性降低了，但减少了大量的磁盘 I/O 操作。这个值默认是0，可动态修改，建议采用默认值。</p><h5 id="从节点-SQL-线程"><a href="#从节点-SQL-线程" class="headerlink" title="从节点 SQL 线程"></a>从节点 SQL 线程</h5><p>SQL 线程负责读取 relay log 中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。</p><p>对于每一个主从连接，都需要这三个进程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个 log dump 进程，而每个从节点都有自己的 I/O 进程，SQL 进程。</p><p>从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候，不会降低读操作的性能。比如，如果从节点没有运行，此时 I/O 进程可以很快从主节点获取更新，尽管 SQL 进程还没有执行。如果在 SQL 进程执行之前从节点服务停止，至少 I/O 进程已经从主节点拉取到了最新的变更并且保存在本地 relay log 中，当服务再次起来之后就可以完成数据的同步。</p><p>要实施复制，首先必须打开 Master 端的 Binlog 功能，否则无法实现。</p><p>因为整个复制过程实际上就是 Slave 从 Master 端获取该日志然后再在自己身上完全顺序的执行日志中所记录的各种操作。如下图所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mvsnp5j31040iyad2.jpg" alt="5"></p><h5 id="复制的基本过程"><a href="#复制的基本过程" class="headerlink" title="复制的基本过程"></a>复制的基本过程</h5><ol><li>在从节点上执行 <code>sart slave</code> 命令开启主从复制开关，开始进行主从复制。从节点上的 I/O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容。</li><li>主节点接收到来自从节点的 I/O 请求后，通过负责复制的 I/O 进程（log Dump Thread）根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的 Binlog file 以及 Binlog position（Binlog 下一个数据读取位置）。</li><li>从节点的 I/O 进程接收到主节点发送过来的日志内容、日志文件及位置点后，将接收到的日志内容更新到本机的 relay log 文件（Mysql-relay-bin.xxx）的最末端，并将读取到的 Binlog文件名和位置保存到<code>master-info</code> 文件中，以便在下一次读取的时候能够清楚的告诉 Master ：“ 我需要从哪个 Binlog 的哪个位置开始往后的日志内容，请发给我”。</li><li>Slave 的 SQL 线程检测到relay log 中新增加了内容后，会将 relay log 的内容解析成在能够执行 SQL 语句，然后在本数据库中按照解析出来的顺序执行，并在 <code>relay log.info</code> 中记录当前应用中继日志的文件名和位置点。</li></ol><h2 id="MySQL-基于-Binlog-主从复制的模式介绍"><a href="#MySQL-基于-Binlog-主从复制的模式介绍" class="headerlink" title="MySQL 基于 Binlog 主从复制的模式介绍"></a>MySQL 基于 Binlog 主从复制的模式介绍</h2><p>MySQL 主从复制默认是 <strong>异步的模式</strong>。MySQL增删改操作会全部记录在 Binlog 中，当 slave 节点连接 master 时，会主动从 master 处获取最新的 Binlog 文件。并把 Binlog 存储到本地的 relay log 中，然后去执行 relay log 的更新内容。</p><h3 id="异步模式-async-mode"><a href="#异步模式-async-mode" class="headerlink" title="异步模式 (async-mode)"></a>异步模式 (async-mode)</h3><p>异步模式如下图所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mu02wbj31160kk0vj.jpg" alt="6"></p><p>这种模式下，主节点不会主动推送数据到从节点，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主节点如果崩溃掉了，此时主节点上已经提交的事务可能并没有传到从节点上，如果此时，强行将从提升为主，可能导致新主节点上的数据不完整。</p><h3 id="全同步模式"><a href="#全同步模式" class="headerlink" title="全同步模式"></a>全同步模式</h3><p>指当主库执行完一个事务，然后所有的从库都复制了该事务并成功执行完才返回成功信息给客户端。因为需要等待所有从库执行完该事务才能返回成功信息，所以全同步复制的性能必然会收到严重的影响。</p><h3 id="半同步模式-semi-sync"><a href="#半同步模式-semi-sync" class="headerlink" title="半同步模式(semi-sync)"></a>半同步模式(semi-sync)</h3><p>介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到 relay log 中才返回成功信息给客户端（只能保证主库的 Binlog 至少传输到了一个从节点上），否则需要等待直到超时时间然后切换成异步模式再提交。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1muypwdj31420jg41q.jpg" alt="7"></p><p>相对于异步复制，半同步复制提高了数据的安全性，一定程度的保证了数据能成功备份到从库，同时它也造成了一定程度的延迟，但是比全同步模式延迟要低，这个延迟最少是一个 TCP/IP 往返的时间。所以，半同步复制最好在低延时的网络中使用。</p><p>半同步模式不是 MySQL 内置的，从 MySQL 5.5 开始集成，需要 master 和 slave 安装插件开启半同步模式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MySQL-BinLog&quot;&gt;&lt;a href=&quot;#MySQL-BinLog&quot; class=&quot;headerlink&quot; title=&quot;MySQL BinLog&quot;&gt;&lt;/a&gt;MySQL BinLog&lt;/h1&gt;&lt;p&gt;MySQL 的 Binlog 日志是一种二进制格式的日志，B</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>10.Java内存模型</title>
    <link href="https://leslieaibin.github.io/2021/09/15/Thread/11.Java%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88JMM)/"/>
    <id>https://leslieaibin.github.io/2021/09/15/Thread/11.Java%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88JMM)/</id>
    <published>2021-09-15T02:15:42.000Z</published>
    <updated>2021-09-15T13:57:21.738Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Java内存模型（JMM）"><a href="#Java内存模型（JMM）" class="headerlink" title="Java内存模型（JMM）"></a>Java内存模型（JMM）</h1><p>JVM内存模型指的是JVM的内存分区；而java内存模型是一种虚拟机规范</p><p>JMM就是Java内存模型（Java Mermory Model）。因为在不同的硬件生产商和不同的操作系统下，内存的访问有一定的差异，所以会造成相同的代码运行在不同的系统上会出现各种问题。<strong>所以Java内存模型（JMM）屏蔽掉各种硬件和和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果</strong></p><p>Java内存模型规定所有的变量存储在主内存中，包括 实例变量，静态变量，但是不包括局部变量和方法参数，每个线程都有自己的工作内存，线程的工作内存保存了该线程用的到变量和主内存的副本拷贝，线程对变量的操作 都在工作内存中进行。线程不能直接读写主内存中的变量。</p><p>不同的线程之间也无法访问对方工作内存中的变量，线程之间变量值的传递均需要通过主内存来完成</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-f36f366c07a6188ea3fdefc794ba021a_720w.jpg" alt="img"></p><p>每个线程的工作内存都是独立的，线程操作数据只能在工作内存中进行，然后刷会主存，这是JMM的线程基本工作方式</p><h2 id="JMM定义了什么"><a href="#JMM定义了什么" class="headerlink" title="JMM定义了什么"></a>JMM定义了什么</h2><p>整个Java内存模型实际上是围绕着三个特征建立起来的。分别是：原子性(Atomicity)，可见性（Visibility），有序性（Ordering）。这三个特征可谓是整个Java并发的基础</p><h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>原子性指的是一个操作是不可分割，不可中断的，一个线程在执行时不会被其他线程干扰。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> j = i;</span><br><span class="line">i++;</span><br><span class="line">i = i + <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>第一句是基本类型赋值操作，必定是原子性操作。</p><p>第二句先读取i的值，再赋值到j，两步操作，不能保证原子性。</p><p>第三和第四句其实是等效的，先读取i的值，再+1，最后赋值到i，三步操作了，不能保证原子性。</p><p>JMM只能保证基本的原子性，如果要保证一个代码块的原子性，提供了monitorenter 和 moniterexit 两个字节码指令，也就是 synchronized 关键字。因此在 synchronized 块之间的操作都是原子性的。</p><h3 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h3><p>可见性指当一个线程修改共享变量的值，其他线程能够立即知道被修改了。Java是利用Volatile关键字来提供可见性的。当变量被volatile修饰时，这个变量被修改后会立即刷新到主内存，当其他线程需要读取该变量时，会去至内存中读取新值。而普通变量则不能保证这一点</p><p>除了volatile关键字之外，final和synchronized也能实现可见性。</p><p>synchronized的原理是，在执行完，进入unlock之前，必须将共享变量同步到主内存中。</p><p>final修饰的字段，一旦初始化完成，如果没有对象逸出（指对象为初始化完成就可以被别的线程使用），那么对于其他线程都是可见的。</p><h3 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h3><p>在Java中，可以使用synchronized或者volatile保证多线程之间操作的有序性。实现原理有些区别：</p><p>volatile关键字是使用内存屏障达到禁止指令重排序，以保证有序性。</p><p>synchronized的原理是，一个线程lock之后，必须unlock后，其他线程才可以重新lock，使得被synchronized包住的代码块在多线程之间是串行执行的。</p><h2 id="八种内存交互操作"><a href="#八种内存交互操作" class="headerlink" title="八种内存交互操作"></a>八种内存交互操作</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210915214648182.png" alt="image-20210915214648182"></p><ul><li>lock(锁定)，作用于<strong>主内存</strong>中的变量，把变量标识为线程独占的状态。</li><li>read(读取)，作用于<strong>主内存</strong>的变量，把变量的值从主内存传输到线程的工作内存中，以便下一步的load操作使用。</li><li>load(加载)，作用于<strong>工作内存</strong>的变量，把read操作主存的变量放入到工作内存的变量副本中。</li><li>use(使用)，作用于<strong>工作内存</strong>的变量，把工作内存中的变量传输到执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。</li><li>assign(赋值)，作用于<strong>工作内存</strong>的变量，它把一个从执行引擎中接受到的值赋值给工作内存的变量副本中，每当虚拟机遇到一个给变量赋值的字节码指令时将会执行这个操作。</li><li>store(存储)，作用于<strong>工作内存</strong>的变量，它把一个从工作内存中一个变量的值传送到主内存中，以便后续的write使用。</li><li>write(写入)：作用于<strong>主内存</strong>中的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。</li><li>unlock(解锁)：作用于<strong>主内存</strong>的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</li></ul><p>再补充一下JMM对8种内存交互操作制定的规则吧：</p><ul><li>不允许read、load、store、write操作之一单独出现，也就是read操作后必须load，store操作后必须write。</li><li>不允许线程丢弃他最近的assign操作，即工作内存中的变量数据改变了之后，必须告知主存。</li><li>不允许线程将没有assign的数据从工作内存同步到主内存。</li><li>一个新的变量必须在主内存中诞生，不允许工作内存直接使用一个未被初始化的变量。就是对变量实施use、store操作之前，必须经过load和assign操作。</li><li>一个变量同一时间只能有一个线程对其进行lock操作。多次lock之后，必须执行相同次数unlock才可以解锁。</li><li>如果对一个变量进行lock操作，会清空所有工作内存中此变量的值。在执行引擎使用这个变量前，必须重新load或assign操作初始化变量的值。</li><li>如果一个变量没有被lock，就不能对其进行unlock操作。也不能unlock一个被其他线程锁住的变量。</li><li>一个线程对一个变量进行unlock操作之前，必须先把此变量同步回主内存。</li></ul><h2 id="volatile关键字"><a href="#volatile关键字" class="headerlink" title="volatile关键字"></a>volatile关键字</h2><ul><li>保证线程间变量的可见性</li><li>禁止CPU进行指令重排</li></ul><h2 id="可见性-1"><a href="#可见性-1" class="headerlink" title="可见性"></a>可见性</h2><p>volatile修饰的变量，当一个线程改变了该变量的值，其他线程是立即可见的。普通变量则需要重新读取才能获得最新值。</p><p>volatile保证可见性的流程大概就是这个一个过程：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2ce112590b4b81cdb02b8839d9d8b686_720w.jpg" alt="img"></p><h2 id="volatile一定能保证线程安全吗"><a href="#volatile一定能保证线程安全吗" class="headerlink" title="volatile一定能保证线程安全吗"></a>volatile一定能保证线程安全吗</h2><p>先说结论吧，volatile不能一定能保证线程安全。</p><p>怎么证明呢，我们看下面一段代码的运行结果就知道了：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * @author Ye Hongzhi 公众号：java技术爱好者</span><br><span class="line"> **/</span><br><span class="line">public class VolatileTest extends Thread &#123;</span><br><span class="line"></span><br><span class="line">    private static volatile int count = 0;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        Vector&lt;Thread&gt; threads = new Vector&lt;&gt;();</span><br><span class="line">        for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">            VolatileTest thread = new VolatileTest();</span><br><span class="line">            threads.add(thread);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">        //等待子线程全部完成</span><br><span class="line">        for (Thread thread : threads) &#123;</span><br><span class="line">            thread.join();</span><br><span class="line">        &#125;</span><br><span class="line">        //输出结果，正确结果应该是1000，实际却是984</span><br><span class="line">        System.out.println(count);//984</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        for (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                //休眠500毫秒</span><br><span class="line">                Thread.sleep(500);</span><br><span class="line">            &#125; catch (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            count++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为什么volatile不能保证线程安全？</p><p>很简单呀，可见性不能保证操作的原子性，前面说过了count++不是原子性操作，会当做三步，先读取count的值，然后+1，最后赋值回去count变量。需要保证线程安全的话，需要使用synchronized关键字或者lock锁，给count++这段代码上锁：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">private static synchronized void add() &#123;</span><br><span class="line">    count++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="禁止指令重排序"><a href="#禁止指令重排序" class="headerlink" title="禁止指令重排序"></a>禁止指令重排序</h2><p>首先要讲一下as-if-serial语义，不管怎么重排序，（单线程）程序的执行结果不能被改变。</p><p>为了使指令更加符合CPU的执行特性，最大限度的发挥机器的性能，提高程序的执行效率，只要程序的最终结果与它顺序化情况的结果相等，那么指令的执行顺序可以与代码逻辑顺序不一致，这个过程就叫做<strong>指令的重排序</strong>。</p><p>重排序的种类分为三种，分别是：编译器重排序，指令级并行的重排序，内存系统重排序。整个过程如下所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210915215020235.png" alt="image-20210915215020235"></p><p>指令重排序在单线程是没有问题的，不会影响执行结果，而且还提高了性能。但是在多线程的环境下就不能保证一定不会影响执行结果了。</p><p><strong>所以在多线程环境下，就需要禁止指令重排序</strong>。</p><p>volatile关键字禁止指令重排序有两层意思：</p><ul><li>当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见，在其后面的操作肯定还没有进行。</li><li>在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。</li></ul><p>下面举个例子：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">private static int a;//非volatile修饰变量</span><br><span class="line">private static int b;//非volatile修饰变量</span><br><span class="line">private static volatile int k;//volatile修饰变量</span><br><span class="line"></span><br><span class="line">private void hello() &#123;</span><br><span class="line">    a = 1;  //语句1</span><br><span class="line">    b = 2;  //语句2</span><br><span class="line">    k = 3;  //语句3</span><br><span class="line">    a = 4;  //语句4</span><br><span class="line">    b = 5;  //语句5</span><br><span class="line">    //以下省略...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>变量a，b是非volatile修饰的变量，k则使用volatile修饰。所以语句3不能放在语句1、2前，也不能放在语句4、5后。但是语句1、2的顺序是不能保证的，同理，语句4、5也不能保证顺序。</p><p>并且，执行到语句3的时候，语句1，2是肯定执行完毕的，而且语句1,2的执行结果对于语句3,4,5是可见的。</p><h2 id="volatile禁止指令重排序的原理是什么"><a href="#volatile禁止指令重排序的原理是什么" class="headerlink" title="volatile禁止指令重排序的原理是什么"></a>volatile禁止指令重排序的原理是什么</h2><p>首先要讲一下内存屏障，内存屏障可以分为以下几类：</p><ul><li>LoadLoad 屏障：对于这样的语句Load1，LoadLoad，Load2。在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</li><li>StoreStore屏障：对于这样的语句Store1， StoreStore， Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。</li><li>LoadStore 屏障：对于这样的语句Load1， LoadStore，Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</li><li>StoreLoad 屏障：对于这样的语句Store1， StoreLoad，Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。</li></ul><p>在每个volatile读操作后插入LoadLoad屏障，在读操作后插入LoadStore屏障。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210915215154275.png" alt="image-20210915215154275"></p><p>在每个volatile写操作的前面插入一个StoreStore屏障，后面插入一个SotreLoad屏障。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210915215209621.png" alt="image-20210915215209621"></p><p>大概的原理就是这样。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Java内存模型（JMM）&quot;&gt;&lt;a href=&quot;#Java内存模型（JMM）&quot; class=&quot;headerlink&quot; title=&quot;Java内存模型（JMM）&quot;&gt;&lt;/a&gt;Java内存模型（JMM）&lt;/h1&gt;&lt;p&gt;JVM内存模型指的是JVM的内存分区；而java内存</summary>
      
    
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>05.分布式锁</title>
    <link href="https://leslieaibin.github.io/2021/09/11/MySQL/05.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>https://leslieaibin.github.io/2021/09/11/MySQL/05.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</id>
    <published>2021-09-11T12:17:42.000Z</published>
    <updated>2021-09-11T02:31:35.974Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><h2 id="什么是锁"><a href="#什么是锁" class="headerlink" title="什么是锁"></a>什么是锁</h2><ul><li>在单线程的系统中，当存在多个线程可以同时改变某个变量（可变共享变量）时，就需要对变量或代码块做同步，使其在修改这种变量时能够线性执行消除并发修改变量</li><li>而同步的本质是通过锁实现的。为了实现多个线程在一个时刻同一代码块只能有一个线程可执行，那么需要在某个地方做个标记，这个必须每个线程都能看到，当标记不存在时可以设置该标记，其余后续线程发现已经有标记了则等待拥有标记的线程结束同步代码块取消标记后再去尝试设置标记。这个标记可以理解为锁。</li><li>不同地方实现锁的方式也不一样，只要能满足所有线程都能看到标记即可。如java中synchroniuze是 在对象头设置标记，Lock接口的实现类基本上都只是某一个volitile修饰的int型变量其保证每个线程都能拥有对该int的可见性和原子性修改，linux内核中也是利用互斥量或信号量等内存数据标记</li><li>除了利用内存数据做锁其他任何互斥的都能做锁（只考虑互斥情况），如流水表中流水号与实践结合做幂等校验可以看作是一个不会释放的锁，或者使用某个文件是否存在作为锁等。只需要满足在对标记进行修改能保证原子性和内存可见性即可。</li></ul><h2 id="什么是分布式"><a href="#什么是分布式" class="headerlink" title="什么是分布式"></a>什么是分布式</h2><p>分布式的CAP理论告诉我们：</p><p>任何一个分布式系统都无法同时满足一致性（Consistency）、 可用性（Avaiability）和分区容错性（Partition tolerance)，最多只能同时满足两项。</p><p>目前很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。基于CAP理论，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证最终一致性</p><h2 id="分布式场景"><a href="#分布式场景" class="headerlink" title="分布式场景"></a>分布式场景</h2><p>在许多的场景中，我们为了保证数据的最终一致性，需要很多技术方案来支持，比如分布式事务，分布式锁等。很多时候我们需要保证一个方法在同一时间只能被同一线程执行。在单机环境中，通过java提供的并发API我们可以解决，但是在分布式环境下，就没有那么简单。</p><ul><li>分布式与单机情况下最大的不同在于其不是多线程而是多进程</li><li>多线程由于共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一物理机上，因此需要将标记存储在一个所有进程都能看到的地方</li></ul><h2 id="什么是分布式锁"><a href="#什么是分布式锁" class="headerlink" title="什么是分布式锁"></a>什么是分布式锁</h2><ul><li>当在分布式模型下，数据只有一份（或有限制），此时需要利用锁的技术控制某一时刻修改数据的进程数</li><li>与单机模型下的锁不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。</li><li>分布式锁还是可以将标记存在内存，只是该内存不是某个进程分配的内存而是公共内存如 Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要保证标记能互斥就行</li></ul><h2 id="我们需要怎样的分布式锁"><a href="#我们需要怎样的分布式锁" class="headerlink" title="我们需要怎样的分布式锁"></a>我们需要怎样的分布式锁</h2><ul><li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。</li><li>这把锁要是一把可重入锁（避免死锁）</li><li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li><li>这把锁最好是一把公平锁（根据业务需求考虑要不要这条）</li><li>有高可用的获取锁和释放锁功能</li><li>获取锁和释放锁的性能要好</li></ul><h1 id="基于表主键唯一做分布式锁"><a href="#基于表主键唯一做分布式锁" class="headerlink" title="基于表主键唯一做分布式锁"></a>基于表主键唯一做分布式锁</h1><p>利用主键的特性，如果多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以任务操作成功的那个县城获得该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可</p><p>上面这种简单的实现有以下几个问题：</p><ul><li>这把锁依赖数据库的可用性，数据库是一个单点，一旦数据库挂了，会导致业务系统不可用</li><li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获取锁</li><li>这把锁只能是非阻塞的，因为 数据insert操作，一旦插入失败就会直接报错。没有获得锁的线程比不会进入排队队列，想要再次获得锁就要再次触发获得锁操作。</li><li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</li><li>这把锁是非公平锁，所有等待锁的线程凭运气去争夺锁。</li><li>在 MySQL 数据库中采用主键冲突防重，在大并发情况下有可能会造成锁表现象。</li></ul><p><strong>我们也可以有其他方式解决上面的问题</strong></p><ul><li>数据库是单点？ 搞两个数据库，数据之前双向同步，一旦挂掉快速切换到备库上</li><li>没有失效时间？ 只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍</li><li>非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。</li><li>非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li><li>非公平的？再建一张中间表，将等待锁的线程全记录下来，并根据创建时间排序，只有最先创建的允许获取锁。</li><li>比较好的办法是在程序中生产主键进行防重。</li></ul><h1 id="基于Redis做分布式锁"><a href="#基于Redis做分布式锁" class="headerlink" title="基于Redis做分布式锁"></a>基于Redis做分布式锁</h1><h2 id="基于redis-的-setnx-、expire-方法做分布式锁"><a href="#基于redis-的-setnx-、expire-方法做分布式锁" class="headerlink" title="基于redis 的 setnx()、expire()方法做分布式锁"></a>基于redis 的 setnx()、expire()方法做分布式锁</h2><h3 id="setnx"><a href="#setnx" class="headerlink" title="setnx()"></a>setnx()</h3><p>setnx 的含义就是 SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果 key 不存在，则设置当前 key 成功，返回 1；如果当前 key 已经存在，则设置当前 key 失败，返回 0。</p><h3 id="expire"><a href="#expire" class="headerlink" title="expire()"></a>expire()</h3><p>expire 设置过期时间，要注意的是 setnx 命令不能设置 key 的超时时间，只能通过 expire() 来对 key 设置。</p><h3 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h3><p>1、setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功</p><p>2、expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。</p><p>3、执行完业务代码后，可以通过 delete 命令删除 key。</p><p>这个方案其实是可以解决日常工作中的需求的，但从技术方案的探讨上来说，可能还有一些可以完善的地方。<strong>比如，如果在第一步 setnx 执行成功后，在 expire() 命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题，所以如果要对其进行完善的话，可以使用 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。</strong></p><h2 id="基于-redis-的-setnx-、get-、getset-方法做分布式锁"><a href="#基于-redis-的-setnx-、get-、getset-方法做分布式锁" class="headerlink" title="基于 redis 的 setnx()、get()、getset()方法做分布式锁"></a>基于 redis 的 setnx()、get()、getset()方法做分布式锁</h2><p>这个方案的背景主要是在 setnx() 和 expire() 的方案上针对可能存在的死锁问题，做了一些优化。</p><h3 id="getset"><a href="#getset" class="headerlink" title="getset()"></a>getset()</h3><p>这个命令主要有两个参数 getset(key，newValue)。该方法是原子的，对 key 设置 newValue 这个值，并且返回 key 原来的旧值。假设 key 原来是不存在的，那么多次执行这个命令，会出现下边的效果：</p><ol><li>getset(key, “value1”) 返回 null 此时 key 的值会被设置为 value1</li><li>getset(key, “value2”) 返回 value1 此时 key 的值会被设置为 value2</li><li>依次类推！</li></ol><h3 id="使用步骤-1"><a href="#使用步骤-1" class="headerlink" title="使用步骤"></a>使用步骤</h3><ol><li>setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。</li><li>get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。</li><li>计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。</li><li>判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。</li><li>在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。</li></ol><h1 id="基于-ZooKeeper-做分布式锁"><a href="#基于-ZooKeeper-做分布式锁" class="headerlink" title="基于 ZooKeeper 做分布式锁"></a>基于 ZooKeeper 做分布式锁</h1><h2 id="zookeeper-锁相关基础知识"><a href="#zookeeper-锁相关基础知识" class="headerlink" title="zookeeper 锁相关基础知识"></a>zookeeper 锁相关基础知识</h2><ul><li>zk一般由多个节点构成（单数），采用zab一致性协议。因此可以将zk看成一个单点结构，对其修改数据其内部自动将所有节点数据进行修改后才提供查询服务</li><li>zk的数据以目录树的形式，每个目录称为znode，znode中可存储数据（一般不超过1M），还可以在其中增加子节点</li><li>子节点有三种类型。序列化节点，每在该节点下增加一个节点自动给该节点的名称上自增。一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。最后就是普通节点。</li><li>Watch 机制，client 可以监控每个节点的变化，当产生变化会给 client 产生一个事件。</li></ul><h2 id="zk基本锁"><a href="#zk基本锁" class="headerlink" title="zk基本锁"></a>zk基本锁</h2><ul><li>原理：利用临时节点与 watch 机制。每个锁占用一个普通节点 /lock，当需要获取锁时在 /lock 目录下创建一个临时节点，创建成功则表示获取锁成功，失败则 watch/lock 节点，有删除操作后再去争锁。临时节点好处在于当进程挂掉后能自动上锁的节点自动删除即取消锁。</li><li>缺点：所有取锁失败的进程都监听父节点，很容易发生羊群效应，即当释放锁后所有等待进程一起来创建节点，并发量很大。</li></ul><h2 id="zk-锁优化"><a href="#zk-锁优化" class="headerlink" title="zk 锁优化"></a>zk 锁优化</h2><ul><li>原理：上锁改为创建临时有序节点，每个上锁的节点均能创建节点成功，只是其序号不同。只有序号最小的可以拥有锁，如果这个节点序号不是最小的则 watch 序号比本身小的前一个节点 (公平锁)。</li><li>步骤：</li><li>在 /lock 节点下创建一个有序临时节点 (EPHEMERAL_SEQUENTIAL)。</li><li>判断创建的节点序号是否最小，如果是最小则获取锁成功。不是则取锁失败，然后 watch 序号比本身小的前一个节点。</li><li>当取锁失败，设置 watch 后则等待 watch 事件到来后，再次判断是否序号最小。</li><li>取锁成功则执行代码，最后释放锁（删除该节点）。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;分布式锁&quot;&gt;&lt;a href=&quot;#分布式锁&quot; class=&quot;headerlink&quot; title=&quot;分布式锁&quot;&gt;&lt;/a&gt;分布式锁&lt;/h1&gt;&lt;h2 id=&quot;什么是锁&quot;&gt;&lt;a href=&quot;#什么是锁&quot; class=&quot;headerlink&quot; title=&quot;什么是锁&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>04.MySQL索引原理及慢查询优化</title>
    <link href="https://leslieaibin.github.io/2021/09/10/MySQL/04.MySQL%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%8F%8A%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
    <id>https://leslieaibin.github.io/2021/09/10/MySQL/04.MySQL%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%8F%8A%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</id>
    <published>2021-09-10T12:17:42.000Z</published>
    <updated>2021-09-11T02:30:25.218Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>MySQL凭借着出色的性能、低廉的成本、丰富的资源，已经成为绝大多数互联网公司的首选关系型数据库。虽然性能出色，但所谓“好马配好鞍”，如何能够更好的使用它，已经成为开发工程师的必修课，我们经常会从职位描述上看到诸如“精通MySQL”、“SQL语句优化”、“了解数据库原理”等要求。我们知道一般的应用系统，读写比例在10:1左右，而且插入操作和一般的更新操作很少出现性能问题，遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，所以查询语句的优化显然是重中之重。背景</p><h2 id="MySQL索引原理"><a href="#MySQL索引原理" class="headerlink" title="MySQL索引原理"></a>MySQL索引原理</h2><h3 id="索引目的"><a href="#索引目的" class="headerlink" title="索引目的"></a>索引目的</h3><p>索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？</p><h3 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a>索引原理</h3><p>除了词典，生活中随处可见索引的例子，如火车站的车次表、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。</p><p>数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&gt;、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。</p><h3 id="磁盘IO与预读"><a href="#磁盘IO与预读" class="headerlink" title="磁盘IO与预读"></a>磁盘IO与预读</h3><p>前面提到了访问磁盘，那么这里先介绍下磁盘IO和预读，磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分，寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。那么访问一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17 = 9ms左右，听起来还挺不错的，但要知道一台500 -MIPS的机器每秒可以执行5亿条指令，因为指令依靠的是电的性质，换句话说执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒的时间，显然是个灾难。下图是计算机硬件延迟的对比图，供大家参考：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/7f46a0a4.png" alt="various-system-software-hardware-latencies"></p><p>考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。</p><h3 id="索引的数据结构"><a href="#索引的数据结构" class="headerlink" title="索引的数据结构"></a>索引的数据结构</h3><p>前面讲了生活中索引的例子，索引的基本原理，数据库的复杂性，又讲了操作系统的相关知识，目的就是让大家了解，任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，我们现在总结一下，我们需要这种数据结构能够做些什么，其实很简单，那就是：每次查找数据时把磁盘IO次数控制在一个很小的数量级，最好是常数数量级。那么我们就想到如果一个高度可控的多路搜索树是否能满足需求呢？就这样，b+树应运而生。</p><p><strong>详解B+树</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/7af22798.jpg" alt="b+树"></p><p>如上图，是一颗b+树，关于b+树的定义可以参见<a href="http://zh.wikipedia.org/wiki/B%2B%E6%A0%91">B+树</a>，这里只说一些重点，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。</p><h4 id="b-树的查找过程"><a href="#b-树的查找过程" class="headerlink" title="b+树的查找过程"></a>b+树的查找过程</h4><p>如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。</p><h4 id="b-树性质"><a href="#b-树性质" class="headerlink" title="b+树性质"></a>b+树性质</h4><p>1.通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。</p><p>2.当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。</p><h2 id="慢查询优化"><a href="#慢查询优化" class="headerlink" title="慢查询优化"></a>慢查询优化</h2><p>关于MySQL索引原理是比较枯燥的东西，大家只需要有一个感性的认识，并不需要理解得非常透彻和深入。我们回头来看看一开始我们说的慢查询，了解完索引原理之后，大家是不是有什么想法呢？先总结一下索引的几大基本原则：</p><h3 id="建索引的几大原则："><a href="#建索引的几大原则：" class="headerlink" title="建索引的几大原则："></a>建索引的几大原则：</h3><ul><li><p>最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p></li><li><p>=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。</p></li><li><p>尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。</p></li><li><p>索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。</p></li><li><p>尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可</p></li></ul><h2 id="回到开始的慢查询"><a href="#回到开始的慢查询" class="headerlink" title="回到开始的慢查询"></a>回到开始的慢查询</h2><p>根据最左匹配原则，最开始的sql语句的索引应该是status、operator_id、type、operate_time的联合索引；其中status、operator_id、type的顺序可以颠倒，所以我才会说，把这个表的所有相关查询都找到，会综合分析；比如还有如下查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from task where status &#x3D; 0 and type &#x3D; 12 limit 10;</span><br><span class="line">select count(*) from task where status &#x3D; 0 ;</span><br></pre></td></tr></table></figure><p>那么索引建立成(status,type,operator_id,operate_time)就是非常正确的，因为可以覆盖到所有情况。这个就是利用了索引的最左匹配的原则</p><h3 id="查询优化神器-explain命令"><a href="#查询优化神器-explain命令" class="headerlink" title="查询优化神器 - explain命令"></a>查询优化神器 - explain命令</h3><p>关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网<a href="http://dev.mysql.com/doc/refman/5.5/en/explain-output.html">explain-output</a>，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。</p><h3 id="慢查询优化基本步骤"><a href="#慢查询优化基本步骤" class="headerlink" title="慢查询优化基本步骤"></a>慢查询优化基本步骤</h3><p>0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE</p><p>1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高</p><p>2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）</p><p>3.order by limit 形式的sql语句让排序的表优先查</p><p>4.了解业务方使用场景</p><p>5.加索引时参照建索引的几大原则</p><p>6.观察结果，不符合预期继续从0分析</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;MySQL凭借着出色的性能、低廉的成本、丰富的资源，已经成为绝大多数互联网公司的首选关系型数据库。虽然性能出色，但所谓“好马配好鞍”，如何能</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>03.一条SQL查询语句如何执行</title>
    <link href="https://leslieaibin.github.io/2021/09/09/MySQL/03.MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/"/>
    <id>https://leslieaibin.github.io/2021/09/09/MySQL/03.MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/</id>
    <published>2021-09-09T12:17:42.000Z</published>
    <updated>2021-09-11T02:30:12.521Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一条SQL查询语句如何执行"><a href="#一条SQL查询语句如何执行" class="headerlink" title="一条SQL查询语句如何执行"></a>一条SQL查询语句如何执行</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210910095617441.png" alt="image-20210910095617441"></p><p>MySQL可以分为Server层和存储引擎层两部分</p><p>Server层包括 <strong>连接器、查询缓存、分析器、优化器、执行器</strong>等，涵盖了MySQL的大多数核心功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程，触发器，视图等。</p><p>而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎InnoDB，它从MySQL5.5.5版本开始成为默认存储引擎。</p><p>也就是说，你执行create table建表的时候，如果不执行搜索引擎，默认的是innodb，不过，你也可以通过执行存储引擎的类型来选择别的引擎，比如在create table 语句中使用 engine=memory，来执行使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同。</p><h2 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h2><p>第一步，你会先连接到这数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接，获取权限，位置和管理连接。连接命令一般是这么写的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h$ip -P$port -u$user -p</span><br></pre></td></tr></table></figure><p>输完命令后，你就需要在交互对话里面输入密码。虽然密码也可以直接在-p后面卸载命令行中，但这样可能会导致你的密码泄露。</p><ul><li>如果用户名或密码不对，你就会收到一个”Access denied for user的错误，然后客户端程序结束执行。</li><li>如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。</li></ul><p>这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。<br>连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist令中看到它。文本中这个图是 show processlist的结果，其中的 Command列显示为Sleep的这一行，就表示现在系统里面有一个空闲连接</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210910103606002.png" alt="image-20210910103606002"></p><p>客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait timeout控制的，默认值是8小时。</p><p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒：Lost connection to MySQL server during query.这时候如果你要继续，就需要重连，然后再执行请求了数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断连接，下次查询再重新建立一个</p><h2 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h2><p>连接建立完成后，你就可以执行 select语句了执行逻辑就会来到第二步：查询缓存MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key- -value对的形式，被直接缓存在内存中。key是查询的语句， value是查询的结果。如果你的查询能够直接在这个缓存中找到key.那么这个 value就会被直接返回给客户端。<br>如果语句不在查询缓存中，就会继续后面的执行阶段执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存， MySQ不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p><p>但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。<br>查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会史新一次。</p><p>比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。<br>好在MSQL也提供了这种“按需使用”的方式。你可以将参数query cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL CACHE显式指定，像下面这个语句一样：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select SQL_CACHE from T where ID&#x3D;10：</span><br></pre></td></tr></table></figure><p><strong>需要注意的是， MySQL8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。</strong></p><h2 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h2><p>如果没有命中查询缓存，就要开始真正执行语句了。首先，MQL需要知道你要做什么，因此需要对SQL语句做解析。</p><p>分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句， MySQL需要识别出里面的字符串分别是什么，代表什么</p><p>MySQL从你输入的”select这个关键字识别出来，这是一个查询语句。它也要把字符串“T识别成“名T，把字符串识别成列D做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MSQL语法</p><p>如果你的语句不对，就会收到You have an error in your SQL syntax的错误提醒，比如下面这个语句 select少打了开头的字母s”。</p><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>经过了分析器，MySQL就知道你要做什么，在开始执行之前，要经过优化器的处理</p><p>优化器是在表里面有多个索引的时候，决定使用哪个索引，或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * <span class="function">from t1 join t2 <span class="title">using</span><span class="params">(ID)</span> where t1.c</span>=<span class="number">10</span> and t2.d = <span class="number">20</span>;</span><br></pre></td></tr></table></figure><ul><li>既可以先从表t1里面取出 c = 10的记录的ID值，在根据ID关联到表t2，再判断t2里面d的值是否等于20</li><li>也可以先从表t2里面取出d=20的记录的id值，在根据ID值关联到t1，在判断t1里面c的值是否等于10</li></ul><p>这两种执行方法的逻辑结果是一样的，但执行的效率会有不同，而优化器的作用是决定选择使用哪个方案</p><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h2><p>MSQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。</p><p>开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from where ID=<span class="number">10</span>;</span><br></pre></td></tr></table></figure><p>如果有权限，就打开表继续执行，打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口</p><p>比如我们这个例子中的表T中，D字段没有索引那么执行器的执行流程是这样的：</p><ul><li>调用InnoDB引擎接口取这个表的第一行，判断D值是不是10，如果不是则跳过，如果是则将这行存在结果集中</li><li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li><li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端至此，这个语句就执行完成了。</li></ul><p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的你会在数据库的慢查询日志中看到一个 rows examined的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。</p><p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rowsexamined并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一条SQL查询语句如何执行&quot;&gt;&lt;a href=&quot;#一条SQL查询语句如何执行&quot; class=&quot;headerlink&quot; title=&quot;一条SQL查询语句如何执行&quot;&gt;&lt;/a&gt;一条SQL查询语句如何执行&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http://test-1874</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>4.HashMap实现原理</title>
    <link href="https://leslieaibin.github.io/2021/09/05/Collection/4.HashMap%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/"/>
    <id>https://leslieaibin.github.io/2021/09/05/Collection/4.HashMap%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/</id>
    <published>2021-09-04T16:15:42.000Z</published>
    <updated>2021-09-24T03:46:08.895Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HashMap的实现原理"><a href="#HashMap的实现原理" class="headerlink" title="HashMap的实现原理"></a>HashMap的实现原理</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>HashMap是Java中对Map接口的实现类，是最常用的实现类中之一。主要有以下几个特性：</p><ul><li>HashMap中的key 和 value 都允许为null， 但最多智能拥有一个null的key</li><li>HashMap不保证顺序性</li><li>HashMap非线性安全</li></ul><p>HashMap的数据结构：</p><p>HashMap内部是以数组+链表的方式存储的数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210904213431065.png" alt="image-20210904213431065"></p><p>HashMap的数组中，每个元素称之为“<strong>桶</strong>”。需要注意的是，这个“桶”并不等同于“键值对（Entity）”。至于它是什么请往下看。</p><p><strong>初始化</strong></p><p>HashMap在初始化时会创建一个Entity的数组。其个数为<strong>16</strong>。其源码类似下面的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    V value;</span><br><span class="line">    Entry&lt;K,V&gt; next;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">    ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中key和value不必多说，不过它还包含了一个next属性，这说明它可以组织成一个链表结构。</p><p><strong>put()方法</strong></p><p>put方法被调用时，HashMap会根据key计算出对应的hashcode，然后根据hashcode确定该Entity应该存放在数组的哪个位置（应该放在哪个桶里）。</p><p>这种设定有一个问题：实际引用中有可能会发生hash碰撞（即两个数据虽然内容不同，但其hashcode有可能是相同的）！因此，HashMap如果发现hashcode已经存在，则会对key进行euqals对比：</p><ul><li>equals结果是true，则认为确实是同一个key，然后将新的value覆盖旧的value（此时put方法将会返回旧value值）。</li><li>equals结果是false，则认为是hash碰撞，此时会将之前的Entity作为新Entity的next，此时形成一个链表，新Entity则处在链表的首位。</li></ul><p>因此，所谓的<strong>“桶”就是数组每个位置放置的“链表”</strong>。</p><p><strong>get()方法</strong></p><p>如果理解了上述的put逻辑，则get方法就很容易理解。主要有以下几个步骤：</p><ul><li>根据key计算hashcode，然后得出其数组下标（位置）。</li><li>去对应位置获取桶（链表）。</li><li>从头到尾遍历链表的每一个Entity，通过equals方法找到对应的Entity。</li><li></li></ul><p>上述的过程中有一个点未详细说明：<strong>如何根据key的hashcode计算出对应的数组坐标呢？</strong></p><p>HashMap的内部实现用了一个非常巧妙的方法。HashMap的初始容量被定为<strong>16</strong>，且每次增长都是2的倍数。这样设计的目的是要<strong>保证存入map中的元素尽量分散</strong>，尽量避免出现桶中出现链表，这可以有效降低数据查询时的处理速度。</p><p>key是这么一步步转化成数组下标的：</p><p>第一步：Object Key –&gt; int hash</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">static final int hash(Object key) &#123;</span><br><span class="line">    int h;</span><br><span class="line">    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果key是null，则其hash为0；否则便将 <strong>hashcode</strong> 与 <strong>hashcode的高位</strong> 做 <strong>异或运算</strong>。这是为了尽量避免“低位不变，高位变化”时造成的hash冲突。</p><p>第二步：hash –&gt; i</p><p>上一步计算出的hash是个长度较长的二进制数字，而通常情况下HashMap的底层数组长度（length）较小，因此如果我们进行 <strong>hash % length</strong> 计算，则一定能得到一个下标，且相对比较分散。而在源码中使用了性能更高的算法：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">i = (length - 1) &amp; hash</span><br></pre></td></tr></table></figure><p>这个公式对hash和length进行了<strong>按位与</strong>运算，等价于<strong>取余。</strong></p><h2 id="为什么底层数组的长度总要是2的n次方呢"><a href="#为什么底层数组的长度总要是2的n次方呢" class="headerlink" title="为什么底层数组的长度总要是2的n次方呢"></a>为什么底层数组的长度总要是2的n次方呢</h2><p>这时就能说清楚另外一件事情：<strong>为什么底层数组的长度总要是2的n次方呢？</strong></p><p>下图是个示例：</p><p><img src="https://pic2.zhimg.com/80/v2-417a388c7b8ae370fc1ede9e854e54a5_720w.jpg" alt="img"></p><p>可以看到，如果数组长度是2的n次方，那么<strong>length-1</strong>的二进制表示中，一定所有位都是<strong>1</strong>，此时取&amp;运算则可以完整保留hash响应位置的二进制数据。相反的，如果数组长度不是2的n次方，则出现hash碰撞的可能性大大提高。</p><h2 id="JDK8中HashMap的改进"><a href="#JDK8中HashMap的改进" class="headerlink" title="JDK8中HashMap的改进"></a>JDK8中HashMap的改进</h2><p>上文曾提到“<strong>桶</strong>”的概念。其实这个概念在JDK8中才是真正有意义的。因为JDK7中，原始数组的每个元素都一定是个链表（链表的节点一个或者多个），而到了JDK8的时候就不一定是链表了。</p><p>JDK8对存储方式进行改进的原因很简单：如果在一个HashMap中，有很多Key发生了碰撞的时候，就会产生一个超级长的链表。那么在数据查询的时候就会花费O(n)的时间。所以，JDK8中HashMap采用了“<strong>桶</strong>+<strong>链表/红黑树</strong>”数据存储方式：如果链表的长度大于等于8时，其内部便会将链表转化为红黑树的结构。红黑树的查询时间是O(log n)。</p><p>由于数据存储方式发生变化，因此列表扩容时也会发生一些变化。具体细节请看下一篇HashMap的扩容。</p><h1 id="扩容机制"><a href="#扩容机制" class="headerlink" title="扩容机制"></a>扩容机制</h1><p>为了方便说明，这里明确几个名词：</p><ul><li>capacity 即容量，默认16。</li><li>loadFactor 加载因子，默认是0.75</li><li>threshold 阈值。阈值=容量*加载因子。默认12。当元素数量超过阈值时便会触发扩容。</li></ul><p><strong>什么时候触发扩容？</strong></p><p>一般情况下，<strong>当元素数量超过阈值时</strong>便会触发扩容。每次扩容的容量都是之前容量的2倍。</p><p>HashMap的容量是有上限的，必须小于<strong>1&lt;&lt;30</strong>，即1073741824。如果容量超出了这个数，则不再增长，且阈值会被设置为<strong>Integer.MAX_VALUE</strong>（2^31^  - 1) ，即永远不会超出阈值了)。</p><h2 id="JDK7中的扩容机制"><a href="#JDK7中的扩容机制" class="headerlink" title="JDK7中的扩容机制"></a><strong>JDK7中的扩容机制</strong></h2><p>JDK7的扩容机制相对简单，有以下特性：</p><ul><li>空参数的构造函数：以默认容量、默认负载因子、默认阈值初始化数组。内部数组是<strong>空数组</strong>。</li><li>有参构造函数：根据参数确定容量、负载因子、阈值等。</li><li>第一次put时会初始化数组，其容量变为<strong>不小于指定容量的2的幂数</strong>。然后根据负载因子确定阈值。</li><li>如果不是第一次扩容，则 <img src="https://www.zhihu.com/equation?tex=%E6%96%B0%E5%AE%B9%E9%87%8F=%E6%97%A7%E5%AE%B9%E9%87%8F%5Ctimes2" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=%E6%96%B0%E9%98%88%E5%80%BC=%E6%96%B0%E5%AE%B9%E9%87%8F%5Ctimes%E8%B4%9F%E8%BD%BD%E5%9B%A0%E5%AD%90" alt="[公式]"> 。</li></ul><h2 id="JDK8的扩容机制"><a href="#JDK8的扩容机制" class="headerlink" title="JDK8的扩容机制"></a><strong>JDK8的扩容机制</strong></h2><p>JDK8的扩容做了许多调整。</p><p>HashMap的容量变化通常存在以下几种情况：</p><ol><li>空参数的构造函数：实例化的HashMap默认内部数组是null，即没有实例化。第一次调用put方法时，则会开始第一次初始化扩容，长度为16。</li><li>有参构造函数：用于指定容量。会根据指定的正整数找到<strong>不小于指定容量的2的幂数</strong>，将这个数设置赋值给<strong>阈值</strong>（threshold）。第一次调用put方法时，会将阈值赋值给容量，然后让 <img src="https://www.zhihu.com/equation?tex=%E9%98%88%E5%80%BC=%E5%AE%B9%E9%87%8F%5Ctimes%E8%B4%9F%E8%BD%BD%E5%9B%A0%E5%AD%90" alt="[公式]"> 。（因此并不是我们手动指定了容量就一定不会触发扩容，超过阈值后一样会扩容！！）</li><li>如果不是第一次扩容，则容量变为原来的2倍，阈值也变为原来的2倍。<em>（容量和阈值都变为原来的2倍时，负载因子还是不变）</em></li></ol><p>此外还有几个细节需要注意：</p><ul><li>首次put时，先会触发扩容（算是初始化），然后存入数据，然后判断是否需要扩容；</li><li>不是首次put，则不再初始化，直接存入数据，然后判断是否需要扩容；</li></ul><h2 id="JDK7的元素迁移"><a href="#JDK7的元素迁移" class="headerlink" title="JDK7的元素迁移"></a><strong>JDK7的元素迁移</strong></h2><p>JDK7中，HashMap的内部数据保存的都是链表。因此逻辑相对简单：在准备好新的数组后，map会遍历数组的每个“桶”，然后遍历桶中的每个Entity，重新计算其hash值（也有可能不计算），找到新数组中的对应位置，以<strong>头插法</strong>插入新的链表。</p><p>这里有几个注意点：</p><ul><li>是否要重新计算hash值的条件这里不深入讨论，读者可自行查阅源码。</li><li>因为是头插法，因此新旧链表的元素位置会发生转置现象。</li><li>元素迁移的过程中在多线程情境下有可能会触发死循环（无限进行链表反转）。</li></ul><h2 id="JDK8的元素迁移"><a href="#JDK8的元素迁移" class="headerlink" title="JDK8的元素迁移"></a><strong>JDK8的元素迁移</strong></h2><p>JDK8则因为巧妙的设计，性能有了大大的提升：由于数组的容量是以2的幂次方扩容的，那么一个Entity在扩容时，新的位置要么在<strong>原位置</strong>，要么在<strong>原长度+原位置</strong>的位置。原因如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-da2df9ad67181daa328bb09515c1e1c8_720w.png" alt="img"></p><p>数组长度变为原来的2倍，表现在二进制上就是<strong>多了一个高位参与数组下标确定</strong>。此时，一个元素通过hash转换坐标的方法计算后，恰好出现一个现象：最高位是0则坐标不变，最高位是1则坐标变为“10000+原坐标”，即“原长度+原坐标”。如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-ac1017eb1b83ce5505bfc032ffbcc29a_720w.jpg" alt="img"></p><p>因此，在扩容时，不需要重新计算元素的hash了，只需要判断最高位是1还是0就好了。</p><p>JDK8的HashMap还有以下细节：</p><ul><li>JDK8在迁移元素时是正序的，不会出现链表转置的发生。</li><li>如果某个桶内的元素超过8个，则会将链表转化成红黑树，加快数据查询效率。</li></ul><h2 id="HashMap扩容死循环问题"><a href="#HashMap扩容死循环问题" class="headerlink" title="HashMap扩容死循环问题"></a>HashMap扩容死循环问题</h2><ul><li><p>当插入一个新的键值对时，会根据key对HashMap底层数组长度取模，得到键值对存放的数组下标，然后调用addEntry() 函数把这个键值对插入到这个下标所在的链表中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(<span class="keyword">int</span> hash, K key , V value, <span class="keyword">int</span> bucketIndex)</span></span>&#123;</span><br><span class="line">    Entry&lt;K, V&gt; e = table[bucketIndex];</span><br><span class="line">    table[bucketIndex] = <span class="keyword">new</span> Entry&lt;&gt;(hash, key , value, e);</span><br><span class="line">    <span class="keyword">if</span>(size++ &gt;= threshold)<span class="comment">// 如果键值对个数超过hashmap当前的阈值</span></span><br><span class="line">        resize(<span class="number">2</span> * table.length)<span class="comment">// 调整resize()函数进行扩容</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>在这个addEntry() 函数中，会判断键值对个数是否超过了HashMap当前容量的阈值，如果超过了，则说明需要扩容，接下来就调用resize() 函数扩容为原来的两倍</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">resize</span><span class="params">(<span class="keyword">int</span> newCapacity)</span> </span>&#123;</span><br><span class="line">    Entry[] oldTable = table;</span><br><span class="line">    <span class="keyword">int</span> oldCapacity = oldTable.length;</span><br><span class="line">    <span class="keyword">if</span> (oldCapacity == MAXIMUM_CAPACITY) &#123;</span><br><span class="line">           threshold = Integer.MAX_VALUE;</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">     &#125;</span><br><span class="line">    Entry[] newTable = <span class="keyword">new</span> Entry[newCapacity];  <span class="comment">// 创建一个新数组</span></span><br><span class="line">    transfer(newTable);        <span class="comment">// 把老数组中的所有键值对都拷贝到新数组中</span></span><br><span class="line">    table = newTable;        <span class="comment">// 修改老数组的指向，把老数组指向新数组，完成扩容</span></span><br><span class="line">    threshold = (<span class="keyword">int</span>)(newCapacity * loadFactor);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>resize()函数会先创建一个新数组，然后调用 transfer() 函数把老数组中的所有键值对都拷贝到新数组中，最后修改老数组的指向，把老数组指向新数组，完成扩容。</p><p>扩容过程中会出现循环链表的情况就是多个线程在执行 transfer() 函数导致的，下面看看 transfer() 函数的代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Entry[] newTable)</span> </span>&#123;</span><br><span class="line">    Entry[] src = table;        <span class="comment">// 老数组</span></span><br><span class="line">    <span class="keyword">int</span> newCapacity = newTable.length;     <span class="comment">// 新数组的长度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; src.length; j++) <span class="comment">// 遍历老数组，把老数组中所有键值对拷贝到新数组</span></span><br><span class="line">        Entry&lt;K,V&gt; e = src[j];    <span class="comment">// 记录下老数组第 j 个链表，接下来会链表上的键值对都拷贝到新数组</span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;        <span class="comment">// 如果链表不为空才需要拷贝</span></span><br><span class="line">            src[j] = <span class="keyword">null</span>;        <span class="comment">// 先老数组第j个链表置为空链表</span></span><br><span class="line">            <span class="keyword">do</span> &#123;                <span class="comment">// 循环遍历刚才记录下来的链表，把所有键值对都采用头插法插入到新数组对应链表</span></span><br><span class="line">                Entry&lt;K,V&gt; next = e.next;        <span class="comment">// 记录下当前结点的下个结点</span></span><br><span class="line">                <span class="keyword">int</span> i = indexFor(e.hash, newCapacity);    <span class="comment">// 求出该键值对在新数组的下标,即该键值对应该被插入到新数组第几个链表</span></span><br><span class="line">                e.next = newTable[i];    <span class="comment">// 把结点的next指针指向新数组的第i个链表头结点</span></span><br><span class="line">                newTable[i] = e;    <span class="comment">// 新数组第i个链表的头结点前移，指向当前结点</span></span><br><span class="line">                e = next;        <span class="comment">// 把指向当前结点的指针后移</span></span><br><span class="line">            &#125; <span class="keyword">while</span> (e != <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>其中最关键的就是其中的 do while()循环，这里面就是会发生循环链表的代码。</p></li></ul><p>现在先走一遍正常扩容的流程,假设有下面这个HashMap, 假设数组大小为2</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210822148-740596617.png" alt="img"></p><p>现在需要对它进行扩容，扩容后数组大小为原来的两倍，创建一个大小为4的数组</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210822686-391022651.png" alt="img"></p><p>假设a、b两个数扩容后刚好又hash冲突了，即又在同一个链表中，所在下标为3；c在下标为1的链表中。下面开始扩容。</p><p>e指针指向了老数组的第1个链表</p><h3 id="执行上面的do-while循环，第一轮循环："><a href="#执行上面的do-while循环，第一轮循环：" class="headerlink" title="执行上面的do while循环，第一轮循环："></a>执行上面的do while循环，第一轮循环：</h3><p><a href="https://img2020.cnblogs.com/blog/1456655/202012/1456655-20201211210823926-116268729.png"><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210823926-116268729.png" alt="img"></a></p><h3 id="第二轮循环："><a href="#第二轮循环：" class="headerlink" title="第二轮循环："></a>第二轮循环：</h3><h3 id=""><a href="#" class="headerlink" title=""></a><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20210820225941991-619872774.png" alt="img"></h3><h3 id="第三轮也是最后一轮循环，前面已经假设结点-c-将在新数组中的第二个链表"><a href="#第三轮也是最后一轮循环，前面已经假设结点-c-将在新数组中的第二个链表" class="headerlink" title="第三轮也是最后一轮循环，前面已经假设结点 c 将在新数组中的第二个链表"></a>第三轮也是最后一轮循环，前面已经假设结点 c 将在新数组中的第二个链表</h3><p><a href="https://img2020.cnblogs.com/blog/1456655/202012/1456655-20201211210826842-959746908.png"><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210826842-959746908.png" alt="img"></a></p><p>至此，老数组中的健值对已全部拷贝到新数组中</p><h3 id="多线程环境中扩容"><a href="#多线程环境中扩容" class="headerlink" title="多线程环境中扩容"></a>多线程环境中扩容</h3><p>假设在第 二 次循环中的第二步（执行完e.next = newTable[i]；）后当前线程的时间片刚好用完了，当前线程被挂起，这时刚好又有一个线程 P2 也来执行扩容操作，它并不会从第二步开始执行，而是重新从第一步开始执行，加入新线程后的扩容图为</p><p><a href="https://img2020.cnblogs.com/blog/1456655/202012/1456655-20201211210829300-1877613427.png"><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210829300-1877613427.png" alt="img"></a></p><p>可以看到，线程2扩容之后的newTable中的单链表形成了一个环，后续执行get操作的时候，会触发死循环，引起CPU的100%问题。</p><h1 id="扩容后，元素是如何重新分布的"><a href="#扩容后，元素是如何重新分布的" class="headerlink" title="扩容后，元素是如何重新分布的"></a>扩容后，元素是如何重新分布的</h1><ul><li><p>HashMap的初始化是在插入第一个元素时调用resize() 完成的</p></li><li><p>不指定容量，默认容量为16</p></li><li><p>指定容量也不一定按照你的值来，会经过tableSizeFor转成不小于输入值的2的n次幂</p><p>tableSizeFor<code>转换成2的n次幂不是直接赋值给</code>capacity<code>，而是先将值暂时保存在</code>threshold<code>，见源码</code>457<code>，然后在put第一个元素resize时，婉转的传递给</code>newCap</p></li><li><p>put元素时，元素的位置取决于数组的长度和key的hash值按位与的结果 <code>i = (n - 1) &amp; hash</code></p></li><li><p>如果这里没有元素直接放在这里</p></li><li><p>如果有，判断是不是键冲突，如果一样就新值覆盖旧值</p></li><li><p>如果有且不是键冲突，则将其放在元素的next位置，判断元素长度是否大于8，大于8进行树化</p></li><li><p>只有当size大于了扩容阈值 <code>size &gt; threshold</code>， 才会触发扩容，扩容前，当前元素已经放好了</p></li><li><p>扩容时，容量和扩容阈值都翻倍，必须小于 1&lt;&lt;30</p></li><li><p>扩容时，元素在新表中的位置分情况</p></li><li><p>当元素只是孤家寡人即元素的next==null时，位置为e.hash &amp; (newCap - 1)</p></li><li><p>当元素有next节点时，该链表上的元素分两类</p><ul><li> e.hash &amp; oldCap = 0的，在新表中与旧表中的位置一样</li><li> e.hash &amp; oldCap != 0的，位置为旧表位置+旧表容量</li></ul></li><li><p>当前节点时树的话</p><ul><li>(e.hash &amp; bit) == 0 在新表中与旧表中的位置一样</li><li>(e.hash &amp; bit) != 0  位置为旧表位置+旧表容量</li><li>在新的newCap中，判断阶段如果节点数小于6进行树退化，重新树化</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;HashMap的实现原理&quot;&gt;&lt;a href=&quot;#HashMap的实现原理&quot; class=&quot;headerlink&quot; title=&quot;HashMap的实现原理&quot;&gt;&lt;/a&gt;HashMap的实现原理&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;</summary>
      
    
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/categories/Collection/"/>
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/tags/Collection/"/>
    
  </entry>
  
  <entry>
    <title>02.索引</title>
    <link href="https://leslieaibin.github.io/2021/09/04/MySQL/02.%E7%B4%A2%E5%BC%95/"/>
    <id>https://leslieaibin.github.io/2021/09/04/MySQL/02.%E7%B4%A2%E5%BC%95/</id>
    <published>2021-09-04T12:17:42.000Z</published>
    <updated>2021-09-04T08:47:40.314Z</updated>
    
    <content type="html"><![CDATA[<h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h2 id="什么是索引"><a href="#什么是索引" class="headerlink" title="什么是索引"></a>什么是索引</h2><p>索引是一个单独的，存储在磁盘上的数据结构，包含着对数据表里所有记录的引用指针，使用索引可以快速记录找出在某个或多个列中有一特定值的行，所有MySQL列数据都可以被索引，所有MySQL列类型都可以被索引，对相关列使用时提高查询操作速度的最佳途径。</p><p>索引是在存储引擎中实现的，因此，每种存储引擎的索引都不一定完全相同，并且每种存储引擎也不一定支持所有索引类型。MySQL中索引的存储类型有两种，即BTREE和HASH，具体和表的存储引擎相关。<strong>MyISAM和InnoDB存储引擎只支持BTREE索引；MEMORY/HEAP存储引擎可以支持HASH和BTREE索引。</strong></p><p>优点：</p><ul><li>通过创建唯一索引，可以保证数据库表中每一行数据的唯一性</li><li>可以大大加快数据的查询速度，这也是创建索引的主要原因</li><li>在实现数据的参考完整性方面，可以加速表和表之间的连接</li><li>在使用分组和排序子句进行数据查询时，也可以显著减少查询中分组和排序的时间。</li></ul><p>缺点：</p><ul><li>创建索引和维护索引需要耗费时间，并且随着数据量的增加所耗费的时间也会增加</li><li>索引需要占磁盘空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果有大量的索引，索引文件可能比数据文件更快达到最大文件尺寸</li><li>当对表中的数据进行增加、删除和修改的时候，索引也要动态地维护，这样就降低了数据的维护速度。</li></ul><h2 id="索引的分类"><a href="#索引的分类" class="headerlink" title="索引的分类"></a>索引的分类</h2><p>按数据结构分类可分为：<strong>B+tree索引、Hash索引、Full-text索引</strong>。</p><p>按物理存储分类可分为：<strong>聚簇索引、二级索引（辅助索引）</strong>。</p><p>按字段特性分类可分为：<strong>主键索引、普通索引、前缀索引</strong>。</p><p>按字段个数分类可分为：<strong>单列索引、联合索引（复合索引、组合索引）</strong>。</p><h3 id="按数据结构分类"><a href="#按数据结构分类" class="headerlink" title="按数据结构分类"></a>按数据结构分类</h3><p>MySQL索引按数据结构分类可分为：<strong>B+tree索引、Hash索引、Full-text索引</strong>。</p><table><thead><tr><th>-</th><th>InnoDB</th><th>MyISAM</th><th>Memory</th></tr></thead><tbody><tr><td>B+tree索引</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Hash索引</td><td>×</td><td>×</td><td>√</td></tr><tr><td>Full-text索引</td><td>√（MySQL5.6+）</td><td>√</td><td>×</td></tr></tbody></table><p><strong>B+tree</strong> 是MySQL中被存储引擎采用最多的索引类型。<strong>B+tree</strong> 中的 <code>B</code> 代表平衡（balance），而不是二叉（binary），因为 <strong>B+tree</strong> 是从最早的平衡二叉树演化而来的。下面展示B+tree数据结构与其他数据结构的对比。</p><h4 id="B-tree与B-tree的对比"><a href="#B-tree与B-tree的对比" class="headerlink" title="B+tree与B-tree的对比"></a><strong>B+tree与B-tree的对比</strong></h4><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037684393" alt="B-tree结构（图片来源于网络）"></p><p><strong>相对于B-tree，B+tree有以下两点不同：</strong></p><ul><li>B+tree 非叶子节点只存储键值信息， 数据记录都存放在叶子节点中。而B-tree的非叶子节点也存储数据。所以B+tree单个节点的数据量更小，在相同的磁盘I/O次数下，能查询更多的节点。</li><li>B+tree 所有叶子节点之间都采用<strong>双向链表</strong>连接。适合MySQL中常见的基于范围的顺序检索场景，而B-tree无法做到这一点。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037684392" alt="B+tree结构（图片来源于网络）"></p><h4 id="B-tree与红黑树的对比"><a href="#B-tree与红黑树的对比" class="headerlink" title="B+tree与红黑树的对比"></a>B+tree与红黑树的对比</h4><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037684042" alt="红黑树结构（图片来源于网络）"></p><p><strong>红黑树</strong>是一种<strong>弱平衡二叉查找树</strong>。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，<strong>红黑树确保没有一条路径会比其他路径长出两倍</strong>。</p><p>对于有N个叶子结点的 <strong>B+tree</strong>，其搜索复杂度为 <code>O(logdN)</code> ，其中 <strong>d</strong>(degree) 为 <strong>B+tree</strong> 的度，表示节点允许的最大子节点个数为<strong>d</strong>个，在实际应用当中，<strong>d</strong>值一般是大于100的，即使数据量达到千万级别时<strong>B+tree</strong>的高度依然维持在3-4左右，保证了3-4次磁盘I/O操作就能查询到目标数据。</p><p><strong>红黑树</strong>是二叉树，节点子节点个数为两个，意味着其搜索复杂度为 <code>O(logN)</code>，树的高度也会比 <strong>B+tree</strong> 高出不少，因此<strong>红黑树</strong>检索到目标数据所需经历的磁盘I/O次数更多。</p><h4 id="B-tree与Hash的对比"><a href="#B-tree与Hash的对比" class="headerlink" title="B+tree与Hash的对比"></a>B+tree与Hash的对比</h4><p>Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。虽然 Hash 索引效率高，但是 Hash 索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些。 Hash 索引仅仅能满足 <code>=</code> , <code>IN</code> 和 <code>&lt;=&gt;</code>(表示NULL安全的等价) 查询，不能使用范围查询。</p><p>由于 Hash 索引比较的是进行 Hash 运算之后的 Hash值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。</p><ul><li>Hash 索引无法适用数据的排序操作。</li><li>Hash 索引不能利用部分索引键查询</li><li>Hash 索引依然需要回表扫描。</li><li>Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。</li></ul><p><strong>由于范围查询是MySQL数据库查询中常见的场景，Hash表不适合做范围查询，它更适合做等值查询。另外Hash表还存在Hash函数选择和Hash值冲突等问题。因此，B+tree索引要比Hash表索引有更广的适用场景。</strong></p><h3 id="按照物理存储分类"><a href="#按照物理存储分类" class="headerlink" title="按照物理存储分类"></a>按照物理存储分类</h3><p>MySQL索引按叶子节点存储的是否为完整表数据分为：<strong>聚簇索引、二级索引（辅助索引）</strong>。全表数据存储在聚簇索引中，聚簇索引以外的其他索引叫做二级索引，也叫辅助索引。</p><h4 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h4><p>聚簇索引的每个叶子节点存储了一行完整的表数据，叶子节点间按id列递增连接，可以方便地进行顺序检索。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688814" alt="聚簇索引B+tree示意图（图片来源于网络）"><br>（图片来源于网络）</p><p>InnoDB表要求必须有聚簇索引，默认在主键字段上建立聚簇索引，在没有主键字段的情况下，表的第一个非空的唯一索引将被建立为聚簇索引，在前两者都没有的情况下，InnoDB将自动生成一个隐式的自增id列，并在此列上建立聚簇索引。</p><h5 id="以MyISAM为存储引擎的表不存在聚簇索引。"><a href="#以MyISAM为存储引擎的表不存在聚簇索引。" class="headerlink" title="以MyISAM为存储引擎的表不存在聚簇索引。"></a>以MyISAM为存储引擎的表不存在聚簇索引。</h5><p>MyISAM表中的主键索引和非主键索引的结构是一样的，索引的叶子节点不存储表数据，存放的是表数据的地址。所以，MyISAM表可以没有主键。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688815" alt="MyISAM索引B+tree示意图（图片来源于网络）"><br>（图片来源于网络）</p><p>MyISAM表的数据和索引是分开存储的。MyISAM表的主键索引和非主键索引的区别仅在于主键索引的B+tree上的key必须符合主键的限制，非主键索引B+tree上的key只要符合相应字段的特性就可以了。</p><h4 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h4><p>二级索引的叶子节点并不存储一行完整的表数据，而是存储了聚簇索引所在列的值。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688816" alt="二级索引B+tree示意图（图片来源于网络）"><br>（图片来源于网络）</p><h5 id="回表查询"><a href="#回表查询" class="headerlink" title="回表查询"></a>回表查询</h5><p>由于二级索引的叶子节点不存储完整的表数据，索引当通过二级索引查询到聚簇索引列值后，还需要回到聚簇索引也就是表数据本身进一步获取数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688817" alt="回表查询示意图（图片来源于网络）"><br>（图片来源于网络）</p><p>回表查询 需要额外的 <strong>B+tree</strong> 搜索过程，必然增大查询耗时。</p><p>需要注意的是，<strong>通过二级索引查询时，回表不是必须的过程</strong>，当<strong>SELECT的所有字段在单个二级索引中都能够找到</strong>时，就不需要回表，MySQL称此时的二级索引为<strong>覆盖索引</strong>或触发了<strong>索引覆盖</strong>。<br>可以用Explain命令查看SQL语句的执行计划，执行计划的Extra字段中若出现<strong>Using index</strong>，表示查询触发了<strong>索引覆盖</strong>。</p><h3 id="按字段特性分类"><a href="#按字段特性分类" class="headerlink" title="按字段特性分类"></a>按字段特性分类</h3><p>MySQL索引按字段特性分类可分为：<strong>主键索引、普通索引、前缀索引</strong>。</p><ul><li><strong>主键索引</strong></li></ul><p>建立在主键上的索引被称为<strong>主键索引</strong>，一张数据表只能有一个主键索引，索引列值不允许有空值，通常在创建表时一起创建。</p><ul><li><strong>唯一索引</strong></li></ul><p>建立在UNIQUE字段上的索引被称为<strong>唯一索引</strong>，一张表可以有多个唯一索引，索引列值允许为空，列值中出现多个空值不会发生重复冲突。</p><ul><li><strong>普通索引</strong></li></ul><p>建立在普通字段上的索引被称为<strong>普通索引</strong>。</p><ul><li><strong>前缀索引</strong></li></ul><p><strong>前缀索引</strong>是指对字符类型字段的前几个字符或对二进制类型字段的前几个bytes建立的索引，而不是在整个字段上建索引。前缀索引可以建立在类型为char、varchar、binary、varbinary的列上，可以大大减少索引占用的存储空间，也能提升索引的查询效率。</p><h3 id="按索引字段个数分类"><a href="#按索引字段个数分类" class="headerlink" title="按索引字段个数分类"></a>按索引字段个数分类</h3><p>MySQL索引按字段个数分类可分为：<strong>单列索引、联合索引（复合索引、组合索引）</strong>。</p><ul><li>单列索引</li></ul><p>建立在单个列上的索引被称为单列索引。</p><ul><li>联合索引（复合索引、组合索引）</li></ul><p>建立在多个列上的索引被称为联合索引，又叫复合索引、组合索引。</p><h2 id="聚簇索引和非聚簇索引有什么区别"><a href="#聚簇索引和非聚簇索引有什么区别" class="headerlink" title="聚簇索引和非聚簇索引有什么区别"></a>聚簇索引和非聚簇索引有什么区别</h2><p>在InnoDB存储引擎中，可以将B+树索引分为聚簇索引和辅助索引（非聚簇索引）。无论是何种索引，每个页的大小都为16KB，且不能更改。</p><p>聚簇索引是根据主键创建的一棵B+树，聚簇索引的叶子节点存放了表中的所有记录。辅助索引是根据索引键创建的一棵B+树，与聚簇索引不同的是，其叶子节点仅存放索引键值，以及该索引键值指向的主键。也就是说，如果通过辅助索引来查找数据，那么当找到辅助索引的叶子节点后，很有可能还需要根据主键值查找聚簇索引来得到数据，这种查找方式又被称为书签查找。因为辅助索引不包含行记录的所有数据，这就意味着每页可以存放更多的键值，因此其高度一般都要小于聚簇索引。</p><h2 id="索引的实现原理"><a href="#索引的实现原理" class="headerlink" title="索引的实现原理"></a>索引的实现原理</h2><p>在MySQL中，索引是在存储引擎层实现的，不同存储引擎对索引的实现方式是不同的，下面我们探讨一下MyISAM和InnoDB两个存储引擎的索引实现方式。</p><h3 id="MyISAM索引实现："><a href="#MyISAM索引实现：" class="headerlink" title="MyISAM索引实现："></a>MyISAM索引实现：</h3><p>MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址，MyISAM索引的原理图如下。这里假设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-1.png" alt="img"></p><p>如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示。同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-2.png" alt="img"></p><h3 id="InnoDB索引实现："><a href="#InnoDB索引实现：" class="headerlink" title="InnoDB索引实现："></a>InnoDB索引实现：</h3><p>虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。</p><p>第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。</p><p>下图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-3.png" alt="img"></p><p>第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。下图为定义在Col3上的一个辅助索引。这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-4.png" alt="img"></p><p>了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;索引&quot;&gt;&lt;a href=&quot;#索引&quot; class=&quot;headerlink&quot; title=&quot;索引&quot;&gt;&lt;/a&gt;索引&lt;/h1&gt;&lt;h2 id=&quot;什么是索引&quot;&gt;&lt;a href=&quot;#什么是索引&quot; class=&quot;headerlink&quot; title=&quot;什么是索引&quot;&gt;&lt;/a&gt;什么是索</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>01.事务的隔离性</title>
    <link href="https://leslieaibin.github.io/2021/09/04/MySQL/01.%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/"/>
    <id>https://leslieaibin.github.io/2021/09/04/MySQL/01.%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/</id>
    <published>2021-09-04T11:17:42.000Z</published>
    <updated>2021-09-04T08:47:01.699Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL事务"><a href="#MySQL事务" class="headerlink" title="MySQL事务"></a>MySQL事务</h1><p>MySQL事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你既需要删除人员的基本资料，也要删除该人员相关的信息，如信箱、文章等等，这样，这些数据库操作语句就构成一个事务</p><ul><li>在MySql中只有使用了Innodb数据库引擎的数据库或表才支持事务</li><li>事务处理可以用来维护数据库的完整性，保证成批的SQL语句要么全部执行，要么全部不执行</li><li>事务用来管理insert、update、delete语句</li></ul><p>一般来说，事务是必须满足四个条件（ACID）：</p><ul><li>原子性（Atomicity）：一个事务中的所有操作要么全部完成，要么全部不完成，不会在结束中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样</li><li>一致性（Consistency）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的数据必须完全符合所有的预设规则，这包含资料的精度，串联性以及后续数据库可以自发性地完成预定的工作</li><li>隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。</li><li>持久性（Durability）：事务处理结束后，对数据的修改是永久的，即使系统故障也不会丢失。</li></ul><p>在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。</p><p>简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。MySQL是一个支持多引擎的系统，但并不是所有引擎都支持事务。比如MySQL原生的MyISAM引擎不支持事务，这也是MyISAM被InnoDB取代的重要原因之一。</p><h1 id="隔离性和隔离级别"><a href="#隔离性和隔离级别" class="headerlink" title="隔离性和隔离级别"></a>隔离性和隔离级别</h1><p>当数据库上多个事务同时执行的时候就可能出现脏读（dirty read)、不可重复读（nonrepeatable read)、幻读（phantom read)等问题。</p><ul><li><p><strong>脏读（读取未提交数据）</strong></p><p>A事务读取B事务尚未提交的数据，此时如果B事务发生错误并执行回滚操作，那么A事务读取到的数据就是脏数据。就好像原本的数据比较干净、纯粹，此时由于B事务更改了它，这个数据变得不再纯粹。这个时候A事务立即读取了这个脏数据，但事务B良心发现，又用回滚把数据恢复成原来干净、纯粹的样子，而事务A却什么都不知道，最终结果就是事务A读取了此次的脏数据，称为脏读。</p></li><li><p><strong>不可重复读（前后多次读取，数据内容不一致）</strong></p><p>事务A在执行读取操作，由整个事务A比较大，前后读取同一条数据需要经历很长的时间 。而在事务A第一次读取数据，比如此时读取了小明的年龄为20岁，事务B执行更改操作，将小明的年龄更改为30岁，此时事务A第二次读取到小明的年龄时，发现其年龄是30岁，和之前的数据不一样了，也就是数据不重复了，系统不可以读取到重复的数据，成为不可重复读</p></li><li><p><strong>幻读（前后多次读取，数据总量不一致）</strong></p><p>事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，成为幻读。</p></li></ul><h2 id="SQL标准的事务隔离级别包括："><a href="#SQL标准的事务隔离级别包括：" class="headerlink" title="SQL标准的事务隔离级别包括："></a>SQL标准的事务隔离级别包括：</h2><ul><li>读未提交（read committed）： 一个事务还没提交，让做的变更就能被其他事务看到</li><li>读提交（read committed）：一个事务提交之后，它做的变更才会被其他事务看到</li><li>可重复读（repeatable read）： 一个事务执行过程中看到的数据，总跟这个事务启动时看到的数据是一值的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li><li>串行化：对于同一行记录，写会加“写锁”，读会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等待前一个事务执行完成，才能继续执行</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210904144955378.png" alt="image-20210904144955378"></p><ul><li>若隔离级别是”读未提交”：则V1的值就是2。 这时候事务B虽然还没有提交， 但是结果已经被A看到了。 因此， V2、 V3也都是2  </li><li>若隔离级别是”读提交”:  则V1是1， V2的值是2。 事务B的更新在提交后才能被A看到。 所以，V3的值也是2。  </li><li>若隔离级别是”可重复读”：则V1、 V2是1， V3是2。 之所以V2还是1， 遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的  </li><li>若隔离级别是”串行化”：则在事务B执行“将1改成2”的时候， 会被锁住。 直到事务A提交后，事务B才可以继续执行。 所以从A的角度看， V1、 V2值是1， V3的值是2。  </li></ul><table><thead><tr><th>隔离级别</th><th>脏读（Dirty Read）</th><th>不可重复读（NonRepeatable Read）</th><th>幻读（Phantom Read）</th></tr></thead><tbody><tr><td>未提交读（Read uncommitted）</td><td>可能</td><td>可能</td><td>可能</td></tr><tr><td>已提交读（Read committed）</td><td>不可能</td><td>可能</td><td>可能</td></tr><tr><td>可重复读（Repeatable read）</td><td>不可能</td><td>不可能</td><td>可能</td></tr><tr><td>可串行化（Serializable ）</td><td>不可能</td><td>不可能</td><td>不可能</td></tr></tbody></table><p>在实现上， 数据库里面会创建一个视图， 访问的时候以视图的逻辑结果为准。 在“可重复读”隔离级别下， 这个视图是在事务启动时创建的， 整个事务存在期间都用这个视图。 在“读提交”隔离级<br>别下， 这个视图是在每个SQL语句开始执行的时候创建的。 这里需要注意的是， “读未提交”隔离<br>级别下直接返回记录上的最新值， 没有视图概念； 而“串行化”隔离级别下直接用加锁的方式来避<br>免并行访问。</p><p>我们可以看到在不同的隔离级别下， 数据库行为是有所不同的。 Oracle数据库的默认隔离级别其实就是“读提交”， 因此对于一些从Oracle迁移到MySQL的应用， 为保证数据库隔离级别的一致，<br>你一定要记得将MySQL的隔离级别设置为“读提交”。配置的方式是， 将启动参数transaction-isolation的值设置成READ-COMMITTED。 你可以用show variables来查看当前的值。  </p><h1 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h1><p>在MySQL中， 实际上每条记录在更新的时候都会同时记录一条回滚操作。 记录上的最新值， 通<br>过回滚操作， 都可以得到前一个状态的值。假设一个值从1被按顺序改成了2、 3、 4， 在回滚日志里面就会有类似下面的记录。  </p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210904150457737.png" alt="image-20210904150457737"></p><p>当前值是4， 但是在查询这条记录的时候， 不同时刻启动的事务会有不同的read-view。 如图中看到的， 在视图A、 B、 C里面， 这一个记录的值分别是1、 2、 4， 同一条记录在系统中可以存在多<br>个版本， 就是数据库的多版本并发控制（MVCC） 。 对于read-view A， 要得到1， 就必须将当前<br>值依次执行图中所有的回滚操作得到。</p><p>同时你会发现， 即使现在有另外一个事务正在将4改成5， 这个事务跟read-view A、 B、 C对应的事务是不会冲突的。</p><p>你一定会问， 回滚日志总不能一直保留吧， 什么时候删除呢？ 答案是， 在不需要的时候才删除。也就是说， 系统会判断， 当没有事务再需要用到这些回滚日志时， 回滚日志会被删除。</p><p>什么时候才不需要了呢？ 就是当系统里没有比这个回滚日志更早的read-view的时候。</p><p>基于上面的说明， 我们来讨论一下为什么建议你尽量不要使用长事务  </p><p>长事务意味着系统里面会存在很老的事务视图。 由于这些事务随时可能访问数据库里面的任何数据， 所以这个事务提交之前， 数据库里面它可能用到的回滚记录都必须保留， 这就会导致大量占<br>用存储空间。</p><p>在MySQL 5.5及以前的版本， 回滚日志是跟数据字典一起放在ibdata文件里的， 即使长事务最终<br>提交， 回滚段被清理， 文件也不会变小。 我见过数据只有20GB， 而回滚段有200GB的库。 最终<br>只好为了清理回滚段， 重建整个库。</p><h3 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h3><p>如前面所述， 长事务有这些潜在风险， 我当然是建议你尽量避免。 其实很多时候业务开发同学并不是有意使用长事务， 通常是由于误用所致。 MySQL的事务启动方式有以下几种：</p><ul><li>显式启动事务语句， begin 或 start transaction。 配套的提交语句是commit， 回滚语句是<br>rollback。</li><li>set autocommit=0， 这个命令会将这个线程的自动提交关掉。 意味着如果你只执行一个<br>select语句， 这个事务就启动了， 而且并不会自动提交。 这个事务持续存在直到你主动执行commit 或 rollback 语句， 或者断开连接  </li></ul><p>有些客户端连接框架会默认连接成功后先执行一个set autocommit=0的命令。 这就导致接下来的<br>查询都在事务中， 如果是长连接， 就导致了意外的长事务。</p><p>因此， 我会建议你总是使用set autocommit=1, 通过显式语句的方式来启动事务。  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MySQL事务&quot;&gt;&lt;a href=&quot;#MySQL事务&quot; class=&quot;headerlink&quot; title=&quot;MySQL事务&quot;&gt;&lt;/a&gt;MySQL事务&lt;/h1&gt;&lt;p&gt;MySQL事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你既需</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Redis基础</title>
    <link href="https://leslieaibin.github.io/2021/09/01/Redis/Redis%E5%9F%BA%E7%A1%80%EF%BC%881%EF%BC%89/"/>
    <id>https://leslieaibin.github.io/2021/09/01/Redis/Redis%E5%9F%BA%E7%A1%80%EF%BC%881%EF%BC%89/</id>
    <published>2021-09-01T01:15:42.000Z</published>
    <updated>2021-09-01T08:37:09.270Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h2><p>Redis是一个使用C语言写成，凯源的高性能key-value非关系缓存数据库。他支持存储的value类型比较多，包括String(字符串)、list(集合)、set(集合)、zset(sorted-set–有序集合) 和 hash (哈希类型）。Redis都是基于缓存的，所以很快，每秒都可以处理10万读写操作，是一直性能最好的key-value DB。redis也可以实现数据写入磁盘中，保证了数据的安全不丢失，而且redis的操作时原子性的</p><h2 id="Redis-有那些优缺点"><a href="#Redis-有那些优缺点" class="headerlink" title="Redis 有那些优缺点"></a>Redis 有那些优缺点</h2><p>优点：</p><ul><li>读写性能优异，redis能读的速度是110000次/s，写的速度是810000次/s</li><li>支持数据持久化，支持AOF和RDB两种持久化方式</li><li>支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操控台合并的原子执行</li><li>数据结构丰富，除了支持String类型的value 外还支持hash、set、zset、list等数据结构</li><li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离</li></ul><p>缺点：</p><ul><li><p>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</p></li><li><p>Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。</p></li><li><p>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。</p></li><li><p>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。</p></li></ul><h2 id="使用redis-有哪些好处"><a href="#使用redis-有哪些好处" class="headerlink" title="使用redis 有哪些好处"></a>使用redis 有哪些好处</h2><ul><li>速度快，因为数据存在内存中，类似于HashMap，HashMap的优势在于查找和操作的时间复杂度低</li><li>支持丰富数据类型，支持String，list，set，zset， hash</li><li>支持事务，操作都是原子性</li><li>丰富的特性：可用于缓存，消息，按key设置过期时间，过期后自动删除</li></ul><h2 id="为什么要用-Redis-而不用-map-guava-做缓存"><a href="#为什么要用-Redis-而不用-map-guava-做缓存" class="headerlink" title="为什么要用 Redis 而不用 map/guava 做缓存?"></a>为什么要用 Redis 而不用 map/guava 做缓存?</h2><ul><li>缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。</li><li>使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。</li></ul><h2 id="Redis为什么这么快"><a href="#Redis为什么这么快" class="headerlink" title="Redis为什么这么快"></a>Redis为什么这么快</h2><ul><li>完全基于内存，绝大部分请求内存操作，影响速度的内存和网络速度，而非CPU</li><li>数据结构简单：Redis的数据结构是为自身专门量身打造的，而这些数据结构查找和操作的时间复杂度都是O(1)</li><li>避免上下文切换：因为单线程模型，因此就避免了不必要的上下文切换和多线程竞争，这就省去了多线程切换带来的时间和性能上的开销，而且单线程不会导致死锁</li><li>多路复用和非阻塞I/O：Redis 使用 I/O 多路复用功能来监听多个 socket 连接客户端，这样就可以使用一个线程来处理多个情况，从而减少线程切换带来的开销，同时也避免了 I/O 阻塞操作，从而大大地提高了 Redis 的性能</li><li>使用底层模型不同，他们之间底层实现方式以及客户端之间通信的应用协议不一样，Redis直接构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定时间去移动和请求</li></ul><h2 id="Redis有哪些数据类型"><a href="#Redis有哪些数据类型" class="headerlink" title="Redis有哪些数据类型"></a>Redis有哪些数据类型</h2><ul><li>Redis主要有5种数据类型，包括String、List、Set、Zset、Hash满足大部分使用要求</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210901105110111.png" alt="image-20210901105110111"></p><h2 id="Redis的应用场景"><a href="#Redis的应用场景" class="headerlink" title="Redis的应用场景"></a>Redis的应用场景</h2><ul><li><p>计数器</p><p>可以对String 进行自增自减运算，从而实现计数器功能。Redis这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量</p></li><li><p>缓存</p><p>将热点数据放到内存中，设置内存的最大使用两以及淘汰策略来保证缓存的命中率</p></li><li><p>会话缓存</p><p>可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。</p></li><li><p>全页缓存 FPC</p><p>除基本的会话token之外，Redis还提供很简便的FPC平台。以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。</p></li><li><p>查找表</p><p>例如DNS记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。</p></li><li><p>消息队列（发布/订阅功能）</p><p>List是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。</p></li><li><p>分布式锁实现</p><p>在分布式场景下，无法使用单机环境下的锁来多个节点上的进程进行同步。可以使用Redis自带的SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。</p></li><li><p>其他</p><p>Set 可以实现交集，并集等操作，从而实现共同好友等功能。ZSet 可以实现有序性操作，从而实现排行榜等功能。</p></li></ul><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><ul><li>什么是Redis 持久化 持久化就是把内存的数据写到磁盘中区，防止服务器宕机了内存数据丢失</li></ul><h2 id="Redis-的持久化机制是什么？-各自的优缺点？"><a href="#Redis-的持久化机制是什么？-各自的优缺点？" class="headerlink" title="Redis 的持久化机制是什么？ 各自的优缺点？"></a>Redis 的持久化机制是什么？ 各自的优缺点？</h2><ul><li>Redis 提供两种持久话机制RDB(默认) 和 AOF 机制：</li></ul><p><strong>RDB：是Redis DataBase缩写快照</strong></p><ul><li>RDB是Redis默认的持久化方式，按照一定时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件dumb.rdb。通过配置文件中的save参数来定义快照的周期</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1717449419419e78~tplv-t2oaga2asx-watermark.awebp" alt="在这里插入图片描述"></p><p>优点：</p><ul><li>只有一个文件dumb.rdb，方便持久化</li><li>容灾性好，一个文件可以保存到安全的磁盘</li><li>性能最大化，fork子进程来完成写操作，让主进程继续处理命令，所以是IO最大化，使用单子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能</li><li>相对于数据集大时，比AOF的启动效率更高</li></ul><p>缺点：</p><ul><li>数据安全性低，RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失，所以这种方式更是华数据要求不严谨的时候</li><li>AOF（Append-only file)持久化方式： 是指所有的命令行记录以 redis 命令请 求协议的格式完全持久化存储)保存为 aof 文件。</li></ul><p><strong>AOF：持久化</strong></p><ul><li>AOF持久化（即Append Only File 持久化）， 则是将Redis 执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志文件恢复数据</li><li>当两种方式同时开启，数据恢复Redis会有限选择AOF恢复</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/171744941b1f2a80~tplv-t2oaga2asx-watermark.awebp" alt="在这里插入图片描述"></p><p>优点：</p><ul><li>数据安全，aof持久化可以配置appendfsync属性，有always，每进行一次命令操作就记录在aof文件中一次</li><li>通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。</li><li>AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)</li></ul><p>缺点：</p><ul><li>AOF文件比RDB文件大，且恢复速度慢</li><li>数据集大的时候，比RDB启动效率低</li></ul><p>两种持久化的优缺点是什么</p><ul><li>AOF文件比RDB更新频率高，优先使用AOF还原数据</li><li>AOF比RDB更安全也更大</li><li>RDB性能比AOF好</li><li>如果两个都配了有限加载AOF</li></ul><h2 id="如果选择合适的持久化方式"><a href="#如果选择合适的持久化方式" class="headerlink" title="如果选择合适的持久化方式"></a>如果选择合适的持久化方式</h2><ul><li><p>一般来说，如果想达到足以媲美PostgreSQL的安全性，你应该同时使用两种持久化功能，在这种情况下，当Redis重启的时候回有限载入AOF文件来恢复原始数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据要完整</p></li><li><p>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。</p></li><li><p>有很多用户都只使用AOF持久化，但并不推荐这种方式，因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免AOF程序的bug。</p></li><li><p>如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。</p></li></ul><h2 id="Redis持久化数据和缓存怎么做扩容？"><a href="#Redis持久化数据和缓存怎么做扩容？" class="headerlink" title="Redis持久化数据和缓存怎么做扩容？"></a>Redis持久化数据和缓存怎么做扩容？</h2><ul><li>如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。</li><li>如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。</li></ul><h2 id="Redis的过期键的删除策略"><a href="#Redis的过期键的删除策略" class="headerlink" title="Redis的过期键的删除策略"></a>Redis的过期键的删除策略</h2><p>Redis是Key - value数据库，我们可以设置Redis中缓存的key的过期时间，Redis的过期缓存策略就是指当 Redis 中缓存的key过期了，Redis如何处理，通常有三种：</p><ul><li><p>定时过期：每个 设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据对内存很友好，但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的相同和吞吐量</p></li><li><p>惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。</p></li><li><p>定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。 (expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)</p></li></ul><p>  Redis中同时使用了惰性过期和定期过期两种过期策略。</p><h2 id="Redis-key的过期时间和永久有效分别怎么设置？"><a href="#Redis-key的过期时间和永久有效分别怎么设置？" class="headerlink" title="Redis key的过期时间和永久有效分别怎么设置？"></a>Redis key的过期时间和永久有效分别怎么设置？</h2><ul><li>expire和persist命令。</li></ul><h2 id="我们知道通过expire来设置key-的过期时间，那么对过期的数据怎么处理呢"><a href="#我们知道通过expire来设置key-的过期时间，那么对过期的数据怎么处理呢" class="headerlink" title="我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?"></a>我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?</h2><ul><li>除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：<ul><li>定时去清理过期的缓存；</li><li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。</li></ul></li></ul><p>两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。</p><h2 id="MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据"><a href="#MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据" class="headerlink" title="MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据"></a>MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据</h2><ul><li>redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</li></ul><h2 id="Redis的内存淘汰策略有哪些"><a href="#Redis的内存淘汰策略有哪些" class="headerlink" title="Redis的内存淘汰策略有哪些"></a>Redis的内存淘汰策略有哪些</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。</span><br></pre></td></tr></table></figure><ul><li>全局的键空间选择性移除<ul><li>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。</li><li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的）</li><li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</li></ul></li><li>设置过期时间的键空间选择性移除<ul><li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。</li><li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。</li><li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</li></ul></li><li>总结</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据；过期策略用于处理过期的缓存数据。</span><br></pre></td></tr></table></figure><h2 id="Redis主要消耗什么物理资源？"><a href="#Redis主要消耗什么物理资源？" class="headerlink" title="Redis主要消耗什么物理资源？"></a>Redis主要消耗什么物理资源？</h2><ul><li>内存。</li></ul><h2 id="Redis的内存用完了会发生什么？"><a href="#Redis的内存用完了会发生什么？" class="headerlink" title="Redis的内存用完了会发生什么？"></a>Redis的内存用完了会发生什么？</h2><ul><li>如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。</li></ul><h2 id="Redis如何做内存优化？"><a href="#Redis如何做内存优化？" class="headerlink" title="Redis如何做内存优化？"></a>Redis如何做内存优化？</h2><ul><li>可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面</li></ul><h1 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h1><ul><li>Redis基于Reactor模式开发了网络事件处理器，这个事件处理器称为文件事件处理器（file event handler)。它的组成结构分为四部分：多个套接字，IO多路复用程序，文件事件分派器，时间处理器。因为文件分派器队列的消费是单线程的，所以Redis是单线程模型</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210901152454724.png" alt="image-20210901152454724"></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210901152509838.png" alt="image-20210901152509838"></p><ul><li>文件事件处理器使用IO多路复用程序同时监听套接字，并根据套接字目前执行的任务为套接字关联不同的时间处理器。</li><li>当被监听的套接字准备好执行连接应答（accept），读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事假处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</li></ul><p>虽然文件事件处理器以单线程方式运行，但通过使用IO多路复用程序来监听多个套接字，文件事件处理器实现了高性能的网络通信模型，又可以很好地与redis服务器中其他 以单线程方式运行的模块进行对接，保持了redis内部单线程设计的简单性</p><p>时间事件：时间事件记录着那些在指定时间点运行的事件，多个时间事件以无序链表结构保存在服务器状态中。服务器需要定期对自身的资源和状态进行检查、整理， 保证服务器维持在一个健康稳定状态， 这类操作被统称为常规操作（cron job）。在 Redis 中， 常规操作由 redis.c/serverCron 实现，包括如下操作： - 更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等 - 清理数据库中的过期键值对 - 对不合理的数据库进行大小调整 - 关闭和清理连接失效的客户端 - 尝试进行 AOF 或RDB 持久化操作 - 如果服务器是主节点的话，对附属节点进行定期同步 - 如果处于集群模式的话，对集群进行定期同步和连接测试。Redis 将 serverCron（后文简称为sC） 作为时间事件运行， 确保它能够定期自动运行一次，又因 sC 需要在 Redis 服务器运行期一直定期运行， 所以它是一个循环时间事件：sC 会一直定期执行，直至服务器关闭。  </p><p>两种事件的调度：简单地说， Redis 里面的两种事件呈协作关系， 它们之间包含如下属性： - 一种事件会等待另一种事件执行完后，才开始执行，事件之间不会出现抢占 - 事件处理器先处理文件事件（即处理命令请求），再执行时间事件（调用 sC） - 文件事件的等待时间（类 poll 函数的最大阻塞时间），由距离到达时间最短的时间事件决定。这表明， 实际处理时间事件的时间， 通常会比事件所预定的时间要晚， 延迟时间取决于时间事件执行前， 执行完成文件事件所耗时间。  </p><h1 id="Redis事务"><a href="#Redis事务" class="headerlink" title="Redis事务"></a>Redis事务</h1><ul><li>事务是一个单独的隔离操作：事务中所有命令都会序列化、按顺序执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断</li><li>事务是一个原子操作：事务中的命令要么全部被执行，要门全部都不执行</li></ul><h2 id="Redis事务的概念"><a href="#Redis事务的概念" class="headerlink" title="Redis事务的概念"></a>Redis事务的概念</h2><ul><li>Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</li><li>总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。</li></ul><h2 id="Redis事务的三个阶段"><a href="#Redis事务的三个阶段" class="headerlink" title="Redis事务的三个阶段"></a>Redis事务的三个阶段</h2><ul><li>事务开始MULTI</li><li>命令入队</li><li>事务执行EXEC</li></ul><p>事务执行过程中，如果服务端收到EXEC、DISCARD、WATCH、MULTI之外的请求，将会请求放入队列排队</p><h2 id="Redis事务相关命令"><a href="#Redis事务相关命令" class="headerlink" title="Redis事务相关命令"></a>Redis事务相关命令</h2><p>Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的</p><p>Redis会将一个事务中的所有命令序列化，然后按顺序执行。</p><ol><li><strong>redis 不支持回滚</strong>，“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。</li><li><strong>如果在一个事务中的命令出现错误，那么所有的命令都不会执行</strong>；</li><li><strong>如果在一个事务中出现运行错误，那么正确的命令会被执行</strong>。</li></ol><ul><li>WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。</li><li>MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。</li><li>EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。</li><li>通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。</li><li>UNWATCH命令可以取消watch对所有key的监控。</li></ul><h2 id="事务管理（ACID）-概述"><a href="#事务管理（ACID）-概述" class="headerlink" title="事务管理（ACID） 概述"></a>事务管理（ACID） 概述</h2><ul><li><p>原子性（Atomicity）</p><p>原子性是指事务是一个不可分割的工作，要么事务中的操作都发生，要么都不发生</p></li><li><p>一致性（Consistency)</p><p>事务前后数据的完整性必须保持一致</p></li><li><p>隔离性（lsolation）</p><p>多个事务并发执行时，一个事务不影响其他事务的执行</p></li><li><p>持久性（Durability）</p><p>持久性是一个事务一旦被提交的，他对数据库中的数据的改变是永久的，接下来即使数据库发生故障也不应该对其有任何影响</p></li></ul><p>Redis的事务总是具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在_AOF_持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性</p><h2 id="Redis事务支持隔离性吗"><a href="#Redis事务支持隔离性吗" class="headerlink" title="Redis事务支持隔离性吗"></a>Redis事务支持隔离性吗</h2><ul><li>Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，<strong>Redis 的事务是总是带有隔离性的</strong>。</li></ul><h2 id="Redis事务保证原子性吗，支持回滚吗"><a href="#Redis事务保证原子性吗，支持回滚吗" class="headerlink" title="Redis事务保证原子性吗，支持回滚吗"></a>Redis事务保证原子性吗，支持回滚吗</h2><ul><li>Redis中，单条命令是原子性执行的，但<strong>事务不保证原子性，且没有回滚</strong>。事务中任意命令执行失败，其余的命令仍会被执行。</li></ul><h2 id="Redis事务其他实现"><a href="#Redis事务其他实现" class="headerlink" title="Redis事务其他实现"></a>Redis事务其他实现</h2><ul><li>基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，<br> 其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完</li><li>基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;h2 id=&quot;什么是Redis&quot;&gt;&lt;a href=&quot;#什么是Redis&quot; class=&quot;headerlink&quot; title=&quot;什么是Redis&quot;</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>17.锁升级和锁状态</title>
    <link href="https://leslieaibin.github.io/2021/08/30/JVM/17.%E9%94%81%E5%8D%87%E7%BA%A7%E5%92%8C%E9%94%81%E7%8A%B6%E6%80%81/"/>
    <id>https://leslieaibin.github.io/2021/08/30/JVM/17.%E9%94%81%E5%8D%87%E7%BA%A7%E5%92%8C%E9%94%81%E7%8A%B6%E6%80%81/</id>
    <published>2021-08-30T01:15:42.000Z</published>
    <updated>2021-08-30T12:38:16.016Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>锁的状态总共有四种，级别由低到高依次为：无锁、偏向锁、轻量级锁、重量级锁，这四种锁状态分别代表什么，为什么会有锁升级。在JDK1.6之前，synchronized还是一个重量级锁，是一个效率比较低下的锁，但在JDK1.6后，JVM为了提高锁的获取与释放效率(sychronized) 进行了优化，引入了偏向锁和轻量级锁，从此以后锁的状态就有四种（无锁， 偏向锁， 轻量级锁，重量级锁），并且四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级，也就是说只能进行锁升级（从低级别到高级别），不能锁降级（高级别到低级别），意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</p><h1 id="锁的四种状态"><a href="#锁的四种状态" class="headerlink" title="锁的四种状态"></a>锁的四种状态</h1><p>在synchronized最初的实现方式是“阻塞或唤醒一个Java线程需要操作系统切换cpu状态来完成，这种状态切换需要耗费处理器时间，如果同步代码块中内容过于简单，这种切换的时间可能比用户代码执行的时间还长”，这种方式就是synchronized实现同步最初的方式，这也是当初开发者诟病的地方，这也是在JDK6以前 synchronized效率低下的原因，JDK6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。</p><p>所以目前锁状态一种有四种，从级别由低到高依次是：无锁、偏向锁，轻量级锁，重量级锁，锁状态只能升级，不能降级</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904666" alt="img"></p><h1 id="锁状态的思路以及特点"><a href="#锁状态的思路以及特点" class="headerlink" title="锁状态的思路以及特点"></a>锁状态的思路以及特点</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904667" alt="img"></p><h1 id="锁对比"><a href="#锁对比" class="headerlink" title="锁对比"></a>锁对比</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904669" alt="img"></p><h1 id="Synchronized锁"><a href="#Synchronized锁" class="headerlink" title="Synchronized锁"></a>Synchronized锁</h1><p>synchronized用的锁是存在Java对象头里的，那么什么是对象头</p><h2 id="Java对象头"><a href="#Java对象头" class="headerlink" title="Java对象头"></a>Java对象头</h2><p>我们以Hotspot虚拟机为例，Hopspot 对象头主要包括两部分数据：Mark Word（标记字段） 和 Klass Pointer（类型指针）</p><p>Mark Word：默认存储对象的hashcode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。</p><p>Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。</p><p>在上面中我们知道了，synchronized 用的锁是存在Java对象头里的，那么具体是存在对象头哪里呢？答案是：存在锁对象的对象头的Mark Word中，那么MarkWord在对象头中到底长什么样，它到底存储了什么呢？</p><p>在64位的虚拟机中：<img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904668" alt="img"></p><p>在32位的虚拟机中：<img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904670" alt="img"></p><p><strong>无锁 ：</strong>对象头开辟 25bit 的空间用来存储对象的 hashcode ，4bit 用于存放对象分代年龄，1bit 用来存放是否偏向锁的标识位，2bit 用来存放锁标识位为01</p><p><strong>偏向锁：</strong> 在偏向锁中划分更细，还是开辟 25bit 的空间，其中23bit 用来存放线程ID，2bit 用来存放 Epoch，4bit 存放对象分代年龄，1bit 存放是否偏向锁标识， 0表示无锁，1表示偏向锁，锁的标识位还是01</p><p><strong>轻量级锁：</strong>在轻量级锁中直接开辟 30bit 的空间存放指向栈中锁记录的指针，2bit 存放锁的标志位，其标志位为00</p><p><strong>重量级锁：</strong> 在重量级锁中和轻量级锁一样，30bit 的空间用来存放指向重量级锁的指针，2bit 存放锁的标识位，为11</p><p>GC标记： 开辟30bit 的内存空间却没有占用，2bit 空间存放锁标志位为11。</p><p>其中无锁和偏向锁的锁标志位都是01，只是在前面的1bit区分了这是无锁状态还是偏向锁状态</p><p>关于内存的分配，我们可以在git中openJDK中 markOop.hpp 可以看出：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// Constants</span></span><br><span class="line">  <span class="class"><span class="keyword">enum</span> </span>&#123; age_bits                 = <span class="number">4</span>,</span><br><span class="line">         lock_bits                = <span class="number">2</span>,</span><br><span class="line">         biased_lock_bits         = <span class="number">1</span>,</span><br><span class="line">         max_hash_bits            = BitsPerWord - age_bits - lock_bits - biased_lock_bits,</span><br><span class="line">         hash_bits                = max_hash_bits &gt; <span class="number">31</span> ? <span class="number">31</span> : max_hash_bits,</span><br><span class="line">         cms_bits                 = LP64_ONLY(<span class="number">1</span>) NOT_LP64(<span class="number">0</span>),</span><br><span class="line">         epoch_bits               = <span class="number">2</span></span><br><span class="line">  &#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>age_bits： 就是我们说的分代回收的标识，占用4字节</p><p>lock_bits： 是锁的标志位，占用2个字节</p><p>biased_lock_bits： 是是否偏向锁的标识，占用1个字节</p><p>max_hash_bits： 是针对无锁计算的hashcode 占用字节数量，如果是32位虚拟机，就是 32 - 4 - 2 </p><p>-1 = 25 byte，如果是64 位虚拟机，64 - 4 - 2 - 1 = 57 byte，但是会有 25 字节未使用，所以64位的 </p><p>hashcode 占用 31 byte</p><p>hash_bits： 是针对 64 位虚拟机来说，如果最大字节数大于 31，则取31，否则取真实的字节数</p><p>cms_bits： 不是64位虚拟机就占用 0 byte，是64位就占用 1byte</p><p>epoch_bits： 就是 epoch 所占用的字节大小，2字节。</p><h2 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h2><p>Monitor 可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个 Java 对象就有一把看不见的锁，称为内部锁或者 Monitor 锁。</p><p>Monitor 是线程私有的数据结构，每一个线程都有一个可用 monitor record 列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个 monitor 关联，同时 monitor 中有一个 Owner 字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。</p><p>Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的，监视器锁本质又是依赖于底层的操作系统的 Mutex Lock（互斥锁）来实现的。而操作系统实现线程之间的切换需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么 Synchronized 效率低的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为重量级锁。</p><p>随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级）。JDK 1.6中默认是开启偏向锁和轻量级锁的，我们也可以通过-XX:-UseBiasedLocking=false来禁用偏向锁。</p><h1 id="锁的分类"><a href="#锁的分类" class="headerlink" title="锁的分类"></a>锁的分类</h1><h2 id="无锁"><a href="#无锁" class="headerlink" title="无锁"></a>无锁</h2><p>无锁是指没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。</p><p>无锁的特点是修改操作会在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。</p><h2 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h2><p>初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），字面意思是“偏向于第一个获得它的线程”的锁。执行完同步代码块后，线程并不会主动释放偏向锁。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。</p><p>偏向锁是指当一段同步代码一直被同一个线程所访问时，即不存在多个线程的竞争时，那么该线程在后续访问时便会自动获得锁，从而降低获取锁带来的消耗，即提高性能。</p><p>当一个线程访问同步代码块并获取锁时，会在 Mark Word 里存储锁偏向的线程 ID。在线程进入和退出同步块时不再通过 CAS 操作来加锁和解锁，而是检测 Mark Word 里是否存储着指向当前线程的偏向锁。轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 ThreadID 的时候依赖一次 CAS 原子指令即可。</p><p>偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程是不会主动释放偏向锁的。</p><p>关于偏向锁的撤销，需要等待全局安全点，即在某个时间点上没有字节码正在执行时，它会先暂停拥有偏向锁的线程，然后判断锁对象是否处于被锁定状态。如果线程不处于活动状态，则将对象头设置成无锁状态，并撤销偏向锁，恢复到无锁（标志位为01）或轻量级锁（标志位为00）的状态。</p><h2 id="轻量级锁（自旋锁）"><a href="#轻量级锁（自旋锁）" class="headerlink" title="轻量级锁（自旋锁）"></a>轻量级锁（自旋锁）</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022904671" alt="img"></p><p>轻量级锁是指当锁是偏向锁的时候，却被另外的线程所访问，此时偏向锁就会升级为轻量级锁，其他线程会通过自旋（关于自旋的介绍见文末）的形式尝试获取锁，线程不会阻塞，从而提高性能。</p><p>轻量级锁的获取主要由两种情况：</p><p>① 当关闭偏向锁功能时；</p><p>② 由于多个线程竞争偏向锁导致偏向锁升级为轻量级锁。</p><p>一旦有第二个线程加入锁竞争，偏向锁就升级为轻量级锁（自旋锁）。这里要明确一下什么是锁竞争：如果多个线程轮流获取一个锁，但是每次获取锁的时候都很顺利，没有发生阻塞，那么就不存在锁竞争。只有当某线程尝试获取锁的时候，发现该锁已经被占用，只能等待其释放，这才发生了锁竞争。</p><p>在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。</p><p>长时间的自旋操作是非常消耗资源的，一个线程持有锁，其他线程就只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做忙等（busy-waiting）。如果多个线程用一个锁，但是没有发生锁竞争，或者发生了很轻微的锁竞争，那么synchronized就用轻量级锁，允许短时间的忙等现象。这是一种折衷的想法，短时间的忙等，换取线程在用户态和内核态之间切换的开销。</p><h2 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h2><p>重量级锁显然，此忙等是有限度的（有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁（依然是CAS修改锁标志位，但不修改持有锁的线程ID）。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起（而不是忙等），等待将来被唤醒。</p><p>重量级锁是指当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态。</p><p>简言之，就是所有的控制权都交给了操作系统，由操作系统来负责线程间的调度和线程的状态变更。而这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，从而消耗大量的系统资源</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;锁的状态总共有四种，级别由低到高依次为：无锁、偏向锁、轻量级锁、重量级锁，这四种锁状态分别代表什么，为什么会有锁升级。在JDK1.6之前，s</summary>
      
    
    
    
    <category term="JVM" scheme="https://leslieaibin.github.io/categories/JVM/"/>
    
    
    <category term="JVM" scheme="https://leslieaibin.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>java异常</title>
    <link href="https://leslieaibin.github.io/2021/08/30/java%E5%9F%BA%E7%A1%80/java%E5%BC%82%E5%B8%B8%E4%BD%93%E7%B3%BB/"/>
    <id>https://leslieaibin.github.io/2021/08/30/java%E5%9F%BA%E7%A1%80/java%E5%BC%82%E5%B8%B8%E4%BD%93%E7%B3%BB/</id>
    <published>2021-08-30T01:15:42.000Z</published>
    <updated>2021-08-30T12:41:34.322Z</updated>
    
    <content type="html"><![CDATA[<p>java把异常作为一类，当做对象来处理。所有异常类的基类是Throwable类，两大子类分别是Error  和 Exception。</p><p>系统错误由Java虚拟机抛出，用Error类表示，Error类描述的是内部系统错误，例如Java虚拟机崩溃。这种情况仅凭程序自身是无法处理的，在程序中也不会对Error异常进行捕捉和抛出。</p><p>异常（Exception）又分为RuntimeException（运行时异常）和 CheckedException（检查时异常），两者区别如下：</p><ul><li>RuntimeException：程序运行过程中才可能发生的异常，一般为代码的逻辑异常，例如：类型错误，数组越界，空指针异常等</li><li>CheckedException：编译期间可以检查到的异常，必须显示的进行处理（捕获或者抛出到上一层）。例如：IOException, FileNotFoundException等等。</li></ul><h2 id="java异常体系结构图"><a href="#java异常体系结构图" class="headerlink" title="java异常体系结构图"></a>java异常体系结构图</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1294391-20180919152605174-2400592.png" alt="img"></p><p>首先说明一点，java中的Exception类的子类不仅仅只是像上图所示只包含IOException和RuntimeException这两大类，事实上Exception的子类很多很多，主要可概括为：运行时异常与非运行时异常。</p><p>Thorwable类（表示可抛出）是所有异常和错误的超类，两个直接子类为Error和Exception，分别表示错误和异常。其中异常类Exception又分为运行时异常(RuntimeException)和非运行时异常， 这两种异常有很大的区别，也称之为不检查异常（Unchecked Exception）和检查异常（Checked Exception）。下面将详细讲述这些异常之间的区别与联系：</p><p>1、Error与Exception</p><p>Error是程序无法处理的错误，它是由JVM产生和抛出的，比如OutOfMemoryError、ThreadDeath等。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。 Exception是程序本身可以处理的异常，这种异常分两大类运行时异常和非运行时异常。程序中应当尽可能去处理这些异常。</p><p>2、运行时异常和非运行时异常</p><p> 运行时异常都是RuntimeException类及其子类异常，如NullPointerException、IndexOutOfBoundsException等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。非运行时异常是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。</p><h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><p><strong>常用关键字：try、catch、throw（抛出一个异常，动词）、throws（声明一个方法可能抛出的异常）、finally。</strong></p><h3 id="throws-声明异常"><a href="#throws-声明异常" class="headerlink" title="throws(声明异常)"></a>throws(声明异常)</h3><p>若方法中存在检查时异常，如果不对其捕获，那必须在方法头中显式声明该异常，以便于告知方法调用者此方法有异常，需要进行处理。 </p><p>在方法中声明一个异常，方法头中使用关键字throws，后面接上要声明的异常。若声明多个异常，则使用逗号分割。</p><p>若是父类的方法没有声明异常，则子类继承方法后，也不能声明异常。</p><h2 id="try-catch-捕获异常"><a href="#try-catch-捕获异常" class="headerlink" title="try-catch(捕获异常)"></a>try-catch(捕获异常)</h2><p>若执行try块的过程中没有发生异常，则跳过catch子句。若是出现异常，try块中剩余语句不再执行。开始逐步检查catch块，判断catch块的异常类实例是否是捕获的异常类型。匹配后执行相应的catch块中的代码。如果异常没有在当前的方法中被捕获，就会被传递给该方法的调用者。这个过程一直重复，直到异常被捕获或被传给main方法（交给JVM来捕获）。</p><p>对于try..catch捕获异常的形式来说，对于异常的捕获，可以有多个catch。对于try里面发生的异常，他会根据发生的异常和catch里面的进行匹配(按照catch块从上往下匹配)，如果有匹配的catch，它就会忽略掉这个catch后面所有的catch。</p><p>如果有finally的话进入到finally里面继续执行。</p><p>try ctach fianally 中有return 时，会先执行return ，但是不会返回。在执行完 finally 后 进行返回。</p><p>return 的是基本类型数据时， fianlly 里面的语句不会影响 return 的值，</p><p>return 的是引用类型数据时，此时已经确定了要返回对象的地址（地址一），后面 fianlly 里面的可以通过修改前面地址一中的内容修改返回的内容，</p><p>但是如果将对象指向另一个地址（地址二），则不会影响返回的内容。因为返回的对象地址已经确定为地址一，只能通过修改地址一对象的内容修改返回的信息。 </p><h2 id="try、catch、finally三个语句块应注意的问题"><a href="#try、catch、finally三个语句块应注意的问题" class="headerlink" title="try、catch、finally三个语句块应注意的问题"></a>try、catch、finally三个语句块应注意的问题</h2><ul><li>try、catch、finally三个语句块均不能单独使用，三者可以组成 try…catch…finally、try…catch、try…finally三种结构，catch语句可以有一个或多个，finally语句最多一个。</li><li>try、catch、finally三个代码块中变量的作用域为代码块内部，分别独立而不能相互访问。如果要在三个块中都可以访问，则需要将变量定义到这些块的外面。</li><li>多个catch块时候，最多只会匹配其中一个异常类且只会执行该catch块代码，而不会再执行其它的catch块，且匹配catch语句的顺序为从上到下，也可能所有的catch都没执行。</li><li>先Catch子类异常再Catch父类异常。</li></ul><h2 id="throw、throws关键字"><a href="#throw、throws关键字" class="headerlink" title="throw、throws关键字"></a>throw、throws关键字</h2><p>  throw关键字是用于方法体内部，用来抛出一个Throwable类型的异常。如果抛出了检查异常，则还应该在方法头部声明方法可能抛出的异常类型。该方法的调用者也必须检查处理抛出的异常。如果所有方法都层层上抛获取的异常，最终JVM会进行处理，处理也很简单，就是打印异常消息和堆栈信息。throw关键字用法如下： </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> <span class="keyword">throws</span> Exception  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">   <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">&quot;方法test中的Exception&quot;</span>);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>  throws关键字用于方法体外部的方法声明部分，用来声明方法可能会抛出某些异常。仅当抛出了检查异常，该方法的调用者才必须处理或者重新抛出该异常。当方法的调用者无力处理该异常的时候，应该继续抛出.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;java把异常作为一类，当做对象来处理。所有异常类的基类是Throwable类，两大子类分别是Error  和 Exception。&lt;/p&gt;
&lt;p&gt;系统错误由Java虚拟机抛出，用Error类表示，Error类描述的是内部系统错误，例如Java虚拟机崩溃。这种情况仅凭程序自</summary>
      
    
    
    
    <category term="计算机基础知识" scheme="https://leslieaibin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
  </entry>
  
  <entry>
    <title>10.ThreadLocal</title>
    <link href="https://leslieaibin.github.io/2021/08/29/Thread/10.ThreadLocal/"/>
    <id>https://leslieaibin.github.io/2021/08/29/Thread/10.ThreadLocal/</id>
    <published>2021-08-29T02:15:42.000Z</published>
    <updated>2021-09-15T06:12:32.316Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ThreadLocal介绍"><a href="#ThreadLocal介绍" class="headerlink" title="ThreadLocal介绍"></a>ThreadLocal介绍</h2><h3 id="官方介绍"><a href="#官方介绍" class="headerlink" title="官方介绍"></a><strong>官方介绍</strong></h3><p>从Java官方文档中描述：ThreadLocal类用来提供线程内部局部变量，这种变量在多线程环境下访问（通过get 和set 方法访问）时能保证各个线程的变量相对于独立于其他线程内的变量。ThreadLocal实例通常来说都是private static类型的，用于关联线程和线程上下文</p><p>可以得知ThreadLocal作用是：提供线程内部的局部变量，不同的线程之间不会相互干扰，这种变量在线程声明周期内其作用，减少同一个线程内多个函数或组件之间一些公共变量传递的复杂度</p><p>总结：</p><ul><li>线程并发：在多线程并发的场景下</li><li>传递数据：可以通过ThreadLocal在统一线程，不同组件中传递公共变量</li><li>线程隔离：每个线程的变量都是独立的，不会相互影响</li></ul><h3 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h3><ul><li>ThreadLocal：创建TheradLocal对象</li><li>public void set(T value)：设置当前线程绑定的局部变量</li><li>public T get()：获取当前线程绑定的局部变量</li><li>public  void remove()：移除当前线程绑定的局部变量</li></ul><h3 id="ThreadLocal类与synchronized关键字"><a href="#ThreadLocal类与synchronized关键字" class="headerlink" title="ThreadLocal类与synchronized关键字"></a>ThreadLocal类与synchronized关键字</h3><p>虽然ThreadLocal模式与synchronized关键字都用于处理多线程并发访问变量的问题，不过两者处理问题的角度和思路不同</p><ul><li>synchronized：同步机制采用“时间换空间”的方式，只提供了一份变量，让不同的线程排队访问，多个线程之间访问资源的同步</li><li>ThreadLocal：采用“空间换时间”的方式，为每一个线程都提供了一份变量的副本，从而实现同时访问而互不干扰。多线程中让每个线程之间的数据相互隔离</li></ul><p>总结：</p><p>在刚刚的案例中，虽然使用ThreadLocal和synchronized都能解决问题，但是使用ThreadLocal更为合适，因为这样可以使得程序拥有更高的并发性</p><h2 id="ThreadLocal的内部结构"><a href="#ThreadLocal的内部结构" class="headerlink" title="ThreadLocal的内部结构"></a>ThreadLocal的内部结构</h2><h3 id="常见的误解"><a href="#常见的误解" class="headerlink" title="常见的误解"></a>常见的误解</h3><p> 如果我们不去看源代码的话，可能会猜测ThreadLocal是这样子设计的：每个ThreadLocal都创建一个Map，然后用线程作为Map的key，要存储的局部变量作为Map的value，这样就能达到各个线程的局部变量隔离的效果。这是最简单的设计方法，JDK最早期的ThreadLocal 确实是这样设计的，但现在早已不是了。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210124115504330.png" alt="img"></p><h3 id="现在设计"><a href="#现在设计" class="headerlink" title="现在设计"></a>现在设计</h3><p> 但是，JDK后面优化了设计方案，在JDK8中 ThreadLocal的设计是：每个Thread维护一个ThreadLocalMap，这个Map的key是ThreadLocal实例本身，value才是真正要存储的值Object。</p><p>具体的过程是这样的：</p><p>每个Thread线程内部都有一个Map (ThreadLocalMap)</p><p>Map里面存储ThreadLocal对象（key）和线程的变量副本（value）</p><p>Thread内部的Map是由ThreadLocal维护的，由ThreadLocal负责向map获取和设置线程的变量值。</p><p> 对于不同的线程，每次获取副本值时，别的线程并不能获取到当前线程的副本值，形成了副本的隔离，互不干扰。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210124120125266.png" alt="在这里插入图片描述"></p><h3 id="这样设计的好处"><a href="#这样设计的好处" class="headerlink" title="这样设计的好处"></a>这样设计的好处</h3><p> 这个设计与我们一开始说的设计刚好相反，这样设计有如下两个优势：</p><p>这样设计之后每个Map存储的Entry数量就会变少。因为之前的存储数量由Thread的数量决定，现在是由ThreadLocal的数量决定。在实际运用当中，往往ThreadLocal的数量要少于Thread的数量。<br>当Thread销毁之后，对应的ThreadLocalMap也会随之销毁，能减少内存的使用。</p><h2 id="ThreadLocal的核心方法源码"><a href="#ThreadLocal的核心方法源码" class="headerlink" title="ThreadLocal的核心方法源码"></a>ThreadLocal的核心方法源码</h2><p> 基于ThreadLocal的内部结构，我们继续分析它的核心方法源码，更深入的了解其操作原理。</p><h3 id="set方法"><a href="#set方法" class="headerlink" title="set方法"></a>set方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 设置当前线程对应的ThreadLocal的值</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> value 将要保存在当前线程对应的ThreadLocal的值</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(T value)</span> </span>&#123;</span><br><span class="line">       <span class="comment">// 获取当前线程对象</span></span><br><span class="line">       Thread t = Thread.currentThread();</span><br><span class="line">       <span class="comment">// 获取此线程对象中维护的ThreadLocalMap对象</span></span><br><span class="line">       ThreadLocalMap map = getMap(t);</span><br><span class="line">       <span class="comment">// 判断map是否存在</span></span><br><span class="line">       <span class="keyword">if</span> (map != <span class="keyword">null</span>)</span><br><span class="line">           <span class="comment">// 存在则调用map.set设置此实体entry</span></span><br><span class="line">           map.set(<span class="keyword">this</span>, value);</span><br><span class="line">       <span class="keyword">else</span></span><br><span class="line">           <span class="comment">// 1）当前线程Thread 不存在ThreadLocalMap对象</span></span><br><span class="line">           <span class="comment">// 2）则调用createMap进行ThreadLocalMap对象的初始化</span></span><br><span class="line">           <span class="comment">// 3）并将 t(当前线程)和value(t对应的值)作为第一个entry存放至ThreadLocalMap中</span></span><br><span class="line">           createMap(t, value);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 获取当前线程Thread对应维护的ThreadLocalMap </span></span><br><span class="line"><span class="comment">    * </span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  t the current thread 当前线程</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> the map 对应维护的ThreadLocalMap </span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function">ThreadLocalMap <span class="title">getMap</span><span class="params">(Thread t)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> t.threadLocals;</span><br><span class="line">   &#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    *创建当前线程Thread对应维护的ThreadLocalMap </span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> t 当前线程</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> firstValue 存放到map中第一个entry的值</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createMap</span><span class="params">(Thread t, T firstValue)</span> </span>&#123;</span><br><span class="line">       <span class="comment">//这里的this是调用此方法的threadLocal</span></span><br><span class="line">       t.threadLocals = <span class="keyword">new</span> ThreadLocalMap(<span class="keyword">this</span>, firstValue);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>首先获取当前线程，并根据当前线程获取一个Map</li><li>如果获取的Map不为空，则将参数设置到Map中（当前ThreadLocal的引用作为key）</li><li>如果Map为空，则给该线程创建Map，并设置初始值</li></ul><h3 id="get方法"><a href="#get方法" class="headerlink" title="get方法"></a>get方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回当前线程中保存ThreadLocal的值</span></span><br><span class="line"><span class="comment"> * 如果当前线程没有此ThreadLocal变量，</span></span><br><span class="line"><span class="comment"> * 则它会通过调用&#123;<span class="doctag">@link</span> #initialValue&#125; 方法进行初始化值</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 返回当前线程对应此ThreadLocal的值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> T <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取当前线程对象</span></span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line">    <span class="comment">// 获取此线程对象中维护的ThreadLocalMap对象</span></span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    <span class="comment">// 如果此map存在</span></span><br><span class="line">    <span class="keyword">if</span> (map != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 以当前的ThreadLocal 为 key，调用getEntry获取对应的存储实体e</span></span><br><span class="line">        ThreadLocalMap.Entry e = map.getEntry(<span class="keyword">this</span>);</span><br><span class="line">        <span class="comment">// 对e进行判空 </span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">            <span class="comment">// 获取存储实体 e 对应的 value值</span></span><br><span class="line">            <span class="comment">// 即为我们想要的当前线程对应此ThreadLocal的值</span></span><br><span class="line">            T result = (T)e.value;</span><br><span class="line">            <span class="keyword">return</span> result;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    初始化 : 有两种情况有执行当前代码</span></span><br><span class="line"><span class="comment">    第一种情况: map不存在，表示此线程没有维护的ThreadLocalMap对象</span></span><br><span class="line"><span class="comment">    第二种情况: map存在, 但是没有与当前ThreadLocal关联的entry</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">return</span> setInitialValue();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 初始化</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> the initial value 初始化后的值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> T <span class="title">setInitialValue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 调用initialValue获取初始化的值</span></span><br><span class="line">    <span class="comment">// 此方法可以被子类重写, 如果不重写默认返回null</span></span><br><span class="line">    T value = initialValue();</span><br><span class="line">    <span class="comment">// 获取当前线程对象</span></span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line">    <span class="comment">// 获取此线程对象中维护的ThreadLocalMap对象</span></span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    <span class="comment">// 判断map是否存在</span></span><br><span class="line">    <span class="keyword">if</span> (map != <span class="keyword">null</span>)</span><br><span class="line">        <span class="comment">// 存在则调用map.set设置此实体entry</span></span><br><span class="line">        map.set(<span class="keyword">this</span>, value);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment">// 1）当前线程Thread 不存在ThreadLocalMap对象</span></span><br><span class="line">        <span class="comment">// 2）则调用createMap进行ThreadLocalMap对象的初始化</span></span><br><span class="line">        <span class="comment">// 3）并将 t(当前线程)和value(t对应的值)作为第一个entry存放至ThreadLocalMap中</span></span><br><span class="line">        createMap(t, value);</span><br><span class="line">    <span class="comment">// 返回设置的值value</span></span><br><span class="line">    <span class="keyword">return</span> value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>首先获取当前线程，根据当前线程获取一个Map</li><li>如果获取的Map不为空，则在Map中以ThreadLocal的引用作为key来在Map中获取对应的Entry e，否则转到D</li><li> 如果e不为null，则返回e.value，否则转到D</li><li>Map为空或者e为空，则通过initialValue函数获取初始值value，然后用ThreadLocal的引用和value作为firstKey和firstValue创建一个新的Map</li></ul><p>总结：<strong>先获取当前线程的 ThreadLocalMap 变量，如果存在则返回值，不存在则创建并返回初始值。</strong></p><h3 id="remove方法"><a href="#remove方法" class="headerlink" title="remove方法"></a>remove方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 删除当前线程中保存的ThreadLocal对应的实体entry</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="comment">// 获取当前线程对象中维护的ThreadLocalMap对象</span></span><br><span class="line">        ThreadLocalMap m = getMap(Thread.currentThread());</span><br><span class="line">       <span class="comment">// 如果此map存在</span></span><br><span class="line">        <span class="keyword">if</span> (m != <span class="keyword">null</span>)</span><br><span class="line">           <span class="comment">// 存在则调用map.remove</span></span><br><span class="line">           <span class="comment">// 以当前ThreadLocal为key删除对应的实体entry</span></span><br><span class="line">            m.remove(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>首先获取当前线程，并根据当前线程获取一个Map</li><li>如果获取的map不为空，则移除当前ThreadLocal对象对应的entry</li></ul><h3 id="initialValue方法"><a href="#initialValue方法" class="headerlink" title="initialValue方法"></a><strong>initialValue方法</strong></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 返回当前线程对应的ThreadLocal的初始值</span></span><br><span class="line"><span class="comment">  </span></span><br><span class="line"><span class="comment">  * 此方法的第一次调用发生在，当线程通过get方法访问此线程的ThreadLocal值时</span></span><br><span class="line"><span class="comment">  * 除非线程先调用了set方法，在这种情况下，initialValue 才不会被这个线程调用。</span></span><br><span class="line"><span class="comment">  * 通常情况下，每个线程最多调用一次这个方法。</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * &lt;p&gt;这个方法仅仅简单的返回null &#123;<span class="doctag">@code</span> null&#125;;</span></span><br><span class="line"><span class="comment">  * 如果程序员想ThreadLocal线程局部变量有一个除null以外的初始值，</span></span><br><span class="line"><span class="comment">  * 必须通过子类继承&#123;<span class="doctag">@code</span> ThreadLocal&#125; 的方式去重写此方法</span></span><br><span class="line"><span class="comment">  * 通常, 可以通过匿名内部类的方式实现</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> 当前ThreadLocal的初始值</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> T <span class="title">initialValue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此方法的作用是 返回该线程局部变量的初始值。</p><ul><li><p> 这个方法是一个延迟调用方法，从上面的代码我们得知，在set方法还未调用而先调用了get方法时才执行，并且仅执行1次。</p></li><li><p>这个方法缺省实现直接返回一个null。</p></li><li><p>如果想要一个除null之外的初始值，可以重写此方法。（备注： 该方法是一个protected的方法，显然是为了让子类覆盖而设计的）</p></li></ul><h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><h3 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h3><p>ThreadLocalMap是ThreadLocal的内部类，没有实现Map接口，用独立的方式实现了Map的功能，其内部的Entry也是独立实现。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210124143602480.png" alt="在这里插入图片描述"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 初始容量 —— 必须是2的整次幂</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> INITIAL_CAPACITY = <span class="number">16</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 存放数据的table，Entry类的定义在下面分析</span></span><br><span class="line"><span class="comment"> * 同样，数组长度必须是2的整次幂。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> Entry[] table;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 数组里面entrys的个数，可以用于判断table当前使用量是否超过阈值。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 进行扩容的阈值，表使用量大于它的时候进行扩容。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> threshold; <span class="comment">// Default to 0</span></span><br></pre></td></tr></table></figure><p> 跟HashMap类似，INITIAL_CAPACITY代表这个Map的初始容量；table 是一个Entry 类型的数组，用于存储数据；size 代表表中的存储数目； threshold 代表需要扩容时对应 size 的阈值。</p><p><strong>存储结构 - Entry</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Entry继承WeakReference，并且用ThreadLocal作为key.</span></span><br><span class="line"><span class="comment"> * 如果key为null(entry.get() == null)，意味着key不再被引用，</span></span><br><span class="line"><span class="comment"> * 因此这时候entry也可以从table中清除。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span> <span class="keyword">extends</span> <span class="title">WeakReference</span>&lt;<span class="title">ThreadLocal</span>&lt;?&gt;&gt; </span>&#123;</span><br><span class="line">    <span class="comment">/** The value associated with this ThreadLocal. */</span></span><br><span class="line">    Object value;</span><br><span class="line"></span><br><span class="line">    Entry(ThreadLocal&lt;?&gt; k, Object v) &#123;</span><br><span class="line">        <span class="keyword">super</span>(k);</span><br><span class="line">        value = v;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在ThreadLocalMap中，也是用Entry来保存K-V结构数据的。不过Entry中的key只能是ThreadLocal对象，这点在构造方法中已经限定死了。</p><p> 另外，Entry继承WeakReference，也就是key（ThreadLocal）是弱引用，其目的是将ThreadLocal对象的生命周期和线程生命周期解绑。</p><h3 id="弱引用和内存泄漏"><a href="#弱引用和内存泄漏" class="headerlink" title="弱引用和内存泄漏"></a>弱引用和内存泄漏</h3><p>有些程序员在使用ThreadLocal的过程中会发现有内存泄漏的情况发生，就猜测这个内存泄漏跟Entry中使用了弱引用的key有关系。这个理解其实是不对的。</p><h4 id="内存泄漏相关概念"><a href="#内存泄漏相关概念" class="headerlink" title="内存泄漏相关概念"></a><strong>内存泄漏相关概念</strong></h4><ul><li>Memory overflow:内存溢出，没有足够的内存提供申请者使用。</li><li>Memory leak: 内存泄漏是指程序中已动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。内存泄漏的堆积终将导致内存溢出。</li></ul><h4 id="弱引用相关概念"><a href="#弱引用相关概念" class="headerlink" title="弱引用相关概念"></a><strong>弱引用相关概念</strong></h4><ul><li><p>Java中的引用有4种类型： 强、软、弱、虚。当前这个问题主要涉及到强引用和弱引用：</p></li><li><p>强引用（“Strong” Reference），就是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾回收器就不会回收这种对象。</p></li><li><p>弱引用（WeakReference），垃圾回收器一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。</p></li></ul><h4 id="如果key使用强引用"><a href="#如果key使用强引用" class="headerlink" title="如果key使用强引用"></a><strong>如果key使用强引用</strong></h4><p> 假设ThreadLocalMap中的key使用了强引用，那么会出现内存泄漏吗？</p><p> 此时ThreadLocal的内存图（实线表示强引用）如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210124144330949.png" alt="在这里插入图片描述"></p><p>假设在业务代码中使用完ThreadLocal ，threadLocal Ref被回收了。</p><p> 但是因为threadLocalMap的Entry强引用了threadLocal，造成threadLocal无法被回收。</p><p> 在没有手动删除这个Entry以及CurrentThread依然运行的前提下，始终有强引用链 threadRef-&gt;currentThread-&gt;threadLocalMap-&gt;entry，Entry就不会被回收（Entry中包括了ThreadLocal实例和value），导致Entry内存泄漏。</p><p> 也就是说，ThreadLocalMap中的key使用了强引用， 是无法完全避免内存泄漏的。</p><h4 id="如果key使用弱引用"><a href="#如果key使用弱引用" class="headerlink" title="如果key使用弱引用"></a><strong>如果key使用弱引用</strong></h4><p> 那么ThreadLocalMap中的key使用了弱引用，会出现内存泄漏吗？</p><p> 此时ThreadLocal的内存图（实线表示强引用，虚线表示弱引用）如下：</p><p> 同样假设在业务代码中使用完ThreadLocal ，threadLocal Ref被回收了。</p><p> 由于ThreadLocalMap只持有ThreadLocal的弱引用，没有任何强引用指向threadlocal实例, 所以threadlocal就可以顺利被gc回收，此时Entry中的key=null。</p><p> 但是在没有手动删除这个Entry以及CurrentThread依然运行的前提下，也存在有强引用链 threadRef-&gt;currentThread-&gt;threadLocalMap-&gt;entry -&gt; value ，value不会被回收， 而这块value永远不会被访问到了，导致value内存泄漏。</p><p> 也就是说，ThreadLocalMap中的key使用了弱引用， 也有可能内存泄漏。</p><h4 id="出现内存泄漏的真实原因"><a href="#出现内存泄漏的真实原因" class="headerlink" title="出现内存泄漏的真实原因"></a><strong>出现内存泄漏的真实原因</strong></h4><p> 比较以上两种情况，我们就会发现，内存泄漏的发生跟ThreadLocalMap中的key是否使用弱引用是没有关系的。那么内存泄漏的的真正原因是什么呢？</p><p> 细心的同学会发现，在以上两种内存泄漏的情况中，都有两个前提：</p><ul><li><p>没有手动删除这个Entry</p></li><li><p>CurrentThread依然运行</p><p>第一点很好理解，只要在使用完ThreadLocal，调用其remove方法删除对应的Entry，就能避免内存泄漏。</p><p>第二点稍微复杂一点， 由于ThreadLocalMap是Thread的一个属性，被当前线程所引用，所以它的生命周期跟Thread一样长。那么在使用完ThreadLocal之后，如果当前Thread也随之执行结束，ThreadLocalMap自然也会被gc回收，从根源上避免了内存泄漏。</p><p>综上，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏。</p></li></ul><h4 id="为什么使用弱引用"><a href="#为什么使用弱引用" class="headerlink" title="为什么使用弱引用"></a><strong>为什么使用弱引用</strong></h4><p> 根据刚才的分析, 我们知道了： 无论ThreadLocalMap中的key使用哪种类型引用都无法完全避免内存泄漏，跟使用弱引用没有关系。</p><p> 要避免内存泄漏有两种方式：</p><ul><li><p>使用完ThreadLocal，调用其remove方法删除对应的Entry</p></li><li><p>使用完ThreadLocal，当前Thread也随之运行结束</p></li></ul><p>相对第一种方式，第二种方式显然更不好控制，特别是使用线程池的时候，线程结束是不会销毁的。</p><p> 也就是说，只要记得在使用完ThreadLocal及时的调用remove，无论key是强引用还是弱引用都不会有问题。那么为什么key要用弱引用呢？</p><p> 事实上，在ThreadLocalMap中的set/getEntry方法中，会对key为null（也即是ThreadLocal为null）进行判断，如果为null的话，那么是会对value置为null的。</p><p> <strong>这就意味着使用完ThreadLocal，CurrentThread依然运行的前提下，就算忘记调用remove方法，弱引用比强引用可以多一层保障：弱引用的ThreadLocal会被回收，对应的value在下一次ThreadLocalMap调用set,get,remove中的任一方法的时候会被清除，从而避免内存泄漏。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ThreadLocal介绍&quot;&gt;&lt;a href=&quot;#ThreadLocal介绍&quot; class=&quot;headerlink&quot; title=&quot;ThreadLocal介绍&quot;&gt;&lt;/a&gt;ThreadLocal介绍&lt;/h2&gt;&lt;h3 id=&quot;官方介绍&quot;&gt;&lt;a href=&quot;#官方介绍&quot;</summary>
      
    
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>平衡二叉树、B 树、B+树</title>
    <link href="https://leslieaibin.github.io/2021/08/29/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%81B%20%E6%A0%91%E3%80%81B+%E6%A0%91/"/>
    <id>https://leslieaibin.github.io/2021/08/29/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%81B%20%E6%A0%91%E3%80%81B+%E6%A0%91/</id>
    <published>2021-08-29T01:15:42.000Z</published>
    <updated>2021-08-29T13:40:53.923Z</updated>
    
    <content type="html"><![CDATA[<h1 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h1><p>平衡二叉树是基于二分法的策略提高数据的查找速度的二叉树的数据结构</p><p><strong>特点：</strong></p><p>平衡二叉树是采用二分法思维把数据按规则组装成一个树型结构的数据，用这个树形结构的数据减少无关数据的检索，大大的提升了数据检索的速度；平衡二叉树的数据结构组装过程有以下规则：</p><ul><li>非叶子节点只能允许最多两个子节点存在</li><li>每一个非叶子检点数据分布规则按照左边的子节点小于当前节点的值，右边的子节点大于当前节点的值（这里的值是基于自己的算法规则而定的，比如hash值）</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-28e39093993f673de576f57ea614d604_720w.jpg" alt="img"></p><p>平衡树的层级结构：因为平衡二叉树查询性能和树的层级（h高度）成反比，h值越小查询越快、为了保证树的结构左右两端数据大致平衡降低二叉树的查询难度一般会采用一种算法机制实现节点数据结构的平衡，实现了这种算法的有比如Treap、红黑树，使用平衡二叉树能保证数据的左右两边的节点层级相差不会大于1.，通过这样避免树形结构由于删除增加变成线性链表影响查询效率，保证数据平衡的情况下查找数据的速度近于二分法查找；</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2b52d4e523f374f41b5429cd587443db_720w.jpg" alt="img"></p><p>总结平衡二叉树特点：</p><ul><li>非叶子节点最多拥有两个子节点</li><li>非叶子节点大于左边子节点，小于右边子节点</li><li>树的左右两边的层级数相差不会大于1</li><li>没有值相等重复的节点</li></ul><h1 id="B树（BTree"><a href="#B树（BTree" class="headerlink" title="B树（BTree)"></a>B树（BTree)</h1><p>B树和平衡二叉树稍有不同的是B树属于多叉树有名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用B树 和 B+树。</p><p><strong>规则：</strong></p><ul><li>排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则；</li><li>子节点数：非叶节点的子节点数&gt;1，且&lt;=M，且 M&gt;=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）；</li><li>关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2);</li><li>所有叶子节点均在同一层，叶子节点除了除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子;</li></ul><p>最后我们用一个图和一个实例的例子理解：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2c2264cc1c6c603dfeca4f84a2575901_720w.jpg" alt="img"></p><ul><li><p><strong>B树的查询流程：</strong></p><p>如上图我要从上图中找到E字母，查找流程如下：</p><ul><li>获取根节点的关键字比较，当前根节点关键字为M，E &lt; M(26个字母顺序)，所以找到指向左边的子节点(二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点);</li><li>拿到关键字D和G，D&lt;E&lt;G 所以直接找到D和G中间的节点；</li><li>拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null）；</li></ul></li><li><p>B<strong>树的插入节点流程</strong></p><p>定义一个5阶树（平衡5路查找树;），现在我们要把3、8、31、11、23、29、50、28 这些数字构建出一个5阶树出来;</p><p>遵循规则：</p><p>（1）节点拆分规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须&lt;=5-1（这里关键字数&gt;4就要进行节点拆分）；</p><p>（2）排序规则：满足节点本身比左边节点大，比右边节点小的排序规则;</p></li></ul><p>  先插入 3、8、31、11</p><p>  <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-e1d65c9c6236d4768c89e8e103e12583_720w.jpg" alt="img"></p><p>  再插入23、29</p><p>  <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-66cdb6187cbc5227fd8c4aabe7282e6c_720w.jpg" alt="img"></p><p>  再插入50、28</p><p>  <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-3057eaab2b1764dd51c2a8658791cc98_720w.jpg" alt="img"></p><ul><li><strong>B树节点的删除</strong></li></ul><p>  <strong>规则：</strong></p><p>  （1）节点合并规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须大于等于ceil（5/2）（这里关键字数&lt;2就要进行节点合并）；</p><p>  （2）满足节点本身比左边节点大，比右边节点小的排序规则;</p><p>  （3）关键字数小于二时先从子节点取，子节点没有符合条件时就向向父节点取，取中间值往父节点放；</p><p>  <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-a0f981fc847772cb28869927cd4fe66d_720w.jpg" alt="img"></p><p>  <strong>特点：</strong></p><p>  B树相对于平衡二叉树的不同是，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度;</p><h1 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h1><p>B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。为什么说B+树查找的效率要比B树更高、更稳定；</p><p><strong>规则：</strong></p><ul><li>B+ 树跟 B树不同 B树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加，</li><li>B+树<strong>叶子</strong>节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样；</li><li>B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。</li><li>非叶子节点的子节点数=关键字数（来源百度百科）（根据各种资料 这里有两种算法的实现方式，另一种为非叶节点的关键字数=子节点数-1（来源维基百科)，虽然他们数据排列结构不一样，但其原理还是一样的Mysql 的B+树是用第一种方式实现）;</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-5f069fd820637db1b877fdd6799a2b67_720w.jpg" alt="img"></p><p><strong>（百度百科算法结构示意图）</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-9644d1a1f83d3e45da779f2e63c35d55_720w.jpg" alt="img"></p><p><strong>（维基百科算法结构示意图）</strong></p><p><strong>特点：</strong></p><ul><li><strong>B+ 树的层级更少：</strong>相较于B树  B+ 树每个非叶子节点存储的关键字更多，树的层级更少所以查询数据更快</li><li><strong>B+ 树查询速度更稳定：</strong>B+ 所有的关键字数据地址都存在叶子节点上，所以每次查找的次数都相等所以查询速度要比B树更稳定</li><li><strong>B+ 树天然具备排序功能：</strong>B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高</li><li>B+<strong>树全节点遍历更快：</strong>B+树遍历整棵树只需要遍历所有的<strong>叶子</strong>节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描</li></ul><p><strong>B树</strong>相对于<strong>B+树</strong>的优点是，如果经常访问的数据离根节点很近，而<strong>B树</strong>的<strong>非叶子</strong>节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比<strong>B+树</strong>快。</p><h1 id="B-树-1"><a href="#B-树-1" class="headerlink" title="B*树"></a>B*树</h1><p>B*树是B+树的变种，相对于B+树他们的不同之处如下：</p><p>（1）首先是关键字个数限制问题，B+树初始化的关键字初始化个数是cei(m/2)，b* 树的初始化个数为（cei(2/3*m)）</p><p>（2）B+树节点满时就会分裂，而B*树节点满时会检查兄弟节点是否满（因为每个节点都有指向兄弟的指针），如果兄弟节点未满则向兄弟节点转移关键字，如果兄弟节点已满，则从当前节点和兄弟节点各拿出1/3的数据创建一个新的节点出来；</p><ul><li><strong>特点</strong></li></ul><p>在B+树的基础上因其初始化的容量变大，使得节点空间使用率更高，而又存有兄弟节点的指针，可以向兄弟节点转移关键字的特性使得B*树额分解次数变得更少；</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-e8bf8ee3230f3d39d59ce5e76a2ee32e_720w.jpg" alt="img"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><strong>相同思想和策略</strong></p><p>从平衡二叉树、B树、B+树、B*树总体来看它们的贯彻的思想是相同的，都是采用二分法和数据平衡策略来提升查找数据的速度；</p><p><strong>不同的方式的磁盘空间利用</strong></p><p>不同点是他们一个一个在演变的过程中通过IO从磁盘读取数据的原理进行一步步的演变，每一次演变都是为了让节点的空间更合理的运用起来，从而使树的层级减少达到快速查找数据的目的；</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;平衡二叉树&quot;&gt;&lt;a href=&quot;#平衡二叉树&quot; class=&quot;headerlink&quot; title=&quot;平衡二叉树&quot;&gt;&lt;/a&gt;平衡二叉树&lt;/h1&gt;&lt;p&gt;平衡二叉树是基于二分法的策略提高数据的查找速度的二叉树的数据结构&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;/stron</summary>
      
    
    
    
    <category term="数据结构" scheme="https://leslieaibin.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="树" scheme="https://leslieaibin.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/"/>
    
    
    <category term="二叉树" scheme="https://leslieaibin.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
  </entry>
  
</feed>
