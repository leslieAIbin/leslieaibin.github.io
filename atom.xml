<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mr.Ai</title>
  
  <subtitle>春暖花开去见你</subtitle>
  <link href="https://leslieaibin.github.io/atom.xml" rel="self"/>
  
  <link href="https://leslieaibin.github.io/"/>
  <updated>2022-02-13T08:08:24.988Z</updated>
  <id>https://leslieaibin.github.io/</id>
  
  <author>
    <name>Leslie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>海量数据处理</title>
    <link href="https://leslieaibin.github.io/2021/12/19/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    <id>https://leslieaibin.github.io/2021/12/19/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</id>
    <published>2021-12-18T16:15:42.000Z</published>
    <updated>2022-02-13T08:08:24.988Z</updated>
    
    <content type="html"><![CDATA[<h1 id="海量数据处理的问题总结"><a href="#海量数据处理的问题总结" class="headerlink" title="海量数据处理的问题总结"></a>海量数据处理的问题总结</h1><p>所谓海量数据处理，无非就是基于海量数据上的存储、处理、操作。何谓海量，就是数据量太大，所以导致要么是无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。</p><p>解决办法呢？针对时间，需要采用巧妙的算法配合合适的数据结构，如<code>Bloom filter</code>/<code>Hash</code>/<code>bit-map</code>/<code>堆</code>/<code>数据库</code>或<code>倒排索引</code>/<code>trie</code>树。针对空间，大而化小，分而治之（<code>hash</code>映射可以做到）。</p><p>至于所谓的单机及集群问题，单机就是处理装载数据的机器有限(只要考虑CPU、内存、硬盘间的数据交互)。而集群，机器有多台，适合分布式处理、并行计算(更多考虑节点和节点间的数据交互)。</p><h1 id="题目1"><a href="#题目1" class="headerlink" title="题目1"></a>题目1</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。</p><h2 id="解答思路"><a href="#解答思路" class="headerlink" title="解答思路"></a>解答思路</h2><p>每个 URL 占 64B，那么 50 亿个 URL占用的空间大小约为 320GB。</p><pre><code>5,000,000,000 * 64B ≈ 5GB * 64 = 320GB</code></pre><p>由于内存大小只有 4G，因此，我们不可能一次性把所有 URL 加载到内存中处理。对于这种类型的题目，一般采用分治策略，即：把一个文件中的 URL 按照某个特征划分为多个小文件，使得每个小文件大小不超过 4G，这样就可以把这个小文件读到内存中进行处理了。</p><p>思路如下：</p><p>首先遍历文件 a，对遍历到的 URL 求<code>hash(URL) % 1000</code>，根据计算结果把遍历到的 URL 存储到 a0, a1, a2, …, a999，这样每个大小约为 300MB。使用同样的方法遍历文件 b，把文件 b 中的 URL 分别存储到文件 b0, b1, b2, …, b999 中。这样处理过后，所有可能相同的 URL 都在对应的小文件中，即 a0 对应 b0, …, a999 对应 b999，不对应的小文件不可能有相同的 URL。那么接下来，我们只需要求出这 1000 对小文件中相同的 URL 就好了。</p><p>接着遍历<code>ai (i∈[0,999])</code>，把 URL 存储到一个<code>HashSet</code>集合中。然后遍历 bi 中每个 URL，看在<code>HashSet</code>集合中是否存在，若存在，说明这就是共同的 URL，可以把这个 URL 保存到一个单独的文件中。</p><p>方法总结</p><ul><li>  分而治之，进行哈希取余；</li><li>  对每个子文件进行<code>HashSet</code>统计。</li></ul><h1 id="题目2"><a href="#题目2" class="headerlink" title="题目2"></a>题目2</h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。</p><h2 id="解答思路-1"><a href="#解答思路-1" class="headerlink" title="解答思路"></a>解答思路</h2><p>由于内存限制，我们依然无法直接将大文件的所有词一次读到内存中。因此，同样可以采用分治策略，把一个大文件分解成多个小文件，保证每个文件的大小小于 1MB，进而直接将单个小文件读取到内存中进行处理。</p><p>思路如下：</p><p>首先遍历大文件，对遍历到的每个词x，执行<code>hash(x) % 5000</code>，将结果为 i 的词存放到文件 ai 中。遍历结束后，我们可以得到 5000 个小文件。每个小文件的大小为 200KB 左右。如果有的小文件大小仍然超过 1MB，则采用同样的方式继续进行分解。</p><p>接着统计每个小文件中出现频数最高的 100 个词。最简单的方式是使用<code>HashMap</code>来实现。其中 key 为词，value 为该词出现的频率。具体方法是：对于遍历到的词 x，如果在 map 中不存在，则执行 map.put(x, 1)；若存在，则执行<code>map.put(x, map.get(x) + 1)</code>，将该词频数加 1。</p><p>上面我们统计了每个小文件单词出现的频数。接下来，我们可以通过维护一个小顶堆来找出所有词中出现频数最高的 100 个。具体方法是：依次遍历每个小文件，构建一个小顶堆，堆大小为 100。如果遍历到的词的出现次数大于堆顶词的出现次数，则用新词替换堆顶的词，然后重新调整为小顶堆，遍历结束后，小顶堆上的词就是出现频数最高的 100 个词。</p><h2 id="方法总结"><a href="#方法总结" class="headerlink" title="方法总结"></a>方法总结</h2><ul><li>  分而治之，进行哈希取余；</li><li>  使用<code>HashMap</code>统计频数；</li><li>  求解最大的<code>TopN</code>个，用小顶堆；求解最小的<code>TopN</code>个，用大顶堆。</li></ul><h1 id="题目3"><a href="#题目3" class="headerlink" title="题目3"></a>题目3</h1><h2 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h2><p>现有海量日志数据保存在一个超大文件中，该文件无法直接读入内存，要求从中提取某天访问百度次数最多的那个 IP。</p><h2 id="解答思路-2"><a href="#解答思路-2" class="headerlink" title="解答思路"></a>解答思路</h2><p>这道题只关心某一天访问百度最多的 IP，因此，可以首先对文件进行一次遍历，把这一天访问百度 IP 的相关信息记录到一个单独的大文件中。接下来采用的方法与上一题一样，大致就是先对 IP 进行哈希映射，接着使用<code>HashMap</code>统计重复 IP 的次数，最后计算出重复次数最多的 IP。</p><p>注：这里只需要找出出现次数最多的 IP，可以不必使用堆，直接用一个变量 max 即可。</p><h2 id="方法总结-1"><a href="#方法总结-1" class="headerlink" title="方法总结"></a>方法总结</h2><ul><li>  分而治之，进行哈希取余；</li><li>  使用<code>HashMap</code>统计频数；</li><li>  求解最大的 TopN 个，用小顶堆；求解最小的 TopN 个，用大顶堆。</li></ul><h1 id="题目4"><a href="#题目4" class="headerlink" title="题目4"></a>题目4</h1><h2 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h2><p>在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。</p><h2 id="解答思路-3"><a href="#解答思路-3" class="headerlink" title="解答思路"></a>解答思路</h2><h3 id="方法一：分治法"><a href="#方法一：分治法" class="headerlink" title="方法一：分治法"></a>方法一：分治法</h3><p>与前面的题目方法类似，先将 2.5 亿个数划分到多个小文件，用<code>HashSet</code>/<code>HashMap</code>找出每个小文件中不重复的整数，再合并每个子结果，即为最终结果。</p><h3 id="方法二：位图法"><a href="#方法二：位图法" class="headerlink" title="方法二：位图法"></a>方法二：位图法</h3><p>位图，就是用一个或多个<code>bit</code>来标记某个元素对应的值，而键就是该元素。采用位作为单位来存储数据，可以大大节省存储空间。</p><p>位图通过使用位数组来表示某些元素是否存在。它可以用于快速查找，判重，排序等。不是很清楚？我先举个小例子。</p><p>假设我们要对 [0,7] 中的 5 个元素 (6, 4, 2, 1, 5) 进行排序，可以采用位图法。0~7 范围总共有 8 个数，只需要 8bit，即 1 个字节。首先将每个位都置 0：</p><pre><code>0 0 0 0 0 0 0 0</code></pre><p>然后遍历 5 个元素，首先遇到 6，那么将下标为 6 的位的 0 置为 1；接着遇到 4，把下标为 4 的位 的 0 置为 1：</p><pre><code>0 0 0 0 1 0 1 0</code></pre><p>依次遍历，结束后，位数组是这样的：</p><pre><code>0 1 1 0 1 1 1 0</code></pre><p>每个为 1 的位，它的下标都表示了一个数：</p><pre><code>for i in range(8):    if bits[i] == 1:        print(i)</code></pre><p>这样我们其实就已经实现了排序。</p><p>对于整数相关的算法的求解，位图法是一种非常实用的算法。假设 int 整数占用 4B，即 32bit，那么我们可以表示的整数的个数为 2^32。</p><p>那么对于这道题，我们用 2 个 bit 来表示各个数字的状态：</p><ul><li>  00 表示这个数字没出现过；</li><li>  01 表示这个数字出现过一次（即为题目所找的不重复整数）；</li><li>  10 表示这个数字出现了多次。</li></ul><p>那么这 2^32 个整数，总共所需内存为 2^32*2b=1GB。因此，当可用内存超过 1GB 时，可以采用位图法。假设内存满足位图法需求，进行下面的操作：</p><p>遍历 2.5 亿个整数，查看位图中对应的位，如果是 00，则变为 01，如果是 01 则变为 10，如果是 10 则保持不变。遍历结束后，查看位图，把对应位是 01 的整数输出即可。</p><h2 id="方法总结-2"><a href="#方法总结-2" class="headerlink" title="方法总结"></a>方法总结</h2><p>判断数字是否重复的问题，位图法是一种非常高效的方法。</p><h1 id="题目5"><a href="#题目5" class="headerlink" title="题目5"></a>题目5</h1><h2 id="题目描述-3"><a href="#题目描述-3" class="headerlink" title="题目描述"></a>题目描述</h2><p>给定 40 亿个不重复的没排过序的<code>unsigned int</code>型整数，然后再给定一个数，如何快速判断这个数是否在这 40 亿个整数当中？</p><h2 id="解答思路-4"><a href="#解答思路-4" class="headerlink" title="解答思路"></a>解答思路</h2><h3 id="方法一：分治法-1"><a href="#方法一：分治法-1" class="headerlink" title="方法一：分治法"></a>方法一：分治法</h3><p>依然可以用分治法解决，方法与前面类似，就不再次赘述了。</p><h3 id="方法二：位图法-1"><a href="#方法二：位图法-1" class="headerlink" title="方法二：位图法"></a>方法二：位图法</h3><p>40 亿个不重复整数，我们用 40 亿个 bit 来表示，初始位均为 0，那么总共需要内存：4,000,000,000b ≈ 512M。</p><p>我们读取这 40 亿个整数，将对应的 bit 设置为 1。接着读取要查询的数，查看相应位是否为 1，如果为 1 表示存在，如果为 0 表示不存在。</p><h2 id="方法总结-3"><a href="#方法总结-3" class="headerlink" title="方法总结"></a>方法总结</h2><p>判断数字是否存在、判断数字是否重复的问题，位图法是一种非常高效的方法。</p><h1 id="题目6"><a href="#题目6" class="headerlink" title="题目6"></a>题目6</h1><h2 id="题目描述-4"><a href="#题目描述-4" class="headerlink" title="题目描述"></a>题目描述</h2><p>搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询床的长度不超过 255 字节。</p><p>假设目前有 1000w 个记录（这些查询串的重复度比较高，虽然总数是 1000w，但如果除去重复后，则不超过 300w 个）。请统计最热门的 10 个查询串，要求使用的内存不能超过 1G。（一个查询串的重复度越高，说明查询它的用户越多，也就越热门。）</p><h2 id="解答思路-5"><a href="#解答思路-5" class="headerlink" title="解答思路"></a>解答思路</h2><p>每个查询串最长为 255B，1000w 个串需要占用 约 2.55G 内存，因此，我们无法将所有字符串全部读入到内存中处理。</p><h3 id="方法一：分治法-2"><a href="#方法一：分治法-2" class="headerlink" title="方法一：分治法"></a>方法一：分治法</h3><p>分治法依然是一个非常实用的方法。</p><p>划分为多个小文件，保证单个小文件中的字符串能被直接加载到内存中处理，然后求出每个文件中出现次数最多的 10 个字符串；最后通过一个小顶堆统计出所有文件中出现最多的 10 个字符串。</p><p>方法可行，但不是最好，下面介绍其他方法。</p><h3 id="方法二：HashMap-法"><a href="#方法二：HashMap-法" class="headerlink" title="方法二：HashMap 法"></a>方法二：HashMap 法</h3><p>虽然字符串总数比较多，但去重后不超过 300w，因此，可以考虑把所有字符串及出现次数保存在一个<code>HashMap</code>中，所占用的空间为 300w*(255+4)≈777M（其中，4表示整数占用的4个字节）。由此可见，1G 的内存空间完全够用。</p><p>思路如下：</p><p>首先，遍历字符串，若不在 map 中，直接存入 map，value 记为 1；若在 map 中，则把对应的 value 加 1，这一步时间复杂度 O(N)。</p><p>接着遍历 map，构建一个 10 个元素的小顶堆，若遍历到的字符串的出现次数大于堆顶字符串的出现次数，则进行替换，并将堆调整为小顶堆。</p><p>遍历结束后，堆中 10 个字符串就是出现次数最多的字符串。这一步时间复杂度 O(Nlog10)。</p><h3 id="方法三：前缀树法"><a href="#方法三：前缀树法" class="headerlink" title="方法三：前缀树法"></a>方法三：前缀树法</h3><p>方法二使用了<code>HashMap</code>来统计次数，当这些字符串有大量相同前缀时，可以考虑使用前缀树来统计字符串出现的次数，树的结点保存字符串出现次数，0 表示没有出现。</p><p>思路如下：</p><p>在遍历字符串时，在前缀树中查找，如果找到，则把结点中保存的字符串次数加 1，否则为这个字符串构建新结点，构建完成后把叶子结点中字符串的出现次数置为 1。</p><p>最后依然使用小顶堆来对字符串的出现次数进行排序。</p><h2 id="方法总结-4"><a href="#方法总结-4" class="headerlink" title="方法总结"></a>方法总结</h2><p>前缀树经常被用来统计字符串的出现次数。它的另外一个大的用途是字符串查找，判断是否有重复的字符串等。</p><h1 id="题目7"><a href="#题目7" class="headerlink" title="题目7"></a>题目7</h1><h2 id="题目描述-5"><a href="#题目描述-5" class="headerlink" title="题目描述"></a>题目描述</h2><p>已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。</p><h2 id="解答思路-6"><a href="#解答思路-6" class="headerlink" title="解答思路"></a>解答思路</h2><p>这道题本质还是求解数据重复的问题，对于这类问题，一般首先考虑位图法。</p><p>对于本题，8 位电话号码可以表示的号码个数为 108 个，即 1 亿个。我们每个号码用一个 bit 来表示，则总共需要 1 亿个 bit，内存占用约 100M。</p><p>思路如下：</p><p>申请一个位图数组，长度为 1 亿，初始化为 0。然后遍历所有电话号码，把号码对应的位图中的位置置为 1。遍历完成后，如果 bit 为 1，则表示这个电话号码在文件中存在，否则不存在。bit 值为 1 的数量即为 不同电话号码的个数。</p><h2 id="方法总结-5"><a href="#方法总结-5" class="headerlink" title="方法总结"></a>方法总结</h2><p>求解数据重复问题，记得考虑位图法。</p><h1 id="题目8"><a href="#题目8" class="headerlink" title="题目8"></a>题目8</h1><p>题目描述 从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 (N+1)/2 个数；当样本数为偶数时，中位数为 第 N/2 个数与第 1+N/2 个数的均值。</p><h2 id="解答思路-7"><a href="#解答思路-7" class="headerlink" title="解答思路"></a>解答思路</h2><p>如果这道题没有内存大小限制，则可以把所有数读到内存中排序后找出中位数。但是最好的排序算法的时间复杂度都为 O(NlogN)。这里使用其他方法。</p><h3 id="方法一：双堆法"><a href="#方法一：双堆法" class="headerlink" title="方法一：双堆法"></a>方法一：双堆法</h3><p>维护两个堆，一个大顶堆，一个小顶堆。大顶堆中最大的数小于等于小顶堆中最小的数；保证这两个堆中的元素个数的差不超过 1。</p><p>若数据总数为偶数，当这两个堆建好之后，中位数就是这两个堆顶元素的平均值。当数据总数为奇数时，根据两个堆的大小，中位数一定在数据多的堆的堆顶。</p><p>以上这种方法，需要把所有数据都加载到内存中。当数据量很大时，就不能这样了，因此，这种方法适用于数据量较小的情况。5 亿个数，每个数字占用 4B，总共需要 2G 内存。如果可用内存不足 2G，就不能使用这种方法了，下面介绍另一种方法。</p><h3 id="方法二：分治法"><a href="#方法二：分治法" class="headerlink" title="方法二：分治法"></a>方法二：分治法</h3><p>分治法的思想是把一个大的问题逐渐转换为规模较小的问题来求解。</p><p>对于这道题，顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为1，则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）。</p><p>划分之后，可以非常容易地知道中位数是在 f0 还是 f1 中。假设 f1 中有 1 亿个数，那么中位数一定在 f0 中，且是在 f0 中，从小到大排列的第 1.5 亿个数与它后面的一个数的平均值。</p><p>提示，5 亿数的中位数是第 2.5 亿与右边相邻一个数求平均值。若 f1 有一亿个数，那么中位数就是 f0 中从第 1.5 亿个数开始的两个数求得的平均值。 对于 f0 可以用次高位的二进制继续将文件一分为二，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。</p><p>注意，当数据总数为偶数，如果划分后两个文件中的数据有相同个数，那么中位数就是数据较小的文件中的最大值与数据较大的文件中的最小值的平均值。</p><h2 id="方法总结-6"><a href="#方法总结-6" class="headerlink" title="方法总结"></a>方法总结</h2><p>分治法，真香！</p><h1 id="题目9"><a href="#题目9" class="headerlink" title="题目9"></a>题目9</h1><h2 id="题目描述-6"><a href="#题目描述-6" class="headerlink" title="题目描述"></a>题目描述</h2><p>有 10 个文件，每个文件大小为 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求按照 query 的频度排序。</p><h2 id="解答思路-8"><a href="#解答思路-8" class="headerlink" title="解答思路"></a>解答思路</h2><p>如果 query 的重复度比较大，可以考虑一次性把所有 query 读入内存中处理；如果 query 的重复率不高，那么可用内存不足以容纳所有的 query，这时候就需要采用分治法或其他的方法来解决。</p><h3 id="方法一：HashMap法"><a href="#方法一：HashMap法" class="headerlink" title="方法一：HashMap法"></a>方法一：<code>HashMap</code>法</h3><p>如果 query 重复率高，说明不同 query 总数比较小，可以考虑把所有的 query 都加载到内存中的<code>HashMap</code>中。接着就可以按照 query 出现的次数进行排序。</p><h3 id="方法二：分治法-1"><a href="#方法二：分治法-1" class="headerlink" title="方法二：分治法"></a>方法二：分治法</h3><p>分治法需要根据数据量大小以及可用内存的大小来确定问题划分的规模。对于这道题，可以顺序遍历 10 个文件中的 query，通过 Hash 函数 hash(query) % 10 把这些 query 划分到 10 个小文件中。之后对每个小文件使用<code>HashMap</code>统计 query 出现次数，根据次数排序并写入到零外一个单独文件中。</p><p>接着对所有文件按照 query 的次数进行排序，这里可以使用归并排序（由于无法把所有 query 都读入内存，因此需要使用外排序）。</p><h2 id="方法总结-7"><a href="#方法总结-7" class="headerlink" title="方法总结"></a>方法总结</h2><ul><li>  内存若够，直接读入进行排序；</li><li>  内存不够，先划分为小文件，小文件排好序后，整理使用外排序进行归并。</li></ul><h1 id="题目10"><a href="#题目10" class="headerlink" title="题目10"></a>题目10</h1><h2 id="题目描述-7"><a href="#题目描述-7" class="headerlink" title="题目描述"></a>题目描述</h2><p>有 20 个数组，每个数组有 500 个元素，并且有序排列。如何在这 20*500 个数中找出前 500 的数？</p><h2 id="解答思路-9"><a href="#解答思路-9" class="headerlink" title="解答思路"></a>解答思路</h2><p>对于 TopK 问题，最常用的方法是使用堆排序。对本题而言，假设数组降序排列，可以采用以下方法：</p><p>首先建立大顶堆，堆的大小为数组的个数，即为 20，把每个数组最大的值存到堆中。</p><p>接着删除堆顶元素，保存到另一个大小为 500 的数组中，然后向大顶堆插入删除的元素所在数组的下一个元素。</p><p>重复上面的步骤，直到删除完第 500 个元素，也即找出了最大的前 500 个数。</p><p>为了在堆中取出一个数据后，能知道它是从哪个数组中取出的，从而可以从这个数组中取下一个值，可以把数组的指针存放到堆中，对这个指针提供比较大小的方法。</p><h2 id="方法总结-8"><a href="#方法总结-8" class="headerlink" title="方法总结"></a>方法总结</h2><p>求 TopK，不妨考虑一下堆排序？</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;海量数据处理的问题总结&quot;&gt;&lt;a href=&quot;#海量数据处理的问题总结&quot; class=&quot;headerlink&quot; title=&quot;海量数据处理的问题总结&quot;&gt;&lt;/a&gt;海量数据处理的问题总结&lt;/h1&gt;&lt;p&gt;所谓海量数据处理，无非就是基于海量数据上的存储、处理、操作。何谓海量</summary>
      
    
    
    
    
    <category term="Java" scheme="https://leslieaibin.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>超卖问题</title>
    <link href="https://leslieaibin.github.io/2021/12/18/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/%E5%AE%9A%E4%BD%8D%E9%97%AE%E9%A2%98/"/>
    <id>https://leslieaibin.github.io/2021/12/18/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/%E5%AE%9A%E4%BD%8D%E9%97%AE%E9%A2%98/</id>
    <published>2021-12-17T16:15:42.000Z</published>
    <updated>2022-02-13T03:55:26.098Z</updated>
    
    <content type="html"><![CDATA[<h3 id="定位问题的先决条件"><a href="#定位问题的先决条件" class="headerlink" title="定位问题的先决条件"></a>定位问题的先决条件</h3><p>需要有详细的日志记录，提前告警的监控平台，事发现场保留</p><blockquote><p>日志 ：业务日志，中间件日志<br>监控 ：CPU、内存、磁盘、网络，类加载、GC、线程等<br>快照 ：-XX:+HeapDumpOnOutOfMemoryError 和 -XX:HeapDumpPath</p></blockquote><h3 id="分析问题，解决问题的思路"><a href="#分析问题，解决问题的思路" class="headerlink" title="分析问题，解决问题的思路"></a>分析问题，解决问题的思路</h3><blockquote><p>经验+直觉，快速定位 &gt; 逐一排查，传输链路 &gt; 寻找规律 不要轻易怀疑监控。考虑资源。优先保证系统能正常运行。保留现场，事后排查定位问题。</p></blockquote><blockquote><p>逐一排查，传输链路，通过日志或工具逐一排查</p><ol><li>内部原因，是否是客户端或者前端问题，程序发布后的Bug，回滚后可以立即解决</li><li>外部原因，比如服务，第三方服务，主机、组件的问题。<ol><li>服务：错误日志邮件提醒或elk快速定位问题，查看gc日志</li><li>第三方服务：单独调用测试，联系第三方加急解决</li><li>主机： CPU相关问题，可以使用 top、vmstat、pidstat、ps 等工具排查； 内存相关问题，可以使用 free、top、ps、vmstat、cachestat、sar 等工具排查；IO 相关问题，可以使用 lsof、iostat、pidstat、sar、iotop、df、du 等工具排查；网络相关问题，可以使用 ifconfig、ip、nslookup、dig、ping、tcpdump、iptables等工具排查。</li><li>组件：查看日志输出，使用命令查看运行情况</li></ol></li><li>因为系统资源不够造成系统假死的问题，通常需要先通过重启和扩容解决问题，之后再进行分析，系统资源不够，一般体现在 CPU 使用高、 内存泄漏或OOM 的问题、IO问题、网络相关问题这四个方面</li></ol></blockquote><h3 id="分析问题的方法"><a href="#分析问题的方法" class="headerlink" title="分析问题的方法"></a>分析问题的方法</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">jps -v 查看java进程</span><br><span class="line">jinfo -flags pid 查看运行参数</span><br><span class="line">jstat -gc 8544 5000 100，将每隔5s采样一次pid为8544的gc，输出100次</span><br><span class="line"></span><br><span class="line">jmap -dump:live,format=b,file=dump.hprof 29170 </span><br><span class="line"><span class="meta">#</span><span class="bash">生成虚拟机的内存转储快照 注意线上可能会触发线上gc</span></span><br><span class="line">jmap -heap 29170</span><br><span class="line">jmap -histo:live 29170 | more</span><br><span class="line">jmap -permstat 29170</span><br><span class="line"></span><br><span class="line">jstack -l 29170 |more 显示虚拟机的线程快照</span><br><span class="line"></span><br><span class="line">df -h # 磁盘 </span><br><span class="line">free -m / -h # 内存</span><br><span class="line">top cpu  # cpu          </span><br><span class="line"></span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><h3 id="线上cpu100-报警（找出最耗时CPU进程-线程-堆栈-代码）"><a href="#线上cpu100-报警（找出最耗时CPU进程-线程-堆栈-代码）" class="headerlink" title="线上cpu100%报警（找出最耗时CPU进程-线程-堆栈-代码）"></a>线上cpu100%报警（找出最耗时CPU进程-线程-堆栈-代码）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">方法1：原生工具，慢</span><br><span class="line">top -c #显示完整信息  P：cpu使用排序 M：内存使用排序</span><br><span class="line">top -Hp 10765 ，#显示一个进程的线程运行信息列表  -H 显示线程信息，-p指定pid &amp; P</span><br><span class="line">printf &quot;%x\n&quot; 10804    转16进制   2f71</span><br><span class="line">jstack 12084 | grep &#x27;0x2f71&#x27; -C5 --color 查看堆栈，找到线程在干嘛</span><br><span class="line"></span><br><span class="line">方法2：</span><br><span class="line">使用提前准备好的sh脚本，可以一条命名查看当前出事的线程代码，快，推荐</span><br><span class="line">sh show-busy-java-threads.sh &gt; a.txt #查询java耗时线程前5个</span><br><span class="line">sh show-busy-java-threads.sh -p &gt; a.txt #查询指定进程</span><br><span class="line"></span><br><span class="line">方法3：</span><br><span class="line">使用arthas，工具内置很多功能，比如可以查看源码，判断是否发布成功，可以用来排查疑难问题</span><br><span class="line">curl -O https://alibaba.github.io/arthas/arthas-boot.jar</span><br><span class="line">java -jar arthas-boot.jar</span><br><span class="line">dashboard</span><br><span class="line">thread -8</span><br><span class="line">jad com.xx.xx.xx.xxximp 查看线上类代码</span><br><span class="line">watch com.xx.xx.xx.xxximp doTask &#x27;&#123;params&#125;&#x27; &#x27;#cost&gt;100&#x27; -x 2 </span><br><span class="line"><span class="meta">#</span><span class="bash">观察会慢在什么入参上，监控耗时超过100毫秒的 doTask方法的入参，并且输出入参，展开2层入参参数</span></span><br><span class="line">ognl #查询某静态字段的值</span><br><span class="line"></span><br><span class="line">定位到堆栈就可以定位到出问题代码的行号，然后找对应的发布分支代码该行号即可</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><h3 id="线上内存OOM"><a href="#线上内存OOM" class="headerlink" title="线上内存OOM"></a>线上内存OOM</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">某Java服务（假设PID&#x3D;12084）出现了OOM，最常见的原因为：</span><br><span class="line">1. 有可能是内存分配确实过小，而正常业务使用了大量内存</span><br><span class="line">2. 某一个对象被频繁申请，却没有释放，内存不断泄漏，导致内存耗尽未调用close()，dispose()释放资源，例如：文件io，网络io</span><br><span class="line">3. 某一个资源被频繁申请，系统资源耗尽，例如：不断创建线程（没有用线程池），不断发起网络连接等</span><br><span class="line">总结：本身资源不够，申请资源太多，资源耗尽</span><br><span class="line"></span><br><span class="line">分析工具：</span><br><span class="line">jvisualvm（直方图），MAT（优先，直方图，跟踪内存使用的引用关系），JProfiler</span><br><span class="line"></span><br><span class="line">线下分析：</span><br><span class="line">服务挂掉之后有保留文件：直接下载dump文件导入mat分析</span><br><span class="line">java -jar -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;</span><br><span class="line"></span><br><span class="line">线上分析：</span><br><span class="line">1. 确认是不是内存本身就分配过小</span><br><span class="line">jmap -heap 12084</span><br><span class="line"></span><br><span class="line">2. 找到最耗内存的对象</span><br><span class="line">jmap -histo:live 12084 | head -n 10  #该命令会强制执行一次fgc</span><br><span class="line"></span><br><span class="line">jmap -dump:format&#x3D;b,file&#x3D;&#x2F;opt&#x2F;dump.hprof &#123;pid&#125; #以二进制输出档当前内存的堆情况，</span><br><span class="line">然后可以导入MAT等工具进行</span><br><span class="line">tar –czf dump.tar.gz dump.hprof</span><br><span class="line"></span><br><span class="line">3. 确认进程创建的线程数，以及网络连接数，如果资源耗尽，也可能出现OOM</span><br><span class="line">ll &#x2F;proc&#x2F;17306&#x2F;fd | wc -l</span><br><span class="line">ll &#x2F;proc&#x2F;17306&#x2F;task | wc -l</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><h3 id="如何防止线上问题发生"><a href="#如何防止线上问题发生" class="headerlink" title="如何防止线上问题发生"></a>如何防止线上问题发生</h3><blockquote><p>数据库：上线一个定时监控和杀掉慢SQL的脚本。这个脚本每分钟执行一次，检测上一分钟内，有没有执行时间超过一分钟（这个阈值可以根据实际情况调整）的慢SQL，如果有大事务自己觉得该阈值的合理性，如果发现，直接杀掉这个会话</p></blockquote><blockquote><p>cpu或者内存的使用率上做报警，大于90%的时候可以dump和jstack一次，甚至jstat也可以做，然后95%的时候也同样执行一次，甚至98或者99的时候也可以做一次，这样不仅可以保留现场，同时还可以对比</p></blockquote><blockquote><p>完善的服务报错日志监控，可选elfk+日志监控或sentry</p></blockquote><blockquote><p>完善的流程机制。完善的主机，中间件监控报警机制</p></blockquote><h3 id="遇到过的线上问题以及解决思路"><a href="#遇到过的线上问题以及解决思路" class="headerlink" title="遇到过的线上问题以及解决思路"></a>遇到过的线上问题以及解决思路</h3><blockquote><p><a href="https://link.juejin.cn/?target=https://chenyongjun.vip/articles/76">Zuul 网关不响应任何请求，zuul假死</a></p></blockquote><blockquote><p>App打不开，请求超时，访问数据库超时，数据库cpu飙升有规律，在某个时间点才飙升，去调度中心找该时间断的的定时任务，排查是异步转账开多了线程导致的</p></blockquote><h3 id="工具汇总"><a href="#工具汇总" class="headerlink" title="工具汇总"></a>工具汇总</h3><ul><li>去哪儿bistour</li><li>mat 分析堆快照</li><li>arthas <a href="https://link.juejin.cn/?target=https://arthas.aliyun.com/doc/quick-start.html">arthas.aliyun.com/doc/quick-s…</a></li><li><a href="https://link.juejin.cn/?target=https://gceasy.io">gceasy.io</a> #在线gc日志，dump文件分析</li><li><a href="https://link.juejin.cn/?target=https://fastthread.io">fastthread.io</a> #在线gc日志，dump文件分析</li><li><a href="https://link.juejin.cn/?target=https://console.perfma.com">console.perfma.com</a> #在线生成jvm参数</li></ul><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="https://link.juejin.cn/?target=https://www.bbsmax.com/A/6pdD7b2X5w/">www.bbsmax.com/A/6pdD7b2X5…</a></li><li><a href="https://link.juejin.cn/?target=https://cloud.tencent.com/developer/article/1600345">cloud.tencent.com/developer/a…</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;定位问题的先决条件&quot;&gt;&lt;a href=&quot;#定位问题的先决条件&quot; class=&quot;headerlink&quot; title=&quot;定位问题的先决条件&quot;&gt;&lt;/a&gt;定位问题的先决条件&lt;/h3&gt;&lt;p&gt;需要有详细的日志记录，提前告警的监控平台，事发现场保留&lt;/p&gt;
&lt;blockquot</summary>
      
    
    
    
    
    <category term="Java" scheme="https://leslieaibin.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>bitMap讲解</title>
    <link href="https://leslieaibin.github.io/2021/12/14/java%E5%9F%BA%E7%A1%80/bitMap%E8%AE%B2%E8%A7%A3/"/>
    <id>https://leslieaibin.github.io/2021/12/14/java%E5%9F%BA%E7%A1%80/bitMap%E8%AE%B2%E8%A7%A3/</id>
    <published>2021-12-14T01:15:42.000Z</published>
    <updated>2021-12-14T14:59:51.979Z</updated>
    
    <content type="html"><![CDATA[<h3 id="小知识"><a href="#小知识" class="headerlink" title="小知识"></a>小知识</h3><ol><li>在实际项目中，我们经常需要聚合统计，比如统计一个年龄在20-30，喜欢看技术书籍，喜欢听音乐，喜欢宅在家的程序员等等一系列标签的用户。 如果使用mysql求并集，首先语句随着标签变长而变长，其次聚合，分组，去重严重影响语句性能。这种情况如何解决？</li><li>比如现在比较火的面试题，在10亿整数中找出100个重复的数，或者任意给定一个整数，判断是否在这个10亿数中。</li></ol><h3 id="bitMap原理"><a href="#bitMap原理" class="headerlink" title="bitMap原理"></a>bitMap原理</h3><p>bitMap就是使用bit位来标记元素，key为该元素，value一般为0或者1，大大节省存储空间.</p><p>现在有(2, 3, 4, 5，7)5个数，任意给定一个在0-7范围内的数字，判断是否在此集合中：</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20211214225035132.png" alt="image-20211214225035132"></p><ul><li><p>创建一个范围为(0-7)的Byte类型数组，将集合数字对应数组的bit位置置1；</p></li><li><p>然后遍历该Byte数组，如果Byte数组位置为1即代表该数存在。</p></li><li><p>同理对于10亿整数也可以这样处理，一个int型数字4个字节，32bit，如果使用bit标记正整数，就可以节省32倍的内存空间。</p></li><li><p>10亿数字，40亿字节，320亿bit，需要大约4g内存，使用bitMap标记，只需要125M内存空间即可存储，大大节省内存空间。</p></li></ul><p>以上和桶排序排序的思想非常相似。</p><h3 id="bitMap实际运用"><a href="#bitMap实际运用" class="headerlink" title="bitMap实际运用"></a>bitMap实际运用</h3><p>对于1千万数据，判断任意给定的数是否在其中？<br> 分治思想<br> 使用int数组作为bitMap。<br> 将数组分成32组，每组内有(0-31)个位置，如果给定数组在指定数组中的bit是0，则不存在。</p><ol><li>求十进制数在对应数组a中的下标<br> a[i] = a[N/32]</li><li>求int[]中bit位置<br> index = a[i] % 32</li></ol><p>上述两个运算可以改成位运算，因为位运算的效率非常高，占用cpu的时钟周期非常少。<br> 结论：对于2的倍数，%2^n = &amp;(2^n-1),模运算等于与预算，例：a % 16 = a &amp; 15,这里的15做与运算时需要化成16进制，即0x0F.</p><p>在10000000个范围为[1-100000]数中，给定指定一个数，判断是否在这个集合中</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BitMapActual</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1千万数据集合</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> N = <span class="number">10000000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//bitmap数组</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span>[] a = <span class="keyword">new</span> <span class="keyword">int</span>[N/<span class="number">32</span> + <span class="number">1</span>]; <span class="comment">//int 等于32个bit 所以数据长度为(N/32+1)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 为集合数据加标记</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> n</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">addValue</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定位数组编号 相当于n/32</span></span><br><span class="line">        <span class="keyword">int</span> row = n &gt;&gt; <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定位数组内slot位置 相当于n%32</span></span><br><span class="line">        <span class="keyword">int</span> offset = n &amp; <span class="number">0x1F</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//数组slot置1</span></span><br><span class="line">        a[row] |= <span class="number">1</span> &lt;&lt; offset;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断给定数字是否存在</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> n</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">exits</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定位数组编号</span></span><br><span class="line">        <span class="keyword">int</span> row = n &gt;&gt; <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定位数组内slot位置</span></span><br><span class="line">        <span class="keyword">int</span> offset = n &amp; <span class="number">0x1F</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 &lt;&lt; position 将a[i]中左移position求与,slot位置有值返回true</span></span><br><span class="line">        <span class="keyword">return</span> (a[row] &amp; ( <span class="number">1</span> &lt;&lt; offset)) != <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//初始化一个长度为N的数组</span></span><br><span class="line">        <span class="keyword">int</span> num[] = <span class="keyword">new</span> <span class="keyword">int</span>[N];</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">            <span class="comment">//随机数范围是(0-100000)</span></span><br><span class="line">            <span class="keyword">int</span> item = random.nextInt(<span class="number">100000</span>);</span><br><span class="line">            num[i] = item;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        BitMapActual map = <span class="keyword">new</span> BitMapActual();</span><br><span class="line">        <span class="comment">//置1</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">            map.addValue(num[i]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> temp = <span class="number">200</span>;</span><br><span class="line">        <span class="keyword">if</span>(map.exits(temp))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;temp:&quot;</span> + temp + <span class="string">&quot;has already exists&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;temp:&quot;</span> + temp + <span class="string">&quot;has no exists&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;小知识&quot;&gt;&lt;a href=&quot;#小知识&quot; class=&quot;headerlink&quot; title=&quot;小知识&quot;&gt;&lt;/a&gt;小知识&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;在实际项目中，我们经常需要聚合统计，比如统计一个年龄在20-30，喜欢看技术书籍，喜欢听音乐，喜欢宅在家的程序员等等一系</summary>
      
    
    
    
    <category term="计算机基础知识" scheme="https://leslieaibin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
  </entry>
  
  <entry>
    <title>反射机制</title>
    <link href="https://leslieaibin.github.io/2021/12/12/java%E5%9F%BA%E7%A1%80/%E5%8F%8D%E5%B0%84/"/>
    <id>https://leslieaibin.github.io/2021/12/12/java%E5%9F%BA%E7%A1%80/%E5%8F%8D%E5%B0%84/</id>
    <published>2021-12-12T01:15:42.000Z</published>
    <updated>2022-02-13T08:21:49.595Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RPC框架手撕之路—java反射以及动态代理机制"><a href="#RPC框架手撕之路—java反射以及动态代理机制" class="headerlink" title="RPC框架手撕之路—java反射以及动态代理机制"></a>RPC框架手撕之路—java反射以及动态代理机制</h1><p><a href="https://www.helloworld.net/p/1793714313">www.helloworld.net</a>lzy 2021-10-05 15:37 748 0 0</p><p>在上一篇文章中，我们提到了，RPC框架所需要的java基础，第一点就是java的动态代理机制，动态代理机制的基础是反射，无论是在实际编程或者是面试时，都是java知识的重中之重。</p><h3 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h3><p>在运行状态中，对于任意一个类，都能够知道这一个类的所有属性和方法，对于任意一个对象都能够通过反射机制调用一个类的任意方法，这种动态获取类信息以及动态调用类方法的功能称为java的反射机制。</p><h3 id="作用："><a href="#作用：" class="headerlink" title="作用："></a>作用：</h3><p>1、动态的创建类的实例，将类绑定到现有对象中，或从现有对象中获取类型。 2、应用程序需要在运行时从某个特定的程序集中载入一个特定的类。</p><p>个人理解的反射机制就是，某些类在程序运行的一开始并没有加载，但是随着程序的运行，我们发现这些类也需要用到，此时就可以通过反射机制，来获取到类的属性和方法。</p><h2 id="代理模式："><a href="#代理模式：" class="headerlink" title="代理模式："></a>代理模式：</h2><h3 id="定义：-1"><a href="#定义：-1" class="headerlink" title="定义："></a>定义：</h3><p>委托模式，是为某个对象提供一个代理对象，并且由代理对象控制对原对象的访问。代理模式通俗来讲就是我们生活中常见的中介。代理模式可以提供非常好的访问控制，应用比较广泛。</p><p>而其中的代理模式中的动态代理不仅在rpc远程访问中有重要的应用，同样在Spring AOP和其他应用中也起到了很重要的作用。</p><p>代理模式的通用类图：</p><p><img src="https://cubox.pro/c/filters:no_upscale()?imageUrl=https://img-hello-world.oss-cn-beijing.aliyuncs.com/imgs/173d2f9e1a2f5a8f6d0010cb64a7677c.png"></p><p><strong>Subject：</strong> 抽象主题角色：可以是抽象类，也可以是接口。抽象主题是一个普通的业务类型，无特殊要求。</p><p><strong>RealSubject：</strong> 具体主题角色：也叫做被委托角色或被代理角色，是业务逻辑的具体执行者。</p><p><strong>Proxy：</strong> 代理主题角色：也叫做委托类或代理类。它负责对真实角色的应用，把所有抽象主题类定义的方法限制委托给真实主题角色实现，并且在具体主题角色处理完毕前后做预处理和善后处理工作。</p><p>按照代理创建的时期来进行分类，可以分为动态代理和静态代理。</p><h3 id="静态代理："><a href="#静态代理：" class="headerlink" title="静态代理："></a>静态代理：</h3><p>一个代理类只能实现一种抽象主题角色，在程序运行之前，代理类.class文件就已经被创建，代理类和委托类的关系在运行前就确定。</p><h3 id="动态代理："><a href="#动态代理：" class="headerlink" title="动态代理："></a>动态代理：</h3><p>一个代理类通过反射机制，可以实现多种不类型的抽象主题角色。动态代理类的源码是在程序运行期间由JVM根据反射等机制动态的生成，所以不存在代理类的字节码文件。代理类和委托类的关系是在程序运行时确定。以下为动态代理概括图： <img src="https://cubox.pro/c/filters:no_upscale()?imageUrl=https://img-hello-world.oss-cn-beijing.aliyuncs.com/imgs/cb919ba78df42f8a74cbc96a317ed2d1.png"></p><p>实现代码块如下：</p><p><strong>抽象角色类实现</strong>(动态代理的抽象决策类只能使用接口)：</p><pre><code>public interface Subject &#123;    /**     * 接口方法，抽象主题类     */    public void request();&#125;</code></pre><p><strong>具体决策类实现：</strong></p><pre><code>public class ConcreteSubject implements Subject&#123;    /**     * 具体业务实现逻辑     */    @Override    public void request() &#123;        //业务处理逻辑        System.out.println(&quot;逻辑执行&quot;);    &#125;&#125;</code></pre><p><strong>动态创建代理对象的类</strong>(代理类，使用反射机制):</p><pre><code>import lombok.extern.slf4j.Slf4j;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;</code></pre><p>​<br>    public class ProxyHandler implements InvocationHandler {<br>        /**<br>         *<br>         * @param proxy<br>         * @param method<br>         * @param args<br>         * @return<br>         * @throws Throwable<br>         */</p><pre><code>    /**     *目标对象     */    private Object target;    /**     */    public Object newProxyInstance(Object target)&#123;       this.target = target;       Object result = Proxy.newProxyInstance(target.getClass().getClassLoader(),               target.getClass().getInterfaces(),this);       return result;    &#125;    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        //TODO原对象方法调用添加的预处理逻辑        Object ret = null;        try&#123;            //调用目标方法            ret = method.invoke(target, args);        &#125;catch (Exception e)&#123;            //log(&quot;调用&#123;&#125;.&#123;&#125;发生异常&quot;, target.getClass().getName(), method.getName(), e);            throw e;        &#125;        return ret;    &#125;&#125;</code></pre><p><strong>客户端类</strong>：</p><pre><code>import lombok.extern.slf4j.Slf4j;import java.util.logging.Logger;</code></pre><p>​<br>    public class Client {<br>        public static void main(String[] args){<br>            System.out.println(“开始”);<br>            ProxyHandler handler = new ProxyHandler();<br>            Subject subject = (Subject) handler.newProxyInstance(new ConcreteSubject());<br>            subject.request();<br>            System.out.println(“结束”);<br>        }<br>    }</p><p>运行结果： <img src="https://cubox.pro/c/filters:no_upscale()?imageUrl=https://img-hello-world.oss-cn-beijing.aliyuncs.com/imgs/943b059667471fd616a3c403f1f574b0.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;RPC框架手撕之路—java反射以及动态代理机制&quot;&gt;&lt;a href=&quot;#RPC框架手撕之路—java反射以及动态代理机制&quot; class=&quot;headerlink&quot; title=&quot;RPC框架手撕之路—java反射以及动态代理机制&quot;&gt;&lt;/a&gt;RPC框架手撕之路—java</summary>
      
    
    
    
    <category term="计算机基础知识" scheme="https://leslieaibin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
  </entry>
  
  <entry>
    <title>Redis缓存与数据库一致性问题</title>
    <link href="https://leslieaibin.github.io/2021/11/30/Redis/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%20Redis%20%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F/"/>
    <id>https://leslieaibin.github.io/2021/11/30/Redis/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%20Redis%20%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F/</id>
    <published>2021-11-30T01:15:42.000Z</published>
    <updated>2021-12-08T15:17:18.413Z</updated>
    
    <content type="html"><![CDATA[<p>在做系统优化时，想到了将数据进行分级存储的思路。因为在系统中会存在一些数据，有些数据的实时性要求不高，比如一些配置信息。</p><p>基本上配置了很久才会变一次。而有一些数据实时性要求非常高，比如订单和流水的数据。所以这里根据数据要求实时性不同将数据分为三级。</p><ul><li>第1级：订单数据和支付流水数据；这两块数据对实时性和精确性要求很高，所以不添加任何缓存，读写操作将直接操作数据库。</li><li>第2级：用户相关数据；这些数据和用户相关，具有读多写少的特征，所以我们使用redis进行缓存。</li><li>第3级：支付配置信息；这些数据和用户无关，具有数据量小，频繁读，几乎不修改的特征，所以我们使用本地内存进行缓存。</li></ul><p>但是只要使用到缓存，无论是本地内存做缓存还是使用 redis 做缓存，那么就会存在数据同步的问题，因为配置信息缓存在内存中，而内存时无法感知到数据在数据库的修改。这样就会造成数据库中的数据与缓存中数据不一致的问题。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>那么我们这里列出来所有策略，并且讨论他们优劣性。</p><ul><li><p>先更新数据库，后更新缓存</p></li><li><p>先更新数据库，后删除缓存</p></li><li><p>先更新缓存，后更新数据库</p></li><li><p>先删除缓存，后更新数据库</p></li></ul><h4 id="先更新数据库，后更新缓存"><a href="#先更新数据库，后更新缓存" class="headerlink" title="先更新数据库，后更新缓存"></a>先更新数据库，后更新缓存</h4><p>这种场景一般是没有人使用的，主要原因是在更新缓存那一步，为什么呢？因为有的业务需求缓存中存在的值并不是直接从数据库中查出来的，有的是需要经过一系列计算来的缓存值，那么这时候后你要更新缓存的话其实代价是很高的。如果此时有大量的对数据库进行写数据的请求，但是读请求并不多，那么此时如果每次写请求都更新一下缓存，那么性能损耗是非常大的。</p><p>举个例子比如在数据库中有一个值为 1 的值，此时我们有 10 个请求对其每次加一的操作，但是这期间并没有读操作进来，如果用了先更新数据库的办法，那么此时就会有十个请求对缓存进行更新，会有大量的冷数据产生，如果我们不更新缓存而是删除缓存，那么在有读请求来的时候那么就会只更新缓存一次。</p><h4 id="先更新缓存，后更新数据库"><a href="#先更新缓存，后更新数据库" class="headerlink" title="先更新缓存，后更新数据库"></a>先更新缓存，后更新数据库</h4><p>这一种情况应该不需要我们考虑了吧，和第一种情况是一样的。</p><h4 id="先删除缓存，后更新数据库"><a href="#先删除缓存，后更新数据库" class="headerlink" title="先删除缓存，后更新数据库"></a>先删除缓存，后更新数据库</h4><p>该方案也会出问题，具体出现的原因如下。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078252.png" alt="先删除缓存，后更新数据库"></p><p>此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）</p><ol><li>请求 A 会先删除 Redis 中的数据，然后去数据库进行更新操作</li><li>此时请求 B 看到 Redis 中的数据时空的，会去数据库中查询该值，补录到 Redis 中</li><li>但是此时请求 A 并没有更新成功，或者事务还未提交</li></ol><p>那么这时候就会产生数据库和 Redis 数据不一致的问题。如何解决呢？其实最简单的解决办法就是延时双删的策略。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078256.png" alt="延时双删"></p><p>在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。具体步骤是：</p><ul><li>先删除缓存</li><li>再写数据库</li><li>休眠500毫秒（根据具体的业务时间来定）</li><li>再次删除缓存。</li></ul><p>但是上述的保证事务提交完以后再进行删除缓存还有一个问题，就是如果你使用的是 Mysql 的读写分离的架构的话，那么其实主从同步之间也会有时间差。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078251.png" alt="主从同步时间差"></p><p>此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）</p><ol><li>请求 A 更新操作，删除了 Redis</li><li>请求主库进行更新操作，主库与从库进行同步数据的操作</li><li>请 B 查询操作，发现 Redis 中没有数据</li><li>去从库中拿去数据</li><li>此时同步数据还未完成，拿到的数据是旧数据</li></ol><p>此时的解决办法就是如果是对 Redis 进行填充数据的查询数据库操作，那么就强制将其指向主库进行查询。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078255.png" alt="从主库中拿数据"></p><h4 id="先更新数据库，后删除缓存"><a href="#先更新数据库，后删除缓存" class="headerlink" title="先更新数据库，后删除缓存"></a>先更新数据库，后删除缓存</h4><p>问题：这一种情况也会出现问题，比如更新数据库成功了，但是在删除缓存的阶段出错了没有删除成功，那么此时再读取缓存的时候每次都是错误的数据了。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078254.png" alt="先更新数据库，后删除缓存"></p><p>此时解决方案就是利用消息队列进行删除的补偿。具体的业务逻辑用语言描述如下：</p><ol><li>请求 A 先对数据库进行更新操作</li><li>在对 Redis 进行删除操作的时候发现报错，删除失败</li><li>此时将Redis 的 key 作为消息体发送到消息队列中</li><li>系统接收到消息队列发送的消息后再次对 Redis 进行删除操作</li></ol><p>但是这个方案会有一个缺点就是会对业务代码造成大量的侵入，深深的耦合在一起，所以这时会有一个优化的方案，我们知道对 Mysql 数据库更新操作后再 binlog 日志中我们都能够找到相应的操作，那么我们可以订阅 Mysql 数据库的 binlog 日志对缓存进行操作。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078253.png" alt="利用订阅 binlog 删除缓存"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>每种方案各有利弊，比如在第三种先删除缓存，后更新数据库这个方案我们最后讨论了要更新 Redis 的时候强制走主库查询就能解决问题，那么这样的操作会对业务代码进行大量的侵入，但是不需要增加的系统，不需要增加整体的服务的复杂度。</p><p>最后一种方案我们最后讨论了利用订阅 binlog 日志进行搭建独立系统操作 Redis，这样的缺点其实就是增加了系统复杂度。其实每一次的选择都需要我们对于我们的业务进行评估来选择，没有一种技术是对于所有业务都通用的。没有最好的，只有最适合我们的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在做系统优化时，想到了将数据进行分级存储的思路。因为在系统中会存在一些数据，有些数据的实时性要求不高，比如一些配置信息。&lt;/p&gt;
&lt;p&gt;基本上配置了很久才会变一次。而有一些数据实时性要求非常高，比如订单和流水的数据。所以这里根据数据要求实时性不同将数据分为三级。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>超卖问题</title>
    <link href="https://leslieaibin.github.io/2021/11/18/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE%E8%B6%85%E5%8D%96%E8%AE%A8%E8%AE%BA/"/>
    <id>https://leslieaibin.github.io/2021/11/18/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE%E8%B6%85%E5%8D%96%E8%AE%A8%E8%AE%BA/</id>
    <published>2021-11-17T16:15:42.000Z</published>
    <updated>2022-02-12T12:29:10.200Z</updated>
    
    <content type="html"><![CDATA[<h1 id="常见写法安全性及效率分析"><a href="#常见写法安全性及效率分析" class="headerlink" title="常见写法安全性及效率分析"></a>常见写法安全性及效率分析</h1><p>假设我们的商品表的schema是下面这样的：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`goods`</span> (<span class="string">``</span><span class="string">`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`</span><span class="string">``</span> <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">10</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT <span class="keyword">COMMENT</span><span class="string">``</span><span class="string">` `</span><span class="string">&#x27;自增id&#x27;</span><span class="string">``</span>,<span class="string">`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`</span><span class="string">``</span> <span class="string">`name`</span> <span class="built_in">varchar</span>(<span class="number">256</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span><span class="string">``</span><span class="string">` `</span><span class="string">&#x27;&#x27;</span><span class="string">` `</span><span class="keyword">COMMENT</span><span class="string">` `</span><span class="string">&#x27;商品名称&#x27;</span><span class="string">``</span>,<span class="string">`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`</span><span class="string">``</span> <span class="string">`available`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">unsigned</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span><span class="string">``</span><span class="string">` `</span><span class="string">&#x27;0&#x27;</span><span class="string">` `</span><span class="keyword">COMMENT</span><span class="string">` `</span><span class="string">&#x27;库存剩余量&#x27;</span><span class="string">``</span>,<span class="string">`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`</span><span class="string">``</span> <span class="string">`stock`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">unsigned</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span><span class="string">``</span><span class="string">` `</span><span class="string">&#x27;0&#x27;</span><span class="string">` `</span><span class="keyword">COMMENT</span><span class="string">` `</span><span class="string">&#x27;总库存量&#x27;</span><span class="string">``</span>,<span class="string">`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)<span class="string">``</span><span class="string">`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`</span>) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8 <span class="keyword">COMMENT</span>=<span class="string">``</span><span class="string">&#x27;商品表&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="设置为字段无符号解决"><a href="#设置为字段无符号解决" class="headerlink" title="设置为字段无符号解决"></a>设置为字段无符号解决</h2><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">num = <span class="keyword">select</span> available <span class="keyword">from</span> goods <span class="keyword">where</span> <span class="keyword">id</span> = xx ;</span><br><span class="line">if(num &gt; 0)&#123;</span><br><span class="line">   affectRows = udpate goods <span class="keyword">set</span> available = available - <span class="number">1</span> <span class="keyword">where</span> <span class="keyword">id</span> = xx ;</span><br><span class="line">   if(affectRows == 1)&#123;</span><br><span class="line">       return ok ;</span><br><span class="line">   &#125;else&#123;</span><br><span class="line">       return fatal ;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>这种做法大家的想法是我们将库存字段设置成无符号类型，这样当库存字段在sql执行时候被置为负数的时候mysql就会报错，那么affectRow就会是0或者可以捕获到这个异常，从而实现并发下的数据安全。</strong></p><h4 id="解法释义"><a href="#解法释义" class="headerlink" title="解法释义"></a>解法释义</h4><p>实际上这段代码是危险的，因为在不同版本的mysql和配置下，这段代码的表现完全不同。具体的情况会出现3种不同的结果：</p><ul><li>  代码正常运行，执行update的时候报错</li><li>  代码最终执行结果出现了 -1</li><li>  最终update操作之后，available变成了一个很大的数目</li></ul><p>为什么会出现这三种情况呢？</p><p>我想在学习开始学习计算机的时候都讲过计算机的加减法计算方法。</p><p><code>思考一下，无符号2 减去 无符号3 在计算机中的运算是什么样的？</code></p><p><code>2 - 3 = 2 + (-3)</code></p><p><code>假设我们的计算机是4位的,2的补码表示:0010,-3的补码表示为1011</code></p><p><code>那么加和的结果是</code></p><p><code>0010</code></p><p><code>1011 +</code></p><p><code>------</code></p><p><code>1111 =</code></p><p><code>1111解释为有符号数是多少呢？ -1</code></p><p><code>1111解释为无符号数是多少呢？ 15</code></p><p>所以呢？如果mysql不做任何处理的话，你的无符号数减法的结果不会报错，最终你算出来的库存还是一个非常大的值(可怕)。<br>但是幸运的是mysql 后来的版本帮你做了这件事情(具体哪个版本我也不清楚)，所以如果是mysql做了无符号检测的话，如果减出的结果是负值，会报错，这是大多数人期待的结果。-1这种情况是需要你设置一下sqlmode的，这也是会出现的情况。</p><h4 id="解法总结"><a href="#解法总结" class="headerlink" title="解法总结"></a>解法总结</h4><ul><li>  这个办法很多人用的时候没问题，那只能说明可能是机缘巧合，但是对于业务代码而言，不能靠碰运气，需要消除不确定性、缩小迁移成本。</li><li>  如果你想采用这种办法，辛苦你把你们msyql相应的版本及配置搞清楚，确定无符号在你所在的版本会出现什么结果。</li></ul><h2 id="select-for-update（感觉并不能保证原子性）"><a href="#select-for-update（感觉并不能保证原子性）" class="headerlink" title="select for update（感觉并不能保证原子性）"></a>select for update（感觉并不能保证原子性）</h2><h4 id="解法释义-1"><a href="#解法释义-1" class="headerlink" title="解法释义"></a>解法释义</h4><p>读取时候就开始加排他锁也是网上常见的办法之一，具体实现如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">begin</span> tran ;</span><br><span class="line">num = <span class="keyword">select</span> avaliable <span class="keyword">from</span> goods <span class="keyword">where</span> <span class="keyword">id</span> = xxx <span class="keyword">for</span> <span class="keyword">update</span>;</span><br><span class="line">if (num &gt;= 0)&#123;</span><br><span class="line">   affectNum = udpate goods <span class="keyword">set</span> available = available - <span class="number">1</span> <span class="keyword">where</span> <span class="keyword">id</span> = xx ;</span><br><span class="line">   <span class="keyword">commit</span> ;</span><br><span class="line"> return affectNum ;</span><br><span class="line">&#125;else&#123;</span><br><span class="line"> <span class="keyword">rollback</span> ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该解法在用户读取的时候对相应的数据加排他锁，保证自己在更新的时候该行的数据不会被别的进程更改.所有写请求及排他锁加锁都会被阻塞。</p><p>想想这样的情况，A进程执行过程中，出现死机的情况导致commit/rollback请求没有被发送到mysqlserver，那么所有请求都会锁等待。</p><h4 id="解法总结-1"><a href="#解法总结-1" class="headerlink" title="解法总结"></a>解法总结</h4><ul><li><p>  低流量可以采用这种办法来保证数据的安全性</p></li><li><p>性能低下，平均需要发送4次mysql请求，同时会造成所有同类请求锁等待。</p><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3></li><li><p>  select for udpate 需要在显式的指定在事务代码块执行，不然不会起作用。很多网友都理所当然的人为select for update直接就可以加排他锁</p></li><li><p>  排他锁的释放是在rollback/commit 动作完成才会释放，不是在update操作之后。mysql innodb执行两段锁协议，加锁阶段只加锁，解锁阶段只解锁。</p></li></ul><h2 id="采用事务，先查后写再查，确保没问题"><a href="#采用事务，先查后写再查，确保没问题" class="headerlink" title="采用事务，先查后写再查，确保没问题"></a>采用事务，先查后写再查，确保没问题</h2><h4 id="解法释义-2"><a href="#解法释义-2" class="headerlink" title="解法释义"></a>解法释义</h4><p>这时候的available设置为有符号类型，解决方案一的问题</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">begin</span> tran ;</span><br><span class="line"></span><br><span class="line">num = <span class="keyword">select</span> available <span class="keyword">from</span> goods <span class="keyword">where</span> <span class="keyword">id</span> = xx ;</span><br><span class="line"></span><br><span class="line">if(num &gt; 0)&#123;</span><br><span class="line">   //实际需要关心这里的返回值，这里不考虑</span><br><span class="line"></span><br><span class="line">   udpate goods <span class="keyword">set</span> available = available - <span class="number">1</span> <span class="keyword">where</span> <span class="keyword">id</span> = xx ;</span><br><span class="line"></span><br><span class="line">   num_afterupdate = <span class="keyword">select</span> available <span class="keyword">from</span> goods <span class="keyword">where</span> <span class="keyword">id</span> = xx ;</span><br><span class="line"></span><br><span class="line">   if(num_afterupdate &lt; 0 )&#123;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">rollback</span> ;</span><br><span class="line"></span><br><span class="line">   &#125;else&#123;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">commit</span> ;</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种解法区分于第一种的办法在于，加了事务、available类型更改、采用了更新后确认的形式，尝试解决问题。</p><p>我们都知道数据库的事务隔离级别有4种：<br><strong>RU，RC，RR，Serializable。</strong><br>我们常见的innodb中RR模式是可以保证可重复读，意思是在同一个事务内部，多次读取的结果是一致的。那么最后一次的读取对于RR隔离级别实际上是无效的。<br>RC模式下，这个代码是可用的，每次请求可以确保自己的进程不会超发。</p><h4 id="解法总结-2"><a href="#解法总结-2" class="headerlink" title="解法总结"></a>解法总结</h4><ul><li>  RR、RC模式下结果不一致.RR下不可保证安全、RC可以。</li><li>  性能不高，一次业务请求到mysql的转化为 1 : 5。</li><li>  这种解法就像老奶奶锁门，总是不放心自己到底锁了没有，走了几步再回来看看，实际上有些时候是徒劳。</li></ul><h2 id="update语句增加available查询条件"><a href="#update语句增加available查询条件" class="headerlink" title="update语句增加available查询条件"></a>update语句增加available查询条件</h2><h4 id="解法释义-3"><a href="#解法释义-3" class="headerlink" title="解法释义"></a>解法释义</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">udpate goods <span class="keyword">set</span> available = available - <span class="number">1</span> <span class="keyword">where</span> <span class="keyword">id</span> = xx<span class="string">` `</span><span class="keyword">and</span><span class="string">` `</span>available - <span class="number">1</span> &gt;= <span class="number">0</span> ;</span><br></pre></td></tr></table></figure><p>大家有的另一个误区是单条语句不是事务，实际上单条sql也是一个事务。-<br>问题的关键就集中在怎么证明这句的安全性的。-<br>我们都知道update操作对于id为主键索引的情况下，是会对数据加行锁。-<br>其实update操作在mysql内部也是一个先查后改的过程，这个过程如果是原子的，那么可以保证update语句是串行的，那我们就来看一下update语句在mysql内部的执行过程。-</p><p>那么对于上面这个语句，一样遵循两段锁协议。-<br>update执行的过程，会去查询满足条件的行并加锁，这个加锁是innodb做的，那么就可以保证别的事务必须等到该事务执行完了之后才能获得锁，此时拿到最新数据。</p><h4 id="解法总结-3"><a href="#解法总结-3" class="headerlink" title="解法总结"></a>解法总结</h4><ul><li>  语句安全、效率最优（我的认知里）</li></ul><h2 id="采用设置库存而不是扣减库存"><a href="#采用设置库存而不是扣减库存" class="headerlink" title="采用设置库存而不是扣减库存"></a>采用设置库存而不是扣减库存</h2><p>这几天我把类似的文章几乎翻了一遍，唯一看到批评我的上一条做法的是我的那个做法是不具备幂等性的。</p><blockquote><ul><li>  所谓幂等性就是，同一个用户对同一连接的访问不会产生副作用。比如上一条的方案，如果记录用户的操作和扣减库存不是原子操作的话，就有可能出现的问题是，库存扣减成功了，但是用户记录失败了，那么用户重复请求，就会出现多次减库存的问题。</li></ul></blockquote><p>那么他们的解法是这样的，采用设置而不是扣减，代码如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num_old = <span class="keyword">select</span> available <span class="keyword">from</span> goods <span class="keyword">where</span> <span class="keyword">id</span> = xx<span class="string">` `</span><span class="keyword">and</span><span class="string">` `</span>available &gt;= <span class="number">1</span> ;</span><br><span class="line">num_new = num_old - 1 ;</span><br><span class="line"><span class="keyword">update</span> goods <span class="keyword">set</span> <span class="keyword">num</span>=num_new <span class="keyword">where</span> <span class="keyword">id</span>=xx<span class="string">` `</span><span class="keyword">and</span><span class="string">` `</span><span class="keyword">num</span>=num_old ;</span><br></pre></td></tr></table></figure><p>这段代码也是安全的，采用的是乐观锁的理念来完成的操作。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>  上面的做法，最后两个是相对安全的，但是你的库存字段还是要设置为无符号，关于是否幂等，要看结合请求看，不是单个扣减块代码。</li></ul><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><ul><li>  <a href="http://hedengcheng.com/?p=771">何登成的技术博客</a>mysql udpate流程学习</li><li>  <a href="http://www.10tiao.com/html/249/201706/2651960197/1.html">幂等性做法来源</a>使用设置库存代替库存扣减</li><li>  <a href="http://www.cnblogs.com/blankqdb/archive/2012/11/03/blank_qdb.html">mysql 无符号问题</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;常见写法安全性及效率分析&quot;&gt;&lt;a href=&quot;#常见写法安全性及效率分析&quot; class=&quot;headerlink&quot; title=&quot;常见写法安全性及效率分析&quot;&gt;&lt;/a&gt;常见写法安全性及效率分析&lt;/h1&gt;&lt;p&gt;假设我们的商品表的schema是下面这样的：&lt;/p&gt;
&lt;fi</summary>
      
    
    
    
    
    <category term="Java" scheme="https://leslieaibin.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>消息队列问题</title>
    <link href="https://leslieaibin.github.io/2021/11/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E5%A0%86%E7%A7%AF%E5%A4%AA%E5%A4%9A%E6%80%8E%E4%B9%88%E5%8A%9E/"/>
    <id>https://leslieaibin.github.io/2021/11/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E5%A0%86%E7%A7%AF%E5%A4%AA%E5%A4%9A%E6%80%8E%E4%B9%88%E5%8A%9E/</id>
    <published>2021-11-11T01:15:42.000Z</published>
    <updated>2022-02-13T02:03:43.435Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MQ-的问题"><a href="#MQ-的问题" class="headerlink" title="MQ 的问题"></a>MQ 的问题</h2><p>任何技术都会有利有弊，MQ 给整体系统架构带来很多好处，但也会付出一定的代价。</p><p>MQ 主要引入了以下问题：</p><ul><li><p><strong>系统可用性降低</strong>：引入了 MQ 后，通信需要基于 MQ 完成，如果 MQ 宕机，则服务不可用。</p></li><li><p>系统复杂度提高</p><p>使用 MQ，需要关注一些新的问题：</p><ul><li>如何保证消息没有 <strong>重复消费</strong>？</li><li>如何处理 <strong>消息丢失</strong> 的问题？</li><li>如何保证传递 <strong>消息的顺序性</strong>？</li><li>如何处理大量 <strong>消息积压</strong> 的问题？</li></ul></li><li><p><strong>一致性问题</strong>：假设系统 A 处理完直接返回成功的结果给用户，用户认为请求成功。但如果此时，系统 BCD 中只要有任意一个写库失败，那么数据就不一致了。这种情况如何处理？</p></li></ul><p>下面，我们针对以上问题来一一分析。</p><h3 id="1-重复消费"><a href="#1-重复消费" class="headerlink" title="1. 重复消费"></a>1. 重复消费</h3><p><strong>如何保证消息不被重复消费</strong> 和 <strong>如何保证消息消费的幂等性</strong> 是同一个问题。</p><p>必须先明确产生重复消费的原因，才能对症下药。</p><h4 id="重复消费问题原因"><a href="#重复消费问题原因" class="headerlink" title="重复消费问题原因"></a>重复消费问题原因</h4><p>重复消费问题通常不是 MQ 来处理，而是由开发来处理的。</p><p>以 Kafka 举例，Kafka 每个 Partition 都是一个有序的、不可变的记录序列，不断追加到结构化的提交日志中。Partition 中为每条记录分配一个连续的 id 号，称为偏移量（Offset），用于唯一标识 Partition 内的记录。</p><p>Kafka 的客户端和 Broker 都会保存 Offset。客户端消费消息后，每隔一段时间，就把已消费的 Offset 提交给 Kafka Broker，表示已消费。</p><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20210427194009.png" alt="img"></p><p>在这个过程中，如果客户端应用消费消息后，因为宕机、重启等情况而没有提交已消费的 Offset 。当系统恢复后，会继续消费消息，由于 Offset 未提交，就会出现重复消费的问题。</p><h4 id="重复消费解决方案"><a href="#重复消费解决方案" class="headerlink" title="重复消费解决方案"></a>重复消费解决方案</h4><p>应对重复消费问题，需要在业务层面，通过 <strong>幂等性设计</strong> 来解决。</p><p>MQ 重复消费不可怕，可怕的是没有应对机制，可以借鉴的思路有：</p><ul><li>如果是写关系型数据库，可以先根据主键查询，判断数据是否已存在，存在则更新，不存在则插入；</li><li>如果是写 Redis，由于 set 操作天然具有幂等性，所以什么都不用做；</li><li>如果是根据消息做较复杂的逻辑处理，可以在消息中加入全局唯一 ID，例如：订单 ID 等。在客户端存储中（Mysql、Redis 等）保存已消费消息的 ID。一旦接受到新消息，先判断消息中的 ID 是否在已消费消息 ID 表中存在，存在则不再处理，不存在则处理。</li></ul><p>在实际开发中，可以参考上面的例子，结合现实场景，设计合理的幂等性方案。</p><h3 id="2-消息丢失"><a href="#2-消息丢失" class="headerlink" title="2. 消息丢失"></a>2. 消息丢失</h3><p><strong>如何处理消息丢失的问题</strong> 和 <strong>如何保证消息不被重复消费</strong> 是同一个问题。关注点有：</p><ul><li>MQ Server 丢失数据</li><li>消费方丢失数据</li><li>生产方丢失数据</li></ul><h4 id="消费方丢失数据"><a href="#消费方丢失数据" class="headerlink" title="消费方丢失数据"></a>消费方丢失数据</h4><p>唯一可能导致消费方丢失数据的情况是：消费方设置了<strong>自动提交 Offset</strong>。一旦设置了自动提交 Offset，接受到消息后就会自动提交 Offset 给 Kafka ，Kafka 就认为消息已被消费。如果此时，消费方尚未来得及处理消息就挂了，那么消息就丢了。</p><p>解决方法就是：消费方关闭自动提交 Offset，处理完消息后<strong>手动提交 Offset</strong>。但这种情况下可能会出现重复消费的情形，需要自行保证幂等性。</p><h4 id="RabbitMq弄丢了数据"><a href="#RabbitMq弄丢了数据" class="headerlink" title="RabbitMq弄丢了数据"></a><strong>RabbitMq弄丢了数据</strong></h4><p>就是 RabbitMQ 自己弄丢了数据，这个你必须<strong>开启 RabbitMQ 的持久化</strong>，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，<strong>恢复之后会自动读取之前存储的数据</strong>，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，<strong>可能导致少量数据丢失</strong>，但是这个概率较小。</p><p>设置持久化有<strong>两个步骤</strong>：</p><ul><li>创建 queue 的时候将其设置为持久化<br>这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。</li><li>第二个是发送消息的时候将消息的 <code>deliveryMode</code> 设置为 2<br>就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。</li></ul><p>必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。</p><p>注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。</p><p>所以，持久化可以跟生产者那边的 <code>confirm</code> 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 <code>ack</code> 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 <code>ack</code>，你也是可以自己重发的。</p><h4 id="生产方丢失数据"><a href="#生产方丢失数据" class="headerlink" title="生产方丢失数据"></a>生产方丢失数据</h4><p>如果按照上述的思路设置了 <code>acks=all</code>，生产方一定不会丢数据。</p><p>要求是，你的 Leader 接收到消息，所有的 Follower 都同步到了消息之后，才认为本生产消息成功了。如果未满足这个条件，生产者会自动不断的重试，重试无限次。</p><h3 id="3-消息的顺序性"><a href="#3-消息的顺序性" class="headerlink" title="3. 消息的顺序性"></a>3. 消息的顺序性</h3><p>要保证 MQ 的顺序性，势必要付出一定的代价，所以实施方案前，要先明确业务场景是不是有必要保证消息的顺序性。只有那些明确对消息处理顺序有要求的业务场景才值得去保证消息顺序性。</p><p>方案一</p><p>一个 Topic，一个 Partition，一个 Consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。</p><p>方案二</p><ul><li>写入数据到 Partition 时指定一个全局唯一的 ID，例如订单 ID。发送方保证相同 ID 的消息有序的发送到同一个 Partition。</li><li>基于上一点，消费方从 Kafka Partition 中消费消息时，此刻一定是顺序的。但如果消费方式以并发方式消费消息，顺序就可能会被打乱。为此，还有做到以下几点：<ul><li>消费方维护 N 个缓存队列，具有相同 ID 的数据都写入同一个队列中；</li><li>创建 N 个线程，每个线程只负责从指定的一个队列中取数据。</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20210427194215.png" alt="img"></p><h3 id="4-消息积压"><a href="#4-消息积压" class="headerlink" title="4. 消息积压"></a>4. 消息积压</h3><p>假设一个 MQ 消费者可以一秒处理 1000 条消息，三个 MQ 消费者可以一秒处理 3000 条消息，那么一分钟的处理量是 18 万条。如果 MQ 中积压了几百万到上千万的数据，即使消费者恢复了，也需要大概很长的时间才能恢复过来。</p><p>对于产线环境来说，漫长的等待是不可接受的，所以面临这种窘境时，只能临时紧急扩容以应对了，具体操作步骤和思路如下：</p><ul><li>先修复 Consumer 的问题，确保其恢复消费速度，然后将现有 Consumer 都停掉。</li><li>新建一个 Topic，Partition 是原来的 10 倍，临时建立好原先 10 倍的 Queue 数量。</li><li>然后写一个临时的分发数据的 Consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 Queue。</li><li>接着临时征用 10 倍的机器来部署 Consumer ，每一批 Consumer 消费一个临时 Queue 的数据。这种做法相当于是临时将 Queue 资源和 Consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。</li><li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;MQ-的问题&quot;&gt;&lt;a href=&quot;#MQ-的问题&quot; class=&quot;headerlink&quot; title=&quot;MQ 的问题&quot;&gt;&lt;/a&gt;MQ 的问题&lt;/h2&gt;&lt;p&gt;任何技术都会有利有弊，MQ 给整体系统架构带来很多好处，但也会付出一定的代价。&lt;/p&gt;
&lt;p&gt;MQ 主要引入</summary>
      
    
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>10.分库分表</title>
    <link href="https://leslieaibin.github.io/2021/10/25/MySQL/10.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    <id>https://leslieaibin.github.io/2021/10/25/MySQL/10.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</id>
    <published>2021-10-25T12:17:42.000Z</published>
    <updated>2022-02-13T01:59:37.479Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-为什么要拆分数据库？"><a href="#1-为什么要拆分数据库？" class="headerlink" title="1. 为什么要拆分数据库？"></a><strong>1. 为什么要拆分数据库？</strong></h2><p>单体项目在构建之初，<a href="https://link.zhihu.com/?target=https://coding.imooc.com/class/274.html?mc_marking=b9478d5f12bd4de1a83dc61bc224d99f&mc_channel=shouji">数据库</a>的负载和数据量都不大，所以不需要对数据库做拆分，小型财务系统、文书系统、ERP系统、OA系统，用一个MySQL数据库实例基本就够用了。</p><p>就像《淘宝技术这十年》里面说到的，电商业务的数据量增长飞快，所以最开始的PHP+MySQL的架构已经不能满足实际要求了，于是淘宝想到的第一个办法就是把MySQL替换成Oracle。但是没过了多久，在08年前后，单节点的Oracle数据库也不好用了，于是淘宝终于告别了单节点数据库，开始拆分数据库。从一个节点，变成多个节点。</p><p>拆分数据库是有讲究的，比如说拆分方法有两种：垂直切分和水平切分。那你是先水平切分还是垂直切分呢？顺序无所谓？不，顺序有所为，次序绝对不能错：先水平切分，然后垂直切分。</p><h2 id="2-什么是垂直切分？"><a href="#2-什么是垂直切分？" class="headerlink" title="2. 什么是垂直切分？"></a><strong>2. 什么是垂直切分？</strong></h2><p>垂直切分是根据业务来拆分数据库，同一类业务的数据表拆分到一个独立的数据库，另一类的数据表拆分到其他数据库。</p><p>比如说一个新零售的电商数据库，我们可以把跟商品相关的数据表拆分成一个数据库，然后在这些数据表的基础之上，构建出商品系统。比如用JAVA或者PHP语言，创建出一个商城系统。然后把跟进销存相关的数据表拆分到另外一个数据库上，再用程序构建出仓库系统。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-cb822f0a43ecbeeeef8ed3845a3fa278_1440w.jpg" alt="img"></p><p><strong>垂直切分解决了什么问题</strong></p><p>垂直切分可以降低单节点数据库的负载。原来所有数据表都放在一个数据库节点上，无疑所有的读写请求也都发到这个MySQL上面，所以数据库的负载太高。如果把一个节点的数据库拆分成多个MySQL数据库，这样就可以有效的降低每个MySQL数据库的负载。</p><p><strong>垂直切分不能解决什么问题</strong></p><p>垂直切分不能解决的是缩表，比如说商品表无论划分给哪个数据库节点，商品表的记录还是那么多，不管你把数据库垂直拆分的有多细致，每个数据表里面的数据量是没有变化的。</p><p>MySQL单表记录超过2000万，读写性能会下降的很快，因此说垂直切分并不能起到缩表的效果。</p><h2 id="3-什么是水平切分？"><a href="#3-什么是水平切分？" class="headerlink" title="3. 什么是水平切分？"></a><strong>3. 什么是水平切分？</strong></h2><p>水平切分是按照某个字段的某种规则，把数据切分到多张数据表。一张数据表化整为零，拆分成多张数据表，这样就可以起到缩表的效果了。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-e8376833abf17549ed97853ab7f71b90_1440w.jpg" alt="img"></p><p>很多人，都会水平切分存在误解，以为水平切分出来的数据表必须保存在不同的MySQL节点上。其实水平切分出来的数据表也可以保存在一个MySQL节点上面。不是水平切分一定需要多个MySQL节点。为什么这么说呢？</p><p>许多人不知道MySQL自带一种数据分区的技术，可以把一张表的数据，按照特殊规则，切分存储在不同的目录下。如果我们给Linux主机挂载了多块硬盘，我们完全可以利用MySQL分区技术，把一张表的数据切分存储在多个硬盘上。这样就由原来一块硬盘有限的IO能力，升级成了多个磁盘增强型的IO。如果你感兴趣数据分区的具体效果，可以看<a href="https://link.zhihu.com/?target=https://coding.imooc.com/class/274.html?mc_marking=b9478d5f12bd4de1a83dc61bc224d99f&mc_channel=shouji">《MySQL数据库集群》</a>这门实战课。</p><p><strong>水平切分的用途</strong></p><p>水平切分可以把数据切分到多张数据表，可以起到缩表的作用。</p><p>但是也不是所有的数据表都要做水平切分。数据量较大的数据表才需要做数据切分，比如说电商系统中的，用户表、商品表、产品表、地址表、订单表等等。有些数据表就不需要切分，因为数据量不多，比如说品牌表、供货商表、仓库表，这些都是不需要切分的。</p><p><strong>水平切分的缺点</strong></p><p>不同数据表的切分规则并不一致，要根据实际业务来确定。所以我们在选择数据库中间件产品的时候，就要选择切分规则丰富的产品。常见的数据库中间件有：MyCat、Atlas、ProxySQL等等。有些人觉得MyCat是Java语言开发的，就怀疑MyCat运行效率。其实数据库中间件的作用相当于SQL语句的路由器。你家路由器硬件配置不怎么高，但是不影响你享用百兆宽带。MyCat也是一个道理，它仅仅是起到SQL语句转发的作用，并不会实际执行SQL语句。我推荐使用MyCat最主要的原因是它自带了非常多的数据切分规则，我们可以按照主键求模切分数据，可以按照主键范围切分数据，还可以按照日期切分数据等等。因此说，为了满足业务的需要，MyCat目前来说算是非常不错的中间件产品。</p><p>水平切分的另一个缺点就是扩容比较麻烦，日积月累，分片迟早有不够用的时候。这时候不是首先选择增加新的集群分片。因为一个MySQL分片，需要4~8个MySQL节点（最小规模），增加一个分片的投入成本是很高的。所以正确的做法是做冷热数据分离，定期对分片中的数据归档。把过期的业务数据，从分片中转移到归档库。目前来说数据压缩比最高的MySQL引擎是TokuDB，而且带着事物的写入速度是InnoDB引擎的6-14倍。用TokuDB作为归档数据库最适合不过。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-90c4e1014db42321db91c4cf330f1168_1440w.jpg" alt="img"></p><h2 id="4-到底是应该先水平还是先垂直"><a href="#4-到底是应该先水平还是先垂直" class="headerlink" title="4. 到底是应该先水平还是先垂直"></a>4. 到底是应该先水平还是先垂直</h2><p><strong>感觉各有道理</strong>。但我支持先垂直，然后水平</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAT2NlYW4mJlN0YXI=,size_10,color_FFFFFF,t_70,g_se,x_16.png" alt="在这里插入图片描述"></p><p>数据库拆分原则：</p><ul><li>优先考虑缓存降低对数据库的读操作</li><li>再考虑读写分离，降低数据库写操作</li><li>最后开始数据拆分：<ul><li>先按照业务垂直拆分</li><li>在考虑水平拆分：先分库（设置数据路由规则，把数据分配到不同的库中）</li><li>最后在考虑分表，单表拆分到数据1000万以内。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-为什么要拆分数据库？&quot;&gt;&lt;a href=&quot;#1-为什么要拆分数据库？&quot; class=&quot;headerlink&quot; title=&quot;1. 为什么要拆分数据库？&quot;&gt;&lt;/a&gt;&lt;strong&gt;1. 为什么要拆分数据库？&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;单体项目在构建之初，&lt;</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>11.数据库优化</title>
    <link href="https://leslieaibin.github.io/2021/10/25/MySQL/11.%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"/>
    <id>https://leslieaibin.github.io/2021/10/25/MySQL/11.%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/</id>
    <published>2021-10-25T12:17:42.000Z</published>
    <updated>2022-02-13T03:56:56.142Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据库优化和查询优化方案"><a href="#数据库优化和查询优化方案" class="headerlink" title="数据库优化和查询优化方案"></a>数据库优化和查询优化方案</h1><h3 id="数据库优化方案"><a href="#数据库优化方案" class="headerlink" title="数据库优化方案"></a>数据库优化方案</h3><ol><li> 优化索引，sql语句，分析慢查询</li><li> 设计表的时候严格按照数据库设计规范来设计数据库</li><li> 使用缓存，把经常访问并且不需要经常变化的数据放在缓存中，能够节约磁盘IO</li><li> 优化硬件，采用ssd，使用磁盘队列技术（RAID0， RAID1，RAID5）</li><li> 采用mysql自带的表分区技术，把数据分析分成不同文件，能够磁盘的读写效率</li><li> 垂直分表，把一些不经常读的数据放在一张表当中，节约磁盘IO</li><li> 主从分离读写，采用主从复制把数据库的读操作和写操作分离开来</li><li> 分库分表分机器，数据量特别大的时候，主要的原理是数据路由</li><li> 选择合适的表引擎，参数上的优化</li><li> 进行架构级别的缓存，静态化和分布式</li><li> 不采用全文检索</li><li> 采用更快的存储方恨少，例如nosql存储经常访问的数据</li></ol><h3 id="优化数据库的查询效率"><a href="#优化数据库的查询效率" class="headerlink" title="优化数据库的查询效率"></a>优化数据库的查询效率</h3><ol><li> 存储引擎的选择，如果数据表需要事务处理，应该考虑Innodb，因为它完全符合ACID的特性，如果不需要食物处理，使用默认存储引擎MyISAM是比较明智的</li><li> 分表分库主从</li><li> 对查询进行优化，要尽量避免全表扫描，首先应考虑在shere以及orderby涉及的列上建立索引</li><li> 应尽量避免在where子句当中使用，不等于或者大于小于操作符，否则将导致引擎放弃使用索引而进行全表扫描</li><li> 应尽量避免在where子句当中使用null值判断，否则将导致引擎放弃使用索引而进行全表扫描</li><li> 应尽量避免在where子句当中使用or的判断，如果一个字段有索引，一个字段没有索引，将会导致引擎放弃使用索引而进行全表扫描</li><li> update语句如果只改一两个字段，不要update全部字段，否则频繁调用，会引起明显的性能消耗，同时带来的大量的日志</li><li> 对于多张数据量的表进行join，要先分页在做join，否则逻辑读写高，性能差</li></ol><hr><p>详细的优化方案</p><ul><li><p>1）数据库设计方面：</p><ul><li><p>  a. 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。</p></li><li><p>  b. 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num is null 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num=0</p></li><li><p>  c. 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时,查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。</p></li><li><p>  d. 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。</p></li><li><p>  e. 应尽可能的避免更新索引数据列，因为索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新索引数据列，那么需要考虑是否应将该索引建为索引。</p></li><li><p>  f. 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。</p></li><li><p>  g. 尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。</p></li><li><p>  h. 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。</p></li><li><p>  i. 避免频繁创建和删除临时表，以减少系统表资源的消耗。</p></li><li><p>  j. 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。</p></li><li><p>  k. 在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。</p></li><li><p>  l. 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。</p></li></ul></li></ul><ul><li><p>2)SQL语句方面：</p><ul><li><p>  a. 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。</p></li><li><p>  b. 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：</p></li></ul></li></ul><p><code>select id from t where num=10 or num=20</code></p><p>可以这样查询：</p><p><code>select id from t where num=10 union all select id from t where num=20</code></p><pre><code>- c. in 和 not in 也要慎用，否则会导致全表扫描，如： </code></pre><p><code>select id from t where num in(1,2,3)</code></p><p>对于连续的数值，能用 between 就不要用 in 了：</p><p><code>select id from t where num between 1 and 3</code></p><pre><code>- d. 下面的查询也将导致全表扫描： </code></pre><p><code>select id from t where name like ‘%abc%’</code></p><pre><code>- e. 如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。</code></pre><p>然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：</p><p><code>select id from t where num=@num</code></p><p>可以改为强制查询使用索引：</p><p><code>select id from t with(index(索引名)) where num=@num</code></p><pre><code>- f. 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： </code></pre><p><code>select id from t where num/2=100</code></p><p>应改为:</p><p><code>select id from t where num=100*2</code></p><pre><code>- g. 应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： </code></pre><p><code>select id from t where substring(name,1,3)=’abc’</code></p><p>–name以abc开头的id</p><p><code>select id from t where datediff(day,createdate,’2005-11-30′)=0</code></p><p>–‘2005-11-30’生成的id</p><p>应改为:</p><p><code>select id from t where name like ‘abc%’ select id from t where createdate&gt;=’2005-11-30′ and createdate&lt;’2005-12-1′</code></p><pre><code>- h. 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。- i. 不要写一些没有意义的查询，如需要生成一个空表结构： </code></pre><p><code>select col1,col2 into #t from t where 1=0</code></p><p>这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：</p><p>create table #t(…)</p><pre><code>- j. 很多时候用 exists 代替 in 是一个好的选择： </code></pre><p><code>select num from a where num in(select num from b)</code></p><p>用下面的语句替换：</p><p><code>select num from a where exists(select 1 from b where num=a.num)</code></p><pre><code>- k. 任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。- l. 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。- m. 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。- n. 尽量避免大事务操作，提高系统并发能力。</code></pre><ul><li><p>3)java方面：重点内容</p><ul><li><p>  a.尽可能的少造对象。</p></li><li><p>  b.合理摆正系统设计的位置。大量数据操作，和少量数据操作一定是分开的。大量的数据操作，肯定不是ORM框架搞定的。，</p></li><li><p>  c.使用jDBC链接数据库操作数据</p></li><li><p>  d.控制好内存，让数据流起来，而不是全部读到内存再处理，而是边读取边处理；</p></li><li><p>  e.合理利用内存，有的数据要缓存</p></li></ul></li></ul><p>如何优化数据库，如何提高数据库的性能?</p><p>1） 硬件调整性能 </p><p>最有可能影响性能的是磁盘和网络吞吐量,解决办法扩大虚拟内存，并保证有足够可以扩充的空间；把数据库服务器上的不必要服务关闭掉；把数据库服务器和主域服务器分开；把SQL数据库服务器的吞吐量调为最大；在具有一个以上处理器的机器上运行SQL。</p><p>2）调整数据库</p><p>若对该表的查询频率比较高，则建立索引；建立索引时，想尽对该表的所有查询搜索操作， 按照where选择条件建立索引，尽量为整型键建立为有且只有一个簇集索引，数据在物理上按顺序在数据页上，缩短查找范围，为在查询经常使用的全部列建立非簇集索引，能最大地覆盖查询；但是索引不可太多，执行UPDATE DELETE INSERT语句需要用于维护这些索引的开销量急剧增加；避免在索引中有太多的索引键；避免使用大型数据类型的列为索引；保证每个索引键值有少数行。</p><p>3）使用存储过程</p><p>应用程序的实现过程中，能够采用存储过程实现的对数据库的操作尽量通过存储过程来实现，因为存储过程是存放在数据库服务器上的一次性被设计、编码、测试，并被再次使用，需要执行该任务的应用可以简单地执行存储过程，并且只返回结果集或者数值，这样不仅可以使程序模块化，同时提高响应速度，减少网络流量，并且通过输入参数接受输入，使得在应用中完成逻辑的一致性实现。</p><p>4）应用程序结构和算法</p><p>建立查询条件索引仅仅是提高速度的前提条件，响应速度的提高还依赖于对索引的使用。因为人们在使用SQL时往往会陷入一个误区，即太关注于所得的结果是否正确，特别是对数据量不是特别大的数据库操作时，是否建立索引和使用索引的好坏对程序的响应速度并不大，因此程序员在书写程序时就忽略了不同的实现方法之间可能存在的性能差异，这种性能差异在数据量特别大时或者大型的或是复杂的数据库环境中（如联机事务处理OLTP或决策支持系统DSS）中表现得尤为明显。在工作实践中发现，不良的SQL往往来自于不恰当的索引设计、不充份的连接条件和不可优化的where子句。在对它们进行适当的优化后，其运行速度有了明显地提高！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据库优化和查询优化方案&quot;&gt;&lt;a href=&quot;#数据库优化和查询优化方案&quot; class=&quot;headerlink&quot; title=&quot;数据库优化和查询优化方案&quot;&gt;&lt;/a&gt;数据库优化和查询优化方案&lt;/h1&gt;&lt;h3 id=&quot;数据库优化方案&quot;&gt;&lt;a href=&quot;#数据库优化方</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>13.线程安全</title>
    <link href="https://leslieaibin.github.io/2021/10/24/Thread/13.%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98/"/>
    <id>https://leslieaibin.github.io/2021/10/24/Thread/13.%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98/</id>
    <published>2021-10-24T02:15:42.000Z</published>
    <updated>2022-02-12T13:50:02.861Z</updated>
    
    <content type="html"><![CDATA[<h1 id="4种解决线程安全问题的方式"><a href="#4种解决线程安全问题的方式" class="headerlink" title="4种解决线程安全问题的方式"></a>4种解决线程安全问题的方式</h1><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>线程安全问题，在做高并发的系统的时候，是程序员经常需要考虑的地方。怎么有效的防止线程安全问题，保证数据的准确性？怎么合理的最大化的利用系统资源等，这些问题都需要充分的理解并运行线程。当然关于多线程的问题在面试的时候也是出现频率比较高的。下面就来学习一下吧！</p><h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><p>先来看看什么是进程和线程？</p><p>进程是资源（CPU、内存等）分配的基本单位，它是程序执行时的一个实例。程序运行时系统就会创建一个进程，并为它分配资源，然后把该进程放入进程就绪队列，进程调度器选中它的时候就会为它分配CPU时间，程序开始真正运行。就比如说，我们开发的一个单体项目，运行它，就会产生一个进程。</p><p>线程是程序执行时的最小单位，它是进程的一个执行流，是CPU调度和分派的基本单位，一个进程可以由很多个线程组成，线程间共享进程的所有资源，每个线程有自己的堆栈和局部变量。线程由CPU独立调度执行，在多CPU环境下就允许多个线程同时运行。同样多线程也可以实现并发操作，每个请求分配一个线程来处理。在这里强调一点就是：计算机中的线程和应用程序中的线程不是同一个概念。</p><p>总之一句话描述就是：进程是资源分配的最小单位，线程是程序执行的最小单位。</p><h3 id="什么是线程安全"><a href="#什么是线程安全" class="headerlink" title="什么是线程安全"></a>什么是线程安全</h3><p>什么是线程安全呢？什么样的情况会造成线程安全问题呢？怎么解决线程安全呢？这些问题都是在下文中所要讲述的。</p><p><strong>线程安全：</strong>当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象就是线程安全的。</p><p>那什么时候会造成线程安全问题呢？当多个线程同时去访问一个对象时，就可能会出现线程安全问题。那么怎么解决呢？请往下看！</p><h3 id="解决线程安全"><a href="#解决线程安全" class="headerlink" title="解决线程安全"></a>解决线程安全</h3><p>在这里提供4种方法来解决线程安全问题，也是最常用的4种方法。前提是项目在一个服务器中，如果是分布式项目可能就会用到分布锁了，这个就放到后面文章来详谈了。</p><p>讲4种方法前，还是先来了解一下悲观锁和乐观锁吧！</p><p>悲观锁，顾名思义它是悲观的。讲得通俗点就是，认为自己在使用数据的时候，一定有别的线程来修改数据，因此在获取数据的时候先加锁，确保数据不会被线程修改。形象理解就是总觉得有刁民想害朕。</p><p>而乐观锁就比较乐观了，认为在使用数据时，不会有别的线程来修改数据，就不会加锁，只是在更新数据的时候去判断之前有没有别的线程来更新了数据。具体用法在下面讲解。</p><p>现在来看有那4种方法吧！</p><h3 id="1-使用synchronized关键字"><a href="#1-使用synchronized关键字" class="headerlink" title="1. 使用synchronized关键字"></a>1. 使用synchronized关键字</h3><p>一个表现为原生语法层面的互斥锁，它是一种悲观锁，使用它的时候我们一般需要一个监听对象 并且监听对象必须是唯一的，通常就是当前类的字节码对象。它是JVM级别的，不会造成死锁的情况。使用synchronized可以拿来修饰类，静态方法，普通方法和代码块。比如：Hashtable类就是使用synchronized来修饰方法的。put方法部分源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Make sure the value is not null</span></span><br><span class="line">  <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">  &#125; </span><br></pre></td></tr></table></figure><p>而ConcurrentHashMap类中就是使用synchronized来锁代码块的。putVal方法部分源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">              V oldVal = <span class="keyword">null</span>;</span><br><span class="line">              <span class="keyword">synchronized</span> (f) &#123;</span><br><span class="line">                  <span class="keyword">if</span> (tabAt(tab, i) == f) &#123;</span><br><span class="line">                      <span class="keyword">if</span> (fh &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                          binCount = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>synchronized关键字底层实现主要是通过monitorenter 与monitorexit计数 ，如果计数器不为0，说明资源被占用，其他线程就不能访问了，但是可重入的除外。说到这，就来讲讲什么是可重入的。这里其实就是指的可重入锁：指的是同一线程外层函数获得锁之后，内层递归函数仍然有获取该锁的代码，但不受影响，执行对象中所有同步方法不用再次获得锁。避免了频繁的持有释放操作，这样既提升了效率，又避免了死锁。</p><p>其实在使用synchronized时，存在一个锁升级原理。它是指在锁对象的对象头里面有一个 threadid 字段，在第一次访问的时候 threadid 为空，jvm 让其持有偏向锁，并将 threadid 设置为其线程 id，再次进入的时候会先判断 threadid 是否与其线程 id 一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。锁升级的目的是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。可能你又会问什么是偏向锁？什么是轻量级锁？什么是重量级锁？这里就简单描述一下吧，能够帮你更好的理解synchronized。</p><p>偏向锁（无锁）：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后（线程的id会记录在对象的Mark Word中），消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。</p><p>轻量级锁（CAS）：就是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；轻量级锁的意图是在没有多线程竞争的情况下，通过CAS操作尝试将MarkWord更新为指向LockRecord的指针，减少了使用重量级锁的系统互斥量产生的性能消耗。</p><p>重量级锁：虚拟机使用CAS操作尝试将MarkWord更新为指向LockRecord的指针，如果更新成功表示线程就拥有该对象的锁；如果失败，会检查MarkWord是否指向当前线程的栈帧，如果是，表示当前线程已经拥有这个锁；如果不是，说明这个锁被其他线程抢占，此时膨胀为重量级锁。</p><h3 id="2-使用Lock接口下的实现类"><a href="#2-使用Lock接口下的实现类" class="headerlink" title="2. 使用Lock接口下的实现类"></a>2. 使用Lock接口下的实现类</h3><p>Lock是juc（java.util.concurrent）包下面的一个接口。常用的实现类就是ReentrantLock 类，它其实也是一种悲观锁。一种表现为 API 层面的互斥锁。通过lock() 和 unlock() 方法配合使用。因此也可以说是一种手动锁，使用比较灵活。但是使用这个锁时一定要注意要释放锁，不然就会造成死锁。一般配合try/finally 语句块来完成。比如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TicketThreadSafe</span> <span class="keyword">extends</span> <span class="title">Thread</span></span>&#123;</span><br><span class="line">      <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> num = <span class="number">5000</span>;</span><br><span class="line">      ReentrantLock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(num&gt;<span class="number">0</span>)&#123;</span><br><span class="line">             <span class="keyword">try</span> &#123;</span><br><span class="line">               lock.lock();</span><br><span class="line">               <span class="keyword">if</span>(num&gt;<span class="number">0</span>)&#123;</span><br><span class="line">                 System.out.println(Thread.currentThread().getName()+<span class="string">&quot;你的票号是&quot;</span>+num--);</span><br><span class="line">               &#125;</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                 e.printStackTrace();</span><br><span class="line">              &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">                 lock.unlock();</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>相比 synchronized，ReentrantLock 增加了一些高级功能，主要有以下 3 项：等待可中断、可实现公平锁，以及锁可以绑定多个条件。</p><p>等待可中断是指：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。</p><p>公平锁是指：多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ReentrantLock</span><span class="params">(<span class="keyword">boolean</span> fair)</span> </span>&#123;</span><br><span class="line">        sync = fair ? <span class="keyword">new</span> FairSync() : <span class="keyword">new</span> NonfairSync();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>锁绑定多个条件是指：一个 ReentrantLock 对象可以同时绑定多个 Condition 对象，而在 synchronized 中，锁对象的 wait() 和 notify() 或 notifyAll() 方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而 ReentrantLock 则无须这样做，只需要多次调用 newCondition() 方法即可。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> ConditionObject <span class="title">newCondition</span><span class="params">()</span> </span>&#123; <span class="comment">//ConditionObject是Condition的实现类</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> ConditionObject();</span><br><span class="line">    &#125; </span><br></pre></td></tr></table></figure><h3 id="3-使用线程本地存储ThreadLocal"><a href="#3-使用线程本地存储ThreadLocal" class="headerlink" title="3. 使用线程本地存储ThreadLocal"></a>3. 使用线程本地存储ThreadLocal</h3><p>当多个线程操作同一个变量且互不干扰的场景下，可以使用ThreadLocal来解决。它会在每个线程中对该变量创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。通过set(T value)方法给线程的局部变量设置值；get()获取线程局部变量中的值。当给线程绑定一个 Object 内容后，只要线程不变,就可以随时取出；改变线程,就无法取出内容.。这里提供一个用法示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadLocalTest</span> </span>&#123;</span><br><span class="line">      <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> a = <span class="number">500</span>;</span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(()-&gt;&#123;</span><br><span class="line">                  ThreadLocal&lt;Integer&gt; local = <span class="keyword">new</span> ThreadLocal&lt;Integer&gt;();</span><br><span class="line">                  <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">                        local.set(++a);   <span class="comment">//子线程对a的操作不会影响主线程中的a</span></span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                              Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                              e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                        System.out.println(<span class="string">&quot;子线程：&quot;</span>+local.get());</span><br><span class="line">                  &#125;</span><br><span class="line">            &#125;).start();</span><br><span class="line">            a = <span class="number">22</span>;</span><br><span class="line">            ThreadLocal&lt;Integer&gt; local = <span class="keyword">new</span> ThreadLocal&lt;Integer&gt;();</span><br><span class="line">            local.set(a);</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">                  <span class="keyword">try</span> &#123;</span><br><span class="line">                        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                  &#125;</span><br><span class="line">                  System.out.println(<span class="string">&quot;主线程：&quot;</span>+local.get());</span><br><span class="line">            &#125;</span><br><span class="line">      &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>ThreadLocal线程容器保存变量时，底层其实是通过ThreadLocalMap来实现的。它是以当前ThreadLocal变量为key ，要存的变量为value。获取的时候就是以当前ThreadLocal变量去找到对应的key，然后获取到对应的值。源码参考如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(T value)</span> </span>&#123;</span><br><span class="line">       Thread t = Thread.currentThread();</span><br><span class="line">       ThreadLocalMap map = getMap(t);</span><br><span class="line">       <span class="keyword">if</span> (map != <span class="keyword">null</span>)</span><br><span class="line">           map.set(<span class="keyword">this</span>, value);</span><br><span class="line">       <span class="keyword">else</span></span><br><span class="line">           createMap(t, value);</span><br><span class="line">   &#125;</span><br><span class="line">    <span class="function">ThreadLocalMap <span class="title">getMap</span><span class="params">(Thread t)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> t.threadLocals; <span class="comment">//ThreadLocal.ThreadLocalMap threadLocals = null;Thread类中声明的</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">createMap</span><span class="params">(Thread t, T firstValue)</span> </span>&#123;</span><br><span class="line">       t.threadLocals = <span class="keyword">new</span> ThreadLocalMap(<span class="keyword">this</span>, firstValue);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>观察源码就会发现，其实每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。</p><p>初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。</p><p>然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找即可。</p><h3 id="4-使用乐观锁机制"><a href="#4-使用乐观锁机制" class="headerlink" title="4. 使用乐观锁机制"></a>4. 使用乐观锁机制</h3><p>前面已经讲述了什么是乐观锁。这里就来描述哈在java开发中怎么使用的。</p><p>其实在表设计的时候，我们通常就需要往表里加一个version字段。每次查询时，查出带有version的数据记录，更新数据时，判断数据库里对应id的记录的version是否和查出的version相同。若相同，则更新数据并把版本号+1；若不同，则说明，该数据发生了并发，被别的线程使用了，进行递归操作，再次执行递归方法，直到成功更新数据为止。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;4种解决线程安全问题的方式&quot;&gt;&lt;a href=&quot;#4种解决线程安全问题的方式&quot; class=&quot;headerlink&quot; title=&quot;4种解决线程安全问题的方式&quot;&gt;&lt;/a&gt;4种解决线程安全问题的方式&lt;/h1&gt;&lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; cla</summary>
      
    
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>5.操作系统-进程调度算法</title>
    <link href="https://leslieaibin.github.io/2021/10/04/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/5.%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/"/>
    <id>https://leslieaibin.github.io/2021/10/04/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/5.%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/</id>
    <published>2021-10-03T16:15:42.000Z</published>
    <updated>2021-10-11T05:38:43.232Z</updated>
    
    <content type="html"><![CDATA[<h1 id="进程调度算法"><a href="#进程调度算法" class="headerlink" title="进程调度算法"></a>进程调度算法</h1><h2 id="先来先服务调度算法"><a href="#先来先服务调度算法" class="headerlink" title="先来先服务调度算法"></a>先来先服务调度算法</h2><p>先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。</p><h2 id="短作业-进程-优先调度算法"><a href="#短作业-进程-优先调度算法" class="headerlink" title="短作业(进程)优先调度算法"></a>短作业(进程)优先调度算法</h2><p>短作业(进程)优先调度算法，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。</p><h2 id="时间片轮转法"><a href="#时间片轮转法" class="headerlink" title="时间片轮转法"></a>时间片轮转法</h2><p>在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU分配给队首进程，并令其执行一个时间片。时间片的大小从几ms到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。</p><h2 id="多级反馈队列调度算法"><a href="#多级反馈队列调度算法" class="headerlink" title="多级反馈队列调度算法"></a>多级反馈队列调度算法</h2><p>前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述：</p><p>1）应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，第i+1个队列的时间片要比第i个队列的时间片长一倍。</p><p>2）当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第n队列后，在第n队列便采取按时间片轮转的方式运行。</p><p>3）仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即第i队列中某个正在运行的进程的时间片用完后，由调度程序选择优先权较高的队列中的那一个进程，把处理机分配给它。</p><h2 id="优先权调度算法"><a href="#优先权调度算法" class="headerlink" title="优先权调度算法"></a>优先权调度算法</h2><p>为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。</p><ol><li>非抢占式优先权算法</li></ol><p>在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。</p><ol start="2"><li>抢占式优先权调度算法</li></ol><p>在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i时，就将其优先权Pi与正在执行的进程j的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi&gt;Pj，则立即停止Pj的执行，做进程切换，使i进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;进程调度算法&quot;&gt;&lt;a href=&quot;#进程调度算法&quot; class=&quot;headerlink&quot; title=&quot;进程调度算法&quot;&gt;&lt;/a&gt;进程调度算法&lt;/h1&gt;&lt;h2 id=&quot;先来先服务调度算法&quot;&gt;&lt;a href=&quot;#先来先服务调度算法&quot; class=&quot;headerlink</summary>
      
    
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>4.操作系统-页面置换算法</title>
    <link href="https://leslieaibin.github.io/2021/10/03/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/4.%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"/>
    <id>https://leslieaibin.github.io/2021/10/03/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/4.%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/</id>
    <published>2021-10-02T16:15:42.000Z</published>
    <updated>2021-10-11T05:38:14.868Z</updated>
    
    <content type="html"><![CDATA[<h1 id="页面置换算法"><a href="#页面置换算法" class="headerlink" title="页面置换算法"></a>页面置换算法</h1><p>地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。当发生缺页中断时操作系统必须在内存选择一个页面将其移除内存，以便为即将调入的页面让出空间。而用来选择淘汰那一页的规则叫做页面置换算法。</p><h2 id="最佳置换算法（OPT）（理想置换算法）"><a href="#最佳置换算法（OPT）（理想置换算法）" class="headerlink" title="最佳置换算法（OPT）（理想置换算法）"></a>最佳置换算法（OPT）（理想置换算法）</h2><p>这是一种理想情况下的页面置换算法，但实际上是不可能实现的。该算法的基本思想是：发生缺页时，有些页面在内存中，其中有一页将很快被访问（也包含紧接着的下一条指令的那页），而其他页面则可能要到10、100或者1000条指令后才会被访问，每个页面都可以用在该页面首次被访问前所要执行的指令数进行标记。最佳页面置换算法只是简单地规定：标记最大的页应该被置换。这个算法唯一的一个问题就是它无法实现。当缺页发生时，操作系统无法知道各个页面下一次是在什么时候被访问。虽然这个算法不可能实现，但是最佳页面置换算法可以用于对可实现算法的性能进行衡量比较。</p><h2 id="先进先出置换算法（FIFO）"><a href="#先进先出置换算法（FIFO）" class="headerlink" title="先进先出置换算法（FIFO）"></a>先进先出置换算法（FIFO）</h2><p>最简单的页面置换算法是先入先出（FIFO）法。这种算法的实质是，总是选择在主存中停留时间最长（即最老）的一页置换，即<strong>先进入内存的页，先退出内存</strong>。理由是：最早调入内存的页，其不再被使用的可能性比刚调入内存的可能性大。建立一个FIFO队列，收容所有在内存中的页。被置换页面总是在队列头上进行。当一个页面被放入内存时，就把它插在队尾上。</p><p>这种算法只是在按线性顺序访问地址空间时才是理想的，否则效率不高。因为那些常被访问的页，往往在主存中也停留得最久，结果它们因变“老”而不得不被置换出去。</p><p>FIFO的另一个缺点是，它有一种异常现象，即在增加存储块的情况下，反而使缺页中断率增加了。当然，导致这种异常现象的页面走向实际上是很少见的。</p><h2 id="最近最久未使用（LRU）算法"><a href="#最近最久未使用（LRU）算法" class="headerlink" title="最近最久未使用（LRU）算法"></a>最近最久未使用（LRU）算法</h2><p>FIFO算法和OPT算法之间的主要差别是，FIFO算法利用页面进入内存后的时间长短作为置换依据，而OPT算法的依据是将来使用页面的时间。如果以最近的过去作为不久将来的近似，那么就可以把过去最长一段时间里不曾被使用的页面置换掉。它的实质是，当需要置换一页时，*<strong>*选择在最近一段时间里最久没有使用过的页面予以置换**</strong>。这种算法就称为<strong>最久未使用算法</strong>（Least Recently Used，LRU）。</p><p>LRU算法是与每个页面最后使用的时间有关的。当必须置换一个页面时，LRU算法选择过去一段时间里最久未被使用的页面。</p><p>LRU算法是经常采用的页面置换算法，并被认为是相当好的，但是存在如何实现它的问题。LRU算法需要实际硬件的支持。其问题是怎么确定最后使用时间的顺序，对此有两种可行的办法：</p><ul><li><p>计数器。最简单的情况是使每个页表项对应一个使用时间字段，并给CPU增加一个逻辑时钟或计数器。每次存储访问，该时钟都加1。每当访问一个页面时，时钟寄存器的内容就被复制到相应页表项的使用时间字段中。这样我们就可以始终保留着每个页面最后访问的“时间”。在置换页面时，选择该时间值最小的页面。这样做，不仅要查页表，而且当页表改变时（因CPU调度）要维护这个页表中的时间，还要考虑到时钟值溢出的问题。</p></li><li><p>栈。用一个栈保留页号。每当访问一个页面时，就把它从栈中取出放在栈顶上。这样一来，栈顶总是放有目前使用最多的页，而栈底放着目前最少使用的页。由于要从栈的中间移走一项，所以要用具有头尾指针的双向链连起来。在最坏的情况下，移走一页并把它放在栈顶上需要改动6个指针。每次修改都要有开销，但需要置换哪个页面却可直接得到，用不着查找，因为尾指针指向栈底，其中有被置换页。</p></li></ul><p>因实现LRU算法必须有大量硬件支持，还需要一定的软件开销。所以实际实现的都是一种简单有效的LRU近似算法。</p><p>一种LRU近似算法是<strong>最近未使用算法</strong>（Not Recently Used，NUR）。它在存储分块表的每一表项中增加一个引用位，操作系统定期地将它们置为0。当某一页被访问时，由硬件将该位置1。过一段时间后，通过检查这些位可以确定哪些页使用过，哪些页自上次置0后还未使用过。就可把该位是0的页淘汰出去，因为在最近一段时间里它未被访问过。</p><h2 id="Clock置换算法（LRU算法的近似实现）"><a href="#Clock置换算法（LRU算法的近似实现）" class="headerlink" title="Clock置换算法（LRU算法的近似实现）"></a>Clock置换算法（LRU算法的近似实现）</h2><h2 id="最少使用（LFU）置换算法"><a href="#最少使用（LFU）置换算法" class="headerlink" title="最少使用（LFU）置换算法"></a>最少使用（LFU）置换算法</h2><p>在采用最少使用置换算法时，应为在内存中的每个页面设置一个移位寄存器，用来记录该页面被访问的频率。该置换算法选择在最近时期使用最少的页面作为淘汰页。由于存储器具有较高的访问速度，例如100 ns，在1 ms时间内可能对某页面连续访问成千上万次，因此，通常不能直接利用计数器来记录某页被访问的次数，而是采用移位寄存器方式。每次访问某页时，便将该移位寄存器的最高位置1，再每隔一定时间(例如100 ns)右移一次。这样，在最近一段时间使用最少的页面将是∑Ri最小的页。</p><p>LFU置换算法的页面访问图与LRU置换算法的访问图完全相同；或者说，利用这样一套硬件既可实现LRU算法，又可实现LFU算法。应该指出，LFU算法并不能真正反映出页面的使用情况，因为在每一时间间隔内，只是用寄存器的一位来记录页的使用情况，因此，访问一次和访问10 000次是等效的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;页面置换算法&quot;&gt;&lt;a href=&quot;#页面置换算法&quot; class=&quot;headerlink&quot; title=&quot;页面置换算法&quot;&gt;&lt;/a&gt;页面置换算法&lt;/h1&gt;&lt;p&gt;地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。当发生缺页中断时操作系统必须在内存选</summary>
      
    
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Redis集群</title>
    <link href="https://leslieaibin.github.io/2021/10/01/Redis/Redis%E9%9B%86%E7%BE%A4/"/>
    <id>https://leslieaibin.github.io/2021/10/01/Redis/Redis%E9%9B%86%E7%BE%A4/</id>
    <published>2021-10-01T01:15:42.000Z</published>
    <updated>2021-10-11T05:42:10.588Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis支持三种集群方案"><a href="#Redis支持三种集群方案" class="headerlink" title="Redis支持三种集群方案"></a>Redis支持三种集群方案</h1><ul><li>主从复制模式</li><li>Sentiel(哨兵)模式</li><li>Cluster模式</li></ul><h2 id="Redis集群的三种模式"><a href="#Redis集群的三种模式" class="headerlink" title="Redis集群的三种模式"></a>Redis集群的三种模式</h2><h3 id="主从复制模式"><a href="#主从复制模式" class="headerlink" title="主从复制模式"></a>主从复制模式</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022808581" alt="img"></p><p><strong>主从复制作用</strong></p><p>通过持久化功能，Redis保证了即使服务器重启的情况下也不会丢失（或少量丢失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。</p><p>为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使一台服务器出现故障，其他服务器依然可以继续提供服务。</p><p>为此，<strong>Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上</strong>。</p><p>在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库(slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。</p><p><strong>总结：引入主从复制机制的目的有两个</strong></p><ul><li>一个是读写分离，分担 “master” 的读写压力</li><li>一个是方便做容灾恢复</li></ul><h4 id="主从复制原理"><a href="#主从复制原理" class="headerlink" title="主从复制原理"></a><strong>主从复制原理</strong></h4><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022808583" alt="img"></p><ul><li>从数据库启动成功后，连接主数据库，发送 SYNC 命令；</li><li>主数据库接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令；</li><li>主数据库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令；</li><li>从数据库收到快照文件后丢弃所有旧数据，载入收到的快照；</li><li>主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令；</li><li>从数据库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（<strong>从数据库初始化完成</strong>）</li><li>主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令（<strong>从数据库初始化完成后的操作</strong>）</li><li>出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库，增量复制。</li><li>主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</li></ul><h4 id="主从复制优缺点"><a href="#主从复制优缺点" class="headerlink" title="主从复制优缺点"></a>主从复制优缺点</h4><p><strong>主从复制优点</strong></p><ul><li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离；</li><li>为了分载 Master 的读操作压力，Slave 服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成；</li><li>Slave 同样可以接受其它 Slaves 的连接和同步请求，这样可以有效的分载 Master 的同步压力；</li><li>Master Server 是以非阻塞的方式为 Slaves 提供服务。所以在 Master-Slave 同步期间，客户端仍然可以提交查询或修改请求；</li><li>Slave Server 同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据；</li></ul><p><strong>主从复制缺点</strong></p><ul><li>Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（<strong>也就是要人工介入</strong>）；</li><li>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；</li><li>如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。</li><li>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；</li></ul><h3 id="Sentinel（哨兵）模式"><a href="#Sentinel（哨兵）模式" class="headerlink" title="Sentinel（哨兵）模式"></a>Sentinel（哨兵）模式</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Redis支持三种集群方案&quot;&gt;&lt;a href=&quot;#Redis支持三种集群方案&quot; class=&quot;headerlink&quot; title=&quot;Redis支持三种集群方案&quot;&gt;&lt;/a&gt;Redis支持三种集群方案&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;主从复制模式&lt;/li&gt;
&lt;li&gt;Sent</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis分布式限流</title>
    <link href="https://leslieaibin.github.io/2021/09/30/Redis/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81/"/>
    <id>https://leslieaibin.github.io/2021/09/30/Redis/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81/</id>
    <published>2021-09-30T01:15:42.000Z</published>
    <updated>2021-09-30T08:44:26.803Z</updated>
    
    <content type="html"><![CDATA[<p>由于互联网公司的流量巨大，系统上线会做一个流量峰值的评估，尤其是像各种秒杀促销活动，为了保证系统不被巨大的流量压垮，会在系统流量到达一定阈值时，拒绝掉一部分流量。</p><p>限流会导致用户在短时间内（这个时间段是毫秒级的）系统不可用，一般我们衡量系统处理能力的指标是每秒的<code>QPS</code>或者<code>TPS</code>，假设系统每秒的流量阈值是1000，理论上一秒内有第1001个请求进来时，那么这个请求就会被限流。</p><h1 id="限流方案"><a href="#限流方案" class="headerlink" title="限流方案"></a>限流方案</h1><h2 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h2><p>Java内部可以通过原子类计数器<code>AtomicInteger</code>、<code>Semaphore</code>信号量来做简单的限流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 限流的个数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> maxCount = <span class="number">10</span>;</span><br><span class="line"><span class="comment">// 指定时间内</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> interval = <span class="number">60</span>;</span><br><span class="line"><span class="comment">// 原子类计数器</span></span><br><span class="line"><span class="keyword">private</span> AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"><span class="comment">// 起始时间</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> startTime = System.currentTimeMills();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">limit</span><span class="params">(<span class="keyword">int</span> maxCount, <span class="keyword">int</span> interval)</span> </span>&#123;</span><br><span class="line">    atomicInteger.addAndGet(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (atomicInteger.get() == <span class="number">1</span>) &#123;</span><br><span class="line">        startTime = System.currentTimeMillis();</span><br><span class="line">        atomicInteger.addAndGet(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 超过了间隔时间，直接重新开始计数</span></span><br><span class="line">    <span class="keyword">if</span> (System.currentTimeMillis() - startTime &gt; interval * <span class="number">1000</span>) &#123;</span><br><span class="line">        startTime = System.currentTimeMillis();</span><br><span class="line">        atomicInteger.set(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 还在间隔时间内,check有没有超过限流的个数</span></span><br><span class="line">    <span class="keyword">if</span> (atomicInteger.get() &gt; maxCount) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h2><p>漏桶算法思路很简单，我们把水比做请求，漏桶比做是系统处理能力极限，水先进入到漏桶里，漏桶里的水按一定速率流出，当流出速率小于流入的速率时，由于漏桶容量有限，后续进入的水直接溢出（拒绝请求），以此实现限流。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210930162736284.png" alt="image-20210930162736284"></p><h2 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h2><p>令牌桶算法的原理也比较简单，可以理解成医院的挂号看病，只要拿到号以后才可以进行诊病。</p><p>系统会维护 一个令牌（token）桶，以一个恒定的速度往桶里放入令牌（token），这时如果有请求进来想要被处理，则需要先从桶里获取一个令牌（token）, 当桶里没有令牌（token）可取时，则该请求将被拒绝服务。令牌桶算法通过控制桶的容量，发放令牌的速率，来达到对请求的限制。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210930163437254.png" alt="image-20210930163437254"></p><h2 id="Redis-Lua"><a href="#Redis-Lua" class="headerlink" title="Redis + Lua"></a>Redis + Lua</h2><p>个人理解，<code>Lua</code>脚本和 <code>MySQL</code>数据库的存储过程比较相似，他们执行一组命令，所有命令的执行要么全部成功或者失败，以此达到原子性。也可以把<code>Lua</code>脚本理解为，一段具有业务逻辑的代码块。</p><p>而<code>Lua</code>本身就是一种编程语言，虽然<code>redis</code> 官方没有直接提供限流相应的<code>API</code>，但却支持了 <code>Lua</code> 脚本的功能，可以使用它实现复杂的令牌桶或漏桶算法，也是分布式系统中实现限流的主要方式之一。</p><p>相比<code>Redis</code>事务，<code>Lua脚本</code>的优点：</p><ul><li>减少网络开销：使用<code>Lua</code>脚本，无需向<code>Redis</code> 发送多次请求，执行一次即可，减少网络传输</li><li>原子操作：<code>Redis</code> 将整个<code>Lua</code>脚本作为一个命令执行，原子，无需担心并发</li><li>复用：<code>Lua</code>脚本一旦执行，会永久保存 <code>Redis</code> 中,，其他客户端可复用</li></ul><p><code>Lua</code>脚本大致逻辑如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">-- 获取调用脚本时传入的第一个key值（用作限流的 key）</span><br><span class="line">local key = KEYS[<span class="number">1</span>]</span><br><span class="line">-- 获取调用脚本时传入的第一个参数值（限流大小）</span><br><span class="line">local limit = tonumber(ARGV[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">-- 获取当前流量大小</span><br><span class="line">local curentLimit = tonumber(redis.call(<span class="string">&#x27;get&#x27;</span>, key) or <span class="string">&quot;0&quot;</span>)</span><br><span class="line"></span><br><span class="line">-- 是否超出限流</span><br><span class="line"><span class="keyword">if</span> curentLimit + <span class="number">1</span> &gt; limit then</span><br><span class="line">    -- 返回(拒绝)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    -- 没有超出 value + <span class="number">1</span></span><br><span class="line">    redis.call(<span class="string">&quot;INCRBY&quot;</span>, key, <span class="number">1</span>)</span><br><span class="line">    -- 设置过期时间</span><br><span class="line">    redis.call(<span class="string">&quot;EXPIRE&quot;</span>, key, <span class="number">2</span>)</span><br><span class="line">    -- 返回(放行)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure><ul><li>通过<code>KEYS[1]</code> 获取传入的key参数</li><li>通过<code>ARGV[1]</code>获取传入的<code>limit</code>参数</li><li><code>redis.call</code>方法，从缓存中<code>get</code>和<code>key</code>相关的值，如果为<code>null</code>那么就返回0</li><li>接着判断缓存中记录的数值是否会大于限制大小，如果超出表示该被限流，返回0</li><li>如果未超过，那么该key的缓存值+1，并设置过期时间为1秒钟以后，并返回缓存值+1</li></ul><p>这种方式是本文推荐的方案，具体实现会在后边做细说。</p><h2 id="网关层限流"><a href="#网关层限流" class="headerlink" title="网关层限流"></a>网关层限流</h2><p>限流常在网关这一层做，比如<code>Nginx</code>、<code>Openresty</code>、<code>kong</code>、<code>zuul</code>、<code>Spring Cloud Gateway</code>等，而像<code>spring cloud - gateway</code>网关限流底层实现原理，就是基于<code>Redis + Lua</code>，通过内置<code>Lua</code>限流脚本的方式。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/640" alt="图片"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;由于互联网公司的流量巨大，系统上线会做一个流量峰值的评估，尤其是像各种秒杀促销活动，为了保证系统不被巨大的流量压垮，会在系统流量到达一定阈值时，拒绝掉一部分流量。&lt;/p&gt;
&lt;p&gt;限流会导致用户在短时间内（这个时间段是毫秒级的）系统不可用，一般我们衡量系统处理能力的指标是每秒</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>3.操作系统-IO模型</title>
    <link href="https://leslieaibin.github.io/2021/09/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3.IO%E6%A8%A1%E5%9E%8B/"/>
    <id>https://leslieaibin.github.io/2021/09/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3.IO%E6%A8%A1%E5%9E%8B/</id>
    <published>2021-09-29T16:15:42.000Z</published>
    <updated>2021-09-30T08:47:28.525Z</updated>
    
    <content type="html"><![CDATA[<h1 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927141630387.png" alt="image-20210927141630387"></p><p>IO (Input/Output，输入/输出)即数据的读取（接收）或写入（发送）操作，通常用户进程中的一个完整IO分为两阶段：用户进程空间&lt;–&gt;内核空间、内核空间&lt;–&gt;设备空间（磁盘、网络等）。IO有内存IO、网络IO和磁盘IO三种，通常我们说的IO指的是后两者。</p><p>LINUX中进程无法直接操作I/O设备，其必须通过系统调用请求kernel来协助完成I/O动作；内核会为每个I/O设备维护一个缓冲区。</p><p>对于一个输入操作来说，进程IO系统调用后，内核会先看缓冲区中有没有相应的缓存数据，没有的话再到设备中读取，因为设备IO一般速度较慢，需要等待；内核缓冲区有数据则直接复制到进程空间。</p><p>所以，对于一个网络输入操作通常包括两个不同阶段：</p><ul><li><p>等待网络数据到达网卡→读取到内核缓冲区，数据准备好；</p></li><li><p>从内核缓冲区复制数据到进程空间。</p><p><strong>从TCP发送数据的流程说起</strong></p></li></ul><p>要深入的理解各种IO模型，那么必须先了解下产生各种IO的原因是什么，要知道这其中的本质问题那么我们就必须要知一条消息是如何从过一个人发送到另外一个人的；</p><p>以两个应用程序通讯为例，我们来了解一下当“A”向”B” 发送一条消息，简单来说会经过如下流程：</p><p><strong>第一步</strong>：应用A把消息发送到 TCP发送缓冲区。</p><p><strong>第二步：</strong> TCP发送缓冲区再把消息发送出去，经过网络传递后，消息会发送到B服务器的TCP接收缓冲区。</p><p><strong>第三步：</strong>B再从TCP接收缓冲区去读取属于自己的数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-5311954c22d15ca91e47ab52168b7ada_720w.jpg" alt="img"></p><p>根据上图我们基本上了解消息发送要经过 应用A、应用A对应服务器的TCP发送缓冲区、经过网络传输后消息发送到了应用B对应服务器TCP接收缓冲区、然后最终B应用读取到消息。</p><p>《UNIX网络编程》说得很清楚，5种IO模型分别是阻塞IO模型、非阻塞IO模型、IO复用模型、信号驱动的IO模型、异步IO模型；前4种为同步IO操作，只有异步IO模型是异步IO操作。</p><h2 id="阻塞IO"><a href="#阻塞IO" class="headerlink" title="阻塞IO"></a>阻塞IO</h2><p><strong>思考一个问题：</strong></p><p>因为应用之间发送消息是间断性的，也就是说在上图中TCP缓冲区还没有接收到属于应用B该读取的消息时，那么此时应用B向TCP缓冲区发起读取申请，TCP接收缓冲区是应该马上告诉应用B 现在没有你的数据，还是说让应用B在这里等着，直到有数据再把数据交给应用B。</p><p>把这个问题应用到第一个步骤也是一样，应用A在向TCP发送缓冲区发送数据时，如果TCP发送缓冲区已经满了，那么是告诉应用A现在没空间了，还是让应用A等待着，等TCP发送缓冲区有空间了再把应用A的数据访拷贝到发送缓冲区。</p><p><strong>什么是阻塞IO</strong></p><p>阻塞IO就是当应用B发起读取数据申请时，在内核数据没有准备好之前，应用B会一直处于等待数据状态，直到内核把数据准备好了交给应用B才结束。</p><p><strong>术语描述</strong>：在应用调用recvfrom读取数据时，其系统调用直到数据包到达且被复制到应用缓冲区中或者发送错误时才返回，在此期间一直会等待，进程从调用到返回这段时间内都是被阻塞的称为阻塞IO；</p><p><strong>流程：</strong></p><p>1、应用进程向内核发起recfrom读取数据。</p><p>2、准备数据报（应用进程阻塞）。</p><p>3、将数据从内核负责到应用空间。</p><p>4、复制完成后，返回成功提示。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927142530568.png" alt="image-20210927142530568"></p><p><strong>1、典型应用：阻塞socket、Java BIO；</strong></p><p><strong>2、特点：</strong></p><ul><li>进程阻塞挂起不消耗CPU资源，及时响应每个操作；</li><li>实现难度低、开发应用较容易；</li><li>适用并发量小的网络应用开发；</li></ul><p>不适用并发量大的应用：因为一个请求IO会阻塞进程，所以，得为每请求分配一个处理进程（线程）以及时响应，系统开销大。</p><h2 id="非阻塞IO"><a href="#非阻塞IO" class="headerlink" title="非阻塞IO"></a>非阻塞IO</h2><p>非阻塞IO就是当应用B发起读取数据申请时，如果内核数据没有准备好会即刻告诉应用B，不会让B在这里等待。</p><p><strong>术语</strong>：非阻塞IO是在应用调用recvfrom读取数据时，如果该缓冲区没有数据的话，就会直接返回一个EWOULDBLOCK错误，不会让应用一直等待中。在没有数据的时候会即刻返回错误标识，那也意味着如果应用要读取数据就需要不断的调用recvfrom请求，直到读取到它数据要的数据为止。</p><p><strong>流程：</strong></p><p>1、应用进程向内核发起recvfrom读取数据。</p><p>2、没有数据报准备好，即刻返回EWOULDBLOCK错误码。</p><p>3、应用进程向内核发起recvfrom读取数据。</p><p>4、已有数据包准备好就进行一下 步骤，否则还是返回错误码。</p><p>5、将数据从内核拷贝到用户空间。</p><p>6、完成后，返回成功提示。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927155649702.png" alt="image-20210927155649702"></p><p>1、典型应用：socket是非阻塞的方式（设置为NONBLOCK）</p><p>2、特点：</p><ul><li>进程轮询（重复）调用，消耗CPU的资源；</li><li>实现难度低、开发应用相对阻塞IO模式较难；</li><li>适用并发量较小、且不需要及时响应的网络应用开发；</li></ul><h2 id="IO复用模型"><a href="#IO复用模型" class="headerlink" title="IO复用模型"></a><strong>IO复用模型</strong></h2><p><strong>思考一个问题：</strong></p><p>我们还是把视角放到应用B从TCP缓冲区中读取数据这个环节来。如果在并发的环境下，可能会N个人向应用B发送消息，这种情况下我们的应用就必须创建多个线程去读取数据，每个线程都会自己调用recvfrom 去读取数据。那么此时情况可能如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-529734ac694c4da96ac78eeebd7deb6b_720w.jpg" alt="img"></p><p>如上图一样，并发情况下服务器很可能一瞬间会收到几十上百万的请求，这种情况下应用B就需要创建几十上百万的线程去读取数据，同时又因为应用线程是不知道什么时候会有数据读取，为了保证消息能及时读取到，那么这些线程自己必须不断的向内核发送recvfrom 请求来读取数据；</p><p>那么问题来了，这么多的线程不断调用recvfrom 请求数据，先不说服务器能不能扛得住这么多线程，就算扛得住那么很明显这种方式是不是太浪费资源了，线程是我们操作系统的宝贵资源，大量的线程用来去读取数据了，那么就意味着能做其它事情的线程就会少。</p><p>所以，有人就提出了一个思路，能不能提供一种方式，可以由一个线程监控多个网络请求（<strong>我们后面将称为fd文件描述符，linux系统把所有网络请求以一个fd来标识</strong>），这样就可以只需要一个或几个线程就可以完成数据状态询问的操作，当有数据准备就绪之后再分配对应的线程去读取数据，这么做就可以节省出大量的线程资源出来，这个就是IO复用模型的思路。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2c65fd3534e58d3a54cdeae778a31446_720w.jpg" alt="img"></p><p>正如上图，IO复用模型的思路就是系统提供了一种函数可以同时监控多个fd的操作，这个函数就是我们常说到的select、poll、epoll函数，有了这个函数后，应用线程通过调用select函数就可以同时监控多个fd，select函数监控的fd中只要有任何一个数据状态准备就绪了，select函数就会返回可读状态，这时询问线程再去通知处理数据的线程，对应线程此时再发起recvfrom请求去读取数据。</p><p><strong>术语描述：</strong>进程通过将一个或多个fd传递给select，阻塞在select操作上，select帮我们侦测多个fd是否准备就绪，当有fd准备就绪时，select返回数据可读状态，应用程序再调用recvfrom读取数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927160639013.png" alt="image-20210927160639013"></p><p>复用IO的基本思路就是通过slect或poll、epoll 来监控多fd ，来达到不必为每个fd创建一个对应的监控线程，从而减少线程资源创建的目的。</p><p>可以看到，多个进程注册IO后，只有另一个select调用进程被阻塞。</p><p>1、典型应用：select、poll、epoll三种方案，nginx都可以选择使用这三个方案;Java NIO;</p><p>2、特点：</p><ul><li>专一进程解决多个进程IO的阻塞问题，性能好；Reactor模式;</li><li>实现、开发应用难度较大；</li><li>适用高并发服务应用开发：一个进程（线程）响应多个请求；</li></ul><p>3、select、poll、epoll</p><ul><li>Linux中IO复用的实现方式主要有select、poll和epoll：</li><li>Select：注册IO、阻塞扫描，监听的IO最大连接数不能多于FD_SIZE；</li><li>Poll：原理和Select相似，没有数量限制，但IO数量大扫描线性性能下降；</li><li>Epoll ：事件驱动不阻塞，mmap实现内核与用户空间的消息传递，数量很大，Linux2.6后内核支持；</li></ul><h2 id="信号驱动IO模型"><a href="#信号驱动IO模型" class="headerlink" title="信号驱动IO模型"></a><strong>信号驱动IO模型</strong></h2><p>复用IO模型解决了一个线程可以监控多个fd的问题，但是select是采用轮询的方式来监控多个fd的，通过不断的轮询fd的可读状态来知道是否就可读的数据，而无脑的轮询就显得有点暴力，因为大部分情况下的轮询都是无效的，所以有人就想，能不能不要我总是去问你是否数据准备就绪，能不能我发出请求后等你数据准备好了就通知我，所以就衍生了信号驱动IO模型。</p><p>于是信号驱动IO不是用循环请求询问的方式去监控数据就绪状态，而是在调用sigaction时候建立一个SIGIO的信号联系，当内核数据准备好之后再通过SIGIO信号通知线程数据准备好后的可读状态，当线程收到可读状态的信号后，此时再向内核发起recvfrom读取数据的请求，因为信号驱动IO的模型下应用线程在发出信号监控后即可返回，不会阻塞，所以这样的方式下，一个应用线程也可以同时监控多个fd。</p><p>类似于下图描述：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2461c8df6a154930afb4e7c345442835_720w.jpg" alt="img"></p><p><strong>术语描述：</strong>首先开启套接口信号驱动IO功能，并通过系统调用sigaction执行一个信号处理函数，此时请求即刻返回，当数据准备就绪时，就生成对应进程的SIGIO信号，通过信号回调通知应用线程调用recvfrom来读取数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927161210407.png" alt="image-20210927161210407"></p><p> IO复用模型里面的select虽然可以监控多个fd了，但select其实现的本质上还是通过不断的轮询fd来监控数据状态， 因为大部分轮询请求其实都是无效的，所以信号驱动IO意在通过这种建立信号关联的方式，实现了发出请求后只需要等待数据就绪的通知即可，这样就可以避免大量无效的数据状态轮询操作。</p><p>特点：回调机制，实现、开发应用难度大；</p><h2 id="异步IO模型"><a href="#异步IO模型" class="headerlink" title="异步IO模型"></a><strong>异步IO模型</strong></h2><p>不管是IO复用还是信号驱动，我们要读取一个数据总是要发起两阶段的请求，第一次发送select请求，询问数据状态是否准备好，第二次发送recevform请求读取数据。</p><p><strong>思考一个问题：</strong></p><p>也许你一开始就有一个疑问，为什么我们明明是想读取数据，什么非得要先发起一个select询问数据状态的请求，然后再发起真正的读取数据请求,能不能有一种一劳永逸的方式，我只要发送一个请求我告诉内核我要读取数据，然后我就什么都不管了，然后内核去帮我去完成剩下的所有事情？</p><p>当然既然你想得出来，那么就会有人做得到，有人设计了一种方案，应用只需要向内核发送一个read 请求,告诉内核它要读取数据后即刻返回；内核收到请求后会建立一个信号联系，当数据准备就绪，内核会主动把数据从内核复制到用户空间，等所有操作都完成之后，内核会发起一个通知告诉应用，我们称这种一劳永逸的模式为异步IO模型。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-96009f54d89ade0d8c4001bc67395c57_720w.jpg" alt="img"></p><p><strong>术语描述：</strong> 应用告知内核启动某个操作，并让内核在整个操作完成之后，通知应用，这种模型与信号驱动模型的主要区别在于，信号驱动IO只是由内核通知我们合适可以开始下一个IO操作，而异步IO模型是由内核通知我们操作什么时候完成。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927161941186.png" alt="image-20210927161941186"></p><p><strong>总结：</strong>异步IO的优化思路是解决了应用程序需要先后发送询问请求、发送接收数据请求两个阶段的模式，在异步IO的模式下，只需要向内核发送一次请求就可以完成状态询问和数拷贝的所有操作。</p><h2 id="IO模型比较"><a href="#IO模型比较" class="headerlink" title="IO模型比较"></a><strong>IO模型比较</strong></h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927164055422.png" alt="image-20210927164055422"></p><h3 id="阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型"><a href="#阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型" class="headerlink" title="阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型"></a><strong>阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型</strong></h3><p>注意这里的阻塞IO调用和非阻塞IO调用不是指阻塞IO模型和非阻塞IO模型：</p><ul><li>阻塞IO调用 ：在用户进程（线程）中调用执行的时候，进程会等待该IO操作，而使得其他操作无法执行。</li><li>非阻塞IO调用：在用户进程中调用执行的时候，无论成功与否，该IO操作会立即返回，之后进程可以进行其他操作（当然如果是读取到数据，一般就接着进行数据处理）。</li></ul><p>这个直接理解就好，进程（线程）IO调用会不会阻塞进程自己。所以这里两个概念是相对调用进程本身状态来讲的。</p><p>从上面对比图片来说，阻塞IO模型是一个阻塞IO调用，而非阻塞IO模型是多个非阻塞IO调用+一个阻塞IO调用，因为多个IO检查会立即返回错误，不会阻塞进程。</p><p>而上面也说过了，非阻塞IO模型对于阻塞IO模型来说区别就是，内核数据没准备好需要进程阻塞的时候，就返回一个错误，以使得进程不被阻塞。</p><h3 id="同步IO和异步IO"><a href="#同步IO和异步IO" class="headerlink" title="同步IO和异步IO"></a><strong>同步IO和异步IO</strong></h3><ul><li>同步IO：导致请求进程阻塞，直到I/O操作完成。</li><li>异步IO：不导致请求进程阻塞。</li></ul><p>上面两个定义是《UNIX网络编程 卷1：套接字联网API》给出的。这不是很好理解，我们来扩展一下，先说说同步和异步，同步和异步关注的是双方的消息通信机制：</p><ul><li>同步：双方的动作是经过双方协调的，步调一致的。</li><li>异步：双方并不需要协调，都可以随意进行各自的操作。</li></ul><p>这里我们的双方是指，用户进程和IO设备；明确同步和异步之后，我们在上面网络输入操作例子的基础上，进行扩展定义：</p><ul><li>同步IO：用户进程发出IO调用，去获取IO设备数据，双方的数据要经过内核缓冲区同步，完全准备好后，再复制返回到用户进程。而复制返回到用户进程会导致请求进程阻塞，直到I/O操作完成。</li><li>异步IO：用户进程发出IO调用，去获取IO设备数据，并不需要同步，内核直接复制到进程，整个过程不导致请求进程阻塞。</li></ul><p>所以， 阻塞IO模型、非阻塞IO模型、IO复用模型、信号驱动的IO模型者为同步IO模型，只有异步IO模型是异步IO。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;IO&quot;&gt;&lt;a href=&quot;#IO&quot; class=&quot;headerlink&quot; title=&quot;IO&quot;&gt;&lt;/a&gt;IO&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20</summary>
      
    
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据结构</title>
    <link href="https://leslieaibin.github.io/2021/09/29/Redis/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://leslieaibin.github.io/2021/09/29/Redis/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2021-09-29T01:15:42.000Z</published>
    <updated>2021-09-30T08:44:00.941Z</updated>
    
    <content type="html"><![CDATA[<p>Redist有五种基本数据结构：<strong>string、hash、set、zset、list</strong>。这五种数据结构的底层数据结构有六种：<strong>动态字符串SDS、链表、哈希表、跳表、整数集合、压缩链表</strong></p><h1 id="底层结构"><a href="#底层结构" class="headerlink" title="底层结构"></a>底层结构</h1><p>Redis是用C语言写的，但是Redis并没有使用C的字符串表示（C是字符串是以<code>\0</code>空字符结尾的字符数组），而是自己构建了一种<strong>简单动态字符串</strong>（simple dynamic string，SDS）的抽象类型，并作为Redis的默认字符串表示</p><p>在Redis中，包含字符串值的键值对底层都是用SDS实现的</p><h2 id="动态字符串SDS"><a href="#动态字符串SDS" class="headerlink" title="动态字符串SDS"></a>动态字符串SDS</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3.0</span></span><br><span class="line">struct sdshdr &#123;</span><br><span class="line">    <span class="comment">// 记录buf数组中已使用字节的数量，即SDS所保存字符串的长度</span></span><br><span class="line">    unsigned <span class="keyword">int</span> len;</span><br><span class="line">    <span class="comment">// 记录buf数据中未使用的字节数量</span></span><br><span class="line">    unsigned <span class="keyword">int</span> free;</span><br><span class="line">    <span class="comment">// 字节数组，用于保存字符串</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.2</span></span><br><span class="line"><span class="comment">/* Note: sdshdr5 is never used, we just access the flags byte directly.</span></span><br><span class="line"><span class="comment"> * However is here to document the layout of type 5 SDS strings. */</span></span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr5 </span>&#123;</span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, and 5 msb of string length */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr8 </span>&#123;</span><br><span class="line">    uint8_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint8_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr16 </span>&#123;</span><br><span class="line">    uint16_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint16_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr32 </span>&#123;</span><br><span class="line">    uint32_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint32_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr64 </span>&#123;</span><br><span class="line">    uint64_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint64_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>3.2版本之后，会根据字符串的长度来选择对应的数据结构</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">char</span> <span class="title">sdsReqType</span><span class="params">(<span class="keyword">size_t</span> string_size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1</span>&lt;&lt;<span class="number">5</span>)  <span class="comment">// 32</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_5;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1</span>&lt;&lt;<span class="number">8</span>)  <span class="comment">// 256</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_8;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1</span>&lt;&lt;<span class="number">16</span>)   <span class="comment">// 65536 64k</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_16;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1l</span>l&lt;&lt;<span class="number">32</span>)  <span class="comment">// 4294967296 4G</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_32;</span><br><span class="line">    <span class="keyword">return</span> SDS_TYPE_64;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d245812d1e41c5~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p><code>len</code>：记录当前已使用的字节数（不包括<code>&#39;\0&#39;</code>），获取SDS长度的复杂度为O(1)</p><p><code>alloc</code>：记录当前字节数组总共分配的字节数量（不包括<code>&#39;\0&#39;</code>）</p><p><code>flags</code>：标记当前字节数组的属性，是<code>sdshdr8</code>还是<code>sdshdr16</code>等，flags值的定义可以看下面代码</p><p><code>buf</code>：字节数组，用于保存字符串，包括结尾空白字符`’\0’</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// flags值定义</span></span><br><span class="line">#define SDS_TYPE_5  0</span><br><span class="line">#define SDS_TYPE_8  1</span><br><span class="line">#define SDS_TYPE_16 2</span><br><span class="line">#define SDS_TYPE_32 3</span><br><span class="line">#define SDS_TYPE_64 4</span><br></pre></td></tr></table></figure><p>上面的字节数组的空白处表示未使用空间，是Redis优化的空间策略，给字符串的操作留有余地，保证安全提高效率</p><h2 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h2><p>链表上的节点定义如下，<code>adlist.h/listNode</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">typedef struct listNode &#123;</span><br><span class="line">    <span class="comment">// 前置节点</span></span><br><span class="line">    struct listNode *prev;</span><br><span class="line">    <span class="comment">// 后置节点</span></span><br><span class="line">    struct listNode *next;</span><br><span class="line">    <span class="comment">// 节点值</span></span><br><span class="line">    <span class="keyword">void</span> *value;</span><br><span class="line">&#125; listNode;</span><br></pre></td></tr></table></figure><p>链表的定义如下，<code>adlist.h/list</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">typedef struct list &#123;</span><br><span class="line">    <span class="comment">// 链表头节点</span></span><br><span class="line">    listNode *head;</span><br><span class="line">    <span class="comment">// 链表尾节点</span></span><br><span class="line">    listNode *tail;</span><br><span class="line">    <span class="comment">// 节点值复制函数</span></span><br><span class="line">    <span class="keyword">void</span> *(*dup)(<span class="keyword">void</span> *ptr);</span><br><span class="line">    <span class="comment">// 节点值释放函数</span></span><br><span class="line">    <span class="keyword">void</span> (*free)(<span class="keyword">void</span> *ptr);</span><br><span class="line">    <span class="comment">// 节点值对比函数</span></span><br><span class="line">    <span class="keyword">int</span> (*match)(<span class="keyword">void</span> *ptr, <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 链表所包含的节点数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> len;</span><br><span class="line">&#125; list;</span><br></pre></td></tr></table></figure><p>每个节点<code>listNode</code>可以通过<code>prev</code>和<code>next</code>指针分布指向前一个节点和后一个节点组成双端链表，同时每个链表还会有一个<code>list</code>结构为链表提供表头指针<code>head</code>、表尾指针<code>tail</code>、以及链表长度计数器<code>len</code>，还有三个用于实现多态链表的类型特定函数</p><ul><li><code>dup</code>：用于复制链表节点所保存的值</li><li><code>free</code>：用于释放链表节点所保存的值</li><li><code>match</code>：用于对比链表节点所保存的值和另一个输入值是否相等</li></ul><p> <strong>链表结构图</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318c8442f7~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p> <strong>链表特性</strong></p><ul><li>双端链表：带有指向前置节点和后置节点的指针，获取这两个节点的复杂度为O(1)</li><li>无环：表头节点的<code>prev</code>和表尾节点的<code>next</code>都指向NULL，对链表的访问以NULL结束</li><li>链表长度计数器：带有<code>len</code>属性，获取链表长度的复杂度为O(1)</li><li>多态：链表节点使用 <code>void*</code>指针保存节点值，可以保存不同类型的值</li></ul><h3 id="3-2版本后更改"><a href="#3-2版本后更改" class="headerlink" title="3.2版本后更改"></a>3.2版本后更改</h3><p>quicklist：</p><p>（1）什么是quicklist：</p><p>quicklist是一个双向链表，而且是一个基于ziplist的双向链表，quicklist的每个节点都是一个ziplist，比如，一个包含3个节点的quicklist，如果每个节点的ziplist又包含4个数据项，那么对外表现上，这个list就总共包含12个数据项。</p><p>quicklist的结构为什么这样设计呢？总结起来，大概又是一个空间和时间的折中：</p><p>双向链表便于在表的两端进行push和pop操作，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。<br>ziplist由于是一整块连续内存，所以存储效率很高。但是，它不利于修改操作，每次数据变动都会引发一次内存的realloc。特别是当ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝，进一步降低性能。<br>于是，结合了双向链表和ziplist的优点，quicklist就应运而生了。</p><p>（2）quicklist中每个ziplist长度的配置：</p><p>不过，这也带来了一个新问题：到底一个quicklist节点包含多长的ziplist合适呢？比如，同样是存储12个数据项，既可以是一个quicklist包含3个节点，而每个节点的ziplist又包含4个数据项，也可以是一个quicklist包含6个节点，而每个节点的ziplist又包含2个数据项。</p><p>这又是一个需要找平衡点的难题。我们只从存储效率上分析一下：</p><p>每个quicklist节点上的ziplist越短，则内存碎片越多。内存碎片多了，有可能在内存中产生很多无法被利用的小碎片，从而降低存储效率。这种情况的极端是每个quicklist节点上的ziplist只包含一个数据项，这就蜕化成一个普通的双向链表了。<br>每个quicklist节点上的ziplist越长，则为ziplist分配大块连续内存空间的难度就越大。有可能出现内存里有很多小块的空闲空间（它们加起来很多），但却找不到一块足够大的空闲空间分配给ziplist的情况。这同样会降低存储效率。这种情况的极端是整个quicklist只有一个节点，所有的数据项都分配在这仅有的一个节点的ziplist里面。这其实蜕化成一个ziplist了<br>可见，一个quicklist节点上的ziplist要保持一个合理的长度。那到底多长合理呢？这可能取决于具体应用场景。实际上，Redis提供了一个配置参数list-max-ziplist-size，就是为了让使用者可以来根据自己的情况进行调整。</p><p>list-max-ziplist-size -2</p><p>这个参数可以取正值，也可以取负值。</p><p>当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。</p><p>当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值，每个值含义如下：</p><p>-5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =&gt; 1024 bytes）</p><p>-4: 每个quicklist节点上的ziplist大小不能超过32 Kb。</p><p>-3: 每个quicklist节点上的ziplist大小不能超过16 Kb。</p><p>-2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值）</p><p>-1: 每个quicklist节点上的ziplist大小不能超过4 Kb。</p><h2 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h2><p>哈希表又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。字典中的每一个键都是唯一的，可以通过键查找与之关联的值，并对其修改或删除</p><p>Redis的键值对存储就是用哈希表实现的，散列（Hash）的底层实现之一也是哈希表</p><p>哈希表结构定义，<code>dict.h/dictht</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictht &#123;</span><br><span class="line">    <span class="comment">// 哈希表数组</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="comment">// 哈希表大小</span></span><br><span class="line">    unsigned <span class="keyword">long</span> size;</span><br><span class="line">    <span class="comment">// 哈希表大小掩码，用于计算索引值，等于size-1</span></span><br><span class="line">    unsigned <span class="keyword">long</span> sizemask;</span><br><span class="line">    <span class="comment">// 哈希表已有节点的数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure><p>哈希表是由数组<code>table</code>组成，<code>table</code>中每个元素都是指向<code>dict.h/dictEntry</code>结构的指针，哈希表节点的定义如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictEntry &#123;</span><br><span class="line">    <span class="comment">// 键</span></span><br><span class="line">    <span class="keyword">void</span> *key;</span><br><span class="line">    <span class="comment">// 值</span></span><br><span class="line">    union &#123;</span><br><span class="line">        <span class="keyword">void</span> *val;</span><br><span class="line">        uint64_t u64;</span><br><span class="line">        int64_t s64;</span><br><span class="line">        <span class="keyword">double</span> d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="comment">// 指向下一个哈希表节点，形成链表</span></span><br><span class="line">    struct dictEntry *next;</span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure><p>其中<code>key</code>是我们的键；<code>v</code>是键值，可以是一个指针，也可以是整数或浮点数；<code>next</code>属性是指向下一个哈希表节点的指针，可以让多个哈希值相同的键值对形成链表，解决键冲突问题</p><p>最后就是我们的字典结构，<code>dict.h/dict</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dict &#123;</span><br><span class="line">    <span class="comment">// 和类型相关的处理函数</span></span><br><span class="line">    dictType *type;</span><br><span class="line">    <span class="comment">// 私有数据</span></span><br><span class="line">    <span class="keyword">void</span> *privdata;</span><br><span class="line">    <span class="comment">// 哈希表</span></span><br><span class="line">    dictht ht[<span class="number">2</span>];</span><br><span class="line">    <span class="comment">// rehash 索引，当rehash不再进行时，值为-1</span></span><br><span class="line">    <span class="keyword">long</span> rehashidx; <span class="comment">/* rehashing not in progress if rehashidx == -1 */</span></span><br><span class="line">    <span class="comment">// 迭代器数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> iterators; <span class="comment">/* number of iterators currently running */</span></span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure><p><code>type</code>属性和<code>privdata</code>属性是针对不同类型的键值对，用于创建多类型的字典，<code>type</code>是指向<code>dictType</code>结构的指针，<code>privdata</code>则保存需要传给类型特定函数的可选参数，关于<code>dictType</code>结构和类型特定函数可以看下面代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictType &#123;</span><br><span class="line">    <span class="comment">// 计算哈希值的行数</span></span><br><span class="line">    uint64_t (*hashFunction)(<span class="keyword">const</span> <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 复制键的函数</span></span><br><span class="line">    <span class="keyword">void</span> *(*keyDup)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 复制值的函数</span></span><br><span class="line">    <span class="keyword">void</span> *(*valDup)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *obj);</span><br><span class="line">    <span class="comment">// 对比键的函数</span></span><br><span class="line">    <span class="keyword">int</span> (*keyCompare)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *key1, <span class="keyword">const</span> <span class="keyword">void</span> *key2);</span><br><span class="line">    <span class="comment">// 销毁键的函数</span></span><br><span class="line">    <span class="keyword">void</span> (*keyDestructor)(<span class="keyword">void</span> *privdata, <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 销毁值的函数</span></span><br><span class="line">    <span class="keyword">void</span> (*valDestructor)(<span class="keyword">void</span> *privdata, <span class="keyword">void</span> *obj);</span><br><span class="line">&#125; dictType;</span><br></pre></td></tr></table></figure><p><code>dict</code>的<code>ht</code>属性是两个元素的数组，包含两个<code>dictht</code>哈希表，一般字典只使用<code>ht[0]</code>哈希表，<code>ht[1]</code>哈希表会在对<code>ht[0]</code>哈希表进行<code>rehash</code>（重哈希）的时候使用，即当哈希表的键值对数量超过负载数量过多的时候，会将键值对迁移到<code>ht[1]</code>上</p><p><code>rehashidx</code>也是跟rehash相关的，rehash的操作不是瞬间完成的，<code>rehashidx</code>记录着rehash的进度，如果目前没有在进行rehash，它的值为-1</p><p>结合上面的几个结构，我们来看一下<strong>字典的结构图</strong>（没有在进行rehash）</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318d3796f5~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><p>一个普通的单链表查询一个元素的时间复杂度为O(N)，即便该单链表是有序的。使用跳跃表（SkipList）是来解决查找问题的，它是一种有序的数据结构，不属于平衡树结构，也不属于Hash结构，它通过在每个节点维持多个指向其他节点的指针，而达到快速访问节点的目的</p><p>跳跃表是有序集合（Sorted Set）的底层实现之一，如果有序集合包含的元素比较多，或者元素的成员是比较长的字符串时，Redis会使用跳跃表做有序集合的底层实现</p><p> <strong>跳跃表的定义</strong></p><p>跳跃表其实可以把它理解为<strong>多层的链表</strong>，它有如下的性质</p><ul><li><strong>多层</strong>的结构组成，每层是一个<strong>有序的链表</strong></li><li>最底层（level 1）的链表包含所有的元素</li><li>跳跃表的查找次数近似于层数，时间复杂度为O(logn)，插入、删除也为 O(logn)</li><li>跳跃表是一种随机化的数据结构(通过抛硬币来决定层数)</li></ul><p>那么如何来理解跳跃表呢，我们从最底层的包含所有元素的链表开始，给定如下的链表</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318d89eb55~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>然后我们每隔一个元素，把它放到上一层的链表当中，这里我把它叫做<strong>上浮</strong>（注意，科学的办法是<strong>抛硬币</strong>的方式，来决定元素是否上浮到上一层链表，我这里先简单每隔一个元素上浮到上一层链表，便于理解），操作完成之后的结构如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318d9e2558~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>查找元素的方法是这样，从上层开始查找，大数向右找到头，小数向左找到头，例如我要查找<code>17</code>，查询的顺序是：13 -&gt; 46  -&gt; 22 -&gt; 17；如果是查找<code>35</code>，则是 13 -&gt; 46 -&gt; 22 -&gt; 46 -&gt; 35；如果是<code>54</code>，则是 13 -&gt; 46 -&gt; 54</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318db56821~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>上面是查找元素，如果是添加元素，是通过抛硬币的方式来决定该元素会出现到多少层，也就是说它会有 1/2的概率出现第二层、1/4 的概率出现在第三层……</p><p>跳跃表节点的删除和添加都是不可预测的，很难保证跳表的索引是始终均匀的，抛硬币的方式可以让大体上是趋于均匀的</p><p>假设我们已经有了上述例子的一个跳跃表了，现在往里面添加一个元素<code>18</code>，通过抛硬币的方式来决定它会出现的层数，是正面就继续，反面就停止，假如我抛了2次硬币，第一次为正面，第二次为反面</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31ad5ebfc9~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>跳跃表的删除很简单，只要先找到要删除的节点，然后顺藤摸瓜删除每一层相同的节点就好了</p><p>跳跃表维持结构平衡的成本是比较低的，完全是依靠随机，相比二叉查找树，在多次插入删除后，需要Rebalance来重新调整结构平衡</p><p><strong>跳跃表的实现</strong></p><p>Redis的跳跃表实现是由<code>redis.h/zskiplistNode</code>和<code>redis.h/zskiplist</code>（3.2版本之后redis.h改为了server.h）两个结构定义，<code>zskiplistNode</code>定义跳跃表的节点，<code>zskiplist</code>保存跳跃表节点的相关信息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ZSETs use a specialized version of Skiplists */</span></span><br><span class="line">typedef struct zskiplistNode &#123;</span><br><span class="line">    <span class="comment">// 成员对象 （robj *obj;）</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">// 分值</span></span><br><span class="line">    <span class="keyword">double</span> score;</span><br><span class="line">    <span class="comment">// 后退指针</span></span><br><span class="line">    struct zskiplistNode *backward;</span><br><span class="line">    <span class="comment">// 层</span></span><br><span class="line">    struct zskiplistLevel &#123;</span><br><span class="line">        <span class="comment">// 前进指针</span></span><br><span class="line">        struct zskiplistNode *forward;</span><br><span class="line">        <span class="comment">// 跨度</span></span><br><span class="line">        <span class="comment">// 跨度实际上是用来计算元素排名(rank)的，在查找某个节点的过程中，将沿途访过的所有层的跨度累积起来，得到的结果就是目标节点在跳跃表中的排位</span></span><br><span class="line">        unsigned <span class="keyword">long</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br><span class="line"></span><br><span class="line">typedef struct zskiplist &#123;</span><br><span class="line">    <span class="comment">// 表头节点和表尾节点</span></span><br><span class="line">    struct zskiplistNode *header, *tail;</span><br><span class="line">    <span class="comment">// 表中节点的数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> length;</span><br><span class="line">    <span class="comment">// 表中层数最大的节点的层数</span></span><br><span class="line">    <span class="keyword">int</span> level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure><p><code>zskiplistNode</code>结构</p><ul><li><code>level</code>数组（层）：每次创建一个新的跳表节点都会根据幂次定律计算出level数组的大小，也就是次层的高度，每一层带有两个属性-<strong>前进指针</strong>和<strong>跨度</strong>，前进指针用于访问表尾方向的其他指针；跨度用于记录当前节点与前进指针所指节点的距离（指向的为NULL，阔度为0）</li><li><code>backward</code>（后退指针）：指向当前节点的前一个节点</li><li><code>score</code>（分值）：用来排序，如果分值相同看成员变量在字典序大小排序</li><li><code>obj</code>或<code>ele</code>：成员对象是一个指针，指向一个字符串对象，里面保存着一个sds；在跳表中各个节点的成员对象必须唯一，分值可以相同</li></ul><p><code>zskiplist</code>结构</p><ul><li><code>header</code>、<code>tail</code>表头节点和表尾节点</li><li><code>length</code>表中节点的数量</li><li><code>level</code>表中层数最大的节点的层数</li></ul><p>假设我们现在展示一个跳跃表，有四个节点，节点的高度分别是2、1、4、</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b0f3da89~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p><code>zskiplist</code>的头结点不是一个有效的节点，它有<strong>ZSKIPLIST_MAXLEVEL</strong>层(32层)，每层的<code>forward</code>指向该层跳跃表的第一个节点，若没有则为NULL，在Redis中，上面的跳跃表结构如下</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b46f4b67~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><ul><li>每个跳跃表节点的层数在1-32之间</li><li>一个跳跃表中，节点按照分值大小排序，多个节点的分值是可以相同的，相同时，节点按成员对象大小排序</li><li>每个节点的成员变量必须是唯一的</li></ul><h2 id="整数集合"><a href="#整数集合" class="headerlink" title="整数集合"></a>整数集合</h2><p>整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，可以保存类型为int16_t、int32_t、int64_t的整数值，并且保证集合中不会出现重复元素</p><p>整数集合是集合（Set）的底层实现之一，如果一个集合只包含整数值元素，且元素数量不多时，会使用整数集合作为底层实现</p><p><strong>整数集合的定义实现</strong></p><p>整数集合的定义为<code>inset.h/inset</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">typedef struct intset &#123;</span><br><span class="line">    <span class="comment">// 编码方式</span></span><br><span class="line">    uint32_t encoding;</span><br><span class="line">    <span class="comment">// 集合包含的元素数量</span></span><br><span class="line">    uint32_t length;</span><br><span class="line">    <span class="comment">// 保存元素的数组</span></span><br><span class="line">    int8_t contents[];</span><br><span class="line">&#125; intset;</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><ul><li><code>contents</code>数组：整数集合的每个元素在数组中按值的大小从小到大排序，且不包含重复项</li><li><code>length</code>记录整数集合的元素数量，即contents数组长度</li><li><code>encoding</code>决定contents数组的真正类型，如INTSET_ENC_INT16、INTSET_ENC_INT32、INTSET_ENC_INT64</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b471202a~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p> <strong>整数集合的升级</strong></p><p>当想要添加一个新元素到整数集合中时，并且新元素的类型比整数集合现有的所有元素的类型都要长，整数集合需要先进行升级（upgrade），才能将新元素添加到整数集合里面。每次想整数集合中添加新元素都有可能会引起升级，每次升级都需要对底层数组已有的所有元素进行类型转换</p><p>升级添加新元素：</p><ul><li>根据新元素类型，扩展整数集合底层数组的空间大小，并为新元素分配空间</li><li>把数组现有的元素都转换成新元素的类型，并将转换后的元素放到正确的位置，且要保持数组的有序性</li><li>添加新元素到底层数组</li></ul><p>整数集合的升级策略可以提升整数集合的灵活性，并尽可能的节约内存</p><p>另外，整数集合不支持降级，一旦升级，编码就会一直保持升级后的状态</p><h2 id="压缩链表"><a href="#压缩链表" class="headerlink" title="压缩链表"></a>压缩链表</h2><p>压缩列表（ziplist）是为了节约内存而设计的，是由一系列特殊编码的连续内存块组成的顺序性（sequential）数据结构，一个压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者一个整数值</p><p>压缩列表是列表（List）和散列（Hash）的底层实现之一，一个列表只包含少量列表项，并且每个列表项是小整数值或比较短的字符串，会使用压缩列表作为底层实现（在3.2版本之后是使用<code>quicklist</code>实现）</p><p><strong>压缩列表的构成</strong></p><p>一个压缩列表可以包含多个节点（entry），每个节点可以保存一个字节数组或者一个整数值</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b5614230~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>各部分组成说明如下</p><ul><li><code>zlbytes</code>：记录整个压缩列表占用的内存字节数，在压缩列表内存重分配，或者计算<code>zlend</code>的位置时使用</li><li><code>zltail</code>：记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过该偏移量，可以不用遍历整个压缩列表就可以确定表尾节点的地址</li><li><code>zllen</code>：记录压缩列表包含的节点数量，但该属性值小于UINT16_MAX（65535）时，该值就是压缩列表的节点数量，否则需要遍历整个压缩列表才能计算出真实的节点数量</li><li><code>entryX</code>：压缩列表的节点</li><li><code>zlend</code>：特殊值0xFF（十进制255），用于标记压缩列表的末端</li></ul><p><strong>压缩列表节点的构成</strong></p><p>每个压缩列表节点可以保存一个字节数字或者一个整数值，结构如下</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b502238d~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><ul><li><code>previous_entry_ength</code>：记录压缩列表前一个字节的长度</li><li><code>encoding</code>：节点的encoding保存的是节点的content的内容类型</li><li><code>content</code>：content区域用于保存节点的内容，节点内容类型和长度由encoding决定</li></ul><h2 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h2><p>上面介绍了Redis的主要底层数据结构，包括简单动态字符串（SDS）、链表、字典、跳跃表、整数集合、压缩列表。但是Redis并没有直接使用这些数据结构来构建键值对数据库，而是基于这些数据结构创建了一个对象系统，也就是我们所熟知的可API操作的Redis那些数据类型，如字符串(String)、列表(List)、散列(Hash)、集合(Set)、有序集合(Sorted Set)</p><p>根据对象的类型可以判断一个对象是否可以执行给定的命令，也可针对不同的使用场景，对象设置有多种不同的数据结构实现，从而优化对象在不同场景下的使用效率</p><table><thead><tr><th>类型</th><th>编码</th><th>BOJECT ENCODING 命令输出</th><th>对象</th></tr></thead><tbody><tr><td>REDIS_STRING</td><td>REDIS_ENCODING_INT</td><td>“int”</td><td>使用整数值实现的字符串对象</td></tr><tr><td>REDIS_STRING</td><td>REDIS_ENCODING_EMBSTR</td><td>“embstr”</td><td>使用embstr编码的简单动态字符串实现的字符串对象</td></tr><tr><td>REDIS_STRING</td><td>REDIS_ENCODING_RAW</td><td>“raw”</td><td>使用简单动态字符串实现的字符串对象</td></tr><tr><td>REDIS_LIST</td><td>REDIS_ENCODING_ZIPLIST</td><td>“ziplist”</td><td>使用压缩列表实现的列表对象</td></tr><tr><td>REDIS_LIST</td><td>REDIS_ENCODING_LINKEDLIST</td><td>‘“linkedlist’</td><td>使用双端链表实现的列表对象</td></tr><tr><td>REDIS_HASH</td><td>REDIS_ENCODING_ZIPLIST</td><td>“ziplist”</td><td>使用压缩列表实现的哈希对象</td></tr><tr><td>REDIS_HASH</td><td>REDIS_ENCODING_HT</td><td>“hashtable”</td><td>使用字典实现的哈希对象</td></tr><tr><td>REDIS_SET</td><td>REDIS_ENCODING_INTSET</td><td>“intset”</td><td>使用整数集合实现的集合对象</td></tr><tr><td>REDIS_SET</td><td>REDIS_ENCODING_HT</td><td>“hashtable”</td><td>使用字典实现的集合对象</td></tr><tr><td>REDIS_ZSET</td><td>REDIS_ENCODING_ZIPLIST</td><td>“ziplist”</td><td>使用压缩列表实现的有序集合对象</td></tr><tr><td>REDIS_ZSET</td><td>REDIS_ENCODING_SKIPLIST</td><td>“skiplist”</td><td>使用跳跃表表实现的有序集合对象</td></tr></tbody></table><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>String数据结构是最简单的数据类型。一般用于复杂的计数功能的缓存：微博数，粉丝数等。</p><p><strong>底层实现方式：动态字符串sds 或者 long</strong></p><p>String的内部存储结构一般是sds（Simple Dynamic String，可以动态扩展内存），但是如果一个String类型的value的值是数字，那么Redis内部会把它转成long类型来存储，从而减少内存的使用。</p><ul><li>确切地说，String在Redis中是用一个robj来表示的。</li><li>用来表示String的robj可能编码成3种内部表示：OBJ_ENCODING_RAW，OBJ_ENCODING_EMBSTR，OBJ_ENCODING_INT。其中前两种编码使用的是sds来存储，最后一种OBJ_ENCODING_INT编码直接把string存成了long型。</li><li>在对string进行incr, decr等操作的时候，如果它内部是OBJ_ENCODING_INT编码，那么可以直接进行加减操作；如果它内部是OBJ_ENCODING_RAW或OBJ_ENCODING_EMBSTR编码，那么Redis会先试图把sds存储的字符串转成long型，如果能转成功，再进行加减操作。</li><li>对一个内部表示成long型的string执行append, setbit, getrange这些命令，针对的仍然是string的值（即十进制表示的字符串），而不是针对内部表示的long型进行操作。比如字符串”32”，如果按照字符数组来解释，它包含两个字符，它们的ASCII码分别是0x33和0x32。当我们执行命令setbit key 7 0的时候，相当于把字符0x33变成了0x32，这样字符串的值就变成了”22”。而如果将字符串”32”按照内部的64位long型来解释，那么它是0x0000000000000020，在这个基础上执行setbit位操作，结果就完全不对了。因此，在这些命令的实现中，会把long型先转成字符串再进行相应的操作。</li></ul><h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><p>Hash特别适合用于存储对象，因为一个对象的各个属性，正好对应一个hash结构的各个field，可以方便地操作对象中的某个字段。</p><p><strong>底层实现方式：压缩列表ziplist 或者 字典dict</strong></p><p>当Hash中数据项比较少的情况下，Hash底层才用压缩列表ziplist进行存储数据，随着数据的增加，底层的ziplist就可能会转成dict，具体配置如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hash-max-ziplist-entries <span class="number">512</span></span><br><span class="line">hash-max-ziplist-value <span class="number">64</span></span><br></pre></td></tr></table></figure><p>当hash中的数据项（即filed-value对）的数目超过512时，也就是ziplist数据项超过1024的时候<br>当hash中插入的任意一个value的长度超过了64字节的时候</p><p>当满足上面两个条件其中之一的时候，Redis就使用dict字典来实现hash。</p><p>Redis的hash之所以这样设计，是因为当ziplist变得很大的时候，它有如下几个缺点：</p><ul><li><p>每次插入或修改引发的realloc操作会有更大的概率造成内存拷贝，从而降低性能。</p></li><li><p>一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。</p></li><li><p>当ziplist数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。</p></li></ul><p>总之，ziplist本来就设计为各个数据项挨在一起组成连续的内存空间，这种结构并不擅长做修改操作。一旦数据发生改动，就会引发内存realloc，可能导致内存拷贝。</p><h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>list 的实现为一个双向链表，经常被用作队列使用，支持在链表两端进行push和pop操作，时间复杂度为O(1)；同时也支持在链表中的任意位置的存取操作，但是都需要对list进行遍历，支持反向查找和遍历，时间复杂度为O(n)。</p><p>list是一个能维持数据项先后顺序的列表（各个数据项的先后顺序由插入位置决定），便于在表的两端追加和删除数据，而对于中间位置的存取具有O(N)的时间复杂度。</p><p>list 的应用场景非常多，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。可以利用lrange命令，做基于redis的分页功能。</p><ul><li><strong>Redis3.2之前的底层实现方式：压缩列表ziplist 或者 双向循环链表linkedlist</strong></li></ul><p>当list存储的数据量比较少且同时满足下面两个条件时，list就使用ziplist存储数据：</p><p>list中保存的每个元素的长度小于 64 字节；</p><p>列表中数据个数少于512个。</p><p>当不能同时满足上面两个条件的时候，list就通过双向循环链表linkedlist来实现了</p><ul><li><strong>Redis3.2及之后的底层实现方式：quicklist</strong></li></ul><p>quicklist是一个双向链表，而且是一个基于ziplist的双向链表，quicklist的每个节点都是一个ziplist，结合了双向链表和ziplist的优点</p><h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>set是一个存放不重复值的无序集合，可以做全局去重的功能，提供了判断某个元素是否在set集合内的功能，这个也是list所不能提供的。基于set可以实现交集、并集、差集的操作，计算共同喜好，全部的喜好，自己独有的喜好等功能。</p><p><strong>底层实现方式：有序整数集合intset 或者 字典dict</strong></p><p>当存储的数据同时满足下面这样两个条件的时候，Redis 就采用整数集合intset来实现set这种数据类型：</p><ul><li>存储的数据都是整数</li><li>存储的数据元素个数小于512个</li></ul><p>当不能同时满足这两个条件的时候，Redis 就使用dict来存储集合中的数据</p><h2 id="Sorted-Set"><a href="#Sorted-Set" class="headerlink" title="Sorted Set"></a>Sorted Set</h2><p>Sorted set多了一个权重参数score，集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。另外，sorted set可以用来做延时任务。最后一个应用就是可以做范围查找。</p><p><strong>底层实现方式：压缩列表ziplist 或者 zskiplistNode</strong></p><p>当存储的数据同时满足下面这两个条件的时候，Redis就使用压缩列表ziplist实现sorted set</p><ul><li>集合中每个数据的大小都要小于 64 字节</li><li>元素个数要小于 128 个，也就是ziplist数据项小于256个</li></ul><p>当不能同时满足这两个条件的时候，Redis 就使用zskiplistNode来实现sorted set。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Redist有五种基本数据结构：&lt;strong&gt;string、hash、set、zset、list&lt;/strong&gt;。这五种数据结构的底层数据结构有六种：&lt;strong&gt;动态字符串SDS、链表、哈希表、跳表、整数集合、压缩链表&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;底层</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>MQ的作用</title>
    <link href="https://leslieaibin.github.io/2021/09/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/MQ%E7%9A%84%E4%BD%9C%E7%94%A8%E6%80%BB%E7%BB%93/"/>
    <id>https://leslieaibin.github.io/2021/09/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/MQ%E7%9A%84%E4%BD%9C%E7%94%A8%E6%80%BB%E7%BB%93/</id>
    <published>2021-09-26T01:15:42.000Z</published>
    <updated>2021-10-06T10:27:41.847Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MQ的作用"><a href="#MQ的作用" class="headerlink" title="MQ的作用"></a>MQ的作用</h1><p>消息队列在大型电子商务类网站，如京东、淘宝、去哪儿等网站有着深入的应用，</p><p>队列的主要作用是消除高并发访问高峰，加快网站的响应速度。</p><p>在不使用消息队列的情况下，用户的请求数据直接写入数据库，在高并发的情况下，会对数据库造成巨大的压力，同时也使得系统响应延迟加剧。</p><p>在使用队列后，用户的请求发给队列后立即返回,</p><p>（例如: 当然不能直接给用户提示订单提交成功，京东上提示：您“您提交了订单，请等待系统确认”），</p><p>再由消息队列的消费者进程从消息队列中获取数据，异步写入数据库。</p><p>由于消息队列的服务处理速度远快于数据库，因此用户的响应延迟可得到有效改善。</p><p>图解说明:</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110300965" alt="img"></p><h2 id="消息队列说明"><a href="#消息队列说明" class="headerlink" title="消息队列说明"></a>消息队列说明</h2><p>消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题。</p><p>实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。</p><p>目前在生产环境，使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等。</p><h2 id="消息队列应用场景"><a href="#消息队列应用场景" class="headerlink" title="消息队列应用场景"></a>消息队列应用场景</h2><p>消息队列在实际应用中常用的使用场景。异步处理，应用解耦，流量削峰和消息通讯四个场景。</p><h2 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h2><p>场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种1.串行的方式；2.并行方式。</p><ul><li>串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110336376" alt="img"></p><ul><li>并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110405511" alt="img"></p><p>假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。</p><p>因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。</p><p>则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）。</p><p>小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？</p><p>引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/2018060811044171" alt="img"></p><p>按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。</p><p>注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，</p><p>因此用户的响应时间可能是50毫秒。所以基于此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。</p><h2 id="应用解耦"><a href="#应用解耦" class="headerlink" title="应用解耦"></a>应用解耦</h2><p>场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。如下图：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/2018060811050932" alt="img"></p><p>传统模式的缺点：</p><p>1） 假如库存系统无法访问，则订单减库存将失败，从而导致订单失败；</p><p>2） 订单系统与库存系统耦合；</p><p>如何解决以上问题呢？引入应用消息队列后的方案，如下图：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110546334" alt="img"></p><ul><li>订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功,请等待物流配送。</li><li>库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。</li><li>假如：在下单时库存系统不能正常使用。也不影响正常下单，</li><li>因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。</li></ul><h2 id="流量削锋"><a href="#流量削锋" class="headerlink" title="流量削锋"></a>流量削锋</h2><p>流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。</p><p>应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用容易挂掉。为解决这个问题，一般需要在应用前端加入消息队列。</p><ol><li><p>可以控制活动的人数.</p></li><li><p>可以缓解短时间内高流量压垮应用；</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110744677" alt="img"></p></li><li><p>用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面；</p></li><li><p>秒杀业务根据消息队列中的请求信息，再做后续处理。</p></li></ol><h2 id="消息通讯"><a href="#消息通讯" class="headerlink" title="消息通讯"></a>消息通讯</h2><p>消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。</p><p>点对点通讯：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608111245390" alt="img"></p><p>客户端A和客户端B使用同一队列，进行消息通讯。</p><p>聊天室通讯：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608111307382" alt="img"></p><p>客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。</p><p>以上实际是消息队列的两种消息模式，点对点或发布订阅模式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MQ的作用&quot;&gt;&lt;a href=&quot;#MQ的作用&quot; class=&quot;headerlink&quot; title=&quot;MQ的作用&quot;&gt;&lt;/a&gt;MQ的作用&lt;/h1&gt;&lt;p&gt;消息队列在大型电子商务类网站，如京东、淘宝、去哪儿等网站有着深入的应用，&lt;/p&gt;
&lt;p&gt;队列的主要作用是消除高并发访</summary>
      
    
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>07.Innodb引擎特性和日志</title>
    <link href="https://leslieaibin.github.io/2021/09/25/MySQL/07.Innodb%E5%BC%95%E6%93%8E%E7%9A%844%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%97%A5%E5%BF%97/"/>
    <id>https://leslieaibin.github.io/2021/09/25/MySQL/07.Innodb%E5%BC%95%E6%93%8E%E7%9A%844%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%97%A5%E5%BF%97/</id>
    <published>2021-09-25T12:17:42.000Z</published>
    <updated>2021-09-25T13:41:21.239Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Innodb引擎的4大特性"><a href="#Innodb引擎的4大特性" class="headerlink" title="Innodb引擎的4大特性"></a>Innodb引擎的4大特性</h1><h2 id="插入缓存（Insert-Buffer-Change-Buffer"><a href="#插入缓存（Insert-Buffer-Change-Buffer" class="headerlink" title="插入缓存（Insert Buffer/Change Buffer)"></a>插入缓存（Insert Buffer/Change Buffer)</h2><p>插入缓存之前版本叫insert buffer，现版本Change Buffer，主要提升插入性能，change buffer 是insert buffer的加强，insert buffer 只针对insert有效，change buffering 对insert、delete、update（delete + insert）、purge都有效</p><p>对于非聚聚索引来说，比如存在用户购买金额这样一个字段，索引是普通索引，每个用户的购买的金额不相同的概率比较大，这样导致可能出现购买记录的数据在数据里的排序可能是1000，3，499，35…，这种不连续的数据，一会插入这个数据页，一会插入那个数据页，这样造成的IO是很耗时的，所以出现了Insert Buffer。</p><p>Insert Buffer是怎么做的呢？mysql对于非聚集索引的插入，先去判断要插入的索引页是否已经在内存中了，如果不在，暂时不着急先把索引页加载到内存中，而是把它放到了一个Insert Buffer对象中，临时先放在这，然后等待情况，等待很多和现在情况一样的非聚集索引，再和要插入的非聚集索引页合并，比如说现在Insert Buffer中有1，99，2，100，合并之前可能要4次插入，合并之后1，2可能是一个页的，99，100可能是一个页的，这样就减少到了2次插入。这样就提升了效率和插入性能，减少了随机IO带来性能损耗。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210330151746375.png" alt="在这里插入图片描述"></p><p>综合上述，Insert Buffer 只对于非聚集索引（非唯一）的插入和更新有效，对于每一次的插入不是写到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，如果在则直接插入；若不在，则先放到Insert Buffer 中，再按照一定的频率进行合并操作，再写回disk。这样通常能将多个插入合并到一个操作中，目的还是减少了随机IO带来性能损耗。</p><p>使用插入缓冲的条件：</p><ul><li>非聚集索引</li><li>非唯一索引</li></ul><p>innodb_change_buffer设置的值有：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">all: 默认值，缓存insert, delete, purges操作</span><br><span class="line">none: 不缓存</span><br><span class="line">inserts: 缓存insert操作</span><br><span class="line">deletes: 缓存delete操作</span><br><span class="line">changes: 缓存insert和delete操作</span><br><span class="line">purges: 缓存后台执行的物理删除操作</span><br></pre></td></tr></table></figure><p>可以通过参数控制其使用的大小：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like <span class="string">&#x27;innodb_change_buffer_max_size&#x27;</span>;</span><br><span class="line">+-------------------------------+-------+</span><br><span class="line">| Variable_name                 | Value |</span><br><span class="line">+-------------------------------+-------+</span><br><span class="line">| innodb_change_buffer_max_size | <span class="number">25</span>    |</span><br><span class="line">+-------------------------------+-------+</span><br><span class="line"><span class="number">1</span> <span class="function">row in <span class="title">set</span> <span class="params">(<span class="number">0.05</span> sec)</span></span></span><br></pre></td></tr></table></figure><p>innodb_change_buffer_max_size，默认是25%，即缓冲池的1/4。最大可设置为50%。当MySQL实例中有大量的修改操作时，要考虑增大innodb_change_buffer_max_size</p><p>上面提过在一定频率下进行合并，那所谓的频率是什么条件？</p><ul><li><p>辅助索引页被读取到缓冲池中。正常的select先检查Insert Buffer是否有该非聚集索引页存在，若有则合并插入。</p></li><li><p>辅助索引页没有可用空间。空间小于1/32页的大小，则会强制合并操作。</p></li><li><p>Master Thread 每秒和每10秒的合并操作。</p></li></ul><h2 id="双写机制（Double-Write）"><a href="#双写机制（Double-Write）" class="headerlink" title="双写机制（Double Write）"></a><strong>双写机制（Double Write）</strong></h2><ol><li>doublewrite缓存位于系统表空间的存储区域，用来缓存innodb的数据页从innodb buffer pool中flush之后并写入到数据文件之前；</li><li>当操作系统或数据库进程在数据页写入磁盘的过程中崩溃，可以在doublewrite缓存中找到数据页的备份，用来执行crash恢复；</li><li>数据页写入到doublewrite缓存的动作所需要的io消耗要小于写入到数据文件的消耗，因为此写入操作会以一次大的连续块的方式写入<img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210330151850245.png" alt="在这里插入图片描述"></li></ol><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-8dc0d0503cc0075578d896ae71ed1609_720w.jpg" alt="img"></p><p>根据上图知道：</p><ol><li><ol><li><p>内存中doublewrite buffer大小2M；物理磁盘上共享表空间中连续的128个页，也就是2个区（extent）大小同样为2M；</p></li><li><p>对缓冲池脏页进行刷新时，不是直接写磁盘。</p></li><li><ol><li>第一步：通过memcpy()函数将脏页先复制到内存中的doublewrite buffer；</li><li>第二步：通过doublewrite分两次，每次1M顺序的写入共享表空间的物理磁盘上。这个过程中，doublewrite页是连续的，因此这个过程是顺序的，所以开销并不大；</li><li>第三步：完成doublewrite页的写入后，再将doublewrite buffer中的页写入各个表空间文件中，此时写入是离散的，可能会较慢；</li><li>如果操作系统在第三步的过程中发生了崩溃，在恢复过程中，可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件中，再应用重做日志；</li></ol></li></ol></li></ol><h2 id="自适应hash索引ahi"><a href="#自适应hash索引ahi" class="headerlink" title="自适应hash索引ahi"></a>自适应hash索引ahi</h2><ol><li>innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，此索引成为热数据，建立hash索引以提升查询速度，此建立是自动建立哈希索引，故称为自适应哈希索引（adaptive hash index）；</li><li>自适应哈希索引会占用innodb buffer pool；</li><li>只适合搜索等值（=）的查询，对于范围查找等操作，是不能使用的；</li></ol><h2 id="预读"><a href="#预读" class="headerlink" title="预读"></a>预读</h2><p>预读（read-ahead)操作是一种IO操作，用于异步将磁盘的页读取到buffer pool中，预料这些页会马上被读取到。预读请求的所有页集中在一个范围内。InnoDB使用两种预读算法：</p><ol><li><p>两种预读算法来提高性能：</p></li><li><ol><li>线性预读：以extent为单位，将下一个extent提前读取到buffer pool中；</li><li>随机预读：以extent中的page为单位，将当前extent中的剩余的page提前读取到buffer pool中；</li></ol></li><li><p>线性预读一个重要参数：innodb_read_ahead_threshold，控制什么时间（访问extent中多少页的阈值）触发预读；</p></li><li><ol><li>默认：56，范围：0～64，值越高，访问模式检查越严格；</li><li>没有该变量之前，当访问到extent最后一个page时，innodb会决定是否将下一个extent放入到buffer pool中；</li></ol></li><li><p>随机预读说明：</p></li><li><ol><li>当同一个extent的一些page在buffer pool中发现时，innodb会将extent中剩余page一并读取到buffer pool中；</li><li>随机预读给innodb code带来一些不必要的复杂性，性能上也不稳定，在5.5版本已经废弃，如果启用，需要修改变量：innodb_random_read_ahead为ON；</li></ol></li></ol><h1 id="mysql三大日志-binlog、redo-log和undo-log"><a href="#mysql三大日志-binlog、redo-log和undo-log" class="headerlink" title="mysql三大日志-binlog、redo log和undo log"></a>mysql三大日志-binlog、redo log和undo log</h1><h2 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h2><p><code>binlog </code>用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。 <code>binlog </code>是 <code>mysql</code>的逻辑日志，并且由 <code>Server </code>层进行记录，使用任何存储引擎的 <code>mysql </code>数据库都会记录 <code>binlog </code>日志。</p><ul><li><strong>逻辑日志</strong>： 可以简单理解为记录的就是sql语句 。</li><li><strong>物理日志</strong>： <code>mysql </code>数据最终是保存在数据页中的，物理日志记录的就是数据页变更 </li></ul><p><code>binlog </code>是通过追加的方式进行写入的，可以通过 <code>max_binlog_size </code>参数设置每个 <code>binlog</code><br>文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。</p><h3 id="binlog使用场景"><a href="#binlog使用场景" class="headerlink" title="binlog使用场景"></a>binlog使用场景</h3><p>在实际应用中， <code>binlog </code>的主要使用场景有两个，分别是 <strong>主从复制</strong> 和 <strong>数据恢复</strong> 。</p><ol><li><strong>主从复制</strong> ：在 <code>Master </code>端开启 <code>binlog </code>，然后将 <code>binlog </code>发送到各个 <code>Slave </code>端， <code>Slave </code>端重放 <code>binlog </code>从而达到主从数据一致。</li><li><strong>数据恢复</strong> ：通过使用 <code>mysqlbinlog </code>工具来恢复数据。</li></ol><h3 id="binlog刷盘时机"><a href="#binlog刷盘时机" class="headerlink" title="binlog刷盘时机"></a>binlog刷盘时机</h3><p>对于 <code>InnoDB </code>存储引擎而言，只有在事务提交时才会记录 <code>biglog </code>，此时记录还在内存中，那么 <code>biglog</code><br>是什么时候刷到磁盘中的呢？ <code>mysql </code>通过 <code>sync_binlog </code>参数控制 <code>biglog </code>的刷盘时机，取值范围是 <code>0-N</code><br>：</p><ul><li>0：不去强制要求，由系统自行判断何时写入磁盘；</li><li>1：每次 <code>commit </code>的时候都要将 <code>binlog </code>写入磁盘；</li><li>N：每N个事务，才会将 <code>binlog </code>写入磁盘。</li></ul><p>从上面可以看出， <code>sync_binlog </code>最安全的是设置是 <code>1 </code>，这也是 <code>MySQL 5.7.7</code><br>之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。</p><h3 id="binlog日志格式"><a href="#binlog日志格式" class="headerlink" title="binlog日志格式"></a>binlog日志格式</h3><p><code>binlog </code>日志有三种格式，分别为 <code>STATMENT </code>、 <code>ROW </code>和 <code>MIXED </code>。</p><blockquote><p>在 <code>MySQL 5.7.7 </code>之前，默认的格式是 <code>STATEMENT </code>， <code>MySQL 5.7.7 </code>之后，默认值是 <code>ROW </code>。日志格式通过 <code>binlog-format </code>指定。</p></blockquote><ul><li><p><code>STATMENT </code>： 基于<code>SQL</code>语句的复制( <code>statement-based replication, SBR </code>)，每一条会修改数据的sql语句会记录到 <code>binlog </code>中 。</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">* 优点： 不需要记录每一行的变化，减少了` binlog ` 日志量，节约了 ` IO ` , 从而提高了性能； </span><br><span class="line">* 缺点： 在某些情况下会导致主从数据不一致，比如执行` sysdate() ` 、 ` slepp() ` 等 。 </span><br></pre></td></tr></table></figure></li><li><p><code>ROW </code>： 基于行的复制(<code>row-based replication, RBR</code>)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了 。</p><ul><li>优点： 不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题 ；</li><li>缺点： 会产生大量的日志，尤其是<code>alter table</code>的时候会让日志暴涨</li></ul></li><li><p><code>MIXED </code>： 基于<code>STATMENT</code>和 <code>ROW </code>两种模式的混合复制( <code>mixed-based replication, MBR </code>)，一般的复制使用 <code>STATEMENT </code>模式保存 <code>binlog </code>，对于 <code>STATEMENT </code>模式无法复制的操作使用 <code>ROW </code>模式保存 <code>binlog</code></p></li></ul><h2 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h2><h3 id="为什么需要redo-log"><a href="#为什么需要redo-log" class="headerlink" title="为什么需要redo log"></a>为什么需要redo log</h3><p>我们都知道，事务的四大特性里面有一个是 <strong>持久性</strong> ，具体来说就是<br><strong>只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态</strong> 。那么 <code>mysql</code><br>是如何保证一致性的呢？最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：</p><ol><li>因为 <code>Innodb </code>是以 <code>页 </code>为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！</li><li>一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！</li></ol><p>因此 <code>mysql </code>设计了 <code>redo log </code>， <strong>具体来说就是只记录事务对数据页做了哪些修改</strong><br>，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)</p><h3 id="redo-log基本概念"><a href="#redo-log基本概念" class="headerlink" title="redo log基本概念"></a>redo log基本概念</h3><p><code>redo log </code>包括两部分：一个是内存中的日志缓冲( <code>redo log buffer </code>)，另一个是磁盘上的日志文件( <code>redo log file</code>)。 <code>mysql </code>每执行一条 <code>DML </code>语句，先将记录写入 <code>redo log buffer </code><br>，后续某个时间点再一次性将多个操作记录写到 <code>redo log file </code>。这种 <strong>先写日志，再写磁盘</strong> 的技术就是 <code>MySQL</code><br>里经常说到的 <code>WAL(Write-Ahead Logging) </code>技术。</p><p>在计算机操作系统中，用户空间( <code>user space </code>)下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间( <code>kernel space</code>)缓冲区( <code>OS Buffer </code>)。因此， <code>redo log buffer </code>写入 <code>redo log file </code>实际上是先写入 <code>OS Buffer </code>，然后再通过系统调用 <code>fsync() </code>将其刷到 <code>redo log file </code><br>中，过程如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000023827701" alt="img"></p><p><code>mysql </code>支持三种将 <code>redo log buffer </code>写入 <code>redo log file </code>的时机，可以通过 <code>innodb_flush_log_at_trx_commit</code> 参数配置，各参数值含义如下：</p><table><thead><tr><th>参数值</th><th>含义</th></tr></thead><tbody><tr><td>0（延迟写）</td><td>事务提交时不会将 <code>redo log buffer </code>中日志写入到 <code>os buffer </code>，而是每秒写入 <code>os buffer </code>并调用 <code>fsync() </code>写入到 <code>redo log file </code>中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。</td></tr><tr><td>1（实时写，实时刷）</td><td>事务每次提交都会将 <code>redo log buffer </code>中的日志写入 <code>os buffer </code>并调用 <code>fsync() </code>刷到 <code>redo log file </code>中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。</td></tr><tr><td>2（实时写，延迟刷）</td><td>每次提交都仅写入到 <code>os buffer </code>，然后是每秒调用 <code>fsync() </code>将 <code>os buffer </code>中的日志写入到 <code>redo log file </code>。</td></tr></tbody></table><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000023827700" alt="img"></p><h3 id="redo-log记录形式"><a href="#redo-log记录形式" class="headerlink" title="redo log记录形式"></a>redo log记录形式</h3><p>前面说过， <code>redo log </code>实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此 <code>redo log</code><br>实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000023827699" alt="img"></p><p>同时我们很容易得知， 在innodb中，既有<code>redo log</code>需要刷盘，还有 <code>数据页 </code>也需要刷盘， <code>redo log </code>存在的意义主要就是降低对 <code>数据页 </code>刷盘的要求 <strong>。在上图中， <code>write pos </code>表示 <code>redo log </code>当前记录的 <code>LSN</code> (逻辑序列号)位置， <code>check point </code>表示</strong> 数据页更改记录** 刷盘后对应 <code>redo log </code>所处的 <code>LSN </code>(逻辑序列号)位置。 <code>write pos </code>到 <code>check point </code>之间的部分是 <code>redo log </code>空着的部分，用于记录新的记录；<code>check point</code>到 <code>write pos </code>之间是 <code>redo log </code>待落盘的数据页更改记录。当 <code>write pos </code>追上 <code>check point </code>时，会先推动 <code>check point </code>向前移动，空出位置再记录新的日志。</p><p>启动 <code>innodb </code>的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。因为 <code>redo log </code>记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如 <code>binlog </code>)要快很多。 重启 <code>innodb </code>时，首先会检查磁盘中数据页的 <code>LSN </code>，如果数据页的 <code>LSN </code>小于日志中的 <code>LSN </code>，则会从 <code>checkpoint </code>开始恢复。 还有一种情况，在宕机前正处于<br><code>checkpoint </code>的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的 <code>LSN </code>大于日志中的 <code>LSN</code><br>，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。</p><h3 id="redo-log与binlog区别"><a href="#redo-log与binlog区别" class="headerlink" title="redo log与binlog区别"></a>redo log与binlog区别</h3><table><thead><tr><th></th><th>redo log</th><th>binlog</th></tr></thead><tbody><tr><td>文件大小</td><td><code>redo log </code>的大小是固定的。</td><td><code>binlog </code>可通过配置参数 <code>max_binlog_size </code>设置每个<code>binlog</code>文件的大小。</td></tr><tr><td>实现方式</td><td><code>redo log </code>是 <code>InnoDB </code>引擎层实现的，并不是所有引擎都有。</td><td><code>binlog </code>是 <code>Server</code> 层实现的，所有引擎都可以使用 <code>binlog </code>日志</td></tr><tr><td>记录方式</td><td>redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。</td><td>binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上</td></tr><tr><td>适用场景</td><td><code>redo log </code>适用于崩溃恢复(crash-safe)</td><td><code>binlog </code>适用于主从复制和数据恢复</td></tr></tbody></table><p>由 <code>binlog </code>和 <code>redo log </code>的区别可知： <code>binlog </code>日志只用于归档，只依靠 <code>binlog </code>是没有 <code>crash-safe</code>能力的。但只有 <code>redo log </code>也不行，因为 <code>redo log </code>是 <code>InnoDB </code><br>特有的，且日志上的记录落盘后会被覆盖掉。因此需要 <code>binlog </code>和 <code>redo log</code><br>二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。</p><h2 id="redo-log是什么，为什么需要redo-log"><a href="#redo-log是什么，为什么需要redo-log" class="headerlink" title="redo log是什么，为什么需要redo log"></a>redo log是什么，为什么需要redo log</h2><ul><li>redo log 是<strong>重做日志</strong>。</li><li>它记录了<strong>数据页</strong>上的改动。</li><li>它指<strong>事务</strong>中修改了的数据，将会备份存储。</li><li>发生数据库服务器宕机、或者脏页未写入磁盘，可以通过redo log恢复。</li><li>它是<strong>Innodb存储</strong>引擎独有的</li></ul><h3 id="为什么需要-redo-log？"><a href="#为什么需要-redo-log？" class="headerlink" title="为什么需要 redo log？"></a>为什么需要 redo log？</h3><ul><li>redo log主要用于MySQL异常重启后的一种数据恢复手段，确保了数据的一致性。</li><li>其实是为了配合MySQL的WAL机制。因为MySQL进行更新操作，为了能够快速响应，所以采用了异步写回磁盘的技术，写入内存后就</li><li>返回。但是这样，会存在<strong>crash后</strong>内存数据丢失的隐患，而redo log具备crash safe的能力。</li></ul><h2 id="什么是WAL技术-好处是什么"><a href="#什么是WAL技术-好处是什么" class="headerlink" title="什么是WAL技术, 好处是什么."></a>什么是WAL技术, 好处是什么.</h2><ul><li>WAL，中文全称是Write-Ahead Logging，它的关键点就是日志先写内存，再写磁盘。MySQL执行更新操作后，<strong>在真正把数据写入到磁盘前，先记录日志</strong>。</li><li>好处是不用每一次操作都实时把数据写盘，就算crash后也可以通过redo log恢复，所以能够实现快速响应SQL语句。</li></ul><h2 id="redo-log的写入方式"><a href="#redo-log的写入方式" class="headerlink" title="redo log的写入方式"></a>redo log的写入方式</h2><p>redo log包括两部分内容，分别是内存中的<strong>日志缓冲</strong>(redo log buffer)和磁盘上的<strong>日志文件</strong>(redo log file)。</p><p>mysql每执行一条DML语句，会先把记录写入<strong>redo log buffer</strong>，后续某个时间点再一次性将多个操作记录写到<strong>redo log file</strong>。这种先写日志，再写磁盘的技术，就是<strong>WAL</strong>。</p><p>在计算机操作系统中，用户空间(user space)下的缓冲区数据，一般是无法直接写入磁盘的，必须经过操作系统内核空间缓冲区(即OS Buffer)。</p><ul><li>日志最开始会写入位于存储引擎Innodb的redo log buffer，这个是在用户空间完成的。</li><li>然后再将日志保存到操作系统内核空间的缓冲区(OS buffer)中。</li><li>最后，通过系统调用<code>fsync()</code>，从<strong>OS buffer</strong>写入到磁盘上的<strong>redo log file</strong>中，完成写入操作。这个写入磁盘的操作，就叫做<strong>刷盘</strong>。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925213720105.png" alt="image-20210925213720105"></p><p>我们可以发现，redo log buffer写入到redo log file，是经过OS buffer中转的。其实可以通过参数<code>innodb_flush_log_at_trx_commit</code>进行配置，参数值含义如下：</p><ul><li>0：称为<strong>延迟写</strong>，事务提交时不会将redo log buffer中日志写入到OS buffer，而是每秒写入OS buffer并调用写入到redo log file中。</li><li>1：称为<strong>实时写</strong>，实时刷”，事务每次提交都会将redo log buffer中的日志写入OS buffer并保存到redo log file中。</li><li>2：称为<strong>实时写，延迟刷</strong>。每次事务提交写入到OS buffer，然后是每秒将日志写入到redo log file。</li></ul><h2 id="Redo-log的执行流程"><a href="#Redo-log的执行流程" class="headerlink" title="Redo log的执行流程"></a>Redo log的执行流程</h2><p>我们来看下Redo log的执行流程，假设执行的SQL如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update T set a &#x3D;1 where id &#x3D;666</span><br></pre></td></tr></table></figure><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925213741905.png" alt="image-20210925213741905"></p><p>redo log的执行流程</p><ol><li>MySQL客户端将请求语句<code>update T set a =1 where id =666</code>，发往MySQL Server层。</li><li>MySQL Server 层接收到SQL请求后，对其进行分析、优化、执行等处理工作，将生成的SQL执行计划发到InnoDb存储引擎层执行。</li><li>InnoDb存储引擎层将<strong>a修改为1</strong>的这个操作记录到内存中。</li><li>记录到内存以后会修改redo log 的记录，会在添加一行记录，其内容是<strong>需要在哪个数据页上做什么修改</strong>。</li><li>此后，将事务的状态设置为prepare ，说明已经准备好提交事务了。</li><li>等到MySQL Server层处理完事务以后，会将事务的状态设置为<strong>commit</strong>，也就是提交该事务。</li><li>在收到事务提交的请求以后，<strong>redo log</strong>会把刚才写入内存中的操作记录写入到磁盘中，从而完成整个日志的记录过程。</li></ol><p>默认状态时先写入 磁盘redolog 再进行事务commit</p><h2 id="redo-log-为什么可以保证crash-safe机制呢？"><a href="#redo-log-为什么可以保证crash-safe机制呢？" class="headerlink" title="redo log 为什么可以保证crash safe机制呢？"></a>redo log 为什么可以保证crash safe机制呢？</h2><ul><li>因为redo log每次更新操作完成后，就一定会写入的，如果<strong>写入失败</strong>，说明此次操作失败，事务也不可能提交。</li><li>redo log内部结构是基于页的，记录了这个页的字段值变化，只要crash后读取redo log进行重放，就可以恢复数据。</li></ul><h2 id="binlog的概念是什么-起到什么作用-可以保证crash-safe吗"><a href="#binlog的概念是什么-起到什么作用-可以保证crash-safe吗" class="headerlink" title="binlog的概念是什么, 起到什么作用, 可以保证crash-safe吗?"></a>binlog的概念是什么, 起到什么作用, 可以保证crash-safe吗?</h2><ul><li>bin log是归档日志，属于MySQL Server层的日志。可以实现<strong>主从复制</strong>和<strong>数据恢复</strong>两个作用。</li><li>当需要<strong>恢复数据</strong>时，可以取出某个时间范围内的bin log进行重放恢复。</li><li>但是bin log不可以做crash safe，因为crash之前，bin log<strong>可能没有写入完全</strong>MySQL就挂了。所以需要配合<strong>redo log</strong>才可以进行crash safe。</li></ul><h2 id="binlog和redolog的不同点有哪些"><a href="#binlog和redolog的不同点有哪些" class="headerlink" title="binlog和redolog的不同点有哪些?"></a>binlog和redolog的不同点有哪些?</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925210728980.png" alt="image-20210925210728980"></p><h2 id="执行器和innoDB在执行update语句时候的流程是什么样的"><a href="#执行器和innoDB在执行update语句时候的流程是什么样的" class="headerlink" title="执行器和innoDB在执行update语句时候的流程是什么样的?"></a>执行器和innoDB在执行update语句时候的流程是什么样的?</h2><ul><li>执行器在优化器选择了索引后，会调用InnoDB读接口，读取要更新的行到内存中</li><li>执行SQL操作后，更新到内存，然后写redo log，写bin log，此时即为完成。</li><li>后续InnoDB会在合适的时候把此次操作的结果写回到磁盘。</li></ul><h2 id="如果数据库误操作-如何执行数据恢复"><a href="#如果数据库误操作-如何执行数据恢复" class="headerlink" title="如果数据库误操作, 如何执行数据恢复?"></a>如果数据库误操作, 如何执行数据恢复?</h2><p>数据库在某个时候误操作，就可以找到距离误操作最近的时间节点的bin log，重放到临时数据库里，然后选择误删的数据节点，恢复到线上数据库。</p><h2 id="什么是MySQL两阶段提交-为什么需要两阶段提交"><a href="#什么是MySQL两阶段提交-为什么需要两阶段提交" class="headerlink" title="什么是MySQL两阶段提交, 为什么需要两阶段提交?"></a>什么是MySQL两阶段提交, 为什么需要两阶段提交?</h2><p>其实所谓的两阶段就是把一个事务分成两个阶段来提交。</p><p>两阶段提交</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925211124058.png" alt="image-20210925211124058"></p><p>两阶段提交主要有三步曲：</p><ol><li>redo log在写入后，进入prepare状态</li><li>执行器写入bin log</li><li>进入commit状态，事务可以提交。</li></ol><p><strong>为什么需要两阶段提交呢?</strong></p><ul><li>如果不用两阶段提交的话，可能会出现这样情况：bin log写入之前，机器crash导致需要重启。重启后redo log继续重放crash之前的操作，而当bin log后续需要作为备份恢复时，会出现数据不一致的情况。</li><li>如果是bin log commit之前crash，那么重启后，发现redo log是prepare状态且bin log完整（bin log写入成功后，redo log会有bin log的标记），就会自动commit，让存储引擎提交事务。</li><li>两阶段提交就是为了保证redo log和binlog数据的安全一致性。只有在这两个日志文件逻辑上高度一致了。你才能放心的使用redo log帮你将数据库中的状态恢复成crash之前的状态，使用binlog实现数据备份、恢复、以及主从复制。</li></ul><h2 id="如果不是两阶段提交-先写redo-log和先写bin-log两种情况各会遇到什么问题"><a href="#如果不是两阶段提交-先写redo-log和先写bin-log两种情况各会遇到什么问题" class="headerlink" title="如果不是两阶段提交, 先写redo log和先写bin log两种情况各会遇到什么问题?"></a>如果不是两阶段提交, 先写redo log和先写bin log两种情况各会遇到什么问题?</h2><ul><li>先写redo log，crash后bin log备份恢复时少了一次更新，与当前数据不一致。</li><li>先写bin log，crash后，由于redo log没写入，事务无效，所以后续bin log备份恢复时，数据不一致。</li></ul><h2 id="binlog刷盘机制"><a href="#binlog刷盘机制" class="headerlink" title="binlog刷盘机制"></a>binlog刷盘机制</h2><p>所有未提交的事务产生的binlog，都会被先记录到binlog的缓存中。等该事务提交时，再将缓存中的数据写入binlog日志文件中。缓存的大小由参数<code>binlog_chache_size</code>控制。</p><p>binlog什么时候刷新到磁盘呢？由参数<code>sync_binlog</code>控制</p><ul><li>当<code>sync_binlog</code>为0时，表示MySQL不控制binlog的刷新，而是由系统自行判断何时写入磁盘。选这种策略，一旦操作系统宕机，缓存中的binlog就会丢失。</li><li><code>sync_binlog</code>为N时，每N个事务，才会将binlog写入磁盘。。</li><li>当<code>sync_binlog</code>为1时，则表示每次commit，都将binlog 写入磁盘。</li></ul><p>来看一个比较完整的流程图吧：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925213845996.png" alt="image-20210925213845996"></p><h2 id="说说Redo-log的记录方式"><a href="#说说Redo-log的记录方式" class="headerlink" title="说说Redo log的记录方式"></a>说说Redo log的记录方式</h2><p>redo log的大小是固定。它采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。如下图（图片来源网络）：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/640" alt="图片">redo log 循环写入</p><p>redo log buffer(内存中)是由首尾相连的四个文件组成的，它们分别是：ib_logfile_1、ib_logfile_2、ib_logfile_3、ib_logfile_4。</p><blockquote><ul><li>write pos表示当前写入记录位置(写入磁盘的数据页的逻辑序列位置)</li><li>check point表示刷盘(写入磁盘)后对应的位置。</li><li>write pos到check point之间的部分用来记录新日志，也就是留给新记录的空间。</li><li>check point到write pos之间是待刷盘的记录，如果不刷盘会被新记录覆盖。</li></ul></blockquote><p>有了 redo log，当数据库发生宕机重启后，可通过 redo log将未落盘的数据（check point之后的数据）恢复，保证已经提交的事务记录不会丢失，这种能力称为<strong>crash-safe</strong>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Innodb引擎的4大特性&quot;&gt;&lt;a href=&quot;#Innodb引擎的4大特性&quot; class=&quot;headerlink&quot; title=&quot;Innodb引擎的4大特性&quot;&gt;&lt;/a&gt;Innodb引擎的4大特性&lt;/h1&gt;&lt;h2 id=&quot;插入缓存（Insert-Buffer-Ch</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>08.ABC联合索引生效问题</title>
    <link href="https://leslieaibin.github.io/2021/09/25/MySQL/08.%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%E7%94%9F%E6%95%88%E9%97%AE%E9%A2%98/"/>
    <id>https://leslieaibin.github.io/2021/09/25/MySQL/08.%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%E7%94%9F%E6%95%88%E9%97%AE%E9%A2%98/</id>
    <published>2021-09-25T12:17:42.000Z</published>
    <updated>2022-02-12T07:14:42.002Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ABC联合索引生效问题"><a href="#ABC联合索引生效问题" class="headerlink" title="ABC联合索引生效问题"></a>ABC联合索引生效问题</h1><p>对于复合索引：Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。例如索引是key index （a,b,c）。 可以支持<strong>a | a,b| a,b,c</strong> 3种组合进行查找，但不支持 b,c进行查找 .当最左侧字段是常量引用时，索引就十分有效。</p><p>以下是一些<strong>例子：</strong></p><ul><li><pre><code class="sql">select * from myTest where a=3 and b=5 and c=4; <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  **abc顺序**</span><br><span class="line">  abc三个索引都在where条件里面用到了，而且**都发挥了作用**</span><br><span class="line"></span><br><span class="line">- &#96;&#96;&#96;sql</span><br><span class="line">  select * from myTest where c&#x3D;4 and b&#x3D;6 and a&#x3D;3</span><br></pre></td></tr></table></figure>**abc顺序**where里面的条件顺序在查询之前会被mysql自动优化，**效果跟上一句一样**</code></pre></li><li><pre><code class="sql">select * from myTest where a=3 and c=7<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  索引abc_index:(a,b,c)，只会在where条件中带有(a)、(a,b)、(a,b,c)的三种类型的查询中使用。其实这里说的有一点歧义，其实当where条件只有(a,c)时也会走，但是只走a字段索引，不会走c字段。</span><br><span class="line"></span><br><span class="line">- &#96;&#96;&#96;sql</span><br><span class="line">  select * from myTest where a&#x3D;3 and b&gt;7 and c&#x3D;3</span><br></pre></td></tr></table></figure> b范围值，断点，阻塞了c的索引a用到了，b也用到了，c没有用到，这个地方**b是范围值，也算断点，只不过自身用到了索引**</code></pre></li><li><pre><code class="sql">select * from myTest where b=3 and c=4<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  联合索引必须按照顺序使用，并且需要全部使用**因为a索引没有使用，所以这里 bc都没有用上索引效果**</span><br><span class="line"></span><br><span class="line">- select \* from myTest where a&gt;4 and b&#x3D;7 and c&#x3D;9;-</span><br><span class="line">  **a用到了** b没有使用，c没有使用（a用了范围所以，相当于断点，之后的b，c都没有用到索引）</span><br><span class="line"></span><br><span class="line">- &#96;&#96;&#96;sql</span><br><span class="line">  select * from myTest where a&#x3D;3 order by b</span><br></pre></td></tr></table></figure>a用到了索引，b在结果排序中也用到了索引的效果，a下面任意一段的b是排好序的</code></pre></li><li><pre><code class="sql">select * from myTest where a=3 order by c<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  a用到了索引，但是这个地方c没有发挥排序效果，因为中间断点了，使用 explain 可以看到 filesort</span><br><span class="line"></span><br><span class="line">- &#96;&#96;&#96;sql</span><br><span class="line">  select * from mytable where b&#x3D;3 order by a</span><br></pre></td></tr></table></figure>b没有用到索引，排序中a也没有发挥索引效果</code></pre></li></ul><h2 id="以下条件会导致索引失效"><a href="#以下条件会导致索引失效" class="headerlink" title="以下条件会导致索引失效:"></a>以下条件会导致索引失效:</h2><ul><li>不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描-</li><li>存储引擎不能使用索引范围条件右边的列（例如 只用到b ， c）</li><li>尽量使用覆盖索引（<strong>只访问索引的查询</strong>（索引列和查询列一致）），**减少select **</li><li><strong>mysql在</strong>使用不等于（！=或者&lt;&gt;）的时候**无法使用索引会导致全表扫描</li><li>is null,is not null也无法使用索引</li><li>ike以通配符开头（’%abc…’）mysql索引失效会变成全表扫描的操作。问题：解决like‘%字符串%’时索引不被使用的方法-<br><img src="https://cubox.pro/c/filters:no_upscale()?imageUrl=https://img-blog.csdnimg.cn/20190724194210412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNjMwODg3,size_16,color_FFFFFF,t_70"></li><li>字符串不加单引号索引失效</li></ul><p><strong>建议：</strong></p><ol><li><p> 对于单键索引，尽量选择针对当前query过滤性更好的索引</p></li><li><p> 在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠前越好。</p></li><li><p> . 在选择组合索引的时候，尽量选择可以能够包含当前query中的where子句中更多字段的索引</p></li><li><p> . 在选择组合索引的时候，尽量选择可以能够包含当前query中的where子句中更多字段的索引</p></li><li><p> 尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ABC联合索引生效问题&quot;&gt;&lt;a href=&quot;#ABC联合索引生效问题&quot; class=&quot;headerlink&quot; title=&quot;ABC联合索引生效问题&quot;&gt;&lt;/a&gt;ABC联合索引生效问题&lt;/h1&gt;&lt;p&gt;对于复合索引：Mysql从左到右的使用索引中的字段，一个查询可以只使</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>09.一条update执行的过程</title>
    <link href="https://leslieaibin.github.io/2021/09/25/MySQL/09.%E4%B8%80%E6%9D%A1update%E6%89%A7%E8%A1%8C%E7%9A%84%E8%BF%87%E7%A8%8B/"/>
    <id>https://leslieaibin.github.io/2021/09/25/MySQL/09.%E4%B8%80%E6%9D%A1update%E6%89%A7%E8%A1%8C%E7%9A%84%E8%BF%87%E7%A8%8B/</id>
    <published>2021-09-25T12:17:42.000Z</published>
    <updated>2022-02-12T12:30:05.813Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> b = <span class="number">200</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">2</span></span><br></pre></td></tr></table></figure><p>语句的执行过程如下：</p><ol><li>客户端（通常是你的服务）发出更新语句” update t set b = 200 where id = 2 “ 并向MySQL服务端建立连接；</li><li>MySQL连接器负责和客户端建立连接，获取权限，维持和管理连接；</li><li>MySQL拿到一个查询请求后，会先到查询缓存看看（MySQL8.x已经废弃了查询缓存），看之前是否已经执行过，如果执行过，执行语句及结果会以key-value形式存储到内存中，如果命中缓存会返回结果。如果没命中缓存，就开始真正执行语句。分析器会先做词法分析，识别出关键字update，表名等等；之后还会做语法分析，判断输入的语句是否符合MySQL语法；</li><li>经过分析器，MySQL已经知道语句是要做什么。优化器接着会选择使用哪个索引（如果多个表，会选择表的连接顺序）；</li><li>MySQL服务端最后一个阶段是执行器会调用引擎的接口去执行语句；</li><li>事务开始（任何一个操作都是事务），写undo log ，记录记录上一个版本数据，并更新记录的回滚指针和事务ID；</li><li>执行器先调用引擎取id=2这一行。id是主键，引擎直接用树搜索找到这一行；<ol><li>如果id=2这一行所在的数据页本来就在内存 中，就直接返回给执行器更新；</li><li>如果记录不在内存，接下来会判断索引是否是唯一索引；<ol><li>如果不是唯一索引，InnoDB会将更新操作缓存在change buffer中；</li><li>如果是唯一索引，就只能将数据页从磁盘读入到内存，返回给执行；</li></ol></li></ol></li><li>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据；</li><li>引擎将这行数据更新到内存中，同时将这个更新操作记录到redo log 里面；</li><li>执行器生成这个操作的binlogbinlog ；</li><li>执行器调用引擎的提交事务接口；</li><li>事务的两阶段提交：commit的prepare阶段：引擎把刚刚写入的redo log刷盘；</li><li>事务的两阶段提交：commit的commit阶段：引擎binlog刷盘。</li></ol><p>[<img src="https://gsmtoday.github.io/2019/02/08/how-update-executes-in-mysql/update%20process.png" alt="MySQL更新语句执行过程">](<a href="https://gsmtoday.github.io/2019/02/08/how-update-executes-in-mysql/update">https://gsmtoday.github.io/2019/02/08/how-update-executes-in-mysql/update</a> process.png)</p><h2 id="MySQL基本架构"><a href="#MySQL基本架构" class="headerlink" title="MySQL基本架构"></a>MySQL基本架构</h2><p>MySQL可以分为<strong>Server层</strong>和<strong>存储引擎层</strong>两部分。</p><p><strong>Server层</strong>包括连接器、查询缓存、分析器、优化器、执行器。涵盖MySQL的大多数核心服务功能，以及所有的内置函数（日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p><p><strong>存储引擎</strong>层负责数据的存储和提取。其架构是插件式的，支持InnoDB,MyISAM,Memory等多个存储引擎。现在最常用的存储引擎是InnoDB, 它从MySQL5.5.5开始成为了默认存储引擎。<br><a href="https://gsmtoday.github.io/2019/02/08/how-update-executes-in-mysql/mysqlAchi.png"><img src="https://gsmtoday.github.io/2019/02/08/how-update-executes-in-mysql/mysqlAchi.png" alt="MySQL架构图"></a></p><h2 id="Undo-log-简述"><a href="#Undo-log-简述" class="headerlink" title="Undo log 简述"></a>Undo log 简述</h2><p>【概述】Undo log 是InnoDB MVCC事务特性的重要组成部分。当我们对记录做了变更操作时就会产生undo记录，undo记录默认被记录到系统表ibdata中，但是从MySQL 5.6以后 也可以使用独立的Undo 表空间。</p><p>【作用】其作用是保存记录的老版本数据，当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着undo链找到满足其可见性的记录。当版本链很长时，通常可以认为是个比较耗时的耗时操作。因此可以用来回滚，崩溃恢复，MVCC。<br>大多数对数据的变更操作包括INSERT/DELETE/UPDATE，其中INSERT操作在事务提交前只对当前事务可见，因此产生的Undo日志可以在事务提交后直接删除，而对于UPDATE/DELETE则需要维护多版本信息，在InnoDB里，UPDATE和DELETE操作产生的Undo日志被归成一类，即update_undo。</p><p>【产生时机】事务开始之前，将当前的数据版本生成Undo log, Undo log也会产生redo log 来保证Undo log的可靠性。</p><p>【释放时机】当事务提交后，Undo log并不能立马被删除，而是放入待清理的链表，由purge 线程判断是否由其他事务在使用undo 段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。</p><p>【存储结构】InnoDB采用回滚段的方式来维护Undo log的并发写入和持久化。<br>回滚段实际上是一种Undo 文件组织方式，Undo内部由多个回滚段组成，即 Rollback segment，一共有128个，保存在ibdata系统表空间中，分别从resg slot0 - resg slot127，每一个resg slot，也就是每一个回滚段，内部由1024个undo segment 组成。<br>为了便于管理和使用undo记录，在内存中维持了如下关键结构体对象：<br>1.所有回滚段都记录在 trx_sys-&gt;rseg_array，数组大小为128，分别对应不同的回滚段；<br>2.rseg_array 数组类型为trx_rseg_t，用于维护回滚段相关信息；<br>3.每个回滚段对象trx_rseg_t 还要管理undo log信息，对应结构体为trx_undo_t, 使用多个链表来维护trx_undo_t信息；<br>4.事务开启时，会专门给他指定一个回滚段，以后该事务用到的undo log页，就从该回滚段上分配；<br>5.事务提交后，需要purge的回滚段会被放到purge队列上（purge_sys-&gt;purge_queue)。</p><h2 id="Change-Buffer简述"><a href="#Change-Buffer简述" class="headerlink" title="Change Buffer简述"></a>Change Buffer简述</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">当需要更新一个数据页：</span><br><span class="line">1. 如果数据页在内存 — 直接更新</span><br><span class="line">2. 如果数据页不在内存，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘读入这个数据页了。在下次查询需要访问这个数据页时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式保证这个数据逻辑的正确性。</span><br></pre></td></tr></table></figure><p>另外，虽然叫change buffer, 实际上此操作也是可以持久化的数据。将change buffer中的操作应用到原始数据页，得到最新结果的过程叫merge。除了访问这个数据页会触发merge 外，系统有后台线程会定期merge. 在db正常关闭的时候，也会执行merge。 — 如果能够将更新操作先记录在change buffer，减少读磁盘，更新语句的执行速度会得到明显的提升 。</p><p>使用场景<br>Change buffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做purge之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。</p><p>因此对于写多读少的业务，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的是账单类，日志类的系统。</p><p>反过来，假设一个业务的更新模式就是写入之后马上会做查询，那么即使满足了条件，将先更新记录在change buffer,但之后由于马上要访问这个数据页，会立即出发purge过程。这样随机访问IO的次数不会减少,反而增加了change buffer的维护代价，所以对于这种业务模式来说，change buffer反而起到了副作用。</p><p>另外，只有普通索引才能使用到change buffer, 唯一索引不能用。因为唯一索引每次都要将数据页读入内存判断唯一性，所以没必要使用change buffer了。</p><h2 id="Redo-log简述"><a href="#Redo-log简述" class="headerlink" title="Redo log简述"></a>Redo log简述</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">保证事务的持久性。日志先行(WAL 先写日志，再写磁盘。)，即在持久化数据文件前，保证之前的redo 日志已经写在磁盘。记录的是新数据的备份。在事务提交前，只要将Redo Log持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是RedoLog已经持久化。系统可以根据RedoLog的内容，将所有数据恢复到最新的状态。</span><br><span class="line">具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里，并更新内存[具体操作参见change buffer]，这个时候更新就算完成了。</span><br><span class="line">同时Innodb引擎会在适当的时候，将这个操作记录更新到磁盘里，而这个更新往往是在系统比较空闲的时候做。（redo log 类似MQ解耦，异步操作，把随机IO的写磁盘变成了顺序IO的写日志。）</span><br></pre></td></tr></table></figure><p>WAL好处：<br>1.利用WAL技术，数据库将随机写换成了顺序写，大大提升了数据库性能。<br>2.保证crash safe : 有了redo log 可以保证即使数据库发生异常重启，之前提交的记录都不会丢失。</p><p>WAL坏处：<br>但是也会带来内存脏页问题，内存脏页会后台线程自动flush,也会由于数据页淘汰而触发flush. flush脏页的过程会占用资源，可能导致查询语句的响应时间长一些。</p><h3 id="Redo-log-特点"><a href="#Redo-log-特点" class="headerlink" title="Redo log 特点"></a>Redo log 特点</h3><p>InnoDB的redo log是固定大小的，比如可以配置为一组4个文档，每个1GB，从头开始写，写到末尾就又回到开头循环写。redo log通过使用两个指针checkpoint&amp;writepos来控制数据更新到数据文件速度。<br>另外，redo log是InnoDB引擎特有的日志。</p><h3 id="WAL-redo-log-V-S-change-buffer"><a href="#WAL-redo-log-V-S-change-buffer" class="headerlink" title="WAL /redo log V.S. change buffer"></a>WAL /redo log V.S. change buffer</h3><p>WAL /redo log 提升性能的核心机制即尽量减少随机写磁盘的IO消耗（转成顺序写）。而Change buffer 的提升性能的核心机制是节省更新语句中随机读磁盘的IO消耗 。</p><h3 id="两阶段提交2PC"><a href="#两阶段提交2PC" class="headerlink" title="两阶段提交2PC"></a>两阶段提交2PC</h3><p>2PC即Innodb对于事务的两阶段提交机制。当MySQL开启binlog的时候，会存在一个内部XA的问题：事务在存储引擎层（redo）commit的顺序和在binlog中提交的顺序不一致的问题。如果不使用两阶段提交，那么数据库的状态有可能用它的日志恢复出来的库的状态不一致。</p><p>事务的commit分为prepare和commit两个阶段：<br>1、prepare阶段：redo持久化到磁盘（redo group commit），并将回滚段置为prepared状态，此时binlog不做操作。<br><a href="https://gsmtoday.github.io/2019/02/08/how-update-executes-in-mysql/prepare.png"><img src="https://gsmtoday.github.io/2019/02/08/how-update-executes-in-mysql/prepare.png" alt="img"></a><br>2、commit阶段：innodb释放锁，释放回滚段，设置提交状态，binlog持久化到磁盘，然后存储引擎层提交。<br><a href="https://gsmtoday.github.io/2019/02/08/how-update-executes-in-mysql/commit.png"><img src="https://gsmtoday.github.io/2019/02/08/how-update-executes-in-mysql/commit.png" alt="img"></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
</feed>
