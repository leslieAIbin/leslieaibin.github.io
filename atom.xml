<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mr.Ai</title>
  
  <subtitle>春暖花开去见你</subtitle>
  <link href="https://leslieaibin.github.io/atom.xml" rel="self"/>
  
  <link href="https://leslieaibin.github.io/"/>
  <updated>2021-12-14T14:59:51.979Z</updated>
  <id>https://leslieaibin.github.io/</id>
  
  <author>
    <name>Leslie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>bitMap讲解</title>
    <link href="https://leslieaibin.github.io/2021/12/14/java%E5%9F%BA%E7%A1%80/bitMap%E8%AE%B2%E8%A7%A3/"/>
    <id>https://leslieaibin.github.io/2021/12/14/java%E5%9F%BA%E7%A1%80/bitMap%E8%AE%B2%E8%A7%A3/</id>
    <published>2021-12-14T01:15:42.000Z</published>
    <updated>2021-12-14T14:59:51.979Z</updated>
    
    <content type="html"><![CDATA[<h3 id="小知识"><a href="#小知识" class="headerlink" title="小知识"></a>小知识</h3><ol><li>在实际项目中，我们经常需要聚合统计，比如统计一个年龄在20-30，喜欢看技术书籍，喜欢听音乐，喜欢宅在家的程序员等等一系列标签的用户。 如果使用mysql求并集，首先语句随着标签变长而变长，其次聚合，分组，去重严重影响语句性能。这种情况如何解决？</li><li>比如现在比较火的面试题，在10亿整数中找出100个重复的数，或者任意给定一个整数，判断是否在这个10亿数中。</li></ol><h3 id="bitMap原理"><a href="#bitMap原理" class="headerlink" title="bitMap原理"></a>bitMap原理</h3><p>bitMap就是使用bit位来标记元素，key为该元素，value一般为0或者1，大大节省存储空间.</p><p>现在有(2, 3, 4, 5，7)5个数，任意给定一个在0-7范围内的数字，判断是否在此集合中：</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20211214225035132.png" alt="image-20211214225035132"></p><ul><li><p>创建一个范围为(0-7)的Byte类型数组，将集合数字对应数组的bit位置置1；</p></li><li><p>然后遍历该Byte数组，如果Byte数组位置为1即代表该数存在。</p></li><li><p>同理对于10亿整数也可以这样处理，一个int型数字4个字节，32bit，如果使用bit标记正整数，就可以节省32倍的内存空间。</p></li><li><p>10亿数字，40亿字节，320亿bit，需要大约4g内存，使用bitMap标记，只需要125M内存空间即可存储，大大节省内存空间。</p></li></ul><p>以上和桶排序排序的思想非常相似。</p><h3 id="bitMap实际运用"><a href="#bitMap实际运用" class="headerlink" title="bitMap实际运用"></a>bitMap实际运用</h3><p>对于1千万数据，判断任意给定的数是否在其中？<br> 分治思想<br> 使用int数组作为bitMap。<br> 将数组分成32组，每组内有(0-31)个位置，如果给定数组在指定数组中的bit是0，则不存在。</p><ol><li>求十进制数在对应数组a中的下标<br> a[i] = a[N/32]</li><li>求int[]中bit位置<br> index = a[i] % 32</li></ol><p>上述两个运算可以改成位运算，因为位运算的效率非常高，占用cpu的时钟周期非常少。<br> 结论：对于2的倍数，%2^n = &amp;(2^n-1),模运算等于与预算，例：a % 16 = a &amp; 15,这里的15做与运算时需要化成16进制，即0x0F.</p><p>在10000000个范围为[1-100000]数中，给定指定一个数，判断是否在这个集合中</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BitMapActual</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1千万数据集合</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> N = <span class="number">10000000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//bitmap数组</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span>[] a = <span class="keyword">new</span> <span class="keyword">int</span>[N/<span class="number">32</span> + <span class="number">1</span>]; <span class="comment">//int 等于32个bit 所以数据长度为(N/32+1)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 为集合数据加标记</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> n</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">addValue</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定位数组编号 相当于n/32</span></span><br><span class="line">        <span class="keyword">int</span> row = n &gt;&gt; <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定位数组内slot位置 相当于n%32</span></span><br><span class="line">        <span class="keyword">int</span> offset = n &amp; <span class="number">0x1F</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//数组slot置1</span></span><br><span class="line">        a[row] |= <span class="number">1</span> &lt;&lt; offset;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断给定数字是否存在</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> n</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">exits</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定位数组编号</span></span><br><span class="line">        <span class="keyword">int</span> row = n &gt;&gt; <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定位数组内slot位置</span></span><br><span class="line">        <span class="keyword">int</span> offset = n &amp; <span class="number">0x1F</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 &lt;&lt; position 将a[i]中左移position求与,slot位置有值返回true</span></span><br><span class="line">        <span class="keyword">return</span> (a[row] &amp; ( <span class="number">1</span> &lt;&lt; offset)) != <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//初始化一个长度为N的数组</span></span><br><span class="line">        <span class="keyword">int</span> num[] = <span class="keyword">new</span> <span class="keyword">int</span>[N];</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">            <span class="comment">//随机数范围是(0-100000)</span></span><br><span class="line">            <span class="keyword">int</span> item = random.nextInt(<span class="number">100000</span>);</span><br><span class="line">            num[i] = item;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        BitMapActual map = <span class="keyword">new</span> BitMapActual();</span><br><span class="line">        <span class="comment">//置1</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">            map.addValue(num[i]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> temp = <span class="number">200</span>;</span><br><span class="line">        <span class="keyword">if</span>(map.exits(temp))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;temp:&quot;</span> + temp + <span class="string">&quot;has already exists&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;temp:&quot;</span> + temp + <span class="string">&quot;has no exists&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;小知识&quot;&gt;&lt;a href=&quot;#小知识&quot; class=&quot;headerlink&quot; title=&quot;小知识&quot;&gt;&lt;/a&gt;小知识&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;在实际项目中，我们经常需要聚合统计，比如统计一个年龄在20-30，喜欢看技术书籍，喜欢听音乐，喜欢宅在家的程序员等等一系</summary>
      
    
    
    
    <category term="计算机基础知识" scheme="https://leslieaibin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
  </entry>
  
  <entry>
    <title>Redis缓存与数据库一致性问题</title>
    <link href="https://leslieaibin.github.io/2021/11/30/Redis/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%20Redis%20%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F/"/>
    <id>https://leslieaibin.github.io/2021/11/30/Redis/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%20Redis%20%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F/</id>
    <published>2021-11-30T01:15:42.000Z</published>
    <updated>2021-12-08T15:17:18.413Z</updated>
    
    <content type="html"><![CDATA[<p>在做系统优化时，想到了将数据进行分级存储的思路。因为在系统中会存在一些数据，有些数据的实时性要求不高，比如一些配置信息。</p><p>基本上配置了很久才会变一次。而有一些数据实时性要求非常高，比如订单和流水的数据。所以这里根据数据要求实时性不同将数据分为三级。</p><ul><li>第1级：订单数据和支付流水数据；这两块数据对实时性和精确性要求很高，所以不添加任何缓存，读写操作将直接操作数据库。</li><li>第2级：用户相关数据；这些数据和用户相关，具有读多写少的特征，所以我们使用redis进行缓存。</li><li>第3级：支付配置信息；这些数据和用户无关，具有数据量小，频繁读，几乎不修改的特征，所以我们使用本地内存进行缓存。</li></ul><p>但是只要使用到缓存，无论是本地内存做缓存还是使用 redis 做缓存，那么就会存在数据同步的问题，因为配置信息缓存在内存中，而内存时无法感知到数据在数据库的修改。这样就会造成数据库中的数据与缓存中数据不一致的问题。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>那么我们这里列出来所有策略，并且讨论他们优劣性。</p><ul><li><p>先更新数据库，后更新缓存</p></li><li><p>先更新数据库，后删除缓存</p></li><li><p>先更新缓存，后更新数据库</p></li><li><p>先删除缓存，后更新数据库</p></li></ul><h4 id="先更新数据库，后更新缓存"><a href="#先更新数据库，后更新缓存" class="headerlink" title="先更新数据库，后更新缓存"></a>先更新数据库，后更新缓存</h4><p>这种场景一般是没有人使用的，主要原因是在更新缓存那一步，为什么呢？因为有的业务需求缓存中存在的值并不是直接从数据库中查出来的，有的是需要经过一系列计算来的缓存值，那么这时候后你要更新缓存的话其实代价是很高的。如果此时有大量的对数据库进行写数据的请求，但是读请求并不多，那么此时如果每次写请求都更新一下缓存，那么性能损耗是非常大的。</p><p>举个例子比如在数据库中有一个值为 1 的值，此时我们有 10 个请求对其每次加一的操作，但是这期间并没有读操作进来，如果用了先更新数据库的办法，那么此时就会有十个请求对缓存进行更新，会有大量的冷数据产生，如果我们不更新缓存而是删除缓存，那么在有读请求来的时候那么就会只更新缓存一次。</p><h4 id="先更新缓存，后更新数据库"><a href="#先更新缓存，后更新数据库" class="headerlink" title="先更新缓存，后更新数据库"></a>先更新缓存，后更新数据库</h4><p>这一种情况应该不需要我们考虑了吧，和第一种情况是一样的。</p><h4 id="先删除缓存，后更新数据库"><a href="#先删除缓存，后更新数据库" class="headerlink" title="先删除缓存，后更新数据库"></a>先删除缓存，后更新数据库</h4><p>该方案也会出问题，具体出现的原因如下。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078252.png" alt="先删除缓存，后更新数据库"></p><p>此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）</p><ol><li>请求 A 会先删除 Redis 中的数据，然后去数据库进行更新操作</li><li>此时请求 B 看到 Redis 中的数据时空的，会去数据库中查询该值，补录到 Redis 中</li><li>但是此时请求 A 并没有更新成功，或者事务还未提交</li></ol><p>那么这时候就会产生数据库和 Redis 数据不一致的问题。如何解决呢？其实最简单的解决办法就是延时双删的策略。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078256.png" alt="延时双删"></p><p>在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。具体步骤是：</p><ul><li>先删除缓存</li><li>再写数据库</li><li>休眠500毫秒（根据具体的业务时间来定）</li><li>再次删除缓存。</li></ul><p>但是上述的保证事务提交完以后再进行删除缓存还有一个问题，就是如果你使用的是 Mysql 的读写分离的架构的话，那么其实主从同步之间也会有时间差。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078251.png" alt="主从同步时间差"></p><p>此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）</p><ol><li>请求 A 更新操作，删除了 Redis</li><li>请求主库进行更新操作，主库与从库进行同步数据的操作</li><li>请 B 查询操作，发现 Redis 中没有数据</li><li>去从库中拿去数据</li><li>此时同步数据还未完成，拿到的数据是旧数据</li></ol><p>此时的解决办法就是如果是对 Redis 进行填充数据的查询数据库操作，那么就强制将其指向主库进行查询。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078255.png" alt="从主库中拿数据"></p><h4 id="先更新数据库，后删除缓存"><a href="#先更新数据库，后删除缓存" class="headerlink" title="先更新数据库，后删除缓存"></a>先更新数据库，后删除缓存</h4><p>问题：这一种情况也会出现问题，比如更新数据库成功了，但是在删除缓存的阶段出错了没有删除成功，那么此时再读取缓存的时候每次都是错误的数据了。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078254.png" alt="先更新数据库，后删除缓存"></p><p>此时解决方案就是利用消息队列进行删除的补偿。具体的业务逻辑用语言描述如下：</p><ol><li>请求 A 先对数据库进行更新操作</li><li>在对 Redis 进行删除操作的时候发现报错，删除失败</li><li>此时将Redis 的 key 作为消息体发送到消息队列中</li><li>系统接收到消息队列发送的消息后再次对 Redis 进行删除操作</li></ol><p>但是这个方案会有一个缺点就是会对业务代码造成大量的侵入，深深的耦合在一起，所以这时会有一个优化的方案，我们知道对 Mysql 数据库更新操作后再 binlog 日志中我们都能够找到相应的操作，那么我们可以订阅 Mysql 数据库的 binlog 日志对缓存进行操作。</p><p><img src="https://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000039078253.png" alt="利用订阅 binlog 删除缓存"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>每种方案各有利弊，比如在第三种先删除缓存，后更新数据库这个方案我们最后讨论了要更新 Redis 的时候强制走主库查询就能解决问题，那么这样的操作会对业务代码进行大量的侵入，但是不需要增加的系统，不需要增加整体的服务的复杂度。</p><p>最后一种方案我们最后讨论了利用订阅 binlog 日志进行搭建独立系统操作 Redis，这样的缺点其实就是增加了系统复杂度。其实每一次的选择都需要我们对于我们的业务进行评估来选择，没有一种技术是对于所有业务都通用的。没有最好的，只有最适合我们的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在做系统优化时，想到了将数据进行分级存储的思路。因为在系统中会存在一些数据，有些数据的实时性要求不高，比如一些配置信息。&lt;/p&gt;
&lt;p&gt;基本上配置了很久才会变一次。而有一些数据实时性要求非常高，比如订单和流水的数据。所以这里根据数据要求实时性不同将数据分为三级。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://leslieaibin.github.io/2021/11/29/Authorization/01.%20Cookie%E3%80%81Session%E3%80%81Token%E3%80%81JWT/"/>
    <id>https://leslieaibin.github.io/2021/11/29/Authorization/01.%20Cookie%E3%80%81Session%E3%80%81Token%E3%80%81JWT/</id>
    <published>2021-11-29T15:16:44.637Z</published>
    <updated>2021-11-29T15:17:48.322Z</updated>
    
    <content type="html"><![CDATA[<h1 id="01-Cookie、Session、Token、JWT"><a href="#01-Cookie、Session、Token、JWT" class="headerlink" title="01.Cookie、Session、Token、JWT"></a>01.Cookie、Session、Token、JWT</h1><h2 id="什么是认证（Authentication"><a href="#什么是认证（Authentication" class="headerlink" title="什么是认证（Authentication)"></a>什么是认证（Authentication)</h2><ul><li><p>通俗地讲就是<strong>验证当前用户的身份</strong>，证明“你是你自己”（比如：你每天上下班打卡，都需要通过指纹打卡，当你的指纹和系统里录入的指纹相匹配时，就打卡成功）</p></li><li><p>互联网中的认证：</p><ul><li>用户名密码登录</li><li>邮箱发送登录链接</li><li>手机号接收验证码</li><li>只要你能收到邮箱/验证码，就默认你是账号的主人</li></ul></li></ul><h2 id="什么是授权（Authorization）"><a href="#什么是授权（Authorization）" class="headerlink" title="什么是授权（Authorization）"></a>什么是授权（Authorization）</h2><ul><li>用户授予第三方应用访问该用户某些资源的权限<ul><li>你在安装手机应用的时候，APP 会询问是否允许授予权限（访问相册、地理位置等权限）</li><li>你在访问微信小程序时，当登录时，小程序会询问是否允许授予权限（获取昵称、头像、地区、性别等个人信息）</li></ul></li><li>实现授权的方式有：cookie、session、token、OAuth</li></ul><h2 id="什么是凭证（Credentials）"><a href="#什么是凭证（Credentials）" class="headerlink" title="什么是凭证（Credentials）"></a>什么是凭证（Credentials）</h2><ul><li>实现认证和授权的前提是需要一种媒介（证书）来标记访问者的身份<ul><li>在战国时期，商鞅变法，发明了照身帖。照身帖由官府发放，是一块打磨光滑细密的竹板，上面刻有持有人的头像和籍贯信息。国人必须持有，如若没有就被认为是黑户，或者间谍之类的。</li><li>在现实生活中，每个人都会有一张专属的<a href="https://link.juejin.cn/?target=https://baike.baidu.com/item/%E5%B1%85%E6%B0%91%E8%BA%AB%E4%BB%BD%E8%AF%81/2080960">居民身份证</a>，是用于证明持有人身份的一种法定<a href="https://link.juejin.cn/?target=https://baike.baidu.com/item/%E8%AF%81%E4%BB%B6/5804999">证件</a>。通过身份证，我们可以办理手机卡/银行卡/个人贷款/交通出行等等，这就是<strong>认证的凭证。</strong></li><li>在互联网应用中，一般网站（如掘金）会有两种模式，游客模式和登录模式。游客模式下，可以正常浏览网站上面的文章，一旦想要点赞/收藏/分享文章，就需要登录或者注册账号。当用户登录成功后，服务器会给该用户使用的浏览器颁发一个令牌（token），这个令牌用来表明你的身份，每次浏览器发送请求时会带上这个令牌，就可以使用游客模式下无法使用的功能。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;01-Cookie、Session、Token、JWT&quot;&gt;&lt;a href=&quot;#01-Cookie、Session、Token、JWT&quot; class=&quot;headerlink&quot; title=&quot;01.Cookie、Session、Token、JWT&quot;&gt;&lt;/a&gt;01.Co</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>5.操作系统-进程调度算法</title>
    <link href="https://leslieaibin.github.io/2021/10/04/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/5.%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/"/>
    <id>https://leslieaibin.github.io/2021/10/04/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/5.%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/</id>
    <published>2021-10-03T16:15:42.000Z</published>
    <updated>2021-10-11T05:38:43.232Z</updated>
    
    <content type="html"><![CDATA[<h1 id="进程调度算法"><a href="#进程调度算法" class="headerlink" title="进程调度算法"></a>进程调度算法</h1><h2 id="先来先服务调度算法"><a href="#先来先服务调度算法" class="headerlink" title="先来先服务调度算法"></a>先来先服务调度算法</h2><p>先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。</p><h2 id="短作业-进程-优先调度算法"><a href="#短作业-进程-优先调度算法" class="headerlink" title="短作业(进程)优先调度算法"></a>短作业(进程)优先调度算法</h2><p>短作业(进程)优先调度算法，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。</p><h2 id="时间片轮转法"><a href="#时间片轮转法" class="headerlink" title="时间片轮转法"></a>时间片轮转法</h2><p>在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU分配给队首进程，并令其执行一个时间片。时间片的大小从几ms到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。</p><h2 id="多级反馈队列调度算法"><a href="#多级反馈队列调度算法" class="headerlink" title="多级反馈队列调度算法"></a>多级反馈队列调度算法</h2><p>前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述：</p><p>1）应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，第i+1个队列的时间片要比第i个队列的时间片长一倍。</p><p>2）当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第n队列后，在第n队列便采取按时间片轮转的方式运行。</p><p>3）仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即第i队列中某个正在运行的进程的时间片用完后，由调度程序选择优先权较高的队列中的那一个进程，把处理机分配给它。</p><h2 id="优先权调度算法"><a href="#优先权调度算法" class="headerlink" title="优先权调度算法"></a>优先权调度算法</h2><p>为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。</p><ol><li>非抢占式优先权算法</li></ol><p>在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。</p><ol start="2"><li>抢占式优先权调度算法</li></ol><p>在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i时，就将其优先权Pi与正在执行的进程j的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi&gt;Pj，则立即停止Pj的执行，做进程切换，使i进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;进程调度算法&quot;&gt;&lt;a href=&quot;#进程调度算法&quot; class=&quot;headerlink&quot; title=&quot;进程调度算法&quot;&gt;&lt;/a&gt;进程调度算法&lt;/h1&gt;&lt;h2 id=&quot;先来先服务调度算法&quot;&gt;&lt;a href=&quot;#先来先服务调度算法&quot; class=&quot;headerlink</summary>
      
    
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>4.操作系统-页面置换算法</title>
    <link href="https://leslieaibin.github.io/2021/10/03/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/4.%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"/>
    <id>https://leslieaibin.github.io/2021/10/03/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/4.%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/</id>
    <published>2021-10-02T16:15:42.000Z</published>
    <updated>2021-10-11T05:38:14.868Z</updated>
    
    <content type="html"><![CDATA[<h1 id="页面置换算法"><a href="#页面置换算法" class="headerlink" title="页面置换算法"></a>页面置换算法</h1><p>地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。当发生缺页中断时操作系统必须在内存选择一个页面将其移除内存，以便为即将调入的页面让出空间。而用来选择淘汰那一页的规则叫做页面置换算法。</p><h2 id="最佳置换算法（OPT）（理想置换算法）"><a href="#最佳置换算法（OPT）（理想置换算法）" class="headerlink" title="最佳置换算法（OPT）（理想置换算法）"></a>最佳置换算法（OPT）（理想置换算法）</h2><p>这是一种理想情况下的页面置换算法，但实际上是不可能实现的。该算法的基本思想是：发生缺页时，有些页面在内存中，其中有一页将很快被访问（也包含紧接着的下一条指令的那页），而其他页面则可能要到10、100或者1000条指令后才会被访问，每个页面都可以用在该页面首次被访问前所要执行的指令数进行标记。最佳页面置换算法只是简单地规定：标记最大的页应该被置换。这个算法唯一的一个问题就是它无法实现。当缺页发生时，操作系统无法知道各个页面下一次是在什么时候被访问。虽然这个算法不可能实现，但是最佳页面置换算法可以用于对可实现算法的性能进行衡量比较。</p><h2 id="先进先出置换算法（FIFO）"><a href="#先进先出置换算法（FIFO）" class="headerlink" title="先进先出置换算法（FIFO）"></a>先进先出置换算法（FIFO）</h2><p>最简单的页面置换算法是先入先出（FIFO）法。这种算法的实质是，总是选择在主存中停留时间最长（即最老）的一页置换，即<strong>先进入内存的页，先退出内存</strong>。理由是：最早调入内存的页，其不再被使用的可能性比刚调入内存的可能性大。建立一个FIFO队列，收容所有在内存中的页。被置换页面总是在队列头上进行。当一个页面被放入内存时，就把它插在队尾上。</p><p>这种算法只是在按线性顺序访问地址空间时才是理想的，否则效率不高。因为那些常被访问的页，往往在主存中也停留得最久，结果它们因变“老”而不得不被置换出去。</p><p>FIFO的另一个缺点是，它有一种异常现象，即在增加存储块的情况下，反而使缺页中断率增加了。当然，导致这种异常现象的页面走向实际上是很少见的。</p><h2 id="最近最久未使用（LRU）算法"><a href="#最近最久未使用（LRU）算法" class="headerlink" title="最近最久未使用（LRU）算法"></a>最近最久未使用（LRU）算法</h2><p>FIFO算法和OPT算法之间的主要差别是，FIFO算法利用页面进入内存后的时间长短作为置换依据，而OPT算法的依据是将来使用页面的时间。如果以最近的过去作为不久将来的近似，那么就可以把过去最长一段时间里不曾被使用的页面置换掉。它的实质是，当需要置换一页时，*<strong>*选择在最近一段时间里最久没有使用过的页面予以置换**</strong>。这种算法就称为<strong>最久未使用算法</strong>（Least Recently Used，LRU）。</p><p>LRU算法是与每个页面最后使用的时间有关的。当必须置换一个页面时，LRU算法选择过去一段时间里最久未被使用的页面。</p><p>LRU算法是经常采用的页面置换算法，并被认为是相当好的，但是存在如何实现它的问题。LRU算法需要实际硬件的支持。其问题是怎么确定最后使用时间的顺序，对此有两种可行的办法：</p><ul><li><p>计数器。最简单的情况是使每个页表项对应一个使用时间字段，并给CPU增加一个逻辑时钟或计数器。每次存储访问，该时钟都加1。每当访问一个页面时，时钟寄存器的内容就被复制到相应页表项的使用时间字段中。这样我们就可以始终保留着每个页面最后访问的“时间”。在置换页面时，选择该时间值最小的页面。这样做，不仅要查页表，而且当页表改变时（因CPU调度）要维护这个页表中的时间，还要考虑到时钟值溢出的问题。</p></li><li><p>栈。用一个栈保留页号。每当访问一个页面时，就把它从栈中取出放在栈顶上。这样一来，栈顶总是放有目前使用最多的页，而栈底放着目前最少使用的页。由于要从栈的中间移走一项，所以要用具有头尾指针的双向链连起来。在最坏的情况下，移走一页并把它放在栈顶上需要改动6个指针。每次修改都要有开销，但需要置换哪个页面却可直接得到，用不着查找，因为尾指针指向栈底，其中有被置换页。</p></li></ul><p>因实现LRU算法必须有大量硬件支持，还需要一定的软件开销。所以实际实现的都是一种简单有效的LRU近似算法。</p><p>一种LRU近似算法是<strong>最近未使用算法</strong>（Not Recently Used，NUR）。它在存储分块表的每一表项中增加一个引用位，操作系统定期地将它们置为0。当某一页被访问时，由硬件将该位置1。过一段时间后，通过检查这些位可以确定哪些页使用过，哪些页自上次置0后还未使用过。就可把该位是0的页淘汰出去，因为在最近一段时间里它未被访问过。</p><h2 id="Clock置换算法（LRU算法的近似实现）"><a href="#Clock置换算法（LRU算法的近似实现）" class="headerlink" title="Clock置换算法（LRU算法的近似实现）"></a>Clock置换算法（LRU算法的近似实现）</h2><h2 id="最少使用（LFU）置换算法"><a href="#最少使用（LFU）置换算法" class="headerlink" title="最少使用（LFU）置换算法"></a>最少使用（LFU）置换算法</h2><p>在采用最少使用置换算法时，应为在内存中的每个页面设置一个移位寄存器，用来记录该页面被访问的频率。该置换算法选择在最近时期使用最少的页面作为淘汰页。由于存储器具有较高的访问速度，例如100 ns，在1 ms时间内可能对某页面连续访问成千上万次，因此，通常不能直接利用计数器来记录某页被访问的次数，而是采用移位寄存器方式。每次访问某页时，便将该移位寄存器的最高位置1，再每隔一定时间(例如100 ns)右移一次。这样，在最近一段时间使用最少的页面将是∑Ri最小的页。</p><p>LFU置换算法的页面访问图与LRU置换算法的访问图完全相同；或者说，利用这样一套硬件既可实现LRU算法，又可实现LFU算法。应该指出，LFU算法并不能真正反映出页面的使用情况，因为在每一时间间隔内，只是用寄存器的一位来记录页的使用情况，因此，访问一次和访问10 000次是等效的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;页面置换算法&quot;&gt;&lt;a href=&quot;#页面置换算法&quot; class=&quot;headerlink&quot; title=&quot;页面置换算法&quot;&gt;&lt;/a&gt;页面置换算法&lt;/h1&gt;&lt;p&gt;地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。当发生缺页中断时操作系统必须在内存选</summary>
      
    
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Redis集群</title>
    <link href="https://leslieaibin.github.io/2021/10/01/Redis/Redis%E9%9B%86%E7%BE%A4/"/>
    <id>https://leslieaibin.github.io/2021/10/01/Redis/Redis%E9%9B%86%E7%BE%A4/</id>
    <published>2021-10-01T01:15:42.000Z</published>
    <updated>2021-10-11T05:42:10.588Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis支持三种集群方案"><a href="#Redis支持三种集群方案" class="headerlink" title="Redis支持三种集群方案"></a>Redis支持三种集群方案</h1><ul><li>主从复制模式</li><li>Sentiel(哨兵)模式</li><li>Cluster模式</li></ul><h2 id="Redis集群的三种模式"><a href="#Redis集群的三种模式" class="headerlink" title="Redis集群的三种模式"></a>Redis集群的三种模式</h2><h3 id="主从复制模式"><a href="#主从复制模式" class="headerlink" title="主从复制模式"></a>主从复制模式</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022808581" alt="img"></p><p><strong>主从复制作用</strong></p><p>通过持久化功能，Redis保证了即使服务器重启的情况下也不会丢失（或少量丢失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。</p><p>为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使一台服务器出现故障，其他服务器依然可以继续提供服务。</p><p>为此，<strong>Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上</strong>。</p><p>在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库(slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。</p><p><strong>总结：引入主从复制机制的目的有两个</strong></p><ul><li>一个是读写分离，分担 “master” 的读写压力</li><li>一个是方便做容灾恢复</li></ul><h4 id="主从复制原理"><a href="#主从复制原理" class="headerlink" title="主从复制原理"></a><strong>主从复制原理</strong></h4><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000022808583" alt="img"></p><ul><li>从数据库启动成功后，连接主数据库，发送 SYNC 命令；</li><li>主数据库接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令；</li><li>主数据库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令；</li><li>从数据库收到快照文件后丢弃所有旧数据，载入收到的快照；</li><li>主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令；</li><li>从数据库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（<strong>从数据库初始化完成</strong>）</li><li>主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令（<strong>从数据库初始化完成后的操作</strong>）</li><li>出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库，增量复制。</li><li>主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</li></ul><h4 id="主从复制优缺点"><a href="#主从复制优缺点" class="headerlink" title="主从复制优缺点"></a>主从复制优缺点</h4><p><strong>主从复制优点</strong></p><ul><li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离；</li><li>为了分载 Master 的读操作压力，Slave 服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成；</li><li>Slave 同样可以接受其它 Slaves 的连接和同步请求，这样可以有效的分载 Master 的同步压力；</li><li>Master Server 是以非阻塞的方式为 Slaves 提供服务。所以在 Master-Slave 同步期间，客户端仍然可以提交查询或修改请求；</li><li>Slave Server 同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据；</li></ul><p><strong>主从复制缺点</strong></p><ul><li>Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（<strong>也就是要人工介入</strong>）；</li><li>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；</li><li>如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。</li><li>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；</li></ul><h3 id="Sentinel（哨兵）模式"><a href="#Sentinel（哨兵）模式" class="headerlink" title="Sentinel（哨兵）模式"></a>Sentinel（哨兵）模式</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Redis支持三种集群方案&quot;&gt;&lt;a href=&quot;#Redis支持三种集群方案&quot; class=&quot;headerlink&quot; title=&quot;Redis支持三种集群方案&quot;&gt;&lt;/a&gt;Redis支持三种集群方案&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;主从复制模式&lt;/li&gt;
&lt;li&gt;Sent</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis分布式限流</title>
    <link href="https://leslieaibin.github.io/2021/09/30/Redis/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81/"/>
    <id>https://leslieaibin.github.io/2021/09/30/Redis/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81/</id>
    <published>2021-09-30T01:15:42.000Z</published>
    <updated>2021-09-30T08:44:26.803Z</updated>
    
    <content type="html"><![CDATA[<p>由于互联网公司的流量巨大，系统上线会做一个流量峰值的评估，尤其是像各种秒杀促销活动，为了保证系统不被巨大的流量压垮，会在系统流量到达一定阈值时，拒绝掉一部分流量。</p><p>限流会导致用户在短时间内（这个时间段是毫秒级的）系统不可用，一般我们衡量系统处理能力的指标是每秒的<code>QPS</code>或者<code>TPS</code>，假设系统每秒的流量阈值是1000，理论上一秒内有第1001个请求进来时，那么这个请求就会被限流。</p><h1 id="限流方案"><a href="#限流方案" class="headerlink" title="限流方案"></a>限流方案</h1><h2 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h2><p>Java内部可以通过原子类计数器<code>AtomicInteger</code>、<code>Semaphore</code>信号量来做简单的限流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 限流的个数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> maxCount = <span class="number">10</span>;</span><br><span class="line"><span class="comment">// 指定时间内</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> interval = <span class="number">60</span>;</span><br><span class="line"><span class="comment">// 原子类计数器</span></span><br><span class="line"><span class="keyword">private</span> AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"><span class="comment">// 起始时间</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> startTime = System.currentTimeMills();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">limit</span><span class="params">(<span class="keyword">int</span> maxCount, <span class="keyword">int</span> interval)</span> </span>&#123;</span><br><span class="line">    atomicInteger.addAndGet(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (atomicInteger.get() == <span class="number">1</span>) &#123;</span><br><span class="line">        startTime = System.currentTimeMillis();</span><br><span class="line">        atomicInteger.addAndGet(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 超过了间隔时间，直接重新开始计数</span></span><br><span class="line">    <span class="keyword">if</span> (System.currentTimeMillis() - startTime &gt; interval * <span class="number">1000</span>) &#123;</span><br><span class="line">        startTime = System.currentTimeMillis();</span><br><span class="line">        atomicInteger.set(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 还在间隔时间内,check有没有超过限流的个数</span></span><br><span class="line">    <span class="keyword">if</span> (atomicInteger.get() &gt; maxCount) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h2><p>漏桶算法思路很简单，我们把水比做请求，漏桶比做是系统处理能力极限，水先进入到漏桶里，漏桶里的水按一定速率流出，当流出速率小于流入的速率时，由于漏桶容量有限，后续进入的水直接溢出（拒绝请求），以此实现限流。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210930162736284.png" alt="image-20210930162736284"></p><h2 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h2><p>令牌桶算法的原理也比较简单，可以理解成医院的挂号看病，只要拿到号以后才可以进行诊病。</p><p>系统会维护 一个令牌（token）桶，以一个恒定的速度往桶里放入令牌（token），这时如果有请求进来想要被处理，则需要先从桶里获取一个令牌（token）, 当桶里没有令牌（token）可取时，则该请求将被拒绝服务。令牌桶算法通过控制桶的容量，发放令牌的速率，来达到对请求的限制。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210930163437254.png" alt="image-20210930163437254"></p><h2 id="Redis-Lua"><a href="#Redis-Lua" class="headerlink" title="Redis + Lua"></a>Redis + Lua</h2><p>个人理解，<code>Lua</code>脚本和 <code>MySQL</code>数据库的存储过程比较相似，他们执行一组命令，所有命令的执行要么全部成功或者失败，以此达到原子性。也可以把<code>Lua</code>脚本理解为，一段具有业务逻辑的代码块。</p><p>而<code>Lua</code>本身就是一种编程语言，虽然<code>redis</code> 官方没有直接提供限流相应的<code>API</code>，但却支持了 <code>Lua</code> 脚本的功能，可以使用它实现复杂的令牌桶或漏桶算法，也是分布式系统中实现限流的主要方式之一。</p><p>相比<code>Redis</code>事务，<code>Lua脚本</code>的优点：</p><ul><li>减少网络开销：使用<code>Lua</code>脚本，无需向<code>Redis</code> 发送多次请求，执行一次即可，减少网络传输</li><li>原子操作：<code>Redis</code> 将整个<code>Lua</code>脚本作为一个命令执行，原子，无需担心并发</li><li>复用：<code>Lua</code>脚本一旦执行，会永久保存 <code>Redis</code> 中,，其他客户端可复用</li></ul><p><code>Lua</code>脚本大致逻辑如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">-- 获取调用脚本时传入的第一个key值（用作限流的 key）</span><br><span class="line">local key = KEYS[<span class="number">1</span>]</span><br><span class="line">-- 获取调用脚本时传入的第一个参数值（限流大小）</span><br><span class="line">local limit = tonumber(ARGV[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">-- 获取当前流量大小</span><br><span class="line">local curentLimit = tonumber(redis.call(<span class="string">&#x27;get&#x27;</span>, key) or <span class="string">&quot;0&quot;</span>)</span><br><span class="line"></span><br><span class="line">-- 是否超出限流</span><br><span class="line"><span class="keyword">if</span> curentLimit + <span class="number">1</span> &gt; limit then</span><br><span class="line">    -- 返回(拒绝)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    -- 没有超出 value + <span class="number">1</span></span><br><span class="line">    redis.call(<span class="string">&quot;INCRBY&quot;</span>, key, <span class="number">1</span>)</span><br><span class="line">    -- 设置过期时间</span><br><span class="line">    redis.call(<span class="string">&quot;EXPIRE&quot;</span>, key, <span class="number">2</span>)</span><br><span class="line">    -- 返回(放行)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure><ul><li>通过<code>KEYS[1]</code> 获取传入的key参数</li><li>通过<code>ARGV[1]</code>获取传入的<code>limit</code>参数</li><li><code>redis.call</code>方法，从缓存中<code>get</code>和<code>key</code>相关的值，如果为<code>null</code>那么就返回0</li><li>接着判断缓存中记录的数值是否会大于限制大小，如果超出表示该被限流，返回0</li><li>如果未超过，那么该key的缓存值+1，并设置过期时间为1秒钟以后，并返回缓存值+1</li></ul><p>这种方式是本文推荐的方案，具体实现会在后边做细说。</p><h2 id="网关层限流"><a href="#网关层限流" class="headerlink" title="网关层限流"></a>网关层限流</h2><p>限流常在网关这一层做，比如<code>Nginx</code>、<code>Openresty</code>、<code>kong</code>、<code>zuul</code>、<code>Spring Cloud Gateway</code>等，而像<code>spring cloud - gateway</code>网关限流底层实现原理，就是基于<code>Redis + Lua</code>，通过内置<code>Lua</code>限流脚本的方式。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/640" alt="图片"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;由于互联网公司的流量巨大，系统上线会做一个流量峰值的评估，尤其是像各种秒杀促销活动，为了保证系统不被巨大的流量压垮，会在系统流量到达一定阈值时，拒绝掉一部分流量。&lt;/p&gt;
&lt;p&gt;限流会导致用户在短时间内（这个时间段是毫秒级的）系统不可用，一般我们衡量系统处理能力的指标是每秒</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>3.操作系统-IO模型</title>
    <link href="https://leslieaibin.github.io/2021/09/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3.IO%E6%A8%A1%E5%9E%8B/"/>
    <id>https://leslieaibin.github.io/2021/09/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3.IO%E6%A8%A1%E5%9E%8B/</id>
    <published>2021-09-29T16:15:42.000Z</published>
    <updated>2021-09-30T08:47:28.525Z</updated>
    
    <content type="html"><![CDATA[<h1 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927141630387.png" alt="image-20210927141630387"></p><p>IO (Input/Output，输入/输出)即数据的读取（接收）或写入（发送）操作，通常用户进程中的一个完整IO分为两阶段：用户进程空间&lt;–&gt;内核空间、内核空间&lt;–&gt;设备空间（磁盘、网络等）。IO有内存IO、网络IO和磁盘IO三种，通常我们说的IO指的是后两者。</p><p>LINUX中进程无法直接操作I/O设备，其必须通过系统调用请求kernel来协助完成I/O动作；内核会为每个I/O设备维护一个缓冲区。</p><p>对于一个输入操作来说，进程IO系统调用后，内核会先看缓冲区中有没有相应的缓存数据，没有的话再到设备中读取，因为设备IO一般速度较慢，需要等待；内核缓冲区有数据则直接复制到进程空间。</p><p>所以，对于一个网络输入操作通常包括两个不同阶段：</p><ul><li><p>等待网络数据到达网卡→读取到内核缓冲区，数据准备好；</p></li><li><p>从内核缓冲区复制数据到进程空间。</p><p><strong>从TCP发送数据的流程说起</strong></p></li></ul><p>要深入的理解各种IO模型，那么必须先了解下产生各种IO的原因是什么，要知道这其中的本质问题那么我们就必须要知一条消息是如何从过一个人发送到另外一个人的；</p><p>以两个应用程序通讯为例，我们来了解一下当“A”向”B” 发送一条消息，简单来说会经过如下流程：</p><p><strong>第一步</strong>：应用A把消息发送到 TCP发送缓冲区。</p><p><strong>第二步：</strong> TCP发送缓冲区再把消息发送出去，经过网络传递后，消息会发送到B服务器的TCP接收缓冲区。</p><p><strong>第三步：</strong>B再从TCP接收缓冲区去读取属于自己的数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-5311954c22d15ca91e47ab52168b7ada_720w.jpg" alt="img"></p><p>根据上图我们基本上了解消息发送要经过 应用A、应用A对应服务器的TCP发送缓冲区、经过网络传输后消息发送到了应用B对应服务器TCP接收缓冲区、然后最终B应用读取到消息。</p><p>《UNIX网络编程》说得很清楚，5种IO模型分别是阻塞IO模型、非阻塞IO模型、IO复用模型、信号驱动的IO模型、异步IO模型；前4种为同步IO操作，只有异步IO模型是异步IO操作。</p><h2 id="阻塞IO"><a href="#阻塞IO" class="headerlink" title="阻塞IO"></a>阻塞IO</h2><p><strong>思考一个问题：</strong></p><p>因为应用之间发送消息是间断性的，也就是说在上图中TCP缓冲区还没有接收到属于应用B该读取的消息时，那么此时应用B向TCP缓冲区发起读取申请，TCP接收缓冲区是应该马上告诉应用B 现在没有你的数据，还是说让应用B在这里等着，直到有数据再把数据交给应用B。</p><p>把这个问题应用到第一个步骤也是一样，应用A在向TCP发送缓冲区发送数据时，如果TCP发送缓冲区已经满了，那么是告诉应用A现在没空间了，还是让应用A等待着，等TCP发送缓冲区有空间了再把应用A的数据访拷贝到发送缓冲区。</p><p><strong>什么是阻塞IO</strong></p><p>阻塞IO就是当应用B发起读取数据申请时，在内核数据没有准备好之前，应用B会一直处于等待数据状态，直到内核把数据准备好了交给应用B才结束。</p><p><strong>术语描述</strong>：在应用调用recvfrom读取数据时，其系统调用直到数据包到达且被复制到应用缓冲区中或者发送错误时才返回，在此期间一直会等待，进程从调用到返回这段时间内都是被阻塞的称为阻塞IO；</p><p><strong>流程：</strong></p><p>1、应用进程向内核发起recfrom读取数据。</p><p>2、准备数据报（应用进程阻塞）。</p><p>3、将数据从内核负责到应用空间。</p><p>4、复制完成后，返回成功提示。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927142530568.png" alt="image-20210927142530568"></p><p><strong>1、典型应用：阻塞socket、Java BIO；</strong></p><p><strong>2、特点：</strong></p><ul><li>进程阻塞挂起不消耗CPU资源，及时响应每个操作；</li><li>实现难度低、开发应用较容易；</li><li>适用并发量小的网络应用开发；</li></ul><p>不适用并发量大的应用：因为一个请求IO会阻塞进程，所以，得为每请求分配一个处理进程（线程）以及时响应，系统开销大。</p><h2 id="非阻塞IO"><a href="#非阻塞IO" class="headerlink" title="非阻塞IO"></a>非阻塞IO</h2><p>非阻塞IO就是当应用B发起读取数据申请时，如果内核数据没有准备好会即刻告诉应用B，不会让B在这里等待。</p><p><strong>术语</strong>：非阻塞IO是在应用调用recvfrom读取数据时，如果该缓冲区没有数据的话，就会直接返回一个EWOULDBLOCK错误，不会让应用一直等待中。在没有数据的时候会即刻返回错误标识，那也意味着如果应用要读取数据就需要不断的调用recvfrom请求，直到读取到它数据要的数据为止。</p><p><strong>流程：</strong></p><p>1、应用进程向内核发起recvfrom读取数据。</p><p>2、没有数据报准备好，即刻返回EWOULDBLOCK错误码。</p><p>3、应用进程向内核发起recvfrom读取数据。</p><p>4、已有数据包准备好就进行一下 步骤，否则还是返回错误码。</p><p>5、将数据从内核拷贝到用户空间。</p><p>6、完成后，返回成功提示。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927155649702.png" alt="image-20210927155649702"></p><p>1、典型应用：socket是非阻塞的方式（设置为NONBLOCK）</p><p>2、特点：</p><ul><li>进程轮询（重复）调用，消耗CPU的资源；</li><li>实现难度低、开发应用相对阻塞IO模式较难；</li><li>适用并发量较小、且不需要及时响应的网络应用开发；</li></ul><h2 id="IO复用模型"><a href="#IO复用模型" class="headerlink" title="IO复用模型"></a><strong>IO复用模型</strong></h2><p><strong>思考一个问题：</strong></p><p>我们还是把视角放到应用B从TCP缓冲区中读取数据这个环节来。如果在并发的环境下，可能会N个人向应用B发送消息，这种情况下我们的应用就必须创建多个线程去读取数据，每个线程都会自己调用recvfrom 去读取数据。那么此时情况可能如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-529734ac694c4da96ac78eeebd7deb6b_720w.jpg" alt="img"></p><p>如上图一样，并发情况下服务器很可能一瞬间会收到几十上百万的请求，这种情况下应用B就需要创建几十上百万的线程去读取数据，同时又因为应用线程是不知道什么时候会有数据读取，为了保证消息能及时读取到，那么这些线程自己必须不断的向内核发送recvfrom 请求来读取数据；</p><p>那么问题来了，这么多的线程不断调用recvfrom 请求数据，先不说服务器能不能扛得住这么多线程，就算扛得住那么很明显这种方式是不是太浪费资源了，线程是我们操作系统的宝贵资源，大量的线程用来去读取数据了，那么就意味着能做其它事情的线程就会少。</p><p>所以，有人就提出了一个思路，能不能提供一种方式，可以由一个线程监控多个网络请求（<strong>我们后面将称为fd文件描述符，linux系统把所有网络请求以一个fd来标识</strong>），这样就可以只需要一个或几个线程就可以完成数据状态询问的操作，当有数据准备就绪之后再分配对应的线程去读取数据，这么做就可以节省出大量的线程资源出来，这个就是IO复用模型的思路。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2c65fd3534e58d3a54cdeae778a31446_720w.jpg" alt="img"></p><p>正如上图，IO复用模型的思路就是系统提供了一种函数可以同时监控多个fd的操作，这个函数就是我们常说到的select、poll、epoll函数，有了这个函数后，应用线程通过调用select函数就可以同时监控多个fd，select函数监控的fd中只要有任何一个数据状态准备就绪了，select函数就会返回可读状态，这时询问线程再去通知处理数据的线程，对应线程此时再发起recvfrom请求去读取数据。</p><p><strong>术语描述：</strong>进程通过将一个或多个fd传递给select，阻塞在select操作上，select帮我们侦测多个fd是否准备就绪，当有fd准备就绪时，select返回数据可读状态，应用程序再调用recvfrom读取数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927160639013.png" alt="image-20210927160639013"></p><p>复用IO的基本思路就是通过slect或poll、epoll 来监控多fd ，来达到不必为每个fd创建一个对应的监控线程，从而减少线程资源创建的目的。</p><p>可以看到，多个进程注册IO后，只有另一个select调用进程被阻塞。</p><p>1、典型应用：select、poll、epoll三种方案，nginx都可以选择使用这三个方案;Java NIO;</p><p>2、特点：</p><ul><li>专一进程解决多个进程IO的阻塞问题，性能好；Reactor模式;</li><li>实现、开发应用难度较大；</li><li>适用高并发服务应用开发：一个进程（线程）响应多个请求；</li></ul><p>3、select、poll、epoll</p><ul><li>Linux中IO复用的实现方式主要有select、poll和epoll：</li><li>Select：注册IO、阻塞扫描，监听的IO最大连接数不能多于FD_SIZE；</li><li>Poll：原理和Select相似，没有数量限制，但IO数量大扫描线性性能下降；</li><li>Epoll ：事件驱动不阻塞，mmap实现内核与用户空间的消息传递，数量很大，Linux2.6后内核支持；</li></ul><h2 id="信号驱动IO模型"><a href="#信号驱动IO模型" class="headerlink" title="信号驱动IO模型"></a><strong>信号驱动IO模型</strong></h2><p>复用IO模型解决了一个线程可以监控多个fd的问题，但是select是采用轮询的方式来监控多个fd的，通过不断的轮询fd的可读状态来知道是否就可读的数据，而无脑的轮询就显得有点暴力，因为大部分情况下的轮询都是无效的，所以有人就想，能不能不要我总是去问你是否数据准备就绪，能不能我发出请求后等你数据准备好了就通知我，所以就衍生了信号驱动IO模型。</p><p>于是信号驱动IO不是用循环请求询问的方式去监控数据就绪状态，而是在调用sigaction时候建立一个SIGIO的信号联系，当内核数据准备好之后再通过SIGIO信号通知线程数据准备好后的可读状态，当线程收到可读状态的信号后，此时再向内核发起recvfrom读取数据的请求，因为信号驱动IO的模型下应用线程在发出信号监控后即可返回，不会阻塞，所以这样的方式下，一个应用线程也可以同时监控多个fd。</p><p>类似于下图描述：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2461c8df6a154930afb4e7c345442835_720w.jpg" alt="img"></p><p><strong>术语描述：</strong>首先开启套接口信号驱动IO功能，并通过系统调用sigaction执行一个信号处理函数，此时请求即刻返回，当数据准备就绪时，就生成对应进程的SIGIO信号，通过信号回调通知应用线程调用recvfrom来读取数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927161210407.png" alt="image-20210927161210407"></p><p> IO复用模型里面的select虽然可以监控多个fd了，但select其实现的本质上还是通过不断的轮询fd来监控数据状态， 因为大部分轮询请求其实都是无效的，所以信号驱动IO意在通过这种建立信号关联的方式，实现了发出请求后只需要等待数据就绪的通知即可，这样就可以避免大量无效的数据状态轮询操作。</p><p>特点：回调机制，实现、开发应用难度大；</p><h2 id="异步IO模型"><a href="#异步IO模型" class="headerlink" title="异步IO模型"></a><strong>异步IO模型</strong></h2><p>不管是IO复用还是信号驱动，我们要读取一个数据总是要发起两阶段的请求，第一次发送select请求，询问数据状态是否准备好，第二次发送recevform请求读取数据。</p><p><strong>思考一个问题：</strong></p><p>也许你一开始就有一个疑问，为什么我们明明是想读取数据，什么非得要先发起一个select询问数据状态的请求，然后再发起真正的读取数据请求,能不能有一种一劳永逸的方式，我只要发送一个请求我告诉内核我要读取数据，然后我就什么都不管了，然后内核去帮我去完成剩下的所有事情？</p><p>当然既然你想得出来，那么就会有人做得到，有人设计了一种方案，应用只需要向内核发送一个read 请求,告诉内核它要读取数据后即刻返回；内核收到请求后会建立一个信号联系，当数据准备就绪，内核会主动把数据从内核复制到用户空间，等所有操作都完成之后，内核会发起一个通知告诉应用，我们称这种一劳永逸的模式为异步IO模型。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-96009f54d89ade0d8c4001bc67395c57_720w.jpg" alt="img"></p><p><strong>术语描述：</strong> 应用告知内核启动某个操作，并让内核在整个操作完成之后，通知应用，这种模型与信号驱动模型的主要区别在于，信号驱动IO只是由内核通知我们合适可以开始下一个IO操作，而异步IO模型是由内核通知我们操作什么时候完成。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927161941186.png" alt="image-20210927161941186"></p><p><strong>总结：</strong>异步IO的优化思路是解决了应用程序需要先后发送询问请求、发送接收数据请求两个阶段的模式，在异步IO的模式下，只需要向内核发送一次请求就可以完成状态询问和数拷贝的所有操作。</p><h2 id="IO模型比较"><a href="#IO模型比较" class="headerlink" title="IO模型比较"></a><strong>IO模型比较</strong></h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210927164055422.png" alt="image-20210927164055422"></p><h3 id="阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型"><a href="#阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型" class="headerlink" title="阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型"></a><strong>阻塞IO调用和非阻塞IO调用、阻塞IO模型和非阻塞IO模型</strong></h3><p>注意这里的阻塞IO调用和非阻塞IO调用不是指阻塞IO模型和非阻塞IO模型：</p><ul><li>阻塞IO调用 ：在用户进程（线程）中调用执行的时候，进程会等待该IO操作，而使得其他操作无法执行。</li><li>非阻塞IO调用：在用户进程中调用执行的时候，无论成功与否，该IO操作会立即返回，之后进程可以进行其他操作（当然如果是读取到数据，一般就接着进行数据处理）。</li></ul><p>这个直接理解就好，进程（线程）IO调用会不会阻塞进程自己。所以这里两个概念是相对调用进程本身状态来讲的。</p><p>从上面对比图片来说，阻塞IO模型是一个阻塞IO调用，而非阻塞IO模型是多个非阻塞IO调用+一个阻塞IO调用，因为多个IO检查会立即返回错误，不会阻塞进程。</p><p>而上面也说过了，非阻塞IO模型对于阻塞IO模型来说区别就是，内核数据没准备好需要进程阻塞的时候，就返回一个错误，以使得进程不被阻塞。</p><h3 id="同步IO和异步IO"><a href="#同步IO和异步IO" class="headerlink" title="同步IO和异步IO"></a><strong>同步IO和异步IO</strong></h3><ul><li>同步IO：导致请求进程阻塞，直到I/O操作完成。</li><li>异步IO：不导致请求进程阻塞。</li></ul><p>上面两个定义是《UNIX网络编程 卷1：套接字联网API》给出的。这不是很好理解，我们来扩展一下，先说说同步和异步，同步和异步关注的是双方的消息通信机制：</p><ul><li>同步：双方的动作是经过双方协调的，步调一致的。</li><li>异步：双方并不需要协调，都可以随意进行各自的操作。</li></ul><p>这里我们的双方是指，用户进程和IO设备；明确同步和异步之后，我们在上面网络输入操作例子的基础上，进行扩展定义：</p><ul><li>同步IO：用户进程发出IO调用，去获取IO设备数据，双方的数据要经过内核缓冲区同步，完全准备好后，再复制返回到用户进程。而复制返回到用户进程会导致请求进程阻塞，直到I/O操作完成。</li><li>异步IO：用户进程发出IO调用，去获取IO设备数据，并不需要同步，内核直接复制到进程，整个过程不导致请求进程阻塞。</li></ul><p>所以， 阻塞IO模型、非阻塞IO模型、IO复用模型、信号驱动的IO模型者为同步IO模型，只有异步IO模型是异步IO。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;IO&quot;&gt;&lt;a href=&quot;#IO&quot; class=&quot;headerlink&quot; title=&quot;IO&quot;&gt;&lt;/a&gt;IO&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20</summary>
      
    
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="操作系统" scheme="https://leslieaibin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据结构</title>
    <link href="https://leslieaibin.github.io/2021/09/29/Redis/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://leslieaibin.github.io/2021/09/29/Redis/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2021-09-29T01:15:42.000Z</published>
    <updated>2021-09-30T08:44:00.941Z</updated>
    
    <content type="html"><![CDATA[<p>Redist有五种基本数据结构：<strong>string、hash、set、zset、list</strong>。这五种数据结构的底层数据结构有六种：<strong>动态字符串SDS、链表、哈希表、跳表、整数集合、压缩链表</strong></p><h1 id="底层结构"><a href="#底层结构" class="headerlink" title="底层结构"></a>底层结构</h1><p>Redis是用C语言写的，但是Redis并没有使用C的字符串表示（C是字符串是以<code>\0</code>空字符结尾的字符数组），而是自己构建了一种<strong>简单动态字符串</strong>（simple dynamic string，SDS）的抽象类型，并作为Redis的默认字符串表示</p><p>在Redis中，包含字符串值的键值对底层都是用SDS实现的</p><h2 id="动态字符串SDS"><a href="#动态字符串SDS" class="headerlink" title="动态字符串SDS"></a>动态字符串SDS</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3.0</span></span><br><span class="line">struct sdshdr &#123;</span><br><span class="line">    <span class="comment">// 记录buf数组中已使用字节的数量，即SDS所保存字符串的长度</span></span><br><span class="line">    unsigned <span class="keyword">int</span> len;</span><br><span class="line">    <span class="comment">// 记录buf数据中未使用的字节数量</span></span><br><span class="line">    unsigned <span class="keyword">int</span> free;</span><br><span class="line">    <span class="comment">// 字节数组，用于保存字符串</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.2</span></span><br><span class="line"><span class="comment">/* Note: sdshdr5 is never used, we just access the flags byte directly.</span></span><br><span class="line"><span class="comment"> * However is here to document the layout of type 5 SDS strings. */</span></span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr5 </span>&#123;</span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, and 5 msb of string length */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr8 </span>&#123;</span><br><span class="line">    uint8_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint8_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr16 </span>&#123;</span><br><span class="line">    uint16_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint16_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr32 </span>&#123;</span><br><span class="line">    uint32_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint32_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">struct <span class="title">__attribute__</span> <span class="params">((__packed__)</span>) sdshdr64 </span>&#123;</span><br><span class="line">    uint64_t len; <span class="comment">/* used */</span></span><br><span class="line">    uint64_t alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    unsigned <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>3.2版本之后，会根据字符串的长度来选择对应的数据结构</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">char</span> <span class="title">sdsReqType</span><span class="params">(<span class="keyword">size_t</span> string_size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1</span>&lt;&lt;<span class="number">5</span>)  <span class="comment">// 32</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_5;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1</span>&lt;&lt;<span class="number">8</span>)  <span class="comment">// 256</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_8;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1</span>&lt;&lt;<span class="number">16</span>)   <span class="comment">// 65536 64k</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_16;</span><br><span class="line">    <span class="keyword">if</span> (string_size &lt; <span class="number">1l</span>l&lt;&lt;<span class="number">32</span>)  <span class="comment">// 4294967296 4G</span></span><br><span class="line">        <span class="keyword">return</span> SDS_TYPE_32;</span><br><span class="line">    <span class="keyword">return</span> SDS_TYPE_64;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d245812d1e41c5~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p><code>len</code>：记录当前已使用的字节数（不包括<code>&#39;\0&#39;</code>），获取SDS长度的复杂度为O(1)</p><p><code>alloc</code>：记录当前字节数组总共分配的字节数量（不包括<code>&#39;\0&#39;</code>）</p><p><code>flags</code>：标记当前字节数组的属性，是<code>sdshdr8</code>还是<code>sdshdr16</code>等，flags值的定义可以看下面代码</p><p><code>buf</code>：字节数组，用于保存字符串，包括结尾空白字符`’\0’</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// flags值定义</span></span><br><span class="line">#define SDS_TYPE_5  0</span><br><span class="line">#define SDS_TYPE_8  1</span><br><span class="line">#define SDS_TYPE_16 2</span><br><span class="line">#define SDS_TYPE_32 3</span><br><span class="line">#define SDS_TYPE_64 4</span><br></pre></td></tr></table></figure><p>上面的字节数组的空白处表示未使用空间，是Redis优化的空间策略，给字符串的操作留有余地，保证安全提高效率</p><h2 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h2><p>链表上的节点定义如下，<code>adlist.h/listNode</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">typedef struct listNode &#123;</span><br><span class="line">    <span class="comment">// 前置节点</span></span><br><span class="line">    struct listNode *prev;</span><br><span class="line">    <span class="comment">// 后置节点</span></span><br><span class="line">    struct listNode *next;</span><br><span class="line">    <span class="comment">// 节点值</span></span><br><span class="line">    <span class="keyword">void</span> *value;</span><br><span class="line">&#125; listNode;</span><br></pre></td></tr></table></figure><p>链表的定义如下，<code>adlist.h/list</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">typedef struct list &#123;</span><br><span class="line">    <span class="comment">// 链表头节点</span></span><br><span class="line">    listNode *head;</span><br><span class="line">    <span class="comment">// 链表尾节点</span></span><br><span class="line">    listNode *tail;</span><br><span class="line">    <span class="comment">// 节点值复制函数</span></span><br><span class="line">    <span class="keyword">void</span> *(*dup)(<span class="keyword">void</span> *ptr);</span><br><span class="line">    <span class="comment">// 节点值释放函数</span></span><br><span class="line">    <span class="keyword">void</span> (*free)(<span class="keyword">void</span> *ptr);</span><br><span class="line">    <span class="comment">// 节点值对比函数</span></span><br><span class="line">    <span class="keyword">int</span> (*match)(<span class="keyword">void</span> *ptr, <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 链表所包含的节点数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> len;</span><br><span class="line">&#125; list;</span><br></pre></td></tr></table></figure><p>每个节点<code>listNode</code>可以通过<code>prev</code>和<code>next</code>指针分布指向前一个节点和后一个节点组成双端链表，同时每个链表还会有一个<code>list</code>结构为链表提供表头指针<code>head</code>、表尾指针<code>tail</code>、以及链表长度计数器<code>len</code>，还有三个用于实现多态链表的类型特定函数</p><ul><li><code>dup</code>：用于复制链表节点所保存的值</li><li><code>free</code>：用于释放链表节点所保存的值</li><li><code>match</code>：用于对比链表节点所保存的值和另一个输入值是否相等</li></ul><p> <strong>链表结构图</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318c8442f7~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p> <strong>链表特性</strong></p><ul><li>双端链表：带有指向前置节点和后置节点的指针，获取这两个节点的复杂度为O(1)</li><li>无环：表头节点的<code>prev</code>和表尾节点的<code>next</code>都指向NULL，对链表的访问以NULL结束</li><li>链表长度计数器：带有<code>len</code>属性，获取链表长度的复杂度为O(1)</li><li>多态：链表节点使用 <code>void*</code>指针保存节点值，可以保存不同类型的值</li></ul><h3 id="3-2版本后更改"><a href="#3-2版本后更改" class="headerlink" title="3.2版本后更改"></a>3.2版本后更改</h3><p>quicklist：</p><p>（1）什么是quicklist：</p><p>quicklist是一个双向链表，而且是一个基于ziplist的双向链表，quicklist的每个节点都是一个ziplist，比如，一个包含3个节点的quicklist，如果每个节点的ziplist又包含4个数据项，那么对外表现上，这个list就总共包含12个数据项。</p><p>quicklist的结构为什么这样设计呢？总结起来，大概又是一个空间和时间的折中：</p><p>双向链表便于在表的两端进行push和pop操作，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。<br>ziplist由于是一整块连续内存，所以存储效率很高。但是，它不利于修改操作，每次数据变动都会引发一次内存的realloc。特别是当ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝，进一步降低性能。<br>于是，结合了双向链表和ziplist的优点，quicklist就应运而生了。</p><p>（2）quicklist中每个ziplist长度的配置：</p><p>不过，这也带来了一个新问题：到底一个quicklist节点包含多长的ziplist合适呢？比如，同样是存储12个数据项，既可以是一个quicklist包含3个节点，而每个节点的ziplist又包含4个数据项，也可以是一个quicklist包含6个节点，而每个节点的ziplist又包含2个数据项。</p><p>这又是一个需要找平衡点的难题。我们只从存储效率上分析一下：</p><p>每个quicklist节点上的ziplist越短，则内存碎片越多。内存碎片多了，有可能在内存中产生很多无法被利用的小碎片，从而降低存储效率。这种情况的极端是每个quicklist节点上的ziplist只包含一个数据项，这就蜕化成一个普通的双向链表了。<br>每个quicklist节点上的ziplist越长，则为ziplist分配大块连续内存空间的难度就越大。有可能出现内存里有很多小块的空闲空间（它们加起来很多），但却找不到一块足够大的空闲空间分配给ziplist的情况。这同样会降低存储效率。这种情况的极端是整个quicklist只有一个节点，所有的数据项都分配在这仅有的一个节点的ziplist里面。这其实蜕化成一个ziplist了<br>可见，一个quicklist节点上的ziplist要保持一个合理的长度。那到底多长合理呢？这可能取决于具体应用场景。实际上，Redis提供了一个配置参数list-max-ziplist-size，就是为了让使用者可以来根据自己的情况进行调整。</p><p>list-max-ziplist-size -2</p><p>这个参数可以取正值，也可以取负值。</p><p>当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。</p><p>当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值，每个值含义如下：</p><p>-5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =&gt; 1024 bytes）</p><p>-4: 每个quicklist节点上的ziplist大小不能超过32 Kb。</p><p>-3: 每个quicklist节点上的ziplist大小不能超过16 Kb。</p><p>-2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值）</p><p>-1: 每个quicklist节点上的ziplist大小不能超过4 Kb。</p><h2 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h2><p>哈希表又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。字典中的每一个键都是唯一的，可以通过键查找与之关联的值，并对其修改或删除</p><p>Redis的键值对存储就是用哈希表实现的，散列（Hash）的底层实现之一也是哈希表</p><p>哈希表结构定义，<code>dict.h/dictht</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictht &#123;</span><br><span class="line">    <span class="comment">// 哈希表数组</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="comment">// 哈希表大小</span></span><br><span class="line">    unsigned <span class="keyword">long</span> size;</span><br><span class="line">    <span class="comment">// 哈希表大小掩码，用于计算索引值，等于size-1</span></span><br><span class="line">    unsigned <span class="keyword">long</span> sizemask;</span><br><span class="line">    <span class="comment">// 哈希表已有节点的数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure><p>哈希表是由数组<code>table</code>组成，<code>table</code>中每个元素都是指向<code>dict.h/dictEntry</code>结构的指针，哈希表节点的定义如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictEntry &#123;</span><br><span class="line">    <span class="comment">// 键</span></span><br><span class="line">    <span class="keyword">void</span> *key;</span><br><span class="line">    <span class="comment">// 值</span></span><br><span class="line">    union &#123;</span><br><span class="line">        <span class="keyword">void</span> *val;</span><br><span class="line">        uint64_t u64;</span><br><span class="line">        int64_t s64;</span><br><span class="line">        <span class="keyword">double</span> d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="comment">// 指向下一个哈希表节点，形成链表</span></span><br><span class="line">    struct dictEntry *next;</span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure><p>其中<code>key</code>是我们的键；<code>v</code>是键值，可以是一个指针，也可以是整数或浮点数；<code>next</code>属性是指向下一个哈希表节点的指针，可以让多个哈希值相同的键值对形成链表，解决键冲突问题</p><p>最后就是我们的字典结构，<code>dict.h/dict</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dict &#123;</span><br><span class="line">    <span class="comment">// 和类型相关的处理函数</span></span><br><span class="line">    dictType *type;</span><br><span class="line">    <span class="comment">// 私有数据</span></span><br><span class="line">    <span class="keyword">void</span> *privdata;</span><br><span class="line">    <span class="comment">// 哈希表</span></span><br><span class="line">    dictht ht[<span class="number">2</span>];</span><br><span class="line">    <span class="comment">// rehash 索引，当rehash不再进行时，值为-1</span></span><br><span class="line">    <span class="keyword">long</span> rehashidx; <span class="comment">/* rehashing not in progress if rehashidx == -1 */</span></span><br><span class="line">    <span class="comment">// 迭代器数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> iterators; <span class="comment">/* number of iterators currently running */</span></span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure><p><code>type</code>属性和<code>privdata</code>属性是针对不同类型的键值对，用于创建多类型的字典，<code>type</code>是指向<code>dictType</code>结构的指针，<code>privdata</code>则保存需要传给类型特定函数的可选参数，关于<code>dictType</code>结构和类型特定函数可以看下面代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">typedef struct dictType &#123;</span><br><span class="line">    <span class="comment">// 计算哈希值的行数</span></span><br><span class="line">    uint64_t (*hashFunction)(<span class="keyword">const</span> <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 复制键的函数</span></span><br><span class="line">    <span class="keyword">void</span> *(*keyDup)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 复制值的函数</span></span><br><span class="line">    <span class="keyword">void</span> *(*valDup)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *obj);</span><br><span class="line">    <span class="comment">// 对比键的函数</span></span><br><span class="line">    <span class="keyword">int</span> (*keyCompare)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *key1, <span class="keyword">const</span> <span class="keyword">void</span> *key2);</span><br><span class="line">    <span class="comment">// 销毁键的函数</span></span><br><span class="line">    <span class="keyword">void</span> (*keyDestructor)(<span class="keyword">void</span> *privdata, <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="comment">// 销毁值的函数</span></span><br><span class="line">    <span class="keyword">void</span> (*valDestructor)(<span class="keyword">void</span> *privdata, <span class="keyword">void</span> *obj);</span><br><span class="line">&#125; dictType;</span><br></pre></td></tr></table></figure><p><code>dict</code>的<code>ht</code>属性是两个元素的数组，包含两个<code>dictht</code>哈希表，一般字典只使用<code>ht[0]</code>哈希表，<code>ht[1]</code>哈希表会在对<code>ht[0]</code>哈希表进行<code>rehash</code>（重哈希）的时候使用，即当哈希表的键值对数量超过负载数量过多的时候，会将键值对迁移到<code>ht[1]</code>上</p><p><code>rehashidx</code>也是跟rehash相关的，rehash的操作不是瞬间完成的，<code>rehashidx</code>记录着rehash的进度，如果目前没有在进行rehash，它的值为-1</p><p>结合上面的几个结构，我们来看一下<strong>字典的结构图</strong>（没有在进行rehash）</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318d3796f5~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><p>一个普通的单链表查询一个元素的时间复杂度为O(N)，即便该单链表是有序的。使用跳跃表（SkipList）是来解决查找问题的，它是一种有序的数据结构，不属于平衡树结构，也不属于Hash结构，它通过在每个节点维持多个指向其他节点的指针，而达到快速访问节点的目的</p><p>跳跃表是有序集合（Sorted Set）的底层实现之一，如果有序集合包含的元素比较多，或者元素的成员是比较长的字符串时，Redis会使用跳跃表做有序集合的底层实现</p><p> <strong>跳跃表的定义</strong></p><p>跳跃表其实可以把它理解为<strong>多层的链表</strong>，它有如下的性质</p><ul><li><strong>多层</strong>的结构组成，每层是一个<strong>有序的链表</strong></li><li>最底层（level 1）的链表包含所有的元素</li><li>跳跃表的查找次数近似于层数，时间复杂度为O(logn)，插入、删除也为 O(logn)</li><li>跳跃表是一种随机化的数据结构(通过抛硬币来决定层数)</li></ul><p>那么如何来理解跳跃表呢，我们从最底层的包含所有元素的链表开始，给定如下的链表</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318d89eb55~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>然后我们每隔一个元素，把它放到上一层的链表当中，这里我把它叫做<strong>上浮</strong>（注意，科学的办法是<strong>抛硬币</strong>的方式，来决定元素是否上浮到上一层链表，我这里先简单每隔一个元素上浮到上一层链表，便于理解），操作完成之后的结构如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318d9e2558~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>查找元素的方法是这样，从上层开始查找，大数向右找到头，小数向左找到头，例如我要查找<code>17</code>，查询的顺序是：13 -&gt; 46  -&gt; 22 -&gt; 17；如果是查找<code>35</code>，则是 13 -&gt; 46 -&gt; 22 -&gt; 46 -&gt; 35；如果是<code>54</code>，则是 13 -&gt; 46 -&gt; 54</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a318db56821~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>上面是查找元素，如果是添加元素，是通过抛硬币的方式来决定该元素会出现到多少层，也就是说它会有 1/2的概率出现第二层、1/4 的概率出现在第三层……</p><p>跳跃表节点的删除和添加都是不可预测的，很难保证跳表的索引是始终均匀的，抛硬币的方式可以让大体上是趋于均匀的</p><p>假设我们已经有了上述例子的一个跳跃表了，现在往里面添加一个元素<code>18</code>，通过抛硬币的方式来决定它会出现的层数，是正面就继续，反面就停止，假如我抛了2次硬币，第一次为正面，第二次为反面</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31ad5ebfc9~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>跳跃表的删除很简单，只要先找到要删除的节点，然后顺藤摸瓜删除每一层相同的节点就好了</p><p>跳跃表维持结构平衡的成本是比较低的，完全是依靠随机，相比二叉查找树，在多次插入删除后，需要Rebalance来重新调整结构平衡</p><p><strong>跳跃表的实现</strong></p><p>Redis的跳跃表实现是由<code>redis.h/zskiplistNode</code>和<code>redis.h/zskiplist</code>（3.2版本之后redis.h改为了server.h）两个结构定义，<code>zskiplistNode</code>定义跳跃表的节点，<code>zskiplist</code>保存跳跃表节点的相关信息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ZSETs use a specialized version of Skiplists */</span></span><br><span class="line">typedef struct zskiplistNode &#123;</span><br><span class="line">    <span class="comment">// 成员对象 （robj *obj;）</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">// 分值</span></span><br><span class="line">    <span class="keyword">double</span> score;</span><br><span class="line">    <span class="comment">// 后退指针</span></span><br><span class="line">    struct zskiplistNode *backward;</span><br><span class="line">    <span class="comment">// 层</span></span><br><span class="line">    struct zskiplistLevel &#123;</span><br><span class="line">        <span class="comment">// 前进指针</span></span><br><span class="line">        struct zskiplistNode *forward;</span><br><span class="line">        <span class="comment">// 跨度</span></span><br><span class="line">        <span class="comment">// 跨度实际上是用来计算元素排名(rank)的，在查找某个节点的过程中，将沿途访过的所有层的跨度累积起来，得到的结果就是目标节点在跳跃表中的排位</span></span><br><span class="line">        unsigned <span class="keyword">long</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br><span class="line"></span><br><span class="line">typedef struct zskiplist &#123;</span><br><span class="line">    <span class="comment">// 表头节点和表尾节点</span></span><br><span class="line">    struct zskiplistNode *header, *tail;</span><br><span class="line">    <span class="comment">// 表中节点的数量</span></span><br><span class="line">    unsigned <span class="keyword">long</span> length;</span><br><span class="line">    <span class="comment">// 表中层数最大的节点的层数</span></span><br><span class="line">    <span class="keyword">int</span> level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure><p><code>zskiplistNode</code>结构</p><ul><li><code>level</code>数组（层）：每次创建一个新的跳表节点都会根据幂次定律计算出level数组的大小，也就是次层的高度，每一层带有两个属性-<strong>前进指针</strong>和<strong>跨度</strong>，前进指针用于访问表尾方向的其他指针；跨度用于记录当前节点与前进指针所指节点的距离（指向的为NULL，阔度为0）</li><li><code>backward</code>（后退指针）：指向当前节点的前一个节点</li><li><code>score</code>（分值）：用来排序，如果分值相同看成员变量在字典序大小排序</li><li><code>obj</code>或<code>ele</code>：成员对象是一个指针，指向一个字符串对象，里面保存着一个sds；在跳表中各个节点的成员对象必须唯一，分值可以相同</li></ul><p><code>zskiplist</code>结构</p><ul><li><code>header</code>、<code>tail</code>表头节点和表尾节点</li><li><code>length</code>表中节点的数量</li><li><code>level</code>表中层数最大的节点的层数</li></ul><p>假设我们现在展示一个跳跃表，有四个节点，节点的高度分别是2、1、4、</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b0f3da89~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p><code>zskiplist</code>的头结点不是一个有效的节点，它有<strong>ZSKIPLIST_MAXLEVEL</strong>层(32层)，每层的<code>forward</code>指向该层跳跃表的第一个节点，若没有则为NULL，在Redis中，上面的跳跃表结构如下</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b46f4b67~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><ul><li>每个跳跃表节点的层数在1-32之间</li><li>一个跳跃表中，节点按照分值大小排序，多个节点的分值是可以相同的，相同时，节点按成员对象大小排序</li><li>每个节点的成员变量必须是唯一的</li></ul><h2 id="整数集合"><a href="#整数集合" class="headerlink" title="整数集合"></a>整数集合</h2><p>整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，可以保存类型为int16_t、int32_t、int64_t的整数值，并且保证集合中不会出现重复元素</p><p>整数集合是集合（Set）的底层实现之一，如果一个集合只包含整数值元素，且元素数量不多时，会使用整数集合作为底层实现</p><p><strong>整数集合的定义实现</strong></p><p>整数集合的定义为<code>inset.h/inset</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">typedef struct intset &#123;</span><br><span class="line">    <span class="comment">// 编码方式</span></span><br><span class="line">    uint32_t encoding;</span><br><span class="line">    <span class="comment">// 集合包含的元素数量</span></span><br><span class="line">    uint32_t length;</span><br><span class="line">    <span class="comment">// 保存元素的数组</span></span><br><span class="line">    int8_t contents[];</span><br><span class="line">&#125; intset;</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><ul><li><code>contents</code>数组：整数集合的每个元素在数组中按值的大小从小到大排序，且不包含重复项</li><li><code>length</code>记录整数集合的元素数量，即contents数组长度</li><li><code>encoding</code>决定contents数组的真正类型，如INTSET_ENC_INT16、INTSET_ENC_INT32、INTSET_ENC_INT64</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b471202a~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p> <strong>整数集合的升级</strong></p><p>当想要添加一个新元素到整数集合中时，并且新元素的类型比整数集合现有的所有元素的类型都要长，整数集合需要先进行升级（upgrade），才能将新元素添加到整数集合里面。每次想整数集合中添加新元素都有可能会引起升级，每次升级都需要对底层数组已有的所有元素进行类型转换</p><p>升级添加新元素：</p><ul><li>根据新元素类型，扩展整数集合底层数组的空间大小，并为新元素分配空间</li><li>把数组现有的元素都转换成新元素的类型，并将转换后的元素放到正确的位置，且要保持数组的有序性</li><li>添加新元素到底层数组</li></ul><p>整数集合的升级策略可以提升整数集合的灵活性，并尽可能的节约内存</p><p>另外，整数集合不支持降级，一旦升级，编码就会一直保持升级后的状态</p><h2 id="压缩链表"><a href="#压缩链表" class="headerlink" title="压缩链表"></a>压缩链表</h2><p>压缩列表（ziplist）是为了节约内存而设计的，是由一系列特殊编码的连续内存块组成的顺序性（sequential）数据结构，一个压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者一个整数值</p><p>压缩列表是列表（List）和散列（Hash）的底层实现之一，一个列表只包含少量列表项，并且每个列表项是小整数值或比较短的字符串，会使用压缩列表作为底层实现（在3.2版本之后是使用<code>quicklist</code>实现）</p><p><strong>压缩列表的构成</strong></p><p>一个压缩列表可以包含多个节点（entry），每个节点可以保存一个字节数组或者一个整数值</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b5614230~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><p>各部分组成说明如下</p><ul><li><code>zlbytes</code>：记录整个压缩列表占用的内存字节数，在压缩列表内存重分配，或者计算<code>zlend</code>的位置时使用</li><li><code>zltail</code>：记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过该偏移量，可以不用遍历整个压缩列表就可以确定表尾节点的地址</li><li><code>zllen</code>：记录压缩列表包含的节点数量，但该属性值小于UINT16_MAX（65535）时，该值就是压缩列表的节点数量，否则需要遍历整个压缩列表才能计算出真实的节点数量</li><li><code>entryX</code>：压缩列表的节点</li><li><code>zlend</code>：特殊值0xFF（十进制255），用于标记压缩列表的末端</li></ul><p><strong>压缩列表节点的构成</strong></p><p>每个压缩列表节点可以保存一个字节数字或者一个整数值，结构如下</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16d04a31b502238d~tplv-t2oaga2asx-watermark.awebp" alt="img"></p><ul><li><code>previous_entry_ength</code>：记录压缩列表前一个字节的长度</li><li><code>encoding</code>：节点的encoding保存的是节点的content的内容类型</li><li><code>content</code>：content区域用于保存节点的内容，节点内容类型和长度由encoding决定</li></ul><h2 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h2><p>上面介绍了Redis的主要底层数据结构，包括简单动态字符串（SDS）、链表、字典、跳跃表、整数集合、压缩列表。但是Redis并没有直接使用这些数据结构来构建键值对数据库，而是基于这些数据结构创建了一个对象系统，也就是我们所熟知的可API操作的Redis那些数据类型，如字符串(String)、列表(List)、散列(Hash)、集合(Set)、有序集合(Sorted Set)</p><p>根据对象的类型可以判断一个对象是否可以执行给定的命令，也可针对不同的使用场景，对象设置有多种不同的数据结构实现，从而优化对象在不同场景下的使用效率</p><table><thead><tr><th>类型</th><th>编码</th><th>BOJECT ENCODING 命令输出</th><th>对象</th></tr></thead><tbody><tr><td>REDIS_STRING</td><td>REDIS_ENCODING_INT</td><td>“int”</td><td>使用整数值实现的字符串对象</td></tr><tr><td>REDIS_STRING</td><td>REDIS_ENCODING_EMBSTR</td><td>“embstr”</td><td>使用embstr编码的简单动态字符串实现的字符串对象</td></tr><tr><td>REDIS_STRING</td><td>REDIS_ENCODING_RAW</td><td>“raw”</td><td>使用简单动态字符串实现的字符串对象</td></tr><tr><td>REDIS_LIST</td><td>REDIS_ENCODING_ZIPLIST</td><td>“ziplist”</td><td>使用压缩列表实现的列表对象</td></tr><tr><td>REDIS_LIST</td><td>REDIS_ENCODING_LINKEDLIST</td><td>‘“linkedlist’</td><td>使用双端链表实现的列表对象</td></tr><tr><td>REDIS_HASH</td><td>REDIS_ENCODING_ZIPLIST</td><td>“ziplist”</td><td>使用压缩列表实现的哈希对象</td></tr><tr><td>REDIS_HASH</td><td>REDIS_ENCODING_HT</td><td>“hashtable”</td><td>使用字典实现的哈希对象</td></tr><tr><td>REDIS_SET</td><td>REDIS_ENCODING_INTSET</td><td>“intset”</td><td>使用整数集合实现的集合对象</td></tr><tr><td>REDIS_SET</td><td>REDIS_ENCODING_HT</td><td>“hashtable”</td><td>使用字典实现的集合对象</td></tr><tr><td>REDIS_ZSET</td><td>REDIS_ENCODING_ZIPLIST</td><td>“ziplist”</td><td>使用压缩列表实现的有序集合对象</td></tr><tr><td>REDIS_ZSET</td><td>REDIS_ENCODING_SKIPLIST</td><td>“skiplist”</td><td>使用跳跃表表实现的有序集合对象</td></tr></tbody></table><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>String数据结构是最简单的数据类型。一般用于复杂的计数功能的缓存：微博数，粉丝数等。</p><p><strong>底层实现方式：动态字符串sds 或者 long</strong></p><p>String的内部存储结构一般是sds（Simple Dynamic String，可以动态扩展内存），但是如果一个String类型的value的值是数字，那么Redis内部会把它转成long类型来存储，从而减少内存的使用。</p><ul><li>确切地说，String在Redis中是用一个robj来表示的。</li><li>用来表示String的robj可能编码成3种内部表示：OBJ_ENCODING_RAW，OBJ_ENCODING_EMBSTR，OBJ_ENCODING_INT。其中前两种编码使用的是sds来存储，最后一种OBJ_ENCODING_INT编码直接把string存成了long型。</li><li>在对string进行incr, decr等操作的时候，如果它内部是OBJ_ENCODING_INT编码，那么可以直接进行加减操作；如果它内部是OBJ_ENCODING_RAW或OBJ_ENCODING_EMBSTR编码，那么Redis会先试图把sds存储的字符串转成long型，如果能转成功，再进行加减操作。</li><li>对一个内部表示成long型的string执行append, setbit, getrange这些命令，针对的仍然是string的值（即十进制表示的字符串），而不是针对内部表示的long型进行操作。比如字符串”32”，如果按照字符数组来解释，它包含两个字符，它们的ASCII码分别是0x33和0x32。当我们执行命令setbit key 7 0的时候，相当于把字符0x33变成了0x32，这样字符串的值就变成了”22”。而如果将字符串”32”按照内部的64位long型来解释，那么它是0x0000000000000020，在这个基础上执行setbit位操作，结果就完全不对了。因此，在这些命令的实现中，会把long型先转成字符串再进行相应的操作。</li></ul><h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><p>Hash特别适合用于存储对象，因为一个对象的各个属性，正好对应一个hash结构的各个field，可以方便地操作对象中的某个字段。</p><p><strong>底层实现方式：压缩列表ziplist 或者 字典dict</strong></p><p>当Hash中数据项比较少的情况下，Hash底层才用压缩列表ziplist进行存储数据，随着数据的增加，底层的ziplist就可能会转成dict，具体配置如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hash-max-ziplist-entries <span class="number">512</span></span><br><span class="line">hash-max-ziplist-value <span class="number">64</span></span><br></pre></td></tr></table></figure><p>当hash中的数据项（即filed-value对）的数目超过512时，也就是ziplist数据项超过1024的时候<br>当hash中插入的任意一个value的长度超过了64字节的时候</p><p>当满足上面两个条件其中之一的时候，Redis就使用dict字典来实现hash。</p><p>Redis的hash之所以这样设计，是因为当ziplist变得很大的时候，它有如下几个缺点：</p><ul><li><p>每次插入或修改引发的realloc操作会有更大的概率造成内存拷贝，从而降低性能。</p></li><li><p>一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。</p></li><li><p>当ziplist数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。</p></li></ul><p>总之，ziplist本来就设计为各个数据项挨在一起组成连续的内存空间，这种结构并不擅长做修改操作。一旦数据发生改动，就会引发内存realloc，可能导致内存拷贝。</p><h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>list 的实现为一个双向链表，经常被用作队列使用，支持在链表两端进行push和pop操作，时间复杂度为O(1)；同时也支持在链表中的任意位置的存取操作，但是都需要对list进行遍历，支持反向查找和遍历，时间复杂度为O(n)。</p><p>list是一个能维持数据项先后顺序的列表（各个数据项的先后顺序由插入位置决定），便于在表的两端追加和删除数据，而对于中间位置的存取具有O(N)的时间复杂度。</p><p>list 的应用场景非常多，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。可以利用lrange命令，做基于redis的分页功能。</p><ul><li><strong>Redis3.2之前的底层实现方式：压缩列表ziplist 或者 双向循环链表linkedlist</strong></li></ul><p>当list存储的数据量比较少且同时满足下面两个条件时，list就使用ziplist存储数据：</p><p>list中保存的每个元素的长度小于 64 字节；</p><p>列表中数据个数少于512个。</p><p>当不能同时满足上面两个条件的时候，list就通过双向循环链表linkedlist来实现了</p><ul><li><strong>Redis3.2及之后的底层实现方式：quicklist</strong></li></ul><p>quicklist是一个双向链表，而且是一个基于ziplist的双向链表，quicklist的每个节点都是一个ziplist，结合了双向链表和ziplist的优点</p><h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>set是一个存放不重复值的无序集合，可以做全局去重的功能，提供了判断某个元素是否在set集合内的功能，这个也是list所不能提供的。基于set可以实现交集、并集、差集的操作，计算共同喜好，全部的喜好，自己独有的喜好等功能。</p><p><strong>底层实现方式：有序整数集合intset 或者 字典dict</strong></p><p>当存储的数据同时满足下面这样两个条件的时候，Redis 就采用整数集合intset来实现set这种数据类型：</p><ul><li>存储的数据都是整数</li><li>存储的数据元素个数小于512个</li></ul><p>当不能同时满足这两个条件的时候，Redis 就使用dict来存储集合中的数据</p><h2 id="Sorted-Set"><a href="#Sorted-Set" class="headerlink" title="Sorted Set"></a>Sorted Set</h2><p>Sorted set多了一个权重参数score，集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。另外，sorted set可以用来做延时任务。最后一个应用就是可以做范围查找。</p><p><strong>底层实现方式：压缩列表ziplist 或者 zskiplistNode</strong></p><p>当存储的数据同时满足下面这两个条件的时候，Redis就使用压缩列表ziplist实现sorted set</p><ul><li>集合中每个数据的大小都要小于 64 字节</li><li>元素个数要小于 128 个，也就是ziplist数据项小于256个</li></ul><p>当不能同时满足这两个条件的时候，Redis 就使用zskiplistNode来实现sorted set。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Redist有五种基本数据结构：&lt;strong&gt;string、hash、set、zset、list&lt;/strong&gt;。这五种数据结构的底层数据结构有六种：&lt;strong&gt;动态字符串SDS、链表、哈希表、跳表、整数集合、压缩链表&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;底层</summary>
      
    
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/categories/Redis/"/>
    
    
    <category term="Redis" scheme="https://leslieaibin.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>MQ的作用</title>
    <link href="https://leslieaibin.github.io/2021/09/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/MQ%E7%9A%84%E4%BD%9C%E7%94%A8%E6%80%BB%E7%BB%93/"/>
    <id>https://leslieaibin.github.io/2021/09/26/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/MQ%E7%9A%84%E4%BD%9C%E7%94%A8%E6%80%BB%E7%BB%93/</id>
    <published>2021-09-26T01:15:42.000Z</published>
    <updated>2021-10-06T10:27:41.847Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MQ的作用"><a href="#MQ的作用" class="headerlink" title="MQ的作用"></a>MQ的作用</h1><p>消息队列在大型电子商务类网站，如京东、淘宝、去哪儿等网站有着深入的应用，</p><p>队列的主要作用是消除高并发访问高峰，加快网站的响应速度。</p><p>在不使用消息队列的情况下，用户的请求数据直接写入数据库，在高并发的情况下，会对数据库造成巨大的压力，同时也使得系统响应延迟加剧。</p><p>在使用队列后，用户的请求发给队列后立即返回,</p><p>（例如: 当然不能直接给用户提示订单提交成功，京东上提示：您“您提交了订单，请等待系统确认”），</p><p>再由消息队列的消费者进程从消息队列中获取数据，异步写入数据库。</p><p>由于消息队列的服务处理速度远快于数据库，因此用户的响应延迟可得到有效改善。</p><p>图解说明:</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110300965" alt="img"></p><h2 id="消息队列说明"><a href="#消息队列说明" class="headerlink" title="消息队列说明"></a>消息队列说明</h2><p>消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题。</p><p>实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。</p><p>目前在生产环境，使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等。</p><h2 id="消息队列应用场景"><a href="#消息队列应用场景" class="headerlink" title="消息队列应用场景"></a>消息队列应用场景</h2><p>消息队列在实际应用中常用的使用场景。异步处理，应用解耦，流量削峰和消息通讯四个场景。</p><h2 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h2><p>场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种1.串行的方式；2.并行方式。</p><ul><li>串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110336376" alt="img"></p><ul><li>并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110405511" alt="img"></p><p>假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。</p><p>因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。</p><p>则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）。</p><p>小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？</p><p>引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/2018060811044171" alt="img"></p><p>按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。</p><p>注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，</p><p>因此用户的响应时间可能是50毫秒。所以基于此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。</p><h2 id="应用解耦"><a href="#应用解耦" class="headerlink" title="应用解耦"></a>应用解耦</h2><p>场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。如下图：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/2018060811050932" alt="img"></p><p>传统模式的缺点：</p><p>1） 假如库存系统无法访问，则订单减库存将失败，从而导致订单失败；</p><p>2） 订单系统与库存系统耦合；</p><p>如何解决以上问题呢？引入应用消息队列后的方案，如下图：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110546334" alt="img"></p><ul><li>订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功,请等待物流配送。</li><li>库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。</li><li>假如：在下单时库存系统不能正常使用。也不影响正常下单，</li><li>因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。</li></ul><h2 id="流量削锋"><a href="#流量削锋" class="headerlink" title="流量削锋"></a>流量削锋</h2><p>流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。</p><p>应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用容易挂掉。为解决这个问题，一般需要在应用前端加入消息队列。</p><ol><li><p>可以控制活动的人数.</p></li><li><p>可以缓解短时间内高流量压垮应用；</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608110744677" alt="img"></p></li><li><p>用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面；</p></li><li><p>秒杀业务根据消息队列中的请求信息，再做后续处理。</p></li></ol><h2 id="消息通讯"><a href="#消息通讯" class="headerlink" title="消息通讯"></a>消息通讯</h2><p>消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。</p><p>点对点通讯：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608111245390" alt="img"></p><p>客户端A和客户端B使用同一队列，进行消息通讯。</p><p>聊天室通讯：</p><p> <img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20180608111307382" alt="img"></p><p>客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。</p><p>以上实际是消息队列的两种消息模式，点对点或发布订阅模式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MQ的作用&quot;&gt;&lt;a href=&quot;#MQ的作用&quot; class=&quot;headerlink&quot; title=&quot;MQ的作用&quot;&gt;&lt;/a&gt;MQ的作用&lt;/h1&gt;&lt;p&gt;消息队列在大型电子商务类网站，如京东、淘宝、去哪儿等网站有着深入的应用，&lt;/p&gt;
&lt;p&gt;队列的主要作用是消除高并发访</summary>
      
    
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://leslieaibin.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>07.Innodb引擎特性和日志</title>
    <link href="https://leslieaibin.github.io/2021/09/25/MySQL/07.Innodb%E5%BC%95%E6%93%8E%E7%9A%844%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%97%A5%E5%BF%97/"/>
    <id>https://leslieaibin.github.io/2021/09/25/MySQL/07.Innodb%E5%BC%95%E6%93%8E%E7%9A%844%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%97%A5%E5%BF%97/</id>
    <published>2021-09-25T12:17:42.000Z</published>
    <updated>2021-09-25T13:41:21.239Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Innodb引擎的4大特性"><a href="#Innodb引擎的4大特性" class="headerlink" title="Innodb引擎的4大特性"></a>Innodb引擎的4大特性</h1><h2 id="插入缓存（Insert-Buffer-Change-Buffer"><a href="#插入缓存（Insert-Buffer-Change-Buffer" class="headerlink" title="插入缓存（Insert Buffer/Change Buffer)"></a>插入缓存（Insert Buffer/Change Buffer)</h2><p>插入缓存之前版本叫insert buffer，现版本Change Buffer，主要提升插入性能，change buffer 是insert buffer的加强，insert buffer 只针对insert有效，change buffering 对insert、delete、update（delete + insert）、purge都有效</p><p>对于非聚聚索引来说，比如存在用户购买金额这样一个字段，索引是普通索引，每个用户的购买的金额不相同的概率比较大，这样导致可能出现购买记录的数据在数据里的排序可能是1000，3，499，35…，这种不连续的数据，一会插入这个数据页，一会插入那个数据页，这样造成的IO是很耗时的，所以出现了Insert Buffer。</p><p>Insert Buffer是怎么做的呢？mysql对于非聚集索引的插入，先去判断要插入的索引页是否已经在内存中了，如果不在，暂时不着急先把索引页加载到内存中，而是把它放到了一个Insert Buffer对象中，临时先放在这，然后等待情况，等待很多和现在情况一样的非聚集索引，再和要插入的非聚集索引页合并，比如说现在Insert Buffer中有1，99，2，100，合并之前可能要4次插入，合并之后1，2可能是一个页的，99，100可能是一个页的，这样就减少到了2次插入。这样就提升了效率和插入性能，减少了随机IO带来性能损耗。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210330151746375.png" alt="在这里插入图片描述"></p><p>综合上述，Insert Buffer 只对于非聚集索引（非唯一）的插入和更新有效，对于每一次的插入不是写到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，如果在则直接插入；若不在，则先放到Insert Buffer 中，再按照一定的频率进行合并操作，再写回disk。这样通常能将多个插入合并到一个操作中，目的还是减少了随机IO带来性能损耗。</p><p>使用插入缓冲的条件：</p><ul><li>非聚集索引</li><li>非唯一索引</li></ul><p>innodb_change_buffer设置的值有：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">all: 默认值，缓存insert, delete, purges操作</span><br><span class="line">none: 不缓存</span><br><span class="line">inserts: 缓存insert操作</span><br><span class="line">deletes: 缓存delete操作</span><br><span class="line">changes: 缓存insert和delete操作</span><br><span class="line">purges: 缓存后台执行的物理删除操作</span><br></pre></td></tr></table></figure><p>可以通过参数控制其使用的大小：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like <span class="string">&#x27;innodb_change_buffer_max_size&#x27;</span>;</span><br><span class="line">+-------------------------------+-------+</span><br><span class="line">| Variable_name                 | Value |</span><br><span class="line">+-------------------------------+-------+</span><br><span class="line">| innodb_change_buffer_max_size | <span class="number">25</span>    |</span><br><span class="line">+-------------------------------+-------+</span><br><span class="line"><span class="number">1</span> <span class="function">row in <span class="title">set</span> <span class="params">(<span class="number">0.05</span> sec)</span></span></span><br></pre></td></tr></table></figure><p>innodb_change_buffer_max_size，默认是25%，即缓冲池的1/4。最大可设置为50%。当MySQL实例中有大量的修改操作时，要考虑增大innodb_change_buffer_max_size</p><p>上面提过在一定频率下进行合并，那所谓的频率是什么条件？</p><ul><li><p>辅助索引页被读取到缓冲池中。正常的select先检查Insert Buffer是否有该非聚集索引页存在，若有则合并插入。</p></li><li><p>辅助索引页没有可用空间。空间小于1/32页的大小，则会强制合并操作。</p></li><li><p>Master Thread 每秒和每10秒的合并操作。</p></li></ul><h2 id="双写机制（Double-Write）"><a href="#双写机制（Double-Write）" class="headerlink" title="双写机制（Double Write）"></a><strong>双写机制（Double Write）</strong></h2><ol><li>doublewrite缓存位于系统表空间的存储区域，用来缓存innodb的数据页从innodb buffer pool中flush之后并写入到数据文件之前；</li><li>当操作系统或数据库进程在数据页写入磁盘的过程中崩溃，可以在doublewrite缓存中找到数据页的备份，用来执行crash恢复；</li><li>数据页写入到doublewrite缓存的动作所需要的io消耗要小于写入到数据文件的消耗，因为此写入操作会以一次大的连续块的方式写入<img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20210330151850245.png" alt="在这里插入图片描述"></li></ol><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-8dc0d0503cc0075578d896ae71ed1609_720w.jpg" alt="img"></p><p>根据上图知道：</p><ol><li><ol><li><p>内存中doublewrite buffer大小2M；物理磁盘上共享表空间中连续的128个页，也就是2个区（extent）大小同样为2M；</p></li><li><p>对缓冲池脏页进行刷新时，不是直接写磁盘。</p></li><li><ol><li>第一步：通过memcpy()函数将脏页先复制到内存中的doublewrite buffer；</li><li>第二步：通过doublewrite分两次，每次1M顺序的写入共享表空间的物理磁盘上。这个过程中，doublewrite页是连续的，因此这个过程是顺序的，所以开销并不大；</li><li>第三步：完成doublewrite页的写入后，再将doublewrite buffer中的页写入各个表空间文件中，此时写入是离散的，可能会较慢；</li><li>如果操作系统在第三步的过程中发生了崩溃，在恢复过程中，可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件中，再应用重做日志；</li></ol></li></ol></li></ol><h2 id="自适应hash索引ahi"><a href="#自适应hash索引ahi" class="headerlink" title="自适应hash索引ahi"></a>自适应hash索引ahi</h2><ol><li>innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，此索引成为热数据，建立hash索引以提升查询速度，此建立是自动建立哈希索引，故称为自适应哈希索引（adaptive hash index）；</li><li>自适应哈希索引会占用innodb buffer pool；</li><li>只适合搜索等值（=）的查询，对于范围查找等操作，是不能使用的；</li></ol><h2 id="预读"><a href="#预读" class="headerlink" title="预读"></a>预读</h2><p>预读（read-ahead)操作是一种IO操作，用于异步将磁盘的页读取到buffer pool中，预料这些页会马上被读取到。预读请求的所有页集中在一个范围内。InnoDB使用两种预读算法：</p><ol><li><p>两种预读算法来提高性能：</p></li><li><ol><li>线性预读：以extent为单位，将下一个extent提前读取到buffer pool中；</li><li>随机预读：以extent中的page为单位，将当前extent中的剩余的page提前读取到buffer pool中；</li></ol></li><li><p>线性预读一个重要参数：innodb_read_ahead_threshold，控制什么时间（访问extent中多少页的阈值）触发预读；</p></li><li><ol><li>默认：56，范围：0～64，值越高，访问模式检查越严格；</li><li>没有该变量之前，当访问到extent最后一个page时，innodb会决定是否将下一个extent放入到buffer pool中；</li></ol></li><li><p>随机预读说明：</p></li><li><ol><li>当同一个extent的一些page在buffer pool中发现时，innodb会将extent中剩余page一并读取到buffer pool中；</li><li>随机预读给innodb code带来一些不必要的复杂性，性能上也不稳定，在5.5版本已经废弃，如果启用，需要修改变量：innodb_random_read_ahead为ON；</li></ol></li></ol><h1 id="mysql三大日志-binlog、redo-log和undo-log"><a href="#mysql三大日志-binlog、redo-log和undo-log" class="headerlink" title="mysql三大日志-binlog、redo log和undo log"></a>mysql三大日志-binlog、redo log和undo log</h1><h2 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h2><p><code>binlog </code>用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。 <code>binlog </code>是 <code>mysql</code>的逻辑日志，并且由 <code>Server </code>层进行记录，使用任何存储引擎的 <code>mysql </code>数据库都会记录 <code>binlog </code>日志。</p><ul><li><strong>逻辑日志</strong>： 可以简单理解为记录的就是sql语句 。</li><li><strong>物理日志</strong>： <code>mysql </code>数据最终是保存在数据页中的，物理日志记录的就是数据页变更 </li></ul><p><code>binlog </code>是通过追加的方式进行写入的，可以通过 <code>max_binlog_size </code>参数设置每个 <code>binlog</code><br>文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。</p><h3 id="binlog使用场景"><a href="#binlog使用场景" class="headerlink" title="binlog使用场景"></a>binlog使用场景</h3><p>在实际应用中， <code>binlog </code>的主要使用场景有两个，分别是 <strong>主从复制</strong> 和 <strong>数据恢复</strong> 。</p><ol><li><strong>主从复制</strong> ：在 <code>Master </code>端开启 <code>binlog </code>，然后将 <code>binlog </code>发送到各个 <code>Slave </code>端， <code>Slave </code>端重放 <code>binlog </code>从而达到主从数据一致。</li><li><strong>数据恢复</strong> ：通过使用 <code>mysqlbinlog </code>工具来恢复数据。</li></ol><h3 id="binlog刷盘时机"><a href="#binlog刷盘时机" class="headerlink" title="binlog刷盘时机"></a>binlog刷盘时机</h3><p>对于 <code>InnoDB </code>存储引擎而言，只有在事务提交时才会记录 <code>biglog </code>，此时记录还在内存中，那么 <code>biglog</code><br>是什么时候刷到磁盘中的呢？ <code>mysql </code>通过 <code>sync_binlog </code>参数控制 <code>biglog </code>的刷盘时机，取值范围是 <code>0-N</code><br>：</p><ul><li>0：不去强制要求，由系统自行判断何时写入磁盘；</li><li>1：每次 <code>commit </code>的时候都要将 <code>binlog </code>写入磁盘；</li><li>N：每N个事务，才会将 <code>binlog </code>写入磁盘。</li></ul><p>从上面可以看出， <code>sync_binlog </code>最安全的是设置是 <code>1 </code>，这也是 <code>MySQL 5.7.7</code><br>之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。</p><h3 id="binlog日志格式"><a href="#binlog日志格式" class="headerlink" title="binlog日志格式"></a>binlog日志格式</h3><p><code>binlog </code>日志有三种格式，分别为 <code>STATMENT </code>、 <code>ROW </code>和 <code>MIXED </code>。</p><blockquote><p>在 <code>MySQL 5.7.7 </code>之前，默认的格式是 <code>STATEMENT </code>， <code>MySQL 5.7.7 </code>之后，默认值是 <code>ROW </code>。日志格式通过 <code>binlog-format </code>指定。</p></blockquote><ul><li><p><code>STATMENT </code>： 基于<code>SQL</code>语句的复制( <code>statement-based replication, SBR </code>)，每一条会修改数据的sql语句会记录到 <code>binlog </code>中 。</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">* 优点： 不需要记录每一行的变化，减少了` binlog ` 日志量，节约了 ` IO ` , 从而提高了性能； </span><br><span class="line">* 缺点： 在某些情况下会导致主从数据不一致，比如执行` sysdate() ` 、 ` slepp() ` 等 。 </span><br></pre></td></tr></table></figure></li><li><p><code>ROW </code>： 基于行的复制(<code>row-based replication, RBR</code>)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了 。</p><ul><li>优点： 不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题 ；</li><li>缺点： 会产生大量的日志，尤其是<code>alter table</code>的时候会让日志暴涨</li></ul></li><li><p><code>MIXED </code>： 基于<code>STATMENT</code>和 <code>ROW </code>两种模式的混合复制( <code>mixed-based replication, MBR </code>)，一般的复制使用 <code>STATEMENT </code>模式保存 <code>binlog </code>，对于 <code>STATEMENT </code>模式无法复制的操作使用 <code>ROW </code>模式保存 <code>binlog</code></p></li></ul><h2 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h2><h3 id="为什么需要redo-log"><a href="#为什么需要redo-log" class="headerlink" title="为什么需要redo log"></a>为什么需要redo log</h3><p>我们都知道，事务的四大特性里面有一个是 <strong>持久性</strong> ，具体来说就是<br><strong>只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态</strong> 。那么 <code>mysql</code><br>是如何保证一致性的呢？最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：</p><ol><li>因为 <code>Innodb </code>是以 <code>页 </code>为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！</li><li>一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！</li></ol><p>因此 <code>mysql </code>设计了 <code>redo log </code>， <strong>具体来说就是只记录事务对数据页做了哪些修改</strong><br>，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)</p><h3 id="redo-log基本概念"><a href="#redo-log基本概念" class="headerlink" title="redo log基本概念"></a>redo log基本概念</h3><p><code>redo log </code>包括两部分：一个是内存中的日志缓冲( <code>redo log buffer </code>)，另一个是磁盘上的日志文件( <code>redo log file</code>)。 <code>mysql </code>每执行一条 <code>DML </code>语句，先将记录写入 <code>redo log buffer </code><br>，后续某个时间点再一次性将多个操作记录写到 <code>redo log file </code>。这种 <strong>先写日志，再写磁盘</strong> 的技术就是 <code>MySQL</code><br>里经常说到的 <code>WAL(Write-Ahead Logging) </code>技术。</p><p>在计算机操作系统中，用户空间( <code>user space </code>)下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间( <code>kernel space</code>)缓冲区( <code>OS Buffer </code>)。因此， <code>redo log buffer </code>写入 <code>redo log file </code>实际上是先写入 <code>OS Buffer </code>，然后再通过系统调用 <code>fsync() </code>将其刷到 <code>redo log file </code><br>中，过程如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000023827701" alt="img"></p><p><code>mysql </code>支持三种将 <code>redo log buffer </code>写入 <code>redo log file </code>的时机，可以通过 <code>innodb_flush_log_at_trx_commit</code> 参数配置，各参数值含义如下：</p><table><thead><tr><th>参数值</th><th>含义</th></tr></thead><tbody><tr><td>0（延迟写）</td><td>事务提交时不会将 <code>redo log buffer </code>中日志写入到 <code>os buffer </code>，而是每秒写入 <code>os buffer </code>并调用 <code>fsync() </code>写入到 <code>redo log file </code>中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。</td></tr><tr><td>1（实时写，实时刷）</td><td>事务每次提交都会将 <code>redo log buffer </code>中的日志写入 <code>os buffer </code>并调用 <code>fsync() </code>刷到 <code>redo log file </code>中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。</td></tr><tr><td>2（实时写，延迟刷）</td><td>每次提交都仅写入到 <code>os buffer </code>，然后是每秒调用 <code>fsync() </code>将 <code>os buffer </code>中的日志写入到 <code>redo log file </code>。</td></tr></tbody></table><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000023827700" alt="img"></p><h3 id="redo-log记录形式"><a href="#redo-log记录形式" class="headerlink" title="redo log记录形式"></a>redo log记录形式</h3><p>前面说过， <code>redo log </code>实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此 <code>redo log</code><br>实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000023827699" alt="img"></p><p>同时我们很容易得知， 在innodb中，既有<code>redo log</code>需要刷盘，还有 <code>数据页 </code>也需要刷盘， <code>redo log </code>存在的意义主要就是降低对 <code>数据页 </code>刷盘的要求 <strong>。在上图中， <code>write pos </code>表示 <code>redo log </code>当前记录的 <code>LSN</code> (逻辑序列号)位置， <code>check point </code>表示</strong> 数据页更改记录** 刷盘后对应 <code>redo log </code>所处的 <code>LSN </code>(逻辑序列号)位置。 <code>write pos </code>到 <code>check point </code>之间的部分是 <code>redo log </code>空着的部分，用于记录新的记录；<code>check point</code>到 <code>write pos </code>之间是 <code>redo log </code>待落盘的数据页更改记录。当 <code>write pos </code>追上 <code>check point </code>时，会先推动 <code>check point </code>向前移动，空出位置再记录新的日志。</p><p>启动 <code>innodb </code>的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。因为 <code>redo log </code>记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如 <code>binlog </code>)要快很多。 重启 <code>innodb </code>时，首先会检查磁盘中数据页的 <code>LSN </code>，如果数据页的 <code>LSN </code>小于日志中的 <code>LSN </code>，则会从 <code>checkpoint </code>开始恢复。 还有一种情况，在宕机前正处于<br><code>checkpoint </code>的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的 <code>LSN </code>大于日志中的 <code>LSN</code><br>，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。</p><h3 id="redo-log与binlog区别"><a href="#redo-log与binlog区别" class="headerlink" title="redo log与binlog区别"></a>redo log与binlog区别</h3><table><thead><tr><th></th><th>redo log</th><th>binlog</th></tr></thead><tbody><tr><td>文件大小</td><td><code>redo log </code>的大小是固定的。</td><td><code>binlog </code>可通过配置参数 <code>max_binlog_size </code>设置每个<code>binlog</code>文件的大小。</td></tr><tr><td>实现方式</td><td><code>redo log </code>是 <code>InnoDB </code>引擎层实现的，并不是所有引擎都有。</td><td><code>binlog </code>是 <code>Server</code> 层实现的，所有引擎都可以使用 <code>binlog </code>日志</td></tr><tr><td>记录方式</td><td>redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。</td><td>binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上</td></tr><tr><td>适用场景</td><td><code>redo log </code>适用于崩溃恢复(crash-safe)</td><td><code>binlog </code>适用于主从复制和数据恢复</td></tr></tbody></table><p>由 <code>binlog </code>和 <code>redo log </code>的区别可知： <code>binlog </code>日志只用于归档，只依靠 <code>binlog </code>是没有 <code>crash-safe</code>能力的。但只有 <code>redo log </code>也不行，因为 <code>redo log </code>是 <code>InnoDB </code><br>特有的，且日志上的记录落盘后会被覆盖掉。因此需要 <code>binlog </code>和 <code>redo log</code><br>二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。</p><h2 id="redo-log是什么，为什么需要redo-log"><a href="#redo-log是什么，为什么需要redo-log" class="headerlink" title="redo log是什么，为什么需要redo log"></a>redo log是什么，为什么需要redo log</h2><ul><li>redo log 是<strong>重做日志</strong>。</li><li>它记录了<strong>数据页</strong>上的改动。</li><li>它指<strong>事务</strong>中修改了的数据，将会备份存储。</li><li>发生数据库服务器宕机、或者脏页未写入磁盘，可以通过redo log恢复。</li><li>它是<strong>Innodb存储</strong>引擎独有的</li></ul><h3 id="为什么需要-redo-log？"><a href="#为什么需要-redo-log？" class="headerlink" title="为什么需要 redo log？"></a>为什么需要 redo log？</h3><ul><li>redo log主要用于MySQL异常重启后的一种数据恢复手段，确保了数据的一致性。</li><li>其实是为了配合MySQL的WAL机制。因为MySQL进行更新操作，为了能够快速响应，所以采用了异步写回磁盘的技术，写入内存后就</li><li>返回。但是这样，会存在<strong>crash后</strong>内存数据丢失的隐患，而redo log具备crash safe的能力。</li></ul><h2 id="什么是WAL技术-好处是什么"><a href="#什么是WAL技术-好处是什么" class="headerlink" title="什么是WAL技术, 好处是什么."></a>什么是WAL技术, 好处是什么.</h2><ul><li>WAL，中文全称是Write-Ahead Logging，它的关键点就是日志先写内存，再写磁盘。MySQL执行更新操作后，<strong>在真正把数据写入到磁盘前，先记录日志</strong>。</li><li>好处是不用每一次操作都实时把数据写盘，就算crash后也可以通过redo log恢复，所以能够实现快速响应SQL语句。</li></ul><h2 id="redo-log的写入方式"><a href="#redo-log的写入方式" class="headerlink" title="redo log的写入方式"></a>redo log的写入方式</h2><p>redo log包括两部分内容，分别是内存中的<strong>日志缓冲</strong>(redo log buffer)和磁盘上的<strong>日志文件</strong>(redo log file)。</p><p>mysql每执行一条DML语句，会先把记录写入<strong>redo log buffer</strong>，后续某个时间点再一次性将多个操作记录写到<strong>redo log file</strong>。这种先写日志，再写磁盘的技术，就是<strong>WAL</strong>。</p><p>在计算机操作系统中，用户空间(user space)下的缓冲区数据，一般是无法直接写入磁盘的，必须经过操作系统内核空间缓冲区(即OS Buffer)。</p><ul><li>日志最开始会写入位于存储引擎Innodb的redo log buffer，这个是在用户空间完成的。</li><li>然后再将日志保存到操作系统内核空间的缓冲区(OS buffer)中。</li><li>最后，通过系统调用<code>fsync()</code>，从<strong>OS buffer</strong>写入到磁盘上的<strong>redo log file</strong>中，完成写入操作。这个写入磁盘的操作，就叫做<strong>刷盘</strong>。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925213720105.png" alt="image-20210925213720105"></p><p>我们可以发现，redo log buffer写入到redo log file，是经过OS buffer中转的。其实可以通过参数<code>innodb_flush_log_at_trx_commit</code>进行配置，参数值含义如下：</p><ul><li>0：称为<strong>延迟写</strong>，事务提交时不会将redo log buffer中日志写入到OS buffer，而是每秒写入OS buffer并调用写入到redo log file中。</li><li>1：称为<strong>实时写</strong>，实时刷”，事务每次提交都会将redo log buffer中的日志写入OS buffer并保存到redo log file中。</li><li>2：称为<strong>实时写，延迟刷</strong>。每次事务提交写入到OS buffer，然后是每秒将日志写入到redo log file。</li></ul><h2 id="Redo-log的执行流程"><a href="#Redo-log的执行流程" class="headerlink" title="Redo log的执行流程"></a>Redo log的执行流程</h2><p>我们来看下Redo log的执行流程，假设执行的SQL如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update T set a &#x3D;1 where id &#x3D;666</span><br></pre></td></tr></table></figure><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925213741905.png" alt="image-20210925213741905"></p><p>redo log的执行流程</p><ol><li>MySQL客户端将请求语句<code>update T set a =1 where id =666</code>，发往MySQL Server层。</li><li>MySQL Server 层接收到SQL请求后，对其进行分析、优化、执行等处理工作，将生成的SQL执行计划发到InnoDb存储引擎层执行。</li><li>InnoDb存储引擎层将<strong>a修改为1</strong>的这个操作记录到内存中。</li><li>记录到内存以后会修改redo log 的记录，会在添加一行记录，其内容是<strong>需要在哪个数据页上做什么修改</strong>。</li><li>此后，将事务的状态设置为prepare ，说明已经准备好提交事务了。</li><li>等到MySQL Server层处理完事务以后，会将事务的状态设置为<strong>commit</strong>，也就是提交该事务。</li><li>在收到事务提交的请求以后，<strong>redo log</strong>会把刚才写入内存中的操作记录写入到磁盘中，从而完成整个日志的记录过程。</li></ol><p>默认状态时先写入 磁盘redolog 再进行事务commit</p><h2 id="redo-log-为什么可以保证crash-safe机制呢？"><a href="#redo-log-为什么可以保证crash-safe机制呢？" class="headerlink" title="redo log 为什么可以保证crash safe机制呢？"></a>redo log 为什么可以保证crash safe机制呢？</h2><ul><li>因为redo log每次更新操作完成后，就一定会写入的，如果<strong>写入失败</strong>，说明此次操作失败，事务也不可能提交。</li><li>redo log内部结构是基于页的，记录了这个页的字段值变化，只要crash后读取redo log进行重放，就可以恢复数据。</li></ul><h2 id="binlog的概念是什么-起到什么作用-可以保证crash-safe吗"><a href="#binlog的概念是什么-起到什么作用-可以保证crash-safe吗" class="headerlink" title="binlog的概念是什么, 起到什么作用, 可以保证crash-safe吗?"></a>binlog的概念是什么, 起到什么作用, 可以保证crash-safe吗?</h2><ul><li>bin log是归档日志，属于MySQL Server层的日志。可以实现<strong>主从复制</strong>和<strong>数据恢复</strong>两个作用。</li><li>当需要<strong>恢复数据</strong>时，可以取出某个时间范围内的bin log进行重放恢复。</li><li>但是bin log不可以做crash safe，因为crash之前，bin log<strong>可能没有写入完全</strong>MySQL就挂了。所以需要配合<strong>redo log</strong>才可以进行crash safe。</li></ul><h2 id="binlog和redolog的不同点有哪些"><a href="#binlog和redolog的不同点有哪些" class="headerlink" title="binlog和redolog的不同点有哪些?"></a>binlog和redolog的不同点有哪些?</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925210728980.png" alt="image-20210925210728980"></p><h2 id="执行器和innoDB在执行update语句时候的流程是什么样的"><a href="#执行器和innoDB在执行update语句时候的流程是什么样的" class="headerlink" title="执行器和innoDB在执行update语句时候的流程是什么样的?"></a>执行器和innoDB在执行update语句时候的流程是什么样的?</h2><ul><li>执行器在优化器选择了索引后，会调用InnoDB读接口，读取要更新的行到内存中</li><li>执行SQL操作后，更新到内存，然后写redo log，写bin log，此时即为完成。</li><li>后续InnoDB会在合适的时候把此次操作的结果写回到磁盘。</li></ul><h2 id="如果数据库误操作-如何执行数据恢复"><a href="#如果数据库误操作-如何执行数据恢复" class="headerlink" title="如果数据库误操作, 如何执行数据恢复?"></a>如果数据库误操作, 如何执行数据恢复?</h2><p>数据库在某个时候误操作，就可以找到距离误操作最近的时间节点的bin log，重放到临时数据库里，然后选择误删的数据节点，恢复到线上数据库。</p><h2 id="什么是MySQL两阶段提交-为什么需要两阶段提交"><a href="#什么是MySQL两阶段提交-为什么需要两阶段提交" class="headerlink" title="什么是MySQL两阶段提交, 为什么需要两阶段提交?"></a>什么是MySQL两阶段提交, 为什么需要两阶段提交?</h2><p>其实所谓的两阶段就是把一个事务分成两个阶段来提交。</p><p>两阶段提交</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925211124058.png" alt="image-20210925211124058"></p><p>两阶段提交主要有三步曲：</p><ol><li>redo log在写入后，进入prepare状态</li><li>执行器写入bin log</li><li>进入commit状态，事务可以提交。</li></ol><p><strong>为什么需要两阶段提交呢?</strong></p><ul><li>如果不用两阶段提交的话，可能会出现这样情况：bin log写入之前，机器crash导致需要重启。重启后redo log继续重放crash之前的操作，而当bin log后续需要作为备份恢复时，会出现数据不一致的情况。</li><li>如果是bin log commit之前crash，那么重启后，发现redo log是prepare状态且bin log完整（bin log写入成功后，redo log会有bin log的标记），就会自动commit，让存储引擎提交事务。</li><li>两阶段提交就是为了保证redo log和binlog数据的安全一致性。只有在这两个日志文件逻辑上高度一致了。你才能放心的使用redo log帮你将数据库中的状态恢复成crash之前的状态，使用binlog实现数据备份、恢复、以及主从复制。</li></ul><h2 id="如果不是两阶段提交-先写redo-log和先写bin-log两种情况各会遇到什么问题"><a href="#如果不是两阶段提交-先写redo-log和先写bin-log两种情况各会遇到什么问题" class="headerlink" title="如果不是两阶段提交, 先写redo log和先写bin log两种情况各会遇到什么问题?"></a>如果不是两阶段提交, 先写redo log和先写bin log两种情况各会遇到什么问题?</h2><ul><li>先写redo log，crash后bin log备份恢复时少了一次更新，与当前数据不一致。</li><li>先写bin log，crash后，由于redo log没写入，事务无效，所以后续bin log备份恢复时，数据不一致。</li></ul><h2 id="binlog刷盘机制"><a href="#binlog刷盘机制" class="headerlink" title="binlog刷盘机制"></a>binlog刷盘机制</h2><p>所有未提交的事务产生的binlog，都会被先记录到binlog的缓存中。等该事务提交时，再将缓存中的数据写入binlog日志文件中。缓存的大小由参数<code>binlog_chache_size</code>控制。</p><p>binlog什么时候刷新到磁盘呢？由参数<code>sync_binlog</code>控制</p><ul><li>当<code>sync_binlog</code>为0时，表示MySQL不控制binlog的刷新，而是由系统自行判断何时写入磁盘。选这种策略，一旦操作系统宕机，缓存中的binlog就会丢失。</li><li><code>sync_binlog</code>为N时，每N个事务，才会将binlog写入磁盘。。</li><li>当<code>sync_binlog</code>为1时，则表示每次commit，都将binlog 写入磁盘。</li></ul><p>来看一个比较完整的流程图吧：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210925213845996.png" alt="image-20210925213845996"></p><h2 id="说说Redo-log的记录方式"><a href="#说说Redo-log的记录方式" class="headerlink" title="说说Redo log的记录方式"></a>说说Redo log的记录方式</h2><p>redo log的大小是固定。它采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。如下图（图片来源网络）：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/640" alt="图片">redo log 循环写入</p><p>redo log buffer(内存中)是由首尾相连的四个文件组成的，它们分别是：ib_logfile_1、ib_logfile_2、ib_logfile_3、ib_logfile_4。</p><blockquote><ul><li>write pos表示当前写入记录位置(写入磁盘的数据页的逻辑序列位置)</li><li>check point表示刷盘(写入磁盘)后对应的位置。</li><li>write pos到check point之间的部分用来记录新日志，也就是留给新记录的空间。</li><li>check point到write pos之间是待刷盘的记录，如果不刷盘会被新记录覆盖。</li></ul></blockquote><p>有了 redo log，当数据库发生宕机重启后，可通过 redo log将未落盘的数据（check point之后的数据）恢复，保证已经提交的事务记录不会丢失，这种能力称为<strong>crash-safe</strong>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Innodb引擎的4大特性&quot;&gt;&lt;a href=&quot;#Innodb引擎的4大特性&quot; class=&quot;headerlink&quot; title=&quot;Innodb引擎的4大特性&quot;&gt;&lt;/a&gt;Innodb引擎的4大特性&lt;/h1&gt;&lt;h2 id=&quot;插入缓存（Insert-Buffer-Ch</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>12.ThreadLocal 分析</title>
    <link href="https://leslieaibin.github.io/2021/09/24/Thread/12.ThreadLocal%E5%88%86%E6%9E%90/"/>
    <id>https://leslieaibin.github.io/2021/09/24/Thread/12.ThreadLocal%E5%88%86%E6%9E%90/</id>
    <published>2021-09-24T02:15:42.000Z</published>
    <updated>2021-09-24T06:36:35.263Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ThreadLocal的数据结构"><a href="#ThreadLocal的数据结构" class="headerlink" title="ThreadLocal的数据结构"></a>ThreadLocal的数据结构</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/2.png" alt="img"></p><p><code>Thread</code>类有一个类型为<code>ThreadLocal.ThreadLocalMap</code>的实例变量<code>threadLocals</code>，也就是说每个线程有一个自己的<code>ThreadLocalMap</code>。</p><p><code>ThreadLocalMap</code>有自己的独立实现，可以简单地将它的<code>key</code>视作<code>ThreadLocal</code>，<code>value</code>为代码中放入的值（实际上<code>key</code>并不是<code>ThreadLocal</code>本身，而是它的一个<strong>弱引用</strong>）。</p><p>每个线程在往<code>ThreadLocal</code>里放值的时候，都会往自己的<code>ThreadLocalMap</code>里存，读也是以<code>ThreadLocal</code>作为引用，在自己的<code>map</code>里找对应的<code>key</code>，从而实现了<strong>线程隔离</strong>。</p><p><code>ThreadLocalMap</code>有点类似<code>HashMap</code>的结构，只是<code>HashMap</code>是由<strong>数组+链表</strong>实现的，而<code>ThreadLocalMap</code>中并没有<strong>链表</strong>结构。</p><p>我们还要注意<code>Entry</code>， 它的<code>key</code>是<code>ThreadLocal&lt;?&gt; k</code> ，继承自<code>WeakReference</code>， 也就是我们常说的弱引用类型。</p><h1 id="GC-之后-key-是否为-null？"><a href="#GC-之后-key-是否为-null？" class="headerlink" title="GC 之后 key 是否为 null？"></a>GC 之后 key 是否为 null？</h1><p>回应开头的那个问题， <code>ThreadLocal</code> 的<code>key</code>是弱引用，那么在<code>ThreadLocal.get()</code>的时候,发生<code>GC</code>之后，<code>key</code>是否是<code>null</code>？</p><p>为了搞清楚这个问题，我们需要搞清楚<code>Java</code>的<strong>四种引用类型</strong>：</p><ul><li><strong>强引用</strong>：我们常常 new 出来的对象就是强引用类型，只要强引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足的时候</li><li><strong>软引用</strong>：使用 SoftReference 修饰的对象被称为软引用，软引用指向的对象在内存要溢出的时候被回收</li><li><strong>弱引用</strong>：使用 WeakReference 修饰的对象被称为弱引用，只要发生垃圾回收，若这个对象只被弱引用指向，那么就会被回收</li><li><strong>虚引用</strong>：虚引用是最弱的引用，在 Java 中使用 PhantomReference 进行定义。虚引用中唯一的作用就是用队列接收对象即将死亡的通知</li></ul><p>在<code>GC</code>之后，<code>key</code>就会被回收。其实是不对的，因为题目说的是在做 <code>ThreadLocal.get()</code> 操作，证明其实还是有<strong>强引用</strong>存在的，所以 <code>key</code> 并不为 <code>null</code>，如下图所示，<code>ThreadLocal</code>的<strong>强引用</strong>仍然是存在的。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/5.png" alt="image.png"></p><p>如果我们的<strong>强引用</strong>不存在的话，那么 <code>key</code> 就会被回收，也就是会出现我们 <code>value</code> 没被回收，<code>key</code> 被回收，导致 <code>value</code> 永远存在，出现内存泄漏。</p><h1 id="ThreadLocal-set-方法源码"><a href="#ThreadLocal-set-方法源码" class="headerlink" title="ThreadLocal.set() 方法源码"></a>ThreadLocal.set() 方法源码</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/6.png" alt="img"></p><p><code>ThreadLocal</code>中的<code>set</code>方法原理如上图所示，很简单，主要是判断<code>ThreadLocalMap</code>是否存在，然后使用<code>ThreadLocal</code>中的<code>set</code>方法进行数据处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(T value)</span> </span>&#123;</span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    <span class="keyword">if</span> (map != <span class="keyword">null</span>)</span><br><span class="line">        map.set(<span class="keyword">this</span>, value);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        createMap(t, value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createMap</span><span class="params">(Thread t, T firstValue)</span> </span>&#123;</span><br><span class="line">    t.threadLocals = <span class="keyword">new</span> ThreadLocalMap(<span class="keyword">this</span>, firstValue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="ThreadLocalMap-Hash算法"><a href="#ThreadLocalMap-Hash算法" class="headerlink" title="ThreadLocalMap Hash算法"></a>ThreadLocalMap Hash算法</h1><p>既然是<code>Map</code>结构，那么<code>ThreadLocalMap</code>当然也要实现自己的<code>hash</code>算法来解决散列表数组冲突问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = key.threadLocalHashCode &amp; (len - <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p><code>ThreadLocalMap</code>中<code>hash</code>算法很简单，这里<code>i</code>就是当前 key 在散列表中对应的数组下标位置。</p><p>这里最关键的就是<code>threadLocalHashCode</code>值的计算，<code>ThreadLocal</code>中有一个属性为<code>HASH_INCREMENT = 0x61c88647</code></p><p>每当创建一个<code>ThreadLocal</code>对象，这个<code>ThreadLocal.nextHashCode</code> 这个值就会增长 <code>0x61c88647</code> 。</p><p>这个值很特殊，它是<strong>斐波那契数</strong> 也叫 <strong>黄金分割数</strong>。<code>hash</code>增量为 这个数字，带来的好处就是 <code>hash</code> <strong>分布非常均匀</strong>。</p><h1 id="ThreadLocalMap-Hash-冲突"><a href="#ThreadLocalMap-Hash-冲突" class="headerlink" title="ThreadLocalMap Hash 冲突"></a>ThreadLocalMap Hash 冲突</h1><p><strong>注明：</strong> 下面所有示例图中，<strong>绿色块</strong><code>Entry</code>代表<strong>正常数据</strong>，<strong>灰色块</strong>代表<code>Entry</code>的<code>key</code>值为<code>null</code>，<strong>已被垃圾回收</strong>。<strong>白色块</strong>表示<code>Entry</code>为<code>null</code>。</p><p>虽然<code>ThreadLocalMap</code>中使用了<strong>黄金分割数来</strong>作为<code>hash</code>计算因子，大大减少了<code>Hash</code>冲突的概率，但是仍然会存在冲突。</p><p><code>HashMap</code>中解决冲突的方法是在数组上构造一个<strong>链表</strong>结构，冲突的数据挂载到链表上，如果链表长度超过一定数量则会转化成<strong>红黑树</strong>。</p><p>而 <code>ThreadLocalMap</code> 中并没有链表结构，所以这里不能使用 <code>HashMap</code> 解决冲突的方式了。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/7.png" alt="img"></p><p>如上图所示，如果我们插入一个<code>value=27</code>的数据，通过 <code>hash</code> 计算后应该落入第 4 个槽位中，而槽位 4 已经有了 <code>Entry</code> 数据。</p><p>此时就会线性向后查找，一直找到 <code>Entry</code> 为 <code>null</code> 的槽位才会停止查找，将当前元素放入此槽位中。当然迭代过程中还有其他的情况，比如遇到了 <code>Entry</code> 不为 <code>null</code> 且 <code>key</code> 值相等的情况，还有 <code>Entry</code> 中的 <code>key</code> 值为 <code>null</code> 的情况等等都会有不同的处理，后面会一一详细讲解。</p><p>这里还画了一个<code>Entry</code>中的<code>key</code>为<code>null</code>的数据（<strong>Entry=2 的灰色块数据</strong>），因为<code>key</code>值是<strong>弱引用</strong>类型，所以会有这种数据存在。在<code>set</code>过程中，如果遇到了<code>key</code>过期的<code>Entry</code>数据，实际上是会进行一轮<strong>探测式清理</strong>操作的，具体操作方式后面会讲到。</p><h1 id="ThreadLocalMap-set-详解"><a href="#ThreadLocalMap-set-详解" class="headerlink" title="ThreadLocalMap.set()详解"></a>ThreadLocalMap.set()详解</h1><p>往<code>ThreadLocalMap</code>中<code>set</code>数据（<strong>新增</strong>或者<strong>更新</strong>数据）分为好几种情况，针对不同的情况我们画图来说说明。</p><ul><li><p>通过<code>hash</code>计算后的槽位对应的<code>Entry</code>数据为空：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/9.png" alt="img"></p><p>这里直接将数据放到该槽位即可。</p></li><li><p>槽位数据不为空，<code>key</code>值与当前<code>ThreadLocal</code>通过<code>hash</code>计算获取的<code>key</code>值一致：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/10.png" alt="img"></p><p>这里直接更新该槽位的数据。</p></li><li><p>槽位数据不为空，往后遍历过程中，在找到<code>Entry</code>为<code>null</code>的槽位之前，没有遇到<code>key</code>过期的<code>Entry</code>：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/11.png" alt="img"></p><p>遍历散列数组，线性往后查找，如果找到<code>Entry</code>为<code>null</code>的槽位，则将数据放入该槽位中，或者往后遍历过程中，遇到了<strong>key 值相等</strong>的数据，直接更新即可</p></li><li><p>槽位数据不为空，往后遍历过程中，在找到<code>Entry</code>为<code>null</code>的槽位之前，遇到<code>key</code>过期的<code>Entry</code>，如下图，往后遍历过程中，一到了<code>index=7</code>的槽位数据<code>Entry</code>的<code>key=null</code>：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/12.png" alt="img"></p></li></ul><p>散列数组下标为 7 位置对应的<code>Entry</code>数据<code>key</code>为<code>null</code>，表明此数据<code>key</code>值已经被垃圾回收掉了，此时就会执行<code>replaceStaleEntry()</code>方法，该方法含义是<strong>替换过期数据的逻辑</strong>，以<strong>index=7</strong>位起点开始遍历，进行探测式数据清理工作。</p><p>初始化探测式清理过期数据扫描的开始位置：<code>slotToExpunge = staleSlot = 7</code></p><p>以当前<code>staleSlot</code>开始 向前迭代查找，找其他过期的数据，然后更新过期数据起始扫描下标<code>slotToExpunge</code>。<code>for</code>循环迭代，直到碰到<code>Entry</code>为<code>null</code>结束。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/13.png" alt="img"></p><p>上面向前迭代的操作是为了更新探测清理过期数据的起始下标<code>slotToExpunge</code>的值，这个值在后面会讲解，它是用来判断当前过期槽位<code>staleSlot</code>之前是否还有过期元素。</p><p>接着开始以<code>staleSlot</code>位置(index=7)向后迭代，<strong>如果找到了相同 key 值的 Entry 数据：</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/14.png" alt="img"></p><p>从当前节点<code>staleSlot</code>向后查找<code>key</code>值相等的<code>Entry</code>元素，找到后更新<code>Entry</code>的值并交换<code>staleSlot</code>元素的位置(<code>staleSlot</code>位置为过期元素)，更新<code>Entry</code>数据，然后开始进行过期<code>Entry</code>的清理工作，如下图所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/view.png" alt="img">向后遍历过程中，如果没有找到相同 key 值的 Entry 数据：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/15.png" alt="img"></p><p>从当前节点<code>staleSlot</code>向后查找<code>key</code>值相等的<code>Entry</code>元素，直到<code>Entry</code>为<code>null</code>则停止寻找。通过上图可知，此时<code>table</code>中没有<code>key</code>值相同的<code>Entry</code>。</p><p>创建新的<code>Entry</code>，替换<code>table[stableSlot]</code>位置：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/16.png" alt="img"></p><p>替换完成后也是进行过期元素清理工作，清理工作主要是有两个方法：<code>expungeStaleEntry()</code>和<code>cleanSomeSlots()</code>，具体细节后面会讲到，请继续往后看。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(ThreadLocal&lt;?&gt; key, Object value)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line">    <span class="keyword">int</span> i = key.threadLocalHashCode &amp; (len-<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Entry e = tab[i];</span><br><span class="line">         e != <span class="keyword">null</span>;</span><br><span class="line">         e = tab[i = nextIndex(i, len)]) &#123;</span><br><span class="line">        ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (k == key) &#123;</span><br><span class="line">            e.value = value;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">            replaceStaleEntry(key, value, i);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tab[i] = <span class="keyword">new</span> Entry(key, value);</span><br><span class="line">    <span class="keyword">int</span> sz = ++size;</span><br><span class="line">    <span class="keyword">if</span> (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)</span><br><span class="line">        rehash();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里会通过<code>key</code>来计算在散列表中的对应位置，然后以当前<code>key</code>对应的桶的位置向后查找，找到可以使用的桶。</p><p>什么情况下桶才是可以使用的呢？</p><ol><li><code>k = key</code> 说明是替换操作，可以使用</li><li>碰到一个过期的桶，执行替换逻辑，占用过期桶</li><li>查找过程中，碰到桶中<code>Entry=null</code>的情况，直接使用</li></ol><p>接着就是执行<code>for</code>循环遍历，向后查找，我们先看下<code>nextIndex()</code>、<code>prevIndex()</code>方法实现：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/17.png" alt="img"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nextIndex</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ((i + <span class="number">1</span> &lt; len) ? i + <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">prevIndex</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ((i - <span class="number">1</span> &gt;= <span class="number">0</span>) ? i - <span class="number">1</span> : len - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li>遍历当前<code>key</code>值对应的桶中<code>Entry</code>数据为空，这说明散列数组这里没有数据冲突，跳出<code>for</code>循环，直接<code>set</code>数据到对应的桶中</li><li>如果<code>key</code>值对应的桶中<code>Entry</code>数据不为空<ul><li>如果<code>k = key</code>，说明当前<code>set</code>操作是一个替换操作，做替换逻辑，直接返回 </li><li>如果<code>key = null</code>，说明当前桶位置的<code>Entry</code>是过期数据，执行<code>replaceStaleEntry()</code>方法(核心方法)，然后返回</li></ul></li><li><code>for</code>循环执行完毕，继续往下执行说明向后迭代的过程中遇到了<code>entry</code>为<code>null</code>的情况 -<ul><li>在<code>Entry</code>为<code>null</code>的桶中创建一个新的<code>Entry</code>对象 </li><li>执行<code>++size</code>操作</li></ul></li><li>调用<code>cleanSomeSlots()</code>做一次启发式清理工作，清理散列数组中<code>Entry</code>的<code>key</code>过期的数据<ul><li>如果清理工作完成后，未清理到任何数据，且<code>size</code>超过了阈值(数组长度的 2/3)，进行<code>rehash()</code>操作</li><li>rehash()<code>中会先进行一轮探测式清理，清理过期</code>key`，清理完成后如果<strong>size &gt;= threshold - threshold / 4</strong>，就会执行真正的扩容逻辑(扩容逻辑往后看)</li></ul></li></ol><p>接着重点看下<code>replaceStaleEntry()</code>方法，<code>replaceStaleEntry()</code>方法提供替换过期数据的功能，我们可以对应上面<strong>第四种情况</strong>的原理图来再回顾下，具体代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">replaceStaleEntry</span><span class="params">(ThreadLocal&lt;?&gt; key, Object value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       <span class="keyword">int</span> staleSlot)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line">    Entry e;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> slotToExpunge = staleSlot;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = prevIndex(staleSlot, len);</span><br><span class="line">         (e = tab[i]) != <span class="keyword">null</span>;</span><br><span class="line">         i = prevIndex(i, len))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (e.get() == <span class="keyword">null</span>)</span><br><span class="line">            slotToExpunge = i;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = nextIndex(staleSlot, len);</span><br><span class="line">         (e = tab[i]) != <span class="keyword">null</span>;</span><br><span class="line">         i = nextIndex(i, len)) &#123;</span><br><span class="line"></span><br><span class="line">        ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (k == key) &#123;</span><br><span class="line">            e.value = value;</span><br><span class="line"></span><br><span class="line">            tab[i] = tab[staleSlot];</span><br><span class="line">            tab[staleSlot] = e;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (slotToExpunge == staleSlot)</span><br><span class="line">                slotToExpunge = i;</span><br><span class="line">            cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span> &amp;&amp; slotToExpunge == staleSlot)</span><br><span class="line">            slotToExpunge = i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tab[staleSlot].value = <span class="keyword">null</span>;</span><br><span class="line">    tab[staleSlot] = <span class="keyword">new</span> Entry(key, value);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (slotToExpunge != staleSlot)</span><br><span class="line">        cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>slotToExpunge<code>表示开始探测式清理过期数据的开始下标，默认从当前的</code>staleSlot<code>开始。以当前的</code>staleSlot<code>开始，向前迭代查找，找到没有过期的数据，</code>for<code>循环一直碰到</code>Entry<code>为</code>null<code>才会结束。如果向前找到了过期数据，更新探测清理过期数据的开始下标为 i，即</code>slotToExpunge=i</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = prevIndex(staleSlot, len);</span><br><span class="line">     (e = tab[i]) != <span class="keyword">null</span>;</span><br><span class="line">     i = prevIndex(i, len))&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e.get() == <span class="keyword">null</span>)&#123;</span><br><span class="line">        slotToExpunge = i;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着开始从<code>staleSlot</code>向后查找，也是碰到<code>Entry</code>为<code>null</code>的桶结束。 如果迭代过程中，<strong>碰到 k == key</strong>，这说明这里是替换逻辑，替换新数据并且交换当前<code>staleSlot</code>位置。如果<code>slotToExpunge == staleSlot</code>，这说明<code>replaceStaleEntry()</code>一开始向前查找过期数据时并未找到过期的<code>Entry</code>数据，接着向后查找过程中也未发现过期数据，修改开始探测式清理过期数据的下标为当前循环的 index，即<code>slotToExpunge = i</code>。最后调用<code>cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</code>进行启发式过期数据清理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (k == key) &#123;</span><br><span class="line">    e.value = value;</span><br><span class="line"></span><br><span class="line">    tab[i] = tab[staleSlot];</span><br><span class="line">    tab[staleSlot] = e;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (slotToExpunge == staleSlot)</span><br><span class="line">        slotToExpunge = i;</span><br><span class="line"></span><br><span class="line">    cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p><code>cleanSomeSlots()</code>和<code>expungeStaleEntry()</code>方法后面都会细讲，这两个是和清理相关的方法，一个是过期<code>key</code>相关<code>Entry</code>的启发式清理(<code>Heuristically scan</code>)，另一个是过期<code>key</code>相关<code>Entry</code>的探测式清理。</p><p><strong>如果 k != key</strong>则会接着往下走，<code>k == null</code>说明当前遍历的<code>Entry</code>是一个过期数据，<code>slotToExpunge == staleSlot</code>说明，一开始的向前查找数据并未找到过期的<code>Entry</code>。如果条件成立，则更新<code>slotToExpunge</code> 为当前位置，这个前提是前驱节点扫描时未发现过期数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (k == <span class="keyword">null</span> &amp;&amp; slotToExpunge == staleSlot)</span><br><span class="line">    slotToExpunge = i;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>往后迭代的过程中如果没有找到<code>k == key</code>的数据，且碰到<code>Entry</code>为<code>null</code>的数据，则结束当前的迭代操作。此时说明这里是一个添加的逻辑，将新的数据添加到<code>table[staleSlot]</code> 对应的<code>slot</code>中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tab[staleSlot].value = <span class="keyword">null</span>;</span><br><span class="line">tab[staleSlot] = <span class="keyword">new</span> Entry(key, value);Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>最后判断除了<code>staleSlot</code>以外，还发现了其他过期的<code>slot</code>数据，就要开启清理数据的逻辑：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (slotToExpunge != staleSlot)</span><br><span class="line">    cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);</span><br></pre></td></tr></table></figure><h1 id="ThreadLocalMap过期-key-的探测式清理流程"><a href="#ThreadLocalMap过期-key-的探测式清理流程" class="headerlink" title="ThreadLocalMap过期 key 的探测式清理流程"></a><code>ThreadLocalMap</code>过期 key 的探测式清理流程</h1><p>我们先讲下探测式清理，也就是<code>expungeStaleEntry</code>方法，遍历散列数组，从开始位置向后探测清理过期数据，将过期数据的<code>Entry</code>设置为<code>null</code>，沿途中碰到未过期的数据则将此数据<code>rehash</code>后重新在<code>table</code>数组中定位，如果定位的位置已经有了数据，则会将未过期的数据放到最靠近此位置的<code>Entry=null</code>的桶中，使<code>rehash</code>后的<code>Entry</code>数据距离正确的桶的位置更近一些。操作逻辑如下：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/18.png" alt="img"></p><p>如上图，<code>set(27)</code> 经过 hash 计算后应该落到<code>index=4</code>的桶中，由于<code>index=4</code>桶已经有了数据，所以往后迭代最终数据放入到<code>index=7</code>的桶中，放入后一段时间后<code>index=5</code>中的<code>Entry</code>数据<code>key</code>变为了<code>null</code></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/19.png" alt="img"></p><p>如果再有其他数据<code>set</code>到<code>map</code>中，就会触发<strong>探测式清理</strong>操作。</p><p>如上图，执行<strong>探测式清理</strong>后，<code>index=5</code>的数据被清理掉，继续往后迭代，到<code>index=7</code>的元素时，经过<code>rehash</code>后发现该元素正确的<code>index=4</code>，而此位置已经已经有了数据，往后查找离<code>index=4</code>最近的<code>Entry=null</code>的节点(刚被探测式清理掉的数据：index=5)，找到后移动<code>index= 7</code>的数据到<code>index=5</code>中，此时桶的位置离正确的位置<code>index=4</code>更近了。</p><p>经过一轮探测式清理后，<code>key</code>过期的数据会被清理掉，没过期的数据经过<code>rehash</code>重定位后所处的桶位置理论上更接近<code>i= key.hashCode &amp; (tab.len - 1)</code>的位置。这种优化会提高整个散列表查询性能。</p><p>接着看下<code>expungeStaleEntry()</code>具体流程，我们还是以先原理图后源码讲解的方式来一步步梳理：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/20.png" alt="img"></p><p>我们假设<code>expungeStaleEntry(3)</code> 来调用此方法，如上图所示，我们可以看到<code>ThreadLocalMap</code>中<code>table</code>的数据情况，接着执行清理操作：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/21.png" alt="img"></p><p>第一步是清空当前<code>staleSlot</code>位置的数据，<code>index=3</code>位置的<code>Entry</code>变成了<code>null</code>。然后接着往后探测：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/22.png" alt="img"></p><p>执行完第二步后，index=4 的元素挪到 index=3 的槽位中。</p><p>继续往后迭代检查，碰到正常数据，计算该数据位置是否偏移，如果被偏移，则重新计算<code>slot</code>位置，目的是让正常数据尽可能存放在正确位置或离正确位置更近的位置</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/23.png" alt="img"></p><p>在往后迭代的过程中碰到空的槽位，终止探测，这样一轮探测式清理工作就完成了，接着我们继续看看具体<strong>实现源代码</strong>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">expungeStaleEntry</span><span class="params">(<span class="keyword">int</span> staleSlot)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line"></span><br><span class="line">    tab[staleSlot].value = <span class="keyword">null</span>;</span><br><span class="line">    tab[staleSlot] = <span class="keyword">null</span>;</span><br><span class="line">    size--;</span><br><span class="line"></span><br><span class="line">    Entry e;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = nextIndex(staleSlot, len);</span><br><span class="line">         (e = tab[i]) != <span class="keyword">null</span>;</span><br><span class="line">         i = nextIndex(i, len)) &#123;</span><br><span class="line">        ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">            e.value = <span class="keyword">null</span>;</span><br><span class="line">            tab[i] = <span class="keyword">null</span>;</span><br><span class="line">            size--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">int</span> h = k.threadLocalHashCode &amp; (len - <span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span> (h != i) &#123;</span><br><span class="line">                tab[i] = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">while</span> (tab[h] != <span class="keyword">null</span>)</span><br><span class="line">                    h = nextIndex(h, len);</span><br><span class="line">                tab[h] = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>这里我们还是以<code>staleSlot=3</code> 来做示例说明，首先是将<code>tab[staleSlot]</code>槽位的数据清空，然后设置<code>size--</code> 接着以<code>staleSlot</code>位置往后迭代，如果遇到<code>k==null</code>的过期数据，也是清空该槽位数据，然后<code>size--</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">    e.value = <span class="keyword">null</span>;</span><br><span class="line">    tab[i] = <span class="keyword">null</span>;</span><br><span class="line">    size--;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>如果<code>key</code>没有过期，重新计算当前<code>key</code>的下标位置是不是当前槽位下标位置，如果不是，那么说明产生了<code>hash</code>冲突，此时以新计算出来正确的槽位位置往后迭代，找到最近一个可以存放<code>entry</code>的位置。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> h = k.threadLocalHashCode &amp; (len - <span class="number">1</span>);</span><br><span class="line"><span class="keyword">if</span> (h != i) &#123;</span><br><span class="line">    tab[i] = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (tab[h] != <span class="keyword">null</span>)</span><br><span class="line">        h = nextIndex(h, len);</span><br><span class="line"></span><br><span class="line">    tab[h] = e;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>这里是处理正常的产生<code>Hash</code>冲突的数据，经过迭代后，有过<code>Hash</code>冲突数据的<code>Entry</code>位置会更靠近正确位置，这样的话，查询的时候 效率才会更高。</p><h1 id="ThreadLocalMap扩容机制"><a href="#ThreadLocalMap扩容机制" class="headerlink" title="ThreadLocalMap扩容机制"></a><code>ThreadLocalMap</code>扩容机制</h1><p>在<code>ThreadLocalMap.set()</code>方法的最后，如果执行完启发式清理工作后，未清理到任何数据，且当前散列数组中<code>Entry</code>的数量已经达到了列表的扩容阈值<code>(len*2/3)</code>，就开始执行<code>rehash()</code>逻辑：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)</span><br><span class="line">    rehash();Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>接着看下<code>rehash()</code>具体实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">rehash</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    expungeStaleEntries();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (size &gt;= threshold - threshold / <span class="number">4</span>)</span><br><span class="line">        resize();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">expungeStaleEntries</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; len; j++) &#123;</span><br><span class="line">        Entry e = tab[j];</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span> &amp;&amp; e.get() == <span class="keyword">null</span>)</span><br><span class="line">            expungeStaleEntry(j);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p>这里首先是会进行探测式清理工作，从<code>table</code>的起始位置往后清理，上面有分析清理的详细流程。清理完成之后，<code>table</code>中可能有一些<code>key</code>为<code>null</code>的<code>Entry</code>数据被清理掉，所以此时通过判断<code>size &gt;= threshold - threshold / 4</code> 也就是<code>size &gt;= threshold* 3/4</code> 来决定是否扩容。</p><p>我们还记得上面进行<code>rehash()</code>的阈值是<code>size &gt;= threshold</code>，所以当面试官套路我们<code>ThreadLocalMap</code>扩容机制的时候 我们一定要说清楚这两个步骤：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/24.png" alt="img"></p><p>接着看看具体的<code>resize()</code>方法，为了方便演示，我们以<code>oldTab.len=8</code>来举例：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/25.png" alt="img"></p><p>扩容后的<code>tab</code>的大小为<code>oldLen * 2</code>，然后遍历老的散列表，重新计算<code>hash</code>位置，然后放到新的<code>tab</code>数组中，如果出现<code>hash</code>冲突则往后寻找最近的<code>entry</code>为<code>null</code>的槽位，遍历完成之后，<code>oldTab</code>中所有的<code>entry</code>数据都已经放入到新的<code>tab</code>中了。重新计算<code>tab</code>下次扩容的<strong>阈值</strong>，具体代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">resize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Entry[] oldTab = table;</span><br><span class="line">    <span class="keyword">int</span> oldLen = oldTab.length;</span><br><span class="line">    <span class="keyword">int</span> newLen = oldLen * <span class="number">2</span>;</span><br><span class="line">    Entry[] newTab = <span class="keyword">new</span> Entry[newLen];</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldLen; ++j) &#123;</span><br><span class="line">        Entry e = oldTab[j];</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">            ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line">            <span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">                e.value = <span class="keyword">null</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">int</span> h = k.threadLocalHashCode &amp; (newLen - <span class="number">1</span>);</span><br><span class="line">                <span class="keyword">while</span> (newTab[h] != <span class="keyword">null</span>)</span><br><span class="line">                    h = nextIndex(h, newLen);</span><br><span class="line">                newTab[h] = e;</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    setThreshold(newLen);</span><br><span class="line">    size = count;</span><br><span class="line">    table = newTab;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="ThreadLocalMap-get-详解"><a href="#ThreadLocalMap-get-详解" class="headerlink" title="ThreadLocalMap.get()详解"></a><code>ThreadLocalMap.get()</code>详解</h1><ul><li>通过查找<code>key</code>值计算出散列表中<code>slot</code>位置，然后该<code>slot</code>位置中的<code>Entry.key</code>和查找的<code>key</code>一致，则直接返回：</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/26.png" alt="img"></p><ul><li><code>slot</code>位置中的<code>Entry.key</code>和要查找的<code>key</code>不一致：</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/27.png" alt="img"></p><p>我们以<code>get(ThreadLocal1)</code>为例，通过<code>hash</code>计算后，正确的<code>slot</code>位置应该是 4，而<code>index=4</code>的槽位已经有了数据，且<code>key</code>值不等于<code>ThreadLocal1</code>，所以需要继续往后迭代查找。</p><p>迭代到<code>index=5</code>的数据时，此时<code>Entry.key=null</code>，触发一次探测式数据回收操作，执行<code>expungeStaleEntry()</code>方法，执行完后，<code>index 5,8</code>的数据都会被回收，而<code>index 6,7</code>的数据都会前移，此时继续往后迭代，到<code>index = 6</code>的时候即找到了<code>key</code>值相等的<code>Entry</code>数据，如下图所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/28.png" alt="img"></p><p> <code>ThreadLocalMap.get()</code>源码详解</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Entry <span class="title">getEntry</span><span class="params">(ThreadLocal&lt;?&gt; key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = key.threadLocalHashCode &amp; (table.length - <span class="number">1</span>);</span><br><span class="line">    Entry e = table[i];</span><br><span class="line">    <span class="keyword">if</span> (e != <span class="keyword">null</span> &amp;&amp; e.get() == key)</span><br><span class="line">        <span class="keyword">return</span> e;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> getEntryAfterMiss(key, i, e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> Entry <span class="title">getEntryAfterMiss</span><span class="params">(ThreadLocal&lt;?&gt; key, <span class="keyword">int</span> i, Entry e)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">        ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line">        <span class="keyword">if</span> (k == key)</span><br><span class="line">            <span class="keyword">return</span> e;</span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span>)</span><br><span class="line">            expungeStaleEntry(i);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            i = nextIndex(i, len);</span><br><span class="line">        e = tab[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="ThreadLocalMap过期-key-的启发式清理流程"><a href="#ThreadLocalMap过期-key-的启发式清理流程" class="headerlink" title="ThreadLocalMap过期 key 的启发式清理流程"></a><code>ThreadLocalMap</code>过期 key 的启发式清理流程</h1><p>上面多次提及到<code>ThreadLocalMap</code>过期可以的两种清理方式：<strong>探测式清理(expungeStaleEntry())\</strong>、<strong>启发式清理(cleanSomeSlots())</strong></p><p>探测式清理是以当前<code>Entry</code> 往后清理，遇到值为<code>null</code>则结束清理，属于<strong>线性探测清理</strong>。</p><p>而启发式清理被作者定义为：<strong>Heuristically scan some cells looking for stale entries</strong>.</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/29.png" alt="img"></p><p>具体代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">cleanSomeSlots</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> removed = <span class="keyword">false</span>;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        i = nextIndex(i, len);</span><br><span class="line">        Entry e = tab[i];</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span> &amp;&amp; e.get() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            n = len;</span><br><span class="line">            removed = <span class="keyword">true</span>;</span><br><span class="line">            i = expungeStaleEntry(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> ( (n &gt;&gt;&gt;= <span class="number">1</span>) != <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> removed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ThreadLocal的数据结构&quot;&gt;&lt;a href=&quot;#ThreadLocal的数据结构&quot; class=&quot;headerlink&quot; title=&quot;ThreadLocal的数据结构&quot;&gt;&lt;/a&gt;ThreadLocal的数据结构&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http</summary>
      
    
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>5.ConcurrentHashMap详解</title>
    <link href="https://leslieaibin.github.io/2021/09/24/Collection/5.ConcurrentHashMap%E8%AF%A6%E8%A7%A3/"/>
    <id>https://leslieaibin.github.io/2021/09/24/Collection/5.ConcurrentHashMap%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-09-23T16:15:42.000Z</published>
    <updated>2021-09-24T11:30:43.664Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ConcurrentHashMap跟HashMap，HashTable的对比"><a href="#ConcurrentHashMap跟HashMap，HashTable的对比" class="headerlink" title="ConcurrentHashMap跟HashMap，HashTable的对比"></a><strong>ConcurrentHashMap跟HashMap，HashTable的对比</strong></h2><p>　我们都知道HashMap不是线程安全的，所以在处理并发的时候会出现问题。</p><p>　而HashTable虽然是线程安全的，但是是通过整个来加锁的方式，当一个线程在写操作的时候，另外的线程则不能进行读写。</p><p>　而ConcurrentHashMap则可以支持并发的读写。跟1.7版本相比，1.8版本又有了很大的变化，已经抛弃了Segment的概念，虽然源码里面还保留了，也只是为了兼容性的考虑。</p><h2 id="ConcurrentHashMap原理概览"><a href="#ConcurrentHashMap原理概览" class="headerlink" title="ConcurrentHashMap原理概览"></a><strong>ConcurrentHashMap原理概览</strong></h2><p>在ConcurrentHashMap中通过一个Node&lt;K,V&gt;[]数组来保存添加到map中的键值对，而在同一个数组位置是通过链表和红黑树的形式来保存的。但是这个数组只有在第一次添加元素的时候才会初始化，否则只是初始化一个ConcurrentHashMap对象的话，只是设定了一个sizeCtl变量，这个变量用来判断对象的一些状态和是否需要扩容，后面会详细解释。</p><p>　　第一次添加元素的时候，默认初期长度为16，当往map中继续添加元素的时候，通过hash值跟数组长度取与来决定放在数组的哪个位置，如果出现放在同一个位置的时候，优先以链表的形式存放，在同一个位置的个数又达到了8个以上，如果数组的长度还小于64的时候，则会扩容数组。如果数组的长度大于等于64了的话，在会将该节点的链表转换成树。</p><p>　　通过扩容数组的方式来把这些节点给分散开。然后将这些元素复制到扩容后的新的数组中，同一个链表中的元素通过hash值的数组长度位来区分，是还是放在原来的位置还是放到扩容的长度的相同位置去 。在扩容完成之后，如果某个节点的是树，同时现在该节点的个数又小于等于6个了，则会将该树转为链表。</p><p>　　取元素的时候，相对来说比较简单，通过计算hash来确定该元素在数组的哪个位置，然后在通过遍历链表或树来判断key和key的hash，取出value值。</p><p>　　往ConcurrentHashMap中添加元素的时候，里面的数据以数组的形式存放的样子大概是这样的：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/979960-20180401205241081-2070730856.png" alt="img"></p><p>　　这个时候因为数组的长度才为16，则不会转化为树，而是会进行扩容。</p><p>　　扩容后数组大概是这样的：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/979960-20180401210643538-263913441.png" alt="img"></p><p>需要注意的是，扩容之后的长度不是32，扩容后的长度在后面细说。</p><p>如果数组扩张后长度达到64了，且继续在某个节点的后面添加元素达到8个以上的时候，则会出现转化为红黑树的情况。</p><p>转化之后大概是这样：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/979960-20180401211320795-401540659.png" alt="img"></p><h2 id="ConcurrentHashMap几个重要概念"><a href="#ConcurrentHashMap几个重要概念" class="headerlink" title="ConcurrentHashMap几个重要概念"></a>ConcurrentHashMap几个重要概念</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CAPACITY = <span class="number">16</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MOVED     = -<span class="number">1</span>; <span class="comment">// 表示正在转移</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEBIN   = -<span class="number">2</span>; <span class="comment">// 表示已经转换成树</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RESERVED  = -<span class="number">3</span>; <span class="comment">// hash for transient reservations</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> HASH_BITS = <span class="number">0x7fffffff</span>; <span class="comment">// usable bits of normal node hash</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">volatile</span> Node&lt;K,V&gt;[] table;<span class="comment">//默认没初始化的数组，用来保存元素</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> Node&lt;K,V&gt;[] nextTable;<span class="comment">//转移的时候用的数组</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 用来控制表初始化和扩容的，默认值为0，当在初始化的时候指定了大小，这会将这个大小保存在sizeCtl中，大小为数组的0.75</span></span><br><span class="line"><span class="comment">     * 当为负的时候，说明表正在初始化或扩张，</span></span><br><span class="line"><span class="comment">     *     -1表示初始化</span></span><br><span class="line"><span class="comment">     *     -(1+n) n:表示活动的扩张线程</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> <span class="keyword">int</span> sizeCtl;</span><br></pre></td></tr></table></figure><p><strong>几个重要的类</strong></p><p>Node&lt;K,V&gt;,这是构成每个元素的基本类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> hash;    <span class="comment">//key的hash值</span></span><br><span class="line">        <span class="keyword">final</span> K key;       <span class="comment">//key</span></span><br><span class="line">        <span class="keyword">volatile</span> V val;    <span class="comment">//value</span></span><br><span class="line">        <span class="keyword">volatile</span> Node&lt;K,V&gt; next; <span class="comment">//表示链表中的下一个节点</span></span><br><span class="line"></span><br><span class="line">        Node(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">            <span class="keyword">this</span>.hash = hash;</span><br><span class="line">            <span class="keyword">this</span>.key = key;</span><br><span class="line">            <span class="keyword">this</span>.val = val;</span><br><span class="line">            <span class="keyword">this</span>.next = next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> K <span class="title">getKey</span><span class="params">()</span>       </span>&#123; <span class="keyword">return</span> key; &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">getValue</span><span class="params">()</span>     </span>&#123; <span class="keyword">return</span> val; &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span>   </span>&#123; <span class="keyword">return</span> key.hashCode() ^ val.hashCode(); &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p> TreeNode，构造树的节点</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        TreeNode&lt;K,V&gt; parent;  <span class="comment">// red-black tree links</span></span><br><span class="line">        TreeNode&lt;K,V&gt; left;</span><br><span class="line">        TreeNode&lt;K,V&gt; right;</span><br><span class="line">        TreeNode&lt;K,V&gt; prev;    <span class="comment">// needed to unlink next upon deletion</span></span><br><span class="line">        <span class="keyword">boolean</span> red;</span><br><span class="line"></span><br><span class="line">        TreeNode(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next,</span><br><span class="line">                 TreeNode&lt;K,V&gt; parent) &#123;</span><br><span class="line">            <span class="keyword">super</span>(hash, key, val, next);</span><br><span class="line">            <span class="keyword">this</span>.parent = parent;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>TreeBin 用作树的头结点，只存储root和first节点，不存储节点的key、value值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeBin</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        TreeNode&lt;K,V&gt; root;</span><br><span class="line">        <span class="keyword">volatile</span> TreeNode&lt;K,V&gt; first;</span><br><span class="line">        <span class="keyword">volatile</span> Thread waiter;</span><br><span class="line">        <span class="keyword">volatile</span> <span class="keyword">int</span> lockState;</span><br><span class="line">        <span class="comment">// values for lockState</span></span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> WRITER = <span class="number">1</span>; <span class="comment">// set while holding write lock</span></span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> WAITER = <span class="number">2</span>; <span class="comment">// set when waiting for write lock</span></span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> READER = <span class="number">4</span>; <span class="comment">// increment value for setting read lock</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ForwardingNode在转移的时候放在头部的节点，是一个空节点</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ForwardingNode</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Node&lt;K,V&gt;[] nextTable;</span><br><span class="line">        ForwardingNode(Node&lt;K,V&gt;[] tab) &#123;</span><br><span class="line">            <span class="keyword">super</span>(MOVED, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">            <span class="keyword">this</span>.nextTable = tab;</span><br><span class="line">        &#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="ConcurrentHashMap的初始化"><a href="#ConcurrentHashMap的初始化" class="headerlink" title="ConcurrentHashMap的初始化"></a><strong>ConcurrentHashMap的初始化</strong></h2><p>构造方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//空的构造</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMapDebug</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//如果在实例化对象的时候指定了容量，则初始化sizeCtl</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMapDebug</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">        <span class="keyword">int</span> cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; <span class="number">1</span>)) ?</span><br><span class="line">                   MAXIMUM_CAPACITY :</span><br><span class="line">                   tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; <span class="number">1</span>) + <span class="number">1</span>));</span><br><span class="line">        <span class="keyword">this</span>.sizeCtl = cap;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//当出入一个Map的时候，先设定sizeCtl为默认容量，在添加元素</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMapDebug</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sizeCtl = DEFAULT_CAPACITY;</span><br><span class="line">        putAll(m);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>可以看到，在任何一个构造方法中，都没有对存储Map元素Node的table变量进行初始化。而是在第一次put操作的时候在进行初始化。</p><p>下面来看看数组的初始化方法initTable</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 初始化数组table，</span></span><br><span class="line"><span class="comment">* 如果sizeCtl小于0，说明别的数组正在进行初始化，则让出执行权</span></span><br><span class="line"><span class="comment">* 如果sizeCtl大于0的话，则初始化一个大小为sizeCtl的数组</span></span><br><span class="line"><span class="comment">* 否则的话初始化一个默认大小(16)的数组</span></span><br><span class="line"><span class="comment">* 然后设置sizeCtl的值为数组长度的3/4</span></span><br><span class="line"><span class="comment">ConcurrentHashMap的put操作详解*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Node&lt;K,V&gt;[] initTable() &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; <span class="keyword">int</span> sc;</span><br><span class="line">    <span class="keyword">while</span> ((tab = table) == <span class="keyword">null</span> || tab.length == <span class="number">0</span>) &#123;    <span class="comment">//第一次put的时候，table还没被初始化，进入while</span></span><br><span class="line">        <span class="keyword">if</span> ((sc = sizeCtl) &lt; <span class="number">0</span>)                            <span class="comment">//sizeCtl初始值为0，当小于0的时候表示在别的线程在初始化表或扩展表</span></span><br><span class="line">            Thread.yield(); <span class="comment">// lost initialization race; just spin</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc, -<span class="number">1</span>)) &#123;    <span class="comment">//SIZECTL：表示当前对象的内存偏移量ConcurrentHashMap的put操作详解，sc表示期望值，-1表示要替换的值，设定为-1表示要初始化表了</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || tab.length == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">int</span> n = (sc &gt; <span class="number">0</span>) ? sc : DEFAULT_CAPACITY;        <span class="comment">//指定了大小的时候就创建指定大小的Node数组，否则创建指定大小(16)的Node数组</span></span><br><span class="line">                    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node&lt;?,?&gt;[n];</span><br><span class="line">                    table = tab = nt;</span><br><span class="line">                    sc = n - (n &gt;&gt;&gt; <span class="number">2</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                sizeCtl = sc;            <span class="comment">//初始化后，sizeCtl长度为数组长度的3/4</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> tab;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ConcurrentHashMap的put操作详解"><a href="#ConcurrentHashMap的put操作详解" class="headerlink" title="ConcurrentHashMap的put操作详解"></a>ConcurrentHashMap的put操作详解</h2><p>下面看看put方法的源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">*    单纯的额调用putVal方法，并且putVal的第三个参数设置为false</span></span><br><span class="line"><span class="comment">*  当设置为false的时候表示这个value一定会设置</span></span><br><span class="line"><span class="comment">*  true的时候，只有当这个key的value为空的时候才会设置</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> putVal(key, value, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再来看putVal</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 当添加一对键值对的时候，首先会去判断保存这些键值对的数组是不是初始化了，</span></span><br><span class="line"><span class="comment">     * 如果没有的话就初始化数组</span></span><br><span class="line"><span class="comment">     *  然后通过计算hash值来确定放在数组的哪个位置</span></span><br><span class="line"><span class="comment">     * 如果这个位置为空则直接添加，如果不为空的话，则取出这个节点来</span></span><br><span class="line"><span class="comment">     * 如果取出来的节点的hash值是MOVED(-1)的话，则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程也去帮助复制</span></span><br><span class="line"><span class="comment">     * 最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过synchronized来加锁，进行添加操作</span></span><br><span class="line"><span class="comment">     *    然后判断当前取出的节点位置存放的是链表还是树</span></span><br><span class="line"><span class="comment">     *    如果是链表的话，则遍历整个链表，直到取出来的节点的key来个要放的key进行比较，如果key相等，并且key的hash值也相等的话，</span></span><br><span class="line"><span class="comment">     *          则说明是同一个key，则覆盖掉value，否则的话则添加到链表的末尾</span></span><br><span class="line"><span class="comment">     *    如果是树的话，则调用putTreeVal方法把这个元素添加到树中去</span></span><br><span class="line"><span class="comment">     *  最后在添加完成之后，会判断在该节点处共有多少个节点（注意是添加前的个数），如果达到8个以上了的话，</span></span><br><span class="line"><span class="comment">     *  则调用treeifyBin方法来尝试将处的链表转为树，或者扩容数组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(K key, V value, <span class="keyword">boolean</span> onlyIfAbsent)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="keyword">null</span> || value == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();<span class="comment">//K,V都不能为空，否则的话跑出异常</span></span><br><span class="line">        <span class="keyword">int</span> hash = spread(key.hashCode());    <span class="comment">//取得key的hash值</span></span><br><span class="line">        <span class="keyword">int</span> binCount = <span class="number">0</span>;    <span class="comment">//用来计算在这个节点总共有多少个元素，用来控制扩容或者转移为树</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;K,V&gt;[] tab = table;;) &#123;    <span class="comment">//</span></span><br><span class="line">            Node&lt;K,V&gt; f; <span class="keyword">int</span> n, i, fh;</span><br><span class="line">            <span class="keyword">if</span> (tab == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)    </span><br><span class="line">                tab = initTable();    <span class="comment">//第一次put的时候table没有初始化，则初始化table</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((f = tabAt(tab, i = (n - <span class="number">1</span>) &amp; hash)) == <span class="keyword">null</span>) &#123;    <span class="comment">//通过哈希计算出一个表中的位置因为n是数组的长度，所以(n-1)&amp;hash肯定不会出现数组越界</span></span><br><span class="line">                <span class="keyword">if</span> (casTabAt(tab, i, <span class="keyword">null</span>,        <span class="comment">//如果这个位置没有元素的话，则通过cas的方式尝试添加，注意这个时候是没有加锁的</span></span><br><span class="line">                             <span class="keyword">new</span> Node&lt;K,V&gt;(hash, key, value, <span class="keyword">null</span>)))        <span class="comment">//创建一个Node添加到数组中区，null表示的是下一个节点为空</span></span><br><span class="line">                    <span class="keyword">break</span>;                   <span class="comment">// no lock when adding to empty bin</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 如果检测到某个节点的hash值是MOVED，则表示正在进行数组扩张的数据复制阶段，</span></span><br><span class="line"><span class="comment">             * 则当前线程也会参与去复制，通过允许多线程复制的功能，一次来减少数组的复制所带来的性能损失</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((fh = f.hash) == MOVED)    </span><br><span class="line">                tab = helpTransfer(tab, f);</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                 * 如果在这个位置有元素的话，就采用synchronized的方式加锁，</span></span><br><span class="line"><span class="comment">                 *     如果是链表的话(hash大于0)，就对这个链表的所有元素进行遍历，</span></span><br><span class="line"><span class="comment">                 *         如果找到了key和key的hash值都一样的节点，则把它的值替换到</span></span><br><span class="line"><span class="comment">                 *         如果没找到的话，则添加在链表的最后面</span></span><br><span class="line"><span class="comment">                 *  否则，是树的话，则调用putTreeVal方法添加到树中去</span></span><br><span class="line"><span class="comment">                 *  </span></span><br><span class="line"><span class="comment">                 *  在添加完之后，会对该节点上关联的的数目进行判断，</span></span><br><span class="line"><span class="comment">                 *  如果在8个以上的话，则会调用treeifyBin方法，来尝试转化为树，或者是扩容</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                V oldVal = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">synchronized</span> (f) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (tabAt(tab, i) == f) &#123;        <span class="comment">//再次取出要存储的位置的元素，跟前面取出来的比较</span></span><br><span class="line">                        <span class="keyword">if</span> (fh &gt;= <span class="number">0</span>) &#123;                <span class="comment">//取出来的元素的hash值大于0，当转换为树之后，hash值为-2</span></span><br><span class="line">                            binCount = <span class="number">1</span>;            </span><br><span class="line">                            <span class="keyword">for</span> (Node&lt;K,V&gt; e = f;; ++binCount) &#123;    <span class="comment">//遍历这个链表</span></span><br><span class="line">                                K ek;</span><br><span class="line">                                <span class="keyword">if</span> (e.hash == hash &amp;&amp;        <span class="comment">//要存的元素的hash，key跟要存储的位置的节点的相同的时候，替换掉该节点的value即可</span></span><br><span class="line">                                    ((ek = e.key) == key ||</span><br><span class="line">                                     (ek != <span class="keyword">null</span> &amp;&amp; key.equals(ek)))) &#123;</span><br><span class="line">                                    oldVal = e.val;</span><br><span class="line">                                    <span class="keyword">if</span> (!onlyIfAbsent)        <span class="comment">//当使用putIfAbsent的时候，只有在这个key没有设置值得时候才设置</span></span><br><span class="line">                                        e.val = value;</span><br><span class="line">                                    <span class="keyword">break</span>;</span><br><span class="line">                                &#125;</span><br><span class="line">                                Node&lt;K,V&gt; pred = e;</span><br><span class="line">                                <span class="keyword">if</span> ((e = e.next) == <span class="keyword">null</span>) &#123;    <span class="comment">//如果不是同样的hash，同样的key的时候，则判断该节点的下一个节点是否为空，</span></span><br><span class="line">                                    pred.next = <span class="keyword">new</span> Node&lt;K,V&gt;(hash, key,        <span class="comment">//为空的话把这个要加入的节点设置为当前节点的下一个节点</span></span><br><span class="line">                                                              value, <span class="keyword">null</span>);</span><br><span class="line">                                    <span class="keyword">break</span>;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span> <span class="keyword">if</span> (f <span class="keyword">instanceof</span> TreeBin) &#123;    <span class="comment">//表示已经转化成红黑树类型了</span></span><br><span class="line">                            Node&lt;K,V&gt; p;</span><br><span class="line">                            binCount = <span class="number">2</span>;</span><br><span class="line">                            <span class="keyword">if</span> ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,    <span class="comment">//调用putTreeVal方法，将该元素添加到树中去</span></span><br><span class="line">                                                           value)) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                                oldVal = p.val;</span><br><span class="line">                                <span class="keyword">if</span> (!onlyIfAbsent)</span><br><span class="line">                                    p.val = value;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (binCount != <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD)    <span class="comment">//当在同一个节点的数目达到8个的时候，则扩张数组或将给节点的数据转为tree</span></span><br><span class="line">                        treeifyBin(tab, i);    </span><br><span class="line">                    <span class="keyword">if</span> (oldVal != <span class="keyword">null</span>)</span><br><span class="line">                        <span class="keyword">return</span> oldVal;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        addCount(<span class="number">1L</span>, binCount);    <span class="comment">//计数</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="ConcurrentHashMap的扩容详解"><a href="#ConcurrentHashMap的扩容详解" class="headerlink" title="ConcurrentHashMap的扩容详解"></a><strong>ConcurrentHashMap的扩容详解</strong></h2><p>在put方法的详解中，我们可以看到，在同一个节点的个数超过8个的时候，会调用treeifyBin方法来看看是扩容还是转化为一棵树</p><p>同时在每次添加完元素的addCount方法中，也会判断当前数组中的元素是否达到了sizeCtl的量，如果达到了的话，则会进入transfer方法去扩容</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Replaces all linked nodes in bin at given index unless table is</span></span><br><span class="line"><span class="comment">     * too small, in which case resizes instead.</span></span><br><span class="line"><span class="comment">     * 当数组长度小于64的时候，扩张数组长度一倍，否则的话把链表转为树</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">treeifyBin</span><span class="params">(Node&lt;K,V&gt;[] tab, <span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">        Node&lt;K,V&gt; b; <span class="keyword">int</span> n, sc;</span><br><span class="line">        <span class="keyword">if</span> (tab != <span class="keyword">null</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;treeifyBin方\t==&gt;数组长：&quot;</span>+tab.length);</span><br><span class="line">            <span class="keyword">if</span> ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY)    <span class="comment">//MIN_TREEIFY_CAPACITY 64</span></span><br><span class="line">                tryPresize(n &lt;&lt; <span class="number">1</span>);        <span class="comment">// 数组扩容</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((b = tabAt(tab, index)) != <span class="keyword">null</span> &amp;&amp; b.hash &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (b) &#123;    <span class="comment">//使用synchronized同步器，将该节点出的链表转为树</span></span><br><span class="line">                    <span class="keyword">if</span> (tabAt(tab, index) == b) &#123;</span><br><span class="line">                        TreeNode&lt;K,V&gt; hd = <span class="keyword">null</span>, tl = <span class="keyword">null</span>;    <span class="comment">//hd：树的头(head)</span></span><br><span class="line">                        <span class="keyword">for</span> (Node&lt;K,V&gt; e = b; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line">                            TreeNode&lt;K,V&gt; p =</span><br><span class="line">                                <span class="keyword">new</span> TreeNode&lt;K,V&gt;(e.hash, e.key, e.val,</span><br><span class="line">                                                  <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">                            <span class="keyword">if</span> ((p.prev = tl) == <span class="keyword">null</span>)        <span class="comment">//把Node组成的链表，转化为TreeNode的链表，头结点任然放在相同的位置</span></span><br><span class="line">                                hd = p;    <span class="comment">//设置head</span></span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                tl.next = p;</span><br><span class="line">                            tl = p;</span><br><span class="line">                        &#125;</span><br><span class="line">                        setTabAt(tab, index, <span class="keyword">new</span> TreeBin&lt;K,V&gt;(hd));<span class="comment">//把TreeNode的链表放入容器TreeBin中</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>可以看到当需要扩容的时候，调用的时候tryPresize方法，看看trePresize的源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 扩容表为指可以容纳指定个数的大小（总是2的N次方）</span></span><br><span class="line"><span class="comment">     * 假设原来的数组长度为16，则在调用tryPresize的时候，size参数的值为16&lt;&lt;1(32)，此时sizeCtl的值为12</span></span><br><span class="line"><span class="comment">     * 计算出来c的值为64,则要扩容到sizeCtl≥为止</span></span><br><span class="line"><span class="comment">     *  第一次扩容之后 数组长：32 sizeCtl：24</span></span><br><span class="line"><span class="comment">     *  第二次扩容之后 数组长：64 sizeCtl：48</span></span><br><span class="line"><span class="comment">     *  第二次扩容之后 数组长：128 sizeCtl：94 --&gt; 这个时候才会退出扩容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">tryPresize</span><span class="params">(<span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * MAXIMUM_CAPACITY = 1 &lt;&lt; 30</span></span><br><span class="line"><span class="comment">             * 如果给定的大小大于等于数组容量的一半，则直接使用最大容量，</span></span><br><span class="line"><span class="comment">             * 否则使用tableSizeFor算出来</span></span><br><span class="line"><span class="comment">             * 后面table一直要扩容到这个值小于等于sizeCtrl(数组长度的3/4)才退出扩容</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">        <span class="keyword">int</span> c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; <span class="number">1</span>)) ? MAXIMUM_CAPACITY :</span><br><span class="line">            tableSizeFor(size + (size &gt;&gt;&gt; <span class="number">1</span>) + <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">int</span> sc;</span><br><span class="line">        <span class="keyword">while</span> ((sc = sizeCtl) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            Node&lt;K,V&gt;[] tab = table; <span class="keyword">int</span> n;</span><br><span class="line"><span class="comment">//            printTable(tab);    调试用的</span></span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 如果数组table还没有被初始化，则初始化一个大小为sizeCtrl和刚刚算出来的c中较大的一个大小的数组</span></span><br><span class="line"><span class="comment">             * 初始化的时候，设置sizeCtrl为-1，初始化完成之后把sizeCtrl设置为数组长度的3/4</span></span><br><span class="line"><span class="comment">             * 为什么要在扩张的地方来初始化数组呢？这是因为如果第一次put的时候不是put单个元素，</span></span><br><span class="line"><span class="comment">             * 而是调用putAll方法直接put一个map的话，在putALl方法中没有调用initTable方法去初始化table，</span></span><br><span class="line"><span class="comment">             * 而是直接调用了tryPresize方法，所以这里需要做一个是不是需要初始化table的判断</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">if</span> (tab == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>) &#123;</span><br><span class="line">                n = (sc &gt; c) ? sc : c;</span><br><span class="line">                <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc, -<span class="number">1</span>)) &#123;    <span class="comment">//初始化tab的时候，把sizeCtl设为-1</span></span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="keyword">if</span> (table == tab) &#123;</span><br><span class="line">                            <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">                            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node&lt;?,?&gt;[n];</span><br><span class="line">                            table = nt;</span><br><span class="line">                            sc = n - (n &gt;&gt;&gt; <span class="number">2</span>);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                        sizeCtl = sc;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 一直扩容到的c小于等于sizeCtl或者数组长度大于最大长度的时候，则退出</span></span><br><span class="line"><span class="comment">             * 所以在一次扩容之后，不是原来长度的两倍，而是2的n次方倍</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;    <span class="comment">//退出扩张</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (tab == table) &#123;</span><br><span class="line">                <span class="keyword">int</span> rs = resizeStamp(n);</span><br><span class="line">                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                 * 如果正在扩容Table的话，则帮助扩容</span></span><br><span class="line"><span class="comment">                 * 否则的话，开始新的扩容</span></span><br><span class="line"><span class="comment">                 * 在transfer操作，将第一个参数的table中的元素，移动到第二个元素的table中去，</span></span><br><span class="line"><span class="comment">                 * 虽然此时第二个参数设置的是null，但是，在transfer方法中，当第二个参数为null的时候，</span></span><br><span class="line"><span class="comment">                 * 会创建一个两倍大小的table</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="keyword">if</span> (sc &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                    Node&lt;K,V&gt;[] nt;</span><br><span class="line">                    <span class="keyword">if</span> ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + <span class="number">1</span> ||</span><br><span class="line">                        sc == rs + MAX_RESIZERS || (nt = nextTable) == <span class="keyword">null</span> ||</span><br><span class="line">                        transferIndex &lt;= <span class="number">0</span>)</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="comment">/*</span></span><br><span class="line"><span class="comment">                     * transfer的线程数加一,该线程将进行transfer的帮忙</span></span><br><span class="line"><span class="comment">                     * 在transfer的时候，sc表示在transfer工作的线程数</span></span><br><span class="line"><span class="comment">                     */</span></span><br><span class="line">                    <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc, sc + <span class="number">1</span>))</span><br><span class="line">                        transfer(tab, nt);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                 * 没有在初始化或扩容，则开始扩容</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc,</span><br><span class="line">                                             (rs &lt;&lt; RESIZE_STAMP_SHIFT) + <span class="number">2</span>)) &#123;</span><br><span class="line">                        transfer(tab, <span class="keyword">null</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>在tryPresize方法中，并没有加锁，允许多个线程进入，如果数组正在扩张，则当前线程也去帮助扩容。</p><p>数组扩容的主要方法就是transfer方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Moves and/or copies the nodes in each bin to new table. See</span></span><br><span class="line"><span class="comment">     * above for explanation.</span></span><br><span class="line"><span class="comment">     * 把数组中的节点复制到新的数组的相同位置，或者移动到扩张部分的相同位置</span></span><br><span class="line"><span class="comment">     * 在这里首先会计算一个步长，表示一个线程处理的数组长度，用来控制对CPU的使用，</span></span><br><span class="line"><span class="comment">     * 每个CPU最少处理16个长度的数组元素,也就是说，如果一个数组的长度只有16，那只有一个线程会对其进行扩容的复制移动操作</span></span><br><span class="line"><span class="comment">     * 扩容的时候会一直遍历，知道复制完所有节点，每处理一个节点的时候会在链表的头部设置一个fwd节点，这样其他线程就会跳过他，</span></span><br><span class="line"><span class="comment">     * 复制后在新数组中的链表不是绝对的反序的</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = tab.length, stride;</span><br><span class="line">        <span class="keyword">if</span> ((stride = (NCPU &gt; <span class="number">1</span>) ? (n &gt;&gt;&gt; <span class="number">3</span>) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)    <span class="comment">//MIN_TRANSFER_STRIDE 用来控制不要占用太多CPU</span></span><br><span class="line">            stride = MIN_TRANSFER_STRIDE; <span class="comment">// subdivide range    //MIN_TRANSFER_STRIDE=16</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 如果复制的目标nextTab为null的话，则初始化一个table两倍长的nextTab</span></span><br><span class="line"><span class="comment">         * 此时nextTable被设置值了(在初始情况下是为null的)</span></span><br><span class="line"><span class="comment">         * 因为如果有一个线程开始了表的扩张的时候，其他线程也会进来帮忙扩张，</span></span><br><span class="line"><span class="comment">         * 而只是第一个开始扩张的线程需要初始化下目标数组</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (nextTab == <span class="keyword">null</span>) &#123;            <span class="comment">// initiating</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">                Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node&lt;?,?&gt;[n &lt;&lt; <span class="number">1</span>];</span><br><span class="line">                nextTab = nt;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Throwable ex) &#123;      <span class="comment">// try to cope with OOME</span></span><br><span class="line">                sizeCtl = Integer.MAX_VALUE;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            nextTable = nextTab;</span><br><span class="line">            transferIndex = n;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> nextn = nextTab.length;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 创建一个fwd节点，这个是用来控制并发的，当一个节点为空或已经被转移之后，就设置为fwd节点</span></span><br><span class="line"><span class="comment">         * 这是一个空的标志节点</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        ForwardingNode&lt;K,V&gt; fwd = <span class="keyword">new</span> ForwardingNode&lt;K,V&gt;(nextTab);</span><br><span class="line">        <span class="keyword">boolean</span> advance = <span class="keyword">true</span>;    <span class="comment">//是否继续向前查找的标志位</span></span><br><span class="line">        <span class="keyword">boolean</span> finishing = <span class="keyword">false</span>; <span class="comment">// to ensure sweep(清扫) before committing nextTab,在完成之前重新在扫描一遍数组，看看有没完成的没</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, bound = <span class="number">0</span>;;) &#123;</span><br><span class="line">            Node&lt;K,V&gt; f; <span class="keyword">int</span> fh;</span><br><span class="line">            <span class="keyword">while</span> (advance) &#123;</span><br><span class="line">                <span class="keyword">int</span> nextIndex, nextBound;</span><br><span class="line">                <span class="keyword">if</span> (--i &gt;= bound || finishing) &#123;</span><br><span class="line">                    advance = <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> ((nextIndex = transferIndex) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    i = -<span class="number">1</span>;</span><br><span class="line">                    advance = <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (U.compareAndSwapInt</span><br><span class="line">                         (<span class="keyword">this</span>, TRANSFERINDEX, nextIndex,</span><br><span class="line">                          nextBound = (nextIndex &gt; stride ?</span><br><span class="line">                                       nextIndex - stride : <span class="number">0</span>))) &#123;</span><br><span class="line">                    bound = nextBound;</span><br><span class="line">                    i = nextIndex - <span class="number">1</span>;</span><br><span class="line">                    advance = <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; <span class="number">0</span> || i &gt;= n || i + n &gt;= nextn) &#123;</span><br><span class="line">                <span class="keyword">int</span> sc;</span><br><span class="line">                <span class="keyword">if</span> (finishing) &#123;        <span class="comment">//已经完成转移</span></span><br><span class="line">                    nextTable = <span class="keyword">null</span>;</span><br><span class="line">                    table = nextTab;</span><br><span class="line">                    sizeCtl = (n &lt;&lt; <span class="number">1</span>) - (n &gt;&gt;&gt; <span class="number">1</span>);    <span class="comment">//设置sizeCtl为扩容后的0.75</span></span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc = sizeCtl, sc - <span class="number">1</span>)) &#123;</span><br><span class="line">                    <span class="keyword">if</span> ((sc - <span class="number">2</span>) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) &#123;</span><br><span class="line">                            <span class="keyword">return</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    finishing = advance = <span class="keyword">true</span>;</span><br><span class="line">                    i = n; <span class="comment">// recheck before commit</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((f = tabAt(tab, i)) == <span class="keyword">null</span>)            <span class="comment">//数组中把null的元素设置为ForwardingNode节点(hash值为MOVED[-1])</span></span><br><span class="line">                advance = casTabAt(tab, i, <span class="keyword">null</span>, fwd);</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((fh = f.hash) == MOVED)</span><br><span class="line">                advance = <span class="keyword">true</span>; <span class="comment">// already processed</span></span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (f) &#123;                <span class="comment">//加锁操作</span></span><br><span class="line">                    <span class="keyword">if</span> (tabAt(tab, i) == f) &#123;</span><br><span class="line">                        Node&lt;K,V&gt; ln, hn;</span><br><span class="line">                        <span class="keyword">if</span> (fh &gt;= <span class="number">0</span>) &#123;        <span class="comment">//该节点的hash值大于等于0，说明是一个Node节点</span></span><br><span class="line">                                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                                 * 因为n的值为数组的长度，且是power(2,x)的，所以，在&amp;操作的结果只可能是0或者n</span></span><br><span class="line"><span class="comment">                                 * 根据这个规则</span></span><br><span class="line"><span class="comment">                                 *         0--&gt;  放在新表的相同位置</span></span><br><span class="line"><span class="comment">                                 *         n--&gt;  放在新表的（n+原来位置）</span></span><br><span class="line"><span class="comment">                                 */</span></span><br><span class="line">                            <span class="keyword">int</span> runBit = fh &amp; n; </span><br><span class="line">                            Node&lt;K,V&gt; lastRun = f;</span><br><span class="line">                            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                             * lastRun 表示的是需要复制的最后一个节点</span></span><br><span class="line"><span class="comment">                             * 每当新节点的hash&amp;n -&gt; b 发生变化的时候，就把runBit设置为这个结果b</span></span><br><span class="line"><span class="comment">                             * 这样for循环之后，runBit的值就是最后不变的hash&amp;n的值</span></span><br><span class="line"><span class="comment">                             * 而lastRun的值就是最后一次导致hash&amp;n 发生变化的节点(假设为p节点)</span></span><br><span class="line"><span class="comment">                             * 为什么要这么做呢？因为p节点后面的节点的hash&amp;n 值跟p节点是一样的，</span></span><br><span class="line"><span class="comment">                             * 所以在复制到新的table的时候，它肯定还是跟p节点在同一个位置</span></span><br><span class="line"><span class="comment">                             * 在复制完p节点之后，p节点的next节点还是指向它原来的节点，就不需要进行复制了，自己就被带过去了</span></span><br><span class="line"><span class="comment">                             * 这也就导致了一个问题就是复制后的链表的顺序并不一定是原来的倒序</span></span><br><span class="line"><span class="comment">                             */</span></span><br><span class="line">                            <span class="keyword">for</span> (Node&lt;K,V&gt; p = f.next; p != <span class="keyword">null</span>; p = p.next) &#123;</span><br><span class="line">                                <span class="keyword">int</span> b = p.hash &amp; n;    <span class="comment">//n的值为扩张前的数组的长度</span></span><br><span class="line">                                <span class="keyword">if</span> (b != runBit) &#123;</span><br><span class="line">                                    runBit = b;</span><br><span class="line">                                    lastRun = p;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">if</span> (runBit == <span class="number">0</span>) &#123;</span><br><span class="line">                                ln = lastRun;</span><br><span class="line">                                hn = <span class="keyword">null</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">else</span> &#123;</span><br><span class="line">                                hn = lastRun;</span><br><span class="line">                                ln = <span class="keyword">null</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                             * 构造两个链表，顺序大部分和原来是反的</span></span><br><span class="line"><span class="comment">                             * 分别放到原来的位置和新增加的长度的相同位置(i/n+i)</span></span><br><span class="line"><span class="comment">                             */</span></span><br><span class="line">                            <span class="keyword">for</span> (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123;</span><br><span class="line">                                <span class="keyword">int</span> ph = p.hash; K pk = p.key; V pv = p.val;</span><br><span class="line">                                <span class="keyword">if</span> ((ph &amp; n) == <span class="number">0</span>)</span><br><span class="line">                                        <span class="comment">/*</span></span><br><span class="line"><span class="comment">                                         * 假设runBit的值为0，</span></span><br><span class="line"><span class="comment">                                         * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同为0的节点)设置到旧的table的第一个hash计算后为0的节点下一个节点</span></span><br><span class="line"><span class="comment">                                         * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点</span></span><br><span class="line"><span class="comment">                                         */</span></span><br><span class="line">                                    ln = <span class="keyword">new</span> Node&lt;K,V&gt;(ph, pk, pv, ln);</span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line">                                        <span class="comment">/*</span></span><br><span class="line"><span class="comment">                                         * 假设runBit的值不为0，</span></span><br><span class="line"><span class="comment">                                         * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同不为0的节点)设置到旧的table的第一个hash计算后不为0的节点下一个节点</span></span><br><span class="line"><span class="comment">                                         * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点</span></span><br><span class="line"><span class="comment">                                         */</span></span><br><span class="line">                                    hn = <span class="keyword">new</span> Node&lt;K,V&gt;(ph, pk, pv, hn);    </span><br><span class="line">                            &#125;</span><br><span class="line">                            setTabAt(nextTab, i, ln);    </span><br><span class="line">                            setTabAt(nextTab, i + n, hn);</span><br><span class="line">                            setTabAt(tab, i, fwd);</span><br><span class="line">                            advance = <span class="keyword">true</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span> <span class="keyword">if</span> (f <span class="keyword">instanceof</span> TreeBin) &#123;    <span class="comment">//否则的话是一个树节点</span></span><br><span class="line">                            TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;</span><br><span class="line">                            TreeNode&lt;K,V&gt; lo = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                            TreeNode&lt;K,V&gt; hi = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                            <span class="keyword">int</span> lc = <span class="number">0</span>, hc = <span class="number">0</span>;</span><br><span class="line">                            <span class="keyword">for</span> (Node&lt;K,V&gt; e = t.first; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line">                                <span class="keyword">int</span> h = e.hash;</span><br><span class="line">                                TreeNode&lt;K,V&gt; p = <span class="keyword">new</span> TreeNode&lt;K,V&gt;</span><br><span class="line">                                    (h, e.key, e.val, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">                                <span class="keyword">if</span> ((h &amp; n) == <span class="number">0</span>) &#123;</span><br><span class="line">                                    <span class="keyword">if</span> ((p.prev = loTail) == <span class="keyword">null</span>)</span><br><span class="line">                                        lo = p;</span><br><span class="line">                                    <span class="keyword">else</span></span><br><span class="line">                                        loTail.next = p;</span><br><span class="line">                                    loTail = p;</span><br><span class="line">                                    ++lc;</span><br><span class="line">                                &#125;</span><br><span class="line">                                <span class="keyword">else</span> &#123;</span><br><span class="line">                                    <span class="keyword">if</span> ((p.prev = hiTail) == <span class="keyword">null</span>)</span><br><span class="line">                                        hi = p;</span><br><span class="line">                                    <span class="keyword">else</span></span><br><span class="line">                                        hiTail.next = p;</span><br><span class="line">                                    hiTail = p;</span><br><span class="line">                                    ++hc;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                             * 在复制完树节点之后，判断该节点处构成的树还有几个节点，</span></span><br><span class="line"><span class="comment">                             * 如果≤6个的话，就转回为一个链表</span></span><br><span class="line"><span class="comment">                             */</span></span><br><span class="line">                            ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :</span><br><span class="line">                                (hc != <span class="number">0</span>) ? <span class="keyword">new</span> TreeBin&lt;K,V&gt;(lo) : t;</span><br><span class="line">                            hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :</span><br><span class="line">                                (lc != <span class="number">0</span>) ? <span class="keyword">new</span> TreeBin&lt;K,V&gt;(hi) : t;</span><br><span class="line">                            setTabAt(nextTab, i, ln);</span><br><span class="line">                            setTabAt(nextTab, i + n, hn);</span><br><span class="line">                            setTabAt(tab, i, fwd);</span><br><span class="line">                            advance = <span class="keyword">true</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>到这里，ConcurrentHashMap的put操作和扩容都介绍的差不多了，</p><p>下面的两点一定要注意：</p><ul><li><p>复制之后的新链表不是旧链表的绝对倒序。</p></li><li><p>在扩容的时候每个线程都有处理的步长，最少为16，在这个步长范围内的数组节点只有自己一个线程来处理</p></li></ul><h2 id="ConcurrentHashMap的get操作详解"><a href="#ConcurrentHashMap的get操作详解" class="headerlink" title="ConcurrentHashMap的get操作详解"></a><strong>ConcurrentHashMap的get操作详解</strong></h2><p>相比put操作，get操作就显得很简单了。废话少说，直接上源码分析。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 相比put方法，get就很单纯了，支持并发操作，</span></span><br><span class="line"><span class="comment">     * 当key为null的时候回抛出NullPointerException的异常</span></span><br><span class="line"><span class="comment">     * get操作通过首先计算key的hash值来确定该元素放在数组的哪个位置</span></span><br><span class="line"><span class="comment">     * 然后遍历该位置的所有节点</span></span><br><span class="line"><span class="comment">     * 如果不存在的话返回null</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; <span class="keyword">int</span> n, eh; K ek;</span><br><span class="line">        <span class="keyword">int</span> h = spread(key.hashCode());</span><br><span class="line">        <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">            (e = tabAt(tab, (n - <span class="number">1</span>) &amp; h)) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> ((eh = e.hash) == h) &#123;</span><br><span class="line">                <span class="keyword">if</span> ((ek = e.key) == key || (ek != <span class="keyword">null</span> &amp;&amp; key.equals(ek)))</span><br><span class="line">                    <span class="keyword">return</span> e.val;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (eh &lt; <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span> (p = e.find(h, key)) != <span class="keyword">null</span> ? p.val : <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (e.hash == h &amp;&amp;</span><br><span class="line">                    ((ek = e.key) == key || (ek != <span class="keyword">null</span> &amp;&amp; key.equals(ek))))</span><br><span class="line">                    <span class="keyword">return</span> e.val;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>前面分析了下ConcurrentHashMap的源码，那么，对于一个映射集合来说，ConcurrentHashMap是如果来做到并发安全，又是如何做到高效的并发的呢？</p><p>首先是读操作，从源码中可以看出来，在get操作中，根本没有使用同步机制，也没有使用unsafe方法，所以读操作是支持并发操作的。</p><p>那么写操作呢？</p><p>分析这个之前，先看看什么情况下会引起数组的扩容，扩容是通过transfer方法来进行的。而调用transfer方法的只有trePresize、helpTransfer和addCount三个方法。</p><p>这三个方法又是分别在什么情况下进行调用的呢？</p><p>tryPresize是在treeIfybin和putAll方法中调用，treeIfybin主要是在put添加元素完之后，判断该数组节点相关元素是不是已经超过8个的时候，如果超过则会调用这个方法来扩容数组或者把链表转为树。</p><p>helpTransfer是在当一个线程要对table中元素进行操作的时候，如果检测到节点的HASH值为MOVED的时候，就会调用helpTransfer方法，在helpTransfer中再调用transfer方法来帮助完成数组的扩容</p><p>addCount是在当对数组进行操作，使得数组中存储的元素个数发生了变化的时候会调用的方法。</p><p>　　</p><p><strong>所以引起数组扩容的情况如下</strong>：</p><p>只有在往map中添加元素的时候，在某一个节点的数目已经超过了8个，同时数组的长度又小于64的时候，才会触发数组的扩容。</p><p>当数组中元素达到了sizeCtl的数量的时候，则会调用transfer方法来进行扩容</p><p>　　</p><p><strong>那么在扩容的时候，可以不可以对数组进行读写操作呢？</strong></p><p>事实上是可以的。当在进行数组扩容的时候，如果当前节点还没有被处理（也就是说还没有设置为fwd节点），那就可以进行设置操作。</p><p>如果该节点已经被处理了，则当前线程也会加入到扩容的操作中去。</p><p>　　</p><p><strong>那么，多个线程又是如何同步处理的呢？</strong></p><p>在ConcurrentHashMap中，同步处理主要是通过Synchronized和unsafe两种方式来完成的。</p><p>在取得sizeCtl、某个位置的Node的时候，使用的都是unsafe的方法，来达到并发安全的目的</p><p>当需要在某个位置设置节点的时候，则会通过Synchronized的同步机制来锁定该位置的节点。</p><p>在数组扩容的时候，则通过处理的步长和fwd节点来达到并发安全的目的，通过设置hash值为MOVED</p><p>当把某个位置的节点复制到扩张后的table的时候，也通过Synchronized的同步机制来保证现程安全</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ConcurrentHashMap跟HashMap，HashTable的对比&quot;&gt;&lt;a href=&quot;#ConcurrentHashMap跟HashMap，HashTable的对比&quot; class=&quot;headerlink&quot; title=&quot;ConcurrentHashMa</summary>
      
    
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/categories/Collection/"/>
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/tags/Collection/"/>
    
  </entry>
  
  <entry>
    <title>06.MySQL的主从复制</title>
    <link href="https://leslieaibin.github.io/2021/09/21/MySQL/06.MySQL%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    <id>https://leslieaibin.github.io/2021/09/21/MySQL/06.MySQL%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</id>
    <published>2021-09-21T12:17:42.000Z</published>
    <updated>2021-09-21T08:38:02.552Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL-BinLog"><a href="#MySQL-BinLog" class="headerlink" title="MySQL BinLog"></a>MySQL BinLog</h1><p>MySQL 的 Binlog 日志是一种二进制格式的日志，Binlog记录所有的DDL和DML语句（除了数据查询语句Select， show 等），以Event的形式记录，同时记录语句执行时间。</p><p>BInlog的 主要作用有两种：</p><ul><li><p>数据恢复：</p><p>因为Binlog详细记录所有修改数据的SQL，当某一个时刻的数据误操作而导致出问题，或者数据库当局数据丢失，那么可以根据binlog回放历史数据</p></li><li><p>主从复制</p><p>想做多级备份的业务，可以去监听当前写库的Binlog日志，同步写库的所有更改</p></li></ul><p>Binlog包括两类文件</p><ul><li>二进制日志索引文件（.index）：记录所有的二进制文件</li><li>二进制日志文件(.00000*)：记录所有DDL和DML语句事件</li></ul><p>Binlog日志功能默认是开启的，线上情况下的Binlog日志的增长速度是很快的，在MySQL配置文件<code>my.cnf</code> 中提供一些参数来对 Binlog 进行设置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">设置此参数表示启用binlog功能，并制定二进制日志的存储目录</span><br><span class="line">log-<span class="built_in">bin</span>=/home/mysql/binlog/</span><br><span class="line"></span><br><span class="line"><span class="comment">#mysql-bin.*日志文件最大字节（单位：字节）</span></span><br><span class="line"><span class="comment">#设置最大100MB</span></span><br><span class="line">max_binlog_size=<span class="number">104857600</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#设置了只保留7天BINLOG（单位：天）</span></span><br><span class="line">expire_logs_days = <span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#binlog日志只记录指定库的更新</span></span><br><span class="line"><span class="comment">#binlog-do-db=db_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#binlog日志不记录指定库的更新</span></span><br><span class="line"><span class="comment">#binlog-ignore-db=db_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#写缓冲多少次，刷一次磁盘，默认0</span></span><br><span class="line">sync_binlog=<span class="number">0</span></span><br></pre></td></tr></table></figure><p><strong>max_binlog_size</strong> ：Binlog 最大和默认值是 1G，该设置并不能严格控制 Binlog 的大小，尤其是 Binlog 比较靠近最大值而又遇到一个比较大事务时，为了保证事务的完整性不可能做切换日志的动作，只能将该事务的所有 SQL 都记录进当前日志直到事务结束。所以真实文件有时候会大于 max_binlog_size 设定值。</p><p><strong>expire_logs_days</strong> ：Binlog 过期删除不是服务定时执行，是需要借助事件触发才执行，事件包括：</p><ul><li>服务器重启</li><li>服务器被更新</li><li>日志达到了最大日志长度 <code>max_binlog_size</code></li><li>日志被刷新</li></ul><p>二进制日志由配置文件的 <code>log-bin</code> 选项负责启用，MySQL 服务器将在数据根目录创建两个新文件<code>mysql-bin.000001</code> 和 <code>mysql-bin.index</code>，若配置选项没有给出文件名，MySQL 将使用主机名称命名这两个文件，其中 <code>.index</code> 文件包含一份全体日志文件的清单。</p><p><strong>sync_binlog</strong>：这个参数决定了 Binlog 日志的更新频率。默认 0 ，表示该操作由操作系统根据自身负载自行决定多久写一次磁盘。</p><p>sync_binlog = 1 表示每一条事务提交都会立刻写盘。sync_binlog=n 表示 n 个事务提交才会写盘。</p><p>根据 MySQL 文档，写 Binlog 的时机是：SQL transaction 执行完，但任何相关的 Locks 还未释放或事务还未最终 commit 前。这样保证了 Binlog 记录的操作时序与数据库实际的数据变更顺序一致。</p><h1 id="MySQL主从复制"><a href="#MySQL主从复制" class="headerlink" title="MySQL主从复制"></a>MySQL主从复制</h1><p>Binlog 日志主要作用是数据恢复和主从复制。本身就是二进制格式的日志文件，网络传输无需进行协议转换。MySQL集群的高可用，负载均衡，读写分类等功能都是基于Binlog来实现的</p><h2 id="MySQL主从复制主流架构模型"><a href="#MySQL主从复制主流架构模型" class="headerlink" title="MySQL主从复制主流架构模型"></a>MySQL主从复制主流架构模型</h2><p>我们基于 Binlog 可以复制出一台 MySQL 服务器，也可以复制出多台，取决于我们想实现什么功能。主流的系统架构有如下几种方式：</p><h3 id="一主一从-一主多从"><a href="#一主一从-一主多从" class="headerlink" title="一主一从 / 一主多从"></a>一主一从 / 一主多从</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mx9n5wj30lu0mwgne.jpg" alt="1"></p><p>一主一从和一主多从是最常见的主从架构方式，一般实现主从配置或者读写分离都可以采用这种架构。</p><p>如果是一主多从的模式，当 Slave 增加到一定数量时，Slave 对 Master 的负载以及网络带宽都会成为一个严重的问题。</p><h3 id="多主一从"><a href="#多主一从" class="headerlink" title="多主一从"></a>多主一从</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mt1km7j30m80l4407.jpg" alt="1"></p><p>MySQL 5.7 开始支持多主一从的模式，将多个库的数据备份到一个库中存储。</p><h3 id="双主复制"><a href="#双主复制" class="headerlink" title="双主复制"></a>双主复制</h3><p>理论上跟主从一样，但是两个MySQL服务器互做对方的从，任何一方有变更，都会复制对方的数据到自己的数据库。双主适用于写压力比较大的业务场景，或者 DBA 做维护需要主从切换的场景，通过双主架构避免了重复搭建从库的麻烦。（主从相互授权连接，读取对方binlog日志并更新到本地数据库的过程；只要对方数据改变，自己就跟着改变）</p><h3 id="级联复制"><a href="#级联复制" class="headerlink" title="级联复制"></a>级联复制</h3><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mr6mxzj30z60hg40u.jpg" alt="1"></p><p>级联模式下因为涉及到的 slave 节点很多，所以如果都连在 master 上对主服务器的压力肯定是不小的。所以部分 slave 节点连接到它上一级的从节点上。这样就缓解了主服务器的压力。</p><p>级联复制解决了一主多从场景下多个从库复制对主库的压力，带来的弊端就是数据同步延迟比较大。</p><h2 id="MySQL-主从复制原理"><a href="#MySQL-主从复制原理" class="headerlink" title="MySQL 主从复制原理"></a>MySQL 主从复制原理</h2><p>MySQL 主从复制涉及到三个线程：</p><ul><li>一个在主节点的线程：<code>log dump thread</code></li><li>从库会生成两个线程：一个 I/O 线程，一个 SQL 线程</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1ms5ezhj312s0imtb5.jpg" alt="4"></p><p>主库会生成一个 log dump 线程,用来给从库 I/O 线程传 Binlog 数据。</p><p>从库的 I/O 线程会去请求主库的 Binlog，并将得到的 Binlog 写到本地的 relay log (中继日志)文件中。</p><p>SQL 线程,会读取 relay log 文件中的日志，并解析成 SQL 语句逐一执行。</p><h5 id="主节点-log-dump-线程"><a href="#主节点-log-dump-线程" class="headerlink" title="主节点 log dump 线程"></a>主节点 log dump 线程</h5><p>当从节点连接主节点时，主节点会为其创建一个 log dump 线程，用于发送和读取 Binlog 的内容。在读取 Binlog 中的操作时，log dump 线程会对主节点上的 Binlog 加锁；当读取完成发送给从节点之前，锁会被释放。<strong>主节点会为自己的每一个从节点创建一个 log dump 线程</strong>。</p><h5 id="从节点I-O线程"><a href="#从节点I-O线程" class="headerlink" title="从节点I/O线程"></a>从节点I/O线程</h5><p>当从节点上执行<code>start slave</code>命令之后，从节点会创建一个 I/O 线程用来连接主节点，请求主库中更新的Binlog。I/O 线程接收到主节点的 log dump 进程发来的更新之后，保存在本地 relay-log（中继日志）中。</p><h5 id="relay-log"><a href="#relay-log" class="headerlink" title="relay log"></a>relay log</h5><p>这里又引申出一个新的日志概念。MySQL 进行主主复制或主从复制的时候会在要复制的服务器下面产生相应的 relay log。</p><p>relay log 是怎么产生的呢？</p><p>从服务器 I/O 线程将主服务器的 Binlog 日志读取过来，解析到各类 Events 之后记录到从服务器本地文件，这个文件就被称为 relay log。然后 SQL 线程会读取 relay log 日志的内容并应用到从服务器，从而使从服务器和主服务器的数据保持一致。中继日志充当缓冲区，这样 master 就不必等待 slave 执行完成才发送下一个事件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt;  show variables like &#39;%relay%&#39;;</span><br><span class="line">+---------------------------+------------------------------------------------------------+</span><br><span class="line">| Variable_name             | Value                                                      |</span><br><span class="line">+---------------------------+------------------------------------------------------------+</span><br><span class="line">| max_relay_log_size        | 0                                                          |</span><br><span class="line">| relay_log                 | yangyuedeMacBook-Pro-relay-bin                             |</span><br><span class="line">| relay_log_basename        | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;yangyuedeMacBook-Pro-relay-bin       |</span><br><span class="line">| relay_log_index           | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;yangyuedeMacBook-Pro-relay-bin.index |</span><br><span class="line">| relay_log_info_file       | relay-log.info                                             |</span><br><span class="line">| relay_log_info_repository | TABLE                                                      |</span><br><span class="line">| relay_log_purge           | ON                                                         |</span><br><span class="line">| relay_log_recovery        | OFF                                                        |</span><br><span class="line">| relay_log_space_limit     | 0                                                          |</span><br><span class="line">| sync_relay_log            | 10000                                                      |</span><br><span class="line">| sync_relay_log_info       | 10000                                                      |</span><br><span class="line">+---------------------------+------------------------------------------------------------+</span><br><span class="line">11 rows in set (0.03 sec)</span><br></pre></td></tr></table></figure><p><strong>max_relay_log_size</strong></p><p>标记 relay log 允许的最大值，如果该值为 0，则默认值为 max_binlog_size(1G)；如果不为 0，则max_relay_log_size 则为最大的 relay_log 文件大小。</p><p><strong>relay_log_purge</strong></p><p>是否自动清空不再需要中继日志时。默认值为1(启用)。</p><p><strong>relay_log_recovery</strong></p><p>当 slave 从库宕机后，假如 relay log 损坏了，导致一部分中继日志没有处理，则自动放弃所有未执行的 relay log，并且重新从 master 上获取日志，这样就保证了 relay log 的完整性。默认情况下该功能是关闭的，将 relay_log_recovery 的值设置为 1 时，可在 slave 从库上开启该功能，建议开启。</p><p><strong>relay_log_space_limit</strong></p><p>防止中继日志写满磁盘，这里设置中继日志最大限额。但此设置存在主库崩溃，从库中继日志不全的情况，不到万不得已，<strong>不推荐使用。</strong></p><p><strong>sync_relay_log</strong></p><p>这个参数和 Binlog 中的 <code>sync_binlog</code>作用相同。当设置为 1 时，slave 的 I/O 线程每次接收到 master 发送过来的 Binlog 日志都要写入系统缓冲区，然后刷入 relay log 中继日志里，这样是最安全的，因为在崩溃的时候，你最多会丢失一个事务，但会造成磁盘的大量 I/O。</p><p>当设置为 0 时，并不是马上就刷入中继日志里，而是由操作系统决定何时来写入，虽然安全性降低了，但减少了大量的磁盘 I/O 操作。这个值默认是 0，可动态修改，建议采用默认值。</p><p><strong>sync_relay_log_info</strong></p><p>当设置为 1 时，slave 的 I/O 线程每次接收到 master 发送过来的 Binlog 日志都要写入系统缓冲区，然后刷入 relay-log.info 里，这样是最安全的，因为在崩溃的时候，你最多会丢失一个事务，但会造成磁盘的大量 I/O。当设置为 0 时，并不是马上就刷入 relay-log.info 里，而是由操作系统决定何时来写入，虽然安全性降低了，但减少了大量的磁盘 I/O 操作。这个值默认是0，可动态修改，建议采用默认值。</p><h5 id="从节点-SQL-线程"><a href="#从节点-SQL-线程" class="headerlink" title="从节点 SQL 线程"></a>从节点 SQL 线程</h5><p>SQL 线程负责读取 relay log 中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。</p><p>对于每一个主从连接，都需要这三个进程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个 log dump 进程，而每个从节点都有自己的 I/O 进程，SQL 进程。</p><p>从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候，不会降低读操作的性能。比如，如果从节点没有运行，此时 I/O 进程可以很快从主节点获取更新，尽管 SQL 进程还没有执行。如果在 SQL 进程执行之前从节点服务停止，至少 I/O 进程已经从主节点拉取到了最新的变更并且保存在本地 relay log 中，当服务再次起来之后就可以完成数据的同步。</p><p>要实施复制，首先必须打开 Master 端的 Binlog 功能，否则无法实现。</p><p>因为整个复制过程实际上就是 Slave 从 Master 端获取该日志然后再在自己身上完全顺序的执行日志中所记录的各种操作。如下图所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mvsnp5j31040iyad2.jpg" alt="5"></p><h5 id="复制的基本过程"><a href="#复制的基本过程" class="headerlink" title="复制的基本过程"></a>复制的基本过程</h5><ol><li>在从节点上执行 <code>sart slave</code> 命令开启主从复制开关，开始进行主从复制。从节点上的 I/O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容。</li><li>主节点接收到来自从节点的 I/O 请求后，通过负责复制的 I/O 进程（log Dump Thread）根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的 Binlog file 以及 Binlog position（Binlog 下一个数据读取位置）。</li><li>从节点的 I/O 进程接收到主节点发送过来的日志内容、日志文件及位置点后，将接收到的日志内容更新到本机的 relay log 文件（Mysql-relay-bin.xxx）的最末端，并将读取到的 Binlog文件名和位置保存到<code>master-info</code> 文件中，以便在下一次读取的时候能够清楚的告诉 Master ：“ 我需要从哪个 Binlog 的哪个位置开始往后的日志内容，请发给我”。</li><li>Slave 的 SQL 线程检测到relay log 中新增加了内容后，会将 relay log 的内容解析成在能够执行 SQL 语句，然后在本数据库中按照解析出来的顺序执行，并在 <code>relay log.info</code> 中记录当前应用中继日志的文件名和位置点。</li></ol><h2 id="MySQL-基于-Binlog-主从复制的模式介绍"><a href="#MySQL-基于-Binlog-主从复制的模式介绍" class="headerlink" title="MySQL 基于 Binlog 主从复制的模式介绍"></a>MySQL 基于 Binlog 主从复制的模式介绍</h2><p>MySQL 主从复制默认是 <strong>异步的模式</strong>。MySQL增删改操作会全部记录在 Binlog 中，当 slave 节点连接 master 时，会主动从 master 处获取最新的 Binlog 文件。并把 Binlog 存储到本地的 relay log 中，然后去执行 relay log 的更新内容。</p><h3 id="异步模式-async-mode"><a href="#异步模式-async-mode" class="headerlink" title="异步模式 (async-mode)"></a>异步模式 (async-mode)</h3><p>异步模式如下图所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1mu02wbj31160kk0vj.jpg" alt="6"></p><p>这种模式下，主节点不会主动推送数据到从节点，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主节点如果崩溃掉了，此时主节点上已经提交的事务可能并没有传到从节点上，如果此时，强行将从提升为主，可能导致新主节点上的数据不完整。</p><h3 id="全同步模式"><a href="#全同步模式" class="headerlink" title="全同步模式"></a>全同步模式</h3><p>指当主库执行完一个事务，然后所有的从库都复制了该事务并成功执行完才返回成功信息给客户端。因为需要等待所有从库执行完该事务才能返回成功信息，所以全同步复制的性能必然会收到严重的影响。</p><h3 id="半同步模式-semi-sync"><a href="#半同步模式-semi-sync" class="headerlink" title="半同步模式(semi-sync)"></a>半同步模式(semi-sync)</h3><p>介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到 relay log 中才返回成功信息给客户端（只能保证主库的 Binlog 至少传输到了一个从节点上），否则需要等待直到超时时间然后切换成异步模式再提交。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/007S8ZIlgy1gjx1muypwdj31420jg41q.jpg" alt="7"></p><p>相对于异步复制，半同步复制提高了数据的安全性，一定程度的保证了数据能成功备份到从库，同时它也造成了一定程度的延迟，但是比全同步模式延迟要低，这个延迟最少是一个 TCP/IP 往返的时间。所以，半同步复制最好在低延时的网络中使用。</p><p>半同步模式不是 MySQL 内置的，从 MySQL 5.5 开始集成，需要 master 和 slave 安装插件开启半同步模式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MySQL-BinLog&quot;&gt;&lt;a href=&quot;#MySQL-BinLog&quot; class=&quot;headerlink&quot; title=&quot;MySQL BinLog&quot;&gt;&lt;/a&gt;MySQL BinLog&lt;/h1&gt;&lt;p&gt;MySQL 的 Binlog 日志是一种二进制格式的日志，B</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>10.Java内存模型</title>
    <link href="https://leslieaibin.github.io/2021/09/15/Thread/11.Java%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88JMM)/"/>
    <id>https://leslieaibin.github.io/2021/09/15/Thread/11.Java%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88JMM)/</id>
    <published>2021-09-15T02:15:42.000Z</published>
    <updated>2021-09-15T13:57:21.738Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Java内存模型（JMM）"><a href="#Java内存模型（JMM）" class="headerlink" title="Java内存模型（JMM）"></a>Java内存模型（JMM）</h1><p>JVM内存模型指的是JVM的内存分区；而java内存模型是一种虚拟机规范</p><p>JMM就是Java内存模型（Java Mermory Model）。因为在不同的硬件生产商和不同的操作系统下，内存的访问有一定的差异，所以会造成相同的代码运行在不同的系统上会出现各种问题。<strong>所以Java内存模型（JMM）屏蔽掉各种硬件和和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果</strong></p><p>Java内存模型规定所有的变量存储在主内存中，包括 实例变量，静态变量，但是不包括局部变量和方法参数，每个线程都有自己的工作内存，线程的工作内存保存了该线程用的到变量和主内存的副本拷贝，线程对变量的操作 都在工作内存中进行。线程不能直接读写主内存中的变量。</p><p>不同的线程之间也无法访问对方工作内存中的变量，线程之间变量值的传递均需要通过主内存来完成</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-f36f366c07a6188ea3fdefc794ba021a_720w.jpg" alt="img"></p><p>每个线程的工作内存都是独立的，线程操作数据只能在工作内存中进行，然后刷会主存，这是JMM的线程基本工作方式</p><h2 id="JMM定义了什么"><a href="#JMM定义了什么" class="headerlink" title="JMM定义了什么"></a>JMM定义了什么</h2><p>整个Java内存模型实际上是围绕着三个特征建立起来的。分别是：原子性(Atomicity)，可见性（Visibility），有序性（Ordering）。这三个特征可谓是整个Java并发的基础</p><h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>原子性指的是一个操作是不可分割，不可中断的，一个线程在执行时不会被其他线程干扰。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> j = i;</span><br><span class="line">i++;</span><br><span class="line">i = i + <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>第一句是基本类型赋值操作，必定是原子性操作。</p><p>第二句先读取i的值，再赋值到j，两步操作，不能保证原子性。</p><p>第三和第四句其实是等效的，先读取i的值，再+1，最后赋值到i，三步操作了，不能保证原子性。</p><p>JMM只能保证基本的原子性，如果要保证一个代码块的原子性，提供了monitorenter 和 moniterexit 两个字节码指令，也就是 synchronized 关键字。因此在 synchronized 块之间的操作都是原子性的。</p><h3 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h3><p>可见性指当一个线程修改共享变量的值，其他线程能够立即知道被修改了。Java是利用Volatile关键字来提供可见性的。当变量被volatile修饰时，这个变量被修改后会立即刷新到主内存，当其他线程需要读取该变量时，会去至内存中读取新值。而普通变量则不能保证这一点</p><p>除了volatile关键字之外，final和synchronized也能实现可见性。</p><p>synchronized的原理是，在执行完，进入unlock之前，必须将共享变量同步到主内存中。</p><p>final修饰的字段，一旦初始化完成，如果没有对象逸出（指对象为初始化完成就可以被别的线程使用），那么对于其他线程都是可见的。</p><h3 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h3><p>在Java中，可以使用synchronized或者volatile保证多线程之间操作的有序性。实现原理有些区别：</p><p>volatile关键字是使用内存屏障达到禁止指令重排序，以保证有序性。</p><p>synchronized的原理是，一个线程lock之后，必须unlock后，其他线程才可以重新lock，使得被synchronized包住的代码块在多线程之间是串行执行的。</p><h2 id="八种内存交互操作"><a href="#八种内存交互操作" class="headerlink" title="八种内存交互操作"></a>八种内存交互操作</h2><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210915214648182.png" alt="image-20210915214648182"></p><ul><li>lock(锁定)，作用于<strong>主内存</strong>中的变量，把变量标识为线程独占的状态。</li><li>read(读取)，作用于<strong>主内存</strong>的变量，把变量的值从主内存传输到线程的工作内存中，以便下一步的load操作使用。</li><li>load(加载)，作用于<strong>工作内存</strong>的变量，把read操作主存的变量放入到工作内存的变量副本中。</li><li>use(使用)，作用于<strong>工作内存</strong>的变量，把工作内存中的变量传输到执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。</li><li>assign(赋值)，作用于<strong>工作内存</strong>的变量，它把一个从执行引擎中接受到的值赋值给工作内存的变量副本中，每当虚拟机遇到一个给变量赋值的字节码指令时将会执行这个操作。</li><li>store(存储)，作用于<strong>工作内存</strong>的变量，它把一个从工作内存中一个变量的值传送到主内存中，以便后续的write使用。</li><li>write(写入)：作用于<strong>主内存</strong>中的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。</li><li>unlock(解锁)：作用于<strong>主内存</strong>的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</li></ul><p>再补充一下JMM对8种内存交互操作制定的规则吧：</p><ul><li>不允许read、load、store、write操作之一单独出现，也就是read操作后必须load，store操作后必须write。</li><li>不允许线程丢弃他最近的assign操作，即工作内存中的变量数据改变了之后，必须告知主存。</li><li>不允许线程将没有assign的数据从工作内存同步到主内存。</li><li>一个新的变量必须在主内存中诞生，不允许工作内存直接使用一个未被初始化的变量。就是对变量实施use、store操作之前，必须经过load和assign操作。</li><li>一个变量同一时间只能有一个线程对其进行lock操作。多次lock之后，必须执行相同次数unlock才可以解锁。</li><li>如果对一个变量进行lock操作，会清空所有工作内存中此变量的值。在执行引擎使用这个变量前，必须重新load或assign操作初始化变量的值。</li><li>如果一个变量没有被lock，就不能对其进行unlock操作。也不能unlock一个被其他线程锁住的变量。</li><li>一个线程对一个变量进行unlock操作之前，必须先把此变量同步回主内存。</li></ul><h2 id="volatile关键字"><a href="#volatile关键字" class="headerlink" title="volatile关键字"></a>volatile关键字</h2><ul><li>保证线程间变量的可见性</li><li>禁止CPU进行指令重排</li></ul><h2 id="可见性-1"><a href="#可见性-1" class="headerlink" title="可见性"></a>可见性</h2><p>volatile修饰的变量，当一个线程改变了该变量的值，其他线程是立即可见的。普通变量则需要重新读取才能获得最新值。</p><p>volatile保证可见性的流程大概就是这个一个过程：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-2ce112590b4b81cdb02b8839d9d8b686_720w.jpg" alt="img"></p><h2 id="volatile一定能保证线程安全吗"><a href="#volatile一定能保证线程安全吗" class="headerlink" title="volatile一定能保证线程安全吗"></a>volatile一定能保证线程安全吗</h2><p>先说结论吧，volatile不能一定能保证线程安全。</p><p>怎么证明呢，我们看下面一段代码的运行结果就知道了：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * @author Ye Hongzhi 公众号：java技术爱好者</span><br><span class="line"> **/</span><br><span class="line">public class VolatileTest extends Thread &#123;</span><br><span class="line"></span><br><span class="line">    private static volatile int count = 0;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        Vector&lt;Thread&gt; threads = new Vector&lt;&gt;();</span><br><span class="line">        for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">            VolatileTest thread = new VolatileTest();</span><br><span class="line">            threads.add(thread);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">        //等待子线程全部完成</span><br><span class="line">        for (Thread thread : threads) &#123;</span><br><span class="line">            thread.join();</span><br><span class="line">        &#125;</span><br><span class="line">        //输出结果，正确结果应该是1000，实际却是984</span><br><span class="line">        System.out.println(count);//984</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        for (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                //休眠500毫秒</span><br><span class="line">                Thread.sleep(500);</span><br><span class="line">            &#125; catch (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            count++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为什么volatile不能保证线程安全？</p><p>很简单呀，可见性不能保证操作的原子性，前面说过了count++不是原子性操作，会当做三步，先读取count的值，然后+1，最后赋值回去count变量。需要保证线程安全的话，需要使用synchronized关键字或者lock锁，给count++这段代码上锁：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">private static synchronized void add() &#123;</span><br><span class="line">    count++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="禁止指令重排序"><a href="#禁止指令重排序" class="headerlink" title="禁止指令重排序"></a>禁止指令重排序</h2><p>首先要讲一下as-if-serial语义，不管怎么重排序，（单线程）程序的执行结果不能被改变。</p><p>为了使指令更加符合CPU的执行特性，最大限度的发挥机器的性能，提高程序的执行效率，只要程序的最终结果与它顺序化情况的结果相等，那么指令的执行顺序可以与代码逻辑顺序不一致，这个过程就叫做<strong>指令的重排序</strong>。</p><p>重排序的种类分为三种，分别是：编译器重排序，指令级并行的重排序，内存系统重排序。整个过程如下所示：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210915215020235.png" alt="image-20210915215020235"></p><p>指令重排序在单线程是没有问题的，不会影响执行结果，而且还提高了性能。但是在多线程的环境下就不能保证一定不会影响执行结果了。</p><p><strong>所以在多线程环境下，就需要禁止指令重排序</strong>。</p><p>volatile关键字禁止指令重排序有两层意思：</p><ul><li>当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见，在其后面的操作肯定还没有进行。</li><li>在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。</li></ul><p>下面举个例子：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">private static int a;//非volatile修饰变量</span><br><span class="line">private static int b;//非volatile修饰变量</span><br><span class="line">private static volatile int k;//volatile修饰变量</span><br><span class="line"></span><br><span class="line">private void hello() &#123;</span><br><span class="line">    a = 1;  //语句1</span><br><span class="line">    b = 2;  //语句2</span><br><span class="line">    k = 3;  //语句3</span><br><span class="line">    a = 4;  //语句4</span><br><span class="line">    b = 5;  //语句5</span><br><span class="line">    //以下省略...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>变量a，b是非volatile修饰的变量，k则使用volatile修饰。所以语句3不能放在语句1、2前，也不能放在语句4、5后。但是语句1、2的顺序是不能保证的，同理，语句4、5也不能保证顺序。</p><p>并且，执行到语句3的时候，语句1，2是肯定执行完毕的，而且语句1,2的执行结果对于语句3,4,5是可见的。</p><h2 id="volatile禁止指令重排序的原理是什么"><a href="#volatile禁止指令重排序的原理是什么" class="headerlink" title="volatile禁止指令重排序的原理是什么"></a>volatile禁止指令重排序的原理是什么</h2><p>首先要讲一下内存屏障，内存屏障可以分为以下几类：</p><ul><li>LoadLoad 屏障：对于这样的语句Load1，LoadLoad，Load2。在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</li><li>StoreStore屏障：对于这样的语句Store1， StoreStore， Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。</li><li>LoadStore 屏障：对于这样的语句Load1， LoadStore，Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</li><li>StoreLoad 屏障：对于这样的语句Store1， StoreLoad，Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。</li></ul><p>在每个volatile读操作后插入LoadLoad屏障，在读操作后插入LoadStore屏障。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210915215154275.png" alt="image-20210915215154275"></p><p>在每个volatile写操作的前面插入一个StoreStore屏障，后面插入一个SotreLoad屏障。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210915215209621.png" alt="image-20210915215209621"></p><p>大概的原理就是这样。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Java内存模型（JMM）&quot;&gt;&lt;a href=&quot;#Java内存模型（JMM）&quot; class=&quot;headerlink&quot; title=&quot;Java内存模型（JMM）&quot;&gt;&lt;/a&gt;Java内存模型（JMM）&lt;/h1&gt;&lt;p&gt;JVM内存模型指的是JVM的内存分区；而java内存</summary>
      
    
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="多线程与并发" scheme="https://leslieaibin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>05.分布式锁</title>
    <link href="https://leslieaibin.github.io/2021/09/11/MySQL/05.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>https://leslieaibin.github.io/2021/09/11/MySQL/05.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</id>
    <published>2021-09-11T12:17:42.000Z</published>
    <updated>2021-09-11T02:31:35.974Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><h2 id="什么是锁"><a href="#什么是锁" class="headerlink" title="什么是锁"></a>什么是锁</h2><ul><li>在单线程的系统中，当存在多个线程可以同时改变某个变量（可变共享变量）时，就需要对变量或代码块做同步，使其在修改这种变量时能够线性执行消除并发修改变量</li><li>而同步的本质是通过锁实现的。为了实现多个线程在一个时刻同一代码块只能有一个线程可执行，那么需要在某个地方做个标记，这个必须每个线程都能看到，当标记不存在时可以设置该标记，其余后续线程发现已经有标记了则等待拥有标记的线程结束同步代码块取消标记后再去尝试设置标记。这个标记可以理解为锁。</li><li>不同地方实现锁的方式也不一样，只要能满足所有线程都能看到标记即可。如java中synchroniuze是 在对象头设置标记，Lock接口的实现类基本上都只是某一个volitile修饰的int型变量其保证每个线程都能拥有对该int的可见性和原子性修改，linux内核中也是利用互斥量或信号量等内存数据标记</li><li>除了利用内存数据做锁其他任何互斥的都能做锁（只考虑互斥情况），如流水表中流水号与实践结合做幂等校验可以看作是一个不会释放的锁，或者使用某个文件是否存在作为锁等。只需要满足在对标记进行修改能保证原子性和内存可见性即可。</li></ul><h2 id="什么是分布式"><a href="#什么是分布式" class="headerlink" title="什么是分布式"></a>什么是分布式</h2><p>分布式的CAP理论告诉我们：</p><p>任何一个分布式系统都无法同时满足一致性（Consistency）、 可用性（Avaiability）和分区容错性（Partition tolerance)，最多只能同时满足两项。</p><p>目前很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。基于CAP理论，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证最终一致性</p><h2 id="分布式场景"><a href="#分布式场景" class="headerlink" title="分布式场景"></a>分布式场景</h2><p>在许多的场景中，我们为了保证数据的最终一致性，需要很多技术方案来支持，比如分布式事务，分布式锁等。很多时候我们需要保证一个方法在同一时间只能被同一线程执行。在单机环境中，通过java提供的并发API我们可以解决，但是在分布式环境下，就没有那么简单。</p><ul><li>分布式与单机情况下最大的不同在于其不是多线程而是多进程</li><li>多线程由于共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一物理机上，因此需要将标记存储在一个所有进程都能看到的地方</li></ul><h2 id="什么是分布式锁"><a href="#什么是分布式锁" class="headerlink" title="什么是分布式锁"></a>什么是分布式锁</h2><ul><li>当在分布式模型下，数据只有一份（或有限制），此时需要利用锁的技术控制某一时刻修改数据的进程数</li><li>与单机模型下的锁不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。</li><li>分布式锁还是可以将标记存在内存，只是该内存不是某个进程分配的内存而是公共内存如 Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要保证标记能互斥就行</li></ul><h2 id="我们需要怎样的分布式锁"><a href="#我们需要怎样的分布式锁" class="headerlink" title="我们需要怎样的分布式锁"></a>我们需要怎样的分布式锁</h2><ul><li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。</li><li>这把锁要是一把可重入锁（避免死锁）</li><li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li><li>这把锁最好是一把公平锁（根据业务需求考虑要不要这条）</li><li>有高可用的获取锁和释放锁功能</li><li>获取锁和释放锁的性能要好</li></ul><h1 id="基于表主键唯一做分布式锁"><a href="#基于表主键唯一做分布式锁" class="headerlink" title="基于表主键唯一做分布式锁"></a>基于表主键唯一做分布式锁</h1><p>利用主键的特性，如果多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以任务操作成功的那个县城获得该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可</p><p>上面这种简单的实现有以下几个问题：</p><ul><li>这把锁依赖数据库的可用性，数据库是一个单点，一旦数据库挂了，会导致业务系统不可用</li><li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获取锁</li><li>这把锁只能是非阻塞的，因为 数据insert操作，一旦插入失败就会直接报错。没有获得锁的线程比不会进入排队队列，想要再次获得锁就要再次触发获得锁操作。</li><li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</li><li>这把锁是非公平锁，所有等待锁的线程凭运气去争夺锁。</li><li>在 MySQL 数据库中采用主键冲突防重，在大并发情况下有可能会造成锁表现象。</li></ul><p><strong>我们也可以有其他方式解决上面的问题</strong></p><ul><li>数据库是单点？ 搞两个数据库，数据之前双向同步，一旦挂掉快速切换到备库上</li><li>没有失效时间？ 只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍</li><li>非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。</li><li>非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li><li>非公平的？再建一张中间表，将等待锁的线程全记录下来，并根据创建时间排序，只有最先创建的允许获取锁。</li><li>比较好的办法是在程序中生产主键进行防重。</li></ul><h1 id="基于Redis做分布式锁"><a href="#基于Redis做分布式锁" class="headerlink" title="基于Redis做分布式锁"></a>基于Redis做分布式锁</h1><h2 id="基于redis-的-setnx-、expire-方法做分布式锁"><a href="#基于redis-的-setnx-、expire-方法做分布式锁" class="headerlink" title="基于redis 的 setnx()、expire()方法做分布式锁"></a>基于redis 的 setnx()、expire()方法做分布式锁</h2><h3 id="setnx"><a href="#setnx" class="headerlink" title="setnx()"></a>setnx()</h3><p>setnx 的含义就是 SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果 key 不存在，则设置当前 key 成功，返回 1；如果当前 key 已经存在，则设置当前 key 失败，返回 0。</p><h3 id="expire"><a href="#expire" class="headerlink" title="expire()"></a>expire()</h3><p>expire 设置过期时间，要注意的是 setnx 命令不能设置 key 的超时时间，只能通过 expire() 来对 key 设置。</p><h3 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h3><p>1、setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功</p><p>2、expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。</p><p>3、执行完业务代码后，可以通过 delete 命令删除 key。</p><p>这个方案其实是可以解决日常工作中的需求的，但从技术方案的探讨上来说，可能还有一些可以完善的地方。<strong>比如，如果在第一步 setnx 执行成功后，在 expire() 命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题，所以如果要对其进行完善的话，可以使用 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。</strong></p><h2 id="基于-redis-的-setnx-、get-、getset-方法做分布式锁"><a href="#基于-redis-的-setnx-、get-、getset-方法做分布式锁" class="headerlink" title="基于 redis 的 setnx()、get()、getset()方法做分布式锁"></a>基于 redis 的 setnx()、get()、getset()方法做分布式锁</h2><p>这个方案的背景主要是在 setnx() 和 expire() 的方案上针对可能存在的死锁问题，做了一些优化。</p><h3 id="getset"><a href="#getset" class="headerlink" title="getset()"></a>getset()</h3><p>这个命令主要有两个参数 getset(key，newValue)。该方法是原子的，对 key 设置 newValue 这个值，并且返回 key 原来的旧值。假设 key 原来是不存在的，那么多次执行这个命令，会出现下边的效果：</p><ol><li>getset(key, “value1”) 返回 null 此时 key 的值会被设置为 value1</li><li>getset(key, “value2”) 返回 value1 此时 key 的值会被设置为 value2</li><li>依次类推！</li></ol><h3 id="使用步骤-1"><a href="#使用步骤-1" class="headerlink" title="使用步骤"></a>使用步骤</h3><ol><li>setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。</li><li>get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。</li><li>计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。</li><li>判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。</li><li>在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。</li></ol><h1 id="基于-ZooKeeper-做分布式锁"><a href="#基于-ZooKeeper-做分布式锁" class="headerlink" title="基于 ZooKeeper 做分布式锁"></a>基于 ZooKeeper 做分布式锁</h1><h2 id="zookeeper-锁相关基础知识"><a href="#zookeeper-锁相关基础知识" class="headerlink" title="zookeeper 锁相关基础知识"></a>zookeeper 锁相关基础知识</h2><ul><li>zk一般由多个节点构成（单数），采用zab一致性协议。因此可以将zk看成一个单点结构，对其修改数据其内部自动将所有节点数据进行修改后才提供查询服务</li><li>zk的数据以目录树的形式，每个目录称为znode，znode中可存储数据（一般不超过1M），还可以在其中增加子节点</li><li>子节点有三种类型。序列化节点，每在该节点下增加一个节点自动给该节点的名称上自增。一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。最后就是普通节点。</li><li>Watch 机制，client 可以监控每个节点的变化，当产生变化会给 client 产生一个事件。</li></ul><h2 id="zk基本锁"><a href="#zk基本锁" class="headerlink" title="zk基本锁"></a>zk基本锁</h2><ul><li>原理：利用临时节点与 watch 机制。每个锁占用一个普通节点 /lock，当需要获取锁时在 /lock 目录下创建一个临时节点，创建成功则表示获取锁成功，失败则 watch/lock 节点，有删除操作后再去争锁。临时节点好处在于当进程挂掉后能自动上锁的节点自动删除即取消锁。</li><li>缺点：所有取锁失败的进程都监听父节点，很容易发生羊群效应，即当释放锁后所有等待进程一起来创建节点，并发量很大。</li></ul><h2 id="zk-锁优化"><a href="#zk-锁优化" class="headerlink" title="zk 锁优化"></a>zk 锁优化</h2><ul><li>原理：上锁改为创建临时有序节点，每个上锁的节点均能创建节点成功，只是其序号不同。只有序号最小的可以拥有锁，如果这个节点序号不是最小的则 watch 序号比本身小的前一个节点 (公平锁)。</li><li>步骤：</li><li>在 /lock 节点下创建一个有序临时节点 (EPHEMERAL_SEQUENTIAL)。</li><li>判断创建的节点序号是否最小，如果是最小则获取锁成功。不是则取锁失败，然后 watch 序号比本身小的前一个节点。</li><li>当取锁失败，设置 watch 后则等待 watch 事件到来后，再次判断是否序号最小。</li><li>取锁成功则执行代码，最后释放锁（删除该节点）。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;分布式锁&quot;&gt;&lt;a href=&quot;#分布式锁&quot; class=&quot;headerlink&quot; title=&quot;分布式锁&quot;&gt;&lt;/a&gt;分布式锁&lt;/h1&gt;&lt;h2 id=&quot;什么是锁&quot;&gt;&lt;a href=&quot;#什么是锁&quot; class=&quot;headerlink&quot; title=&quot;什么是锁&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>04.MySQL索引原理及慢查询优化</title>
    <link href="https://leslieaibin.github.io/2021/09/10/MySQL/04.MySQL%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%8F%8A%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
    <id>https://leslieaibin.github.io/2021/09/10/MySQL/04.MySQL%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%8F%8A%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</id>
    <published>2021-09-10T12:17:42.000Z</published>
    <updated>2021-09-11T02:30:25.218Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>MySQL凭借着出色的性能、低廉的成本、丰富的资源，已经成为绝大多数互联网公司的首选关系型数据库。虽然性能出色，但所谓“好马配好鞍”，如何能够更好的使用它，已经成为开发工程师的必修课，我们经常会从职位描述上看到诸如“精通MySQL”、“SQL语句优化”、“了解数据库原理”等要求。我们知道一般的应用系统，读写比例在10:1左右，而且插入操作和一般的更新操作很少出现性能问题，遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，所以查询语句的优化显然是重中之重。背景</p><h2 id="MySQL索引原理"><a href="#MySQL索引原理" class="headerlink" title="MySQL索引原理"></a>MySQL索引原理</h2><h3 id="索引目的"><a href="#索引目的" class="headerlink" title="索引目的"></a>索引目的</h3><p>索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？</p><h3 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a>索引原理</h3><p>除了词典，生活中随处可见索引的例子，如火车站的车次表、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。</p><p>数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&gt;、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。</p><h3 id="磁盘IO与预读"><a href="#磁盘IO与预读" class="headerlink" title="磁盘IO与预读"></a>磁盘IO与预读</h3><p>前面提到了访问磁盘，那么这里先介绍下磁盘IO和预读，磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分，寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。那么访问一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17 = 9ms左右，听起来还挺不错的，但要知道一台500 -MIPS的机器每秒可以执行5亿条指令，因为指令依靠的是电的性质，换句话说执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒的时间，显然是个灾难。下图是计算机硬件延迟的对比图，供大家参考：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/7f46a0a4.png" alt="various-system-software-hardware-latencies"></p><p>考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。</p><h3 id="索引的数据结构"><a href="#索引的数据结构" class="headerlink" title="索引的数据结构"></a>索引的数据结构</h3><p>前面讲了生活中索引的例子，索引的基本原理，数据库的复杂性，又讲了操作系统的相关知识，目的就是让大家了解，任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，我们现在总结一下，我们需要这种数据结构能够做些什么，其实很简单，那就是：每次查找数据时把磁盘IO次数控制在一个很小的数量级，最好是常数数量级。那么我们就想到如果一个高度可控的多路搜索树是否能满足需求呢？就这样，b+树应运而生。</p><p><strong>详解B+树</strong></p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/7af22798.jpg" alt="b+树"></p><p>如上图，是一颗b+树，关于b+树的定义可以参见<a href="http://zh.wikipedia.org/wiki/B%2B%E6%A0%91">B+树</a>，这里只说一些重点，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。</p><h4 id="b-树的查找过程"><a href="#b-树的查找过程" class="headerlink" title="b+树的查找过程"></a>b+树的查找过程</h4><p>如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。</p><h4 id="b-树性质"><a href="#b-树性质" class="headerlink" title="b+树性质"></a>b+树性质</h4><p>1.通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。</p><p>2.当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。</p><h2 id="慢查询优化"><a href="#慢查询优化" class="headerlink" title="慢查询优化"></a>慢查询优化</h2><p>关于MySQL索引原理是比较枯燥的东西，大家只需要有一个感性的认识，并不需要理解得非常透彻和深入。我们回头来看看一开始我们说的慢查询，了解完索引原理之后，大家是不是有什么想法呢？先总结一下索引的几大基本原则：</p><h3 id="建索引的几大原则："><a href="#建索引的几大原则：" class="headerlink" title="建索引的几大原则："></a>建索引的几大原则：</h3><ul><li><p>最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p></li><li><p>=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。</p></li><li><p>尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。</p></li><li><p>索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。</p></li><li><p>尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可</p></li></ul><h2 id="回到开始的慢查询"><a href="#回到开始的慢查询" class="headerlink" title="回到开始的慢查询"></a>回到开始的慢查询</h2><p>根据最左匹配原则，最开始的sql语句的索引应该是status、operator_id、type、operate_time的联合索引；其中status、operator_id、type的顺序可以颠倒，所以我才会说，把这个表的所有相关查询都找到，会综合分析；比如还有如下查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from task where status &#x3D; 0 and type &#x3D; 12 limit 10;</span><br><span class="line">select count(*) from task where status &#x3D; 0 ;</span><br></pre></td></tr></table></figure><p>那么索引建立成(status,type,operator_id,operate_time)就是非常正确的，因为可以覆盖到所有情况。这个就是利用了索引的最左匹配的原则</p><h3 id="查询优化神器-explain命令"><a href="#查询优化神器-explain命令" class="headerlink" title="查询优化神器 - explain命令"></a>查询优化神器 - explain命令</h3><p>关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网<a href="http://dev.mysql.com/doc/refman/5.5/en/explain-output.html">explain-output</a>，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。</p><h3 id="慢查询优化基本步骤"><a href="#慢查询优化基本步骤" class="headerlink" title="慢查询优化基本步骤"></a>慢查询优化基本步骤</h3><p>0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE</p><p>1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高</p><p>2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）</p><p>3.order by limit 形式的sql语句让排序的表优先查</p><p>4.了解业务方使用场景</p><p>5.加索引时参照建索引的几大原则</p><p>6.观察结果，不符合预期继续从0分析</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;MySQL凭借着出色的性能、低廉的成本、丰富的资源，已经成为绝大多数互联网公司的首选关系型数据库。虽然性能出色，但所谓“好马配好鞍”，如何能</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>03.一条SQL查询语句如何执行</title>
    <link href="https://leslieaibin.github.io/2021/09/09/MySQL/03.MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/"/>
    <id>https://leslieaibin.github.io/2021/09/09/MySQL/03.MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/</id>
    <published>2021-09-09T12:17:42.000Z</published>
    <updated>2021-09-11T02:30:12.521Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一条SQL查询语句如何执行"><a href="#一条SQL查询语句如何执行" class="headerlink" title="一条SQL查询语句如何执行"></a>一条SQL查询语句如何执行</h1><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210910095617441.png" alt="image-20210910095617441"></p><p>MySQL可以分为Server层和存储引擎层两部分</p><p>Server层包括 <strong>连接器、查询缓存、分析器、优化器、执行器</strong>等，涵盖了MySQL的大多数核心功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程，触发器，视图等。</p><p>而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎InnoDB，它从MySQL5.5.5版本开始成为默认存储引擎。</p><p>也就是说，你执行create table建表的时候，如果不执行搜索引擎，默认的是innodb，不过，你也可以通过执行存储引擎的类型来选择别的引擎，比如在create table 语句中使用 engine=memory，来执行使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同。</p><h2 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h2><p>第一步，你会先连接到这数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接，获取权限，位置和管理连接。连接命令一般是这么写的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h$ip -P$port -u$user -p</span><br></pre></td></tr></table></figure><p>输完命令后，你就需要在交互对话里面输入密码。虽然密码也可以直接在-p后面卸载命令行中，但这样可能会导致你的密码泄露。</p><ul><li>如果用户名或密码不对，你就会收到一个”Access denied for user的错误，然后客户端程序结束执行。</li><li>如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。</li></ul><p>这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。<br>连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist令中看到它。文本中这个图是 show processlist的结果，其中的 Command列显示为Sleep的这一行，就表示现在系统里面有一个空闲连接</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210910103606002.png" alt="image-20210910103606002"></p><p>客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait timeout控制的，默认值是8小时。</p><p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒：Lost connection to MySQL server during query.这时候如果你要继续，就需要重连，然后再执行请求了数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断连接，下次查询再重新建立一个</p><h2 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h2><p>连接建立完成后，你就可以执行 select语句了执行逻辑就会来到第二步：查询缓存MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key- -value对的形式，被直接缓存在内存中。key是查询的语句， value是查询的结果。如果你的查询能够直接在这个缓存中找到key.那么这个 value就会被直接返回给客户端。<br>如果语句不在查询缓存中，就会继续后面的执行阶段执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存， MySQ不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p><p>但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。<br>查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会史新一次。</p><p>比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。<br>好在MSQL也提供了这种“按需使用”的方式。你可以将参数query cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL CACHE显式指定，像下面这个语句一样：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select SQL_CACHE from T where ID&#x3D;10：</span><br></pre></td></tr></table></figure><p><strong>需要注意的是， MySQL8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。</strong></p><h2 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h2><p>如果没有命中查询缓存，就要开始真正执行语句了。首先，MQL需要知道你要做什么，因此需要对SQL语句做解析。</p><p>分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句， MySQL需要识别出里面的字符串分别是什么，代表什么</p><p>MySQL从你输入的”select这个关键字识别出来，这是一个查询语句。它也要把字符串“T识别成“名T，把字符串识别成列D做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MSQL语法</p><p>如果你的语句不对，就会收到You have an error in your SQL syntax的错误提醒，比如下面这个语句 select少打了开头的字母s”。</p><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>经过了分析器，MySQL就知道你要做什么，在开始执行之前，要经过优化器的处理</p><p>优化器是在表里面有多个索引的时候，决定使用哪个索引，或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * <span class="function">from t1 join t2 <span class="title">using</span><span class="params">(ID)</span> where t1.c</span>=<span class="number">10</span> and t2.d = <span class="number">20</span>;</span><br></pre></td></tr></table></figure><ul><li>既可以先从表t1里面取出 c = 10的记录的ID值，在根据ID关联到表t2，再判断t2里面d的值是否等于20</li><li>也可以先从表t2里面取出d=20的记录的id值，在根据ID值关联到t1，在判断t1里面c的值是否等于10</li></ul><p>这两种执行方法的逻辑结果是一样的，但执行的效率会有不同，而优化器的作用是决定选择使用哪个方案</p><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h2><p>MSQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。</p><p>开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from where ID=<span class="number">10</span>;</span><br></pre></td></tr></table></figure><p>如果有权限，就打开表继续执行，打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口</p><p>比如我们这个例子中的表T中，D字段没有索引那么执行器的执行流程是这样的：</p><ul><li>调用InnoDB引擎接口取这个表的第一行，判断D值是不是10，如果不是则跳过，如果是则将这行存在结果集中</li><li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li><li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端至此，这个语句就执行完成了。</li></ul><p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的你会在数据库的慢查询日志中看到一个 rows examined的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。</p><p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rowsexamined并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一条SQL查询语句如何执行&quot;&gt;&lt;a href=&quot;#一条SQL查询语句如何执行&quot; class=&quot;headerlink&quot; title=&quot;一条SQL查询语句如何执行&quot;&gt;&lt;/a&gt;一条SQL查询语句如何执行&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http://test-1874</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>4.HashMap实现原理</title>
    <link href="https://leslieaibin.github.io/2021/09/05/Collection/4.HashMap%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/"/>
    <id>https://leslieaibin.github.io/2021/09/05/Collection/4.HashMap%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/</id>
    <published>2021-09-04T16:15:42.000Z</published>
    <updated>2021-09-24T03:46:08.895Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HashMap的实现原理"><a href="#HashMap的实现原理" class="headerlink" title="HashMap的实现原理"></a>HashMap的实现原理</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>HashMap是Java中对Map接口的实现类，是最常用的实现类中之一。主要有以下几个特性：</p><ul><li>HashMap中的key 和 value 都允许为null， 但最多智能拥有一个null的key</li><li>HashMap不保证顺序性</li><li>HashMap非线性安全</li></ul><p>HashMap的数据结构：</p><p>HashMap内部是以数组+链表的方式存储的数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/image-20210904213431065.png" alt="image-20210904213431065"></p><p>HashMap的数组中，每个元素称之为“<strong>桶</strong>”。需要注意的是，这个“桶”并不等同于“键值对（Entity）”。至于它是什么请往下看。</p><p><strong>初始化</strong></p><p>HashMap在初始化时会创建一个Entity的数组。其个数为<strong>16</strong>。其源码类似下面的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    V value;</span><br><span class="line">    Entry&lt;K,V&gt; next;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">    ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中key和value不必多说，不过它还包含了一个next属性，这说明它可以组织成一个链表结构。</p><p><strong>put()方法</strong></p><p>put方法被调用时，HashMap会根据key计算出对应的hashcode，然后根据hashcode确定该Entity应该存放在数组的哪个位置（应该放在哪个桶里）。</p><p>这种设定有一个问题：实际引用中有可能会发生hash碰撞（即两个数据虽然内容不同，但其hashcode有可能是相同的）！因此，HashMap如果发现hashcode已经存在，则会对key进行euqals对比：</p><ul><li>equals结果是true，则认为确实是同一个key，然后将新的value覆盖旧的value（此时put方法将会返回旧value值）。</li><li>equals结果是false，则认为是hash碰撞，此时会将之前的Entity作为新Entity的next，此时形成一个链表，新Entity则处在链表的首位。</li></ul><p>因此，所谓的<strong>“桶”就是数组每个位置放置的“链表”</strong>。</p><p><strong>get()方法</strong></p><p>如果理解了上述的put逻辑，则get方法就很容易理解。主要有以下几个步骤：</p><ul><li>根据key计算hashcode，然后得出其数组下标（位置）。</li><li>去对应位置获取桶（链表）。</li><li>从头到尾遍历链表的每一个Entity，通过equals方法找到对应的Entity。</li><li></li></ul><p>上述的过程中有一个点未详细说明：<strong>如何根据key的hashcode计算出对应的数组坐标呢？</strong></p><p>HashMap的内部实现用了一个非常巧妙的方法。HashMap的初始容量被定为<strong>16</strong>，且每次增长都是2的倍数。这样设计的目的是要<strong>保证存入map中的元素尽量分散</strong>，尽量避免出现桶中出现链表，这可以有效降低数据查询时的处理速度。</p><p>key是这么一步步转化成数组下标的：</p><p>第一步：Object Key –&gt; int hash</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">static final int hash(Object key) &#123;</span><br><span class="line">    int h;</span><br><span class="line">    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果key是null，则其hash为0；否则便将 <strong>hashcode</strong> 与 <strong>hashcode的高位</strong> 做 <strong>异或运算</strong>。这是为了尽量避免“低位不变，高位变化”时造成的hash冲突。</p><p>第二步：hash –&gt; i</p><p>上一步计算出的hash是个长度较长的二进制数字，而通常情况下HashMap的底层数组长度（length）较小，因此如果我们进行 <strong>hash % length</strong> 计算，则一定能得到一个下标，且相对比较分散。而在源码中使用了性能更高的算法：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">i = (length - 1) &amp; hash</span><br></pre></td></tr></table></figure><p>这个公式对hash和length进行了<strong>按位与</strong>运算，等价于<strong>取余。</strong></p><h2 id="为什么底层数组的长度总要是2的n次方呢"><a href="#为什么底层数组的长度总要是2的n次方呢" class="headerlink" title="为什么底层数组的长度总要是2的n次方呢"></a>为什么底层数组的长度总要是2的n次方呢</h2><p>这时就能说清楚另外一件事情：<strong>为什么底层数组的长度总要是2的n次方呢？</strong></p><p>下图是个示例：</p><p><img src="https://pic2.zhimg.com/80/v2-417a388c7b8ae370fc1ede9e854e54a5_720w.jpg" alt="img"></p><p>可以看到，如果数组长度是2的n次方，那么<strong>length-1</strong>的二进制表示中，一定所有位都是<strong>1</strong>，此时取&amp;运算则可以完整保留hash响应位置的二进制数据。相反的，如果数组长度不是2的n次方，则出现hash碰撞的可能性大大提高。</p><h2 id="JDK8中HashMap的改进"><a href="#JDK8中HashMap的改进" class="headerlink" title="JDK8中HashMap的改进"></a>JDK8中HashMap的改进</h2><p>上文曾提到“<strong>桶</strong>”的概念。其实这个概念在JDK8中才是真正有意义的。因为JDK7中，原始数组的每个元素都一定是个链表（链表的节点一个或者多个），而到了JDK8的时候就不一定是链表了。</p><p>JDK8对存储方式进行改进的原因很简单：如果在一个HashMap中，有很多Key发生了碰撞的时候，就会产生一个超级长的链表。那么在数据查询的时候就会花费O(n)的时间。所以，JDK8中HashMap采用了“<strong>桶</strong>+<strong>链表/红黑树</strong>”数据存储方式：如果链表的长度大于等于8时，其内部便会将链表转化为红黑树的结构。红黑树的查询时间是O(log n)。</p><p>由于数据存储方式发生变化，因此列表扩容时也会发生一些变化。具体细节请看下一篇HashMap的扩容。</p><h1 id="扩容机制"><a href="#扩容机制" class="headerlink" title="扩容机制"></a>扩容机制</h1><p>为了方便说明，这里明确几个名词：</p><ul><li>capacity 即容量，默认16。</li><li>loadFactor 加载因子，默认是0.75</li><li>threshold 阈值。阈值=容量*加载因子。默认12。当元素数量超过阈值时便会触发扩容。</li></ul><p><strong>什么时候触发扩容？</strong></p><p>一般情况下，<strong>当元素数量超过阈值时</strong>便会触发扩容。每次扩容的容量都是之前容量的2倍。</p><p>HashMap的容量是有上限的，必须小于<strong>1&lt;&lt;30</strong>，即1073741824。如果容量超出了这个数，则不再增长，且阈值会被设置为<strong>Integer.MAX_VALUE</strong>（2^31^  - 1) ，即永远不会超出阈值了)。</p><h2 id="JDK7中的扩容机制"><a href="#JDK7中的扩容机制" class="headerlink" title="JDK7中的扩容机制"></a><strong>JDK7中的扩容机制</strong></h2><p>JDK7的扩容机制相对简单，有以下特性：</p><ul><li>空参数的构造函数：以默认容量、默认负载因子、默认阈值初始化数组。内部数组是<strong>空数组</strong>。</li><li>有参构造函数：根据参数确定容量、负载因子、阈值等。</li><li>第一次put时会初始化数组，其容量变为<strong>不小于指定容量的2的幂数</strong>。然后根据负载因子确定阈值。</li><li>如果不是第一次扩容，则 <img src="https://www.zhihu.com/equation?tex=%E6%96%B0%E5%AE%B9%E9%87%8F=%E6%97%A7%E5%AE%B9%E9%87%8F%5Ctimes2" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=%E6%96%B0%E9%98%88%E5%80%BC=%E6%96%B0%E5%AE%B9%E9%87%8F%5Ctimes%E8%B4%9F%E8%BD%BD%E5%9B%A0%E5%AD%90" alt="[公式]"> 。</li></ul><h2 id="JDK8的扩容机制"><a href="#JDK8的扩容机制" class="headerlink" title="JDK8的扩容机制"></a><strong>JDK8的扩容机制</strong></h2><p>JDK8的扩容做了许多调整。</p><p>HashMap的容量变化通常存在以下几种情况：</p><ol><li>空参数的构造函数：实例化的HashMap默认内部数组是null，即没有实例化。第一次调用put方法时，则会开始第一次初始化扩容，长度为16。</li><li>有参构造函数：用于指定容量。会根据指定的正整数找到<strong>不小于指定容量的2的幂数</strong>，将这个数设置赋值给<strong>阈值</strong>（threshold）。第一次调用put方法时，会将阈值赋值给容量，然后让 <img src="https://www.zhihu.com/equation?tex=%E9%98%88%E5%80%BC=%E5%AE%B9%E9%87%8F%5Ctimes%E8%B4%9F%E8%BD%BD%E5%9B%A0%E5%AD%90" alt="[公式]"> 。（因此并不是我们手动指定了容量就一定不会触发扩容，超过阈值后一样会扩容！！）</li><li>如果不是第一次扩容，则容量变为原来的2倍，阈值也变为原来的2倍。<em>（容量和阈值都变为原来的2倍时，负载因子还是不变）</em></li></ol><p>此外还有几个细节需要注意：</p><ul><li>首次put时，先会触发扩容（算是初始化），然后存入数据，然后判断是否需要扩容；</li><li>不是首次put，则不再初始化，直接存入数据，然后判断是否需要扩容；</li></ul><h2 id="JDK7的元素迁移"><a href="#JDK7的元素迁移" class="headerlink" title="JDK7的元素迁移"></a><strong>JDK7的元素迁移</strong></h2><p>JDK7中，HashMap的内部数据保存的都是链表。因此逻辑相对简单：在准备好新的数组后，map会遍历数组的每个“桶”，然后遍历桶中的每个Entity，重新计算其hash值（也有可能不计算），找到新数组中的对应位置，以<strong>头插法</strong>插入新的链表。</p><p>这里有几个注意点：</p><ul><li>是否要重新计算hash值的条件这里不深入讨论，读者可自行查阅源码。</li><li>因为是头插法，因此新旧链表的元素位置会发生转置现象。</li><li>元素迁移的过程中在多线程情境下有可能会触发死循环（无限进行链表反转）。</li></ul><h2 id="JDK8的元素迁移"><a href="#JDK8的元素迁移" class="headerlink" title="JDK8的元素迁移"></a><strong>JDK8的元素迁移</strong></h2><p>JDK8则因为巧妙的设计，性能有了大大的提升：由于数组的容量是以2的幂次方扩容的，那么一个Entity在扩容时，新的位置要么在<strong>原位置</strong>，要么在<strong>原长度+原位置</strong>的位置。原因如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-da2df9ad67181daa328bb09515c1e1c8_720w.png" alt="img"></p><p>数组长度变为原来的2倍，表现在二进制上就是<strong>多了一个高位参与数组下标确定</strong>。此时，一个元素通过hash转换坐标的方法计算后，恰好出现一个现象：最高位是0则坐标不变，最高位是1则坐标变为“10000+原坐标”，即“原长度+原坐标”。如下图：</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/v2-ac1017eb1b83ce5505bfc032ffbcc29a_720w.jpg" alt="img"></p><p>因此，在扩容时，不需要重新计算元素的hash了，只需要判断最高位是1还是0就好了。</p><p>JDK8的HashMap还有以下细节：</p><ul><li>JDK8在迁移元素时是正序的，不会出现链表转置的发生。</li><li>如果某个桶内的元素超过8个，则会将链表转化成红黑树，加快数据查询效率。</li></ul><h2 id="HashMap扩容死循环问题"><a href="#HashMap扩容死循环问题" class="headerlink" title="HashMap扩容死循环问题"></a>HashMap扩容死循环问题</h2><ul><li><p>当插入一个新的键值对时，会根据key对HashMap底层数组长度取模，得到键值对存放的数组下标，然后调用addEntry() 函数把这个键值对插入到这个下标所在的链表中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(<span class="keyword">int</span> hash, K key , V value, <span class="keyword">int</span> bucketIndex)</span></span>&#123;</span><br><span class="line">    Entry&lt;K, V&gt; e = table[bucketIndex];</span><br><span class="line">    table[bucketIndex] = <span class="keyword">new</span> Entry&lt;&gt;(hash, key , value, e);</span><br><span class="line">    <span class="keyword">if</span>(size++ &gt;= threshold)<span class="comment">// 如果键值对个数超过hashmap当前的阈值</span></span><br><span class="line">        resize(<span class="number">2</span> * table.length)<span class="comment">// 调整resize()函数进行扩容</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>在这个addEntry() 函数中，会判断键值对个数是否超过了HashMap当前容量的阈值，如果超过了，则说明需要扩容，接下来就调用resize() 函数扩容为原来的两倍</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">resize</span><span class="params">(<span class="keyword">int</span> newCapacity)</span> </span>&#123;</span><br><span class="line">    Entry[] oldTable = table;</span><br><span class="line">    <span class="keyword">int</span> oldCapacity = oldTable.length;</span><br><span class="line">    <span class="keyword">if</span> (oldCapacity == MAXIMUM_CAPACITY) &#123;</span><br><span class="line">           threshold = Integer.MAX_VALUE;</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">     &#125;</span><br><span class="line">    Entry[] newTable = <span class="keyword">new</span> Entry[newCapacity];  <span class="comment">// 创建一个新数组</span></span><br><span class="line">    transfer(newTable);        <span class="comment">// 把老数组中的所有键值对都拷贝到新数组中</span></span><br><span class="line">    table = newTable;        <span class="comment">// 修改老数组的指向，把老数组指向新数组，完成扩容</span></span><br><span class="line">    threshold = (<span class="keyword">int</span>)(newCapacity * loadFactor);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>resize()函数会先创建一个新数组，然后调用 transfer() 函数把老数组中的所有键值对都拷贝到新数组中，最后修改老数组的指向，把老数组指向新数组，完成扩容。</p><p>扩容过程中会出现循环链表的情况就是多个线程在执行 transfer() 函数导致的，下面看看 transfer() 函数的代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Entry[] newTable)</span> </span>&#123;</span><br><span class="line">    Entry[] src = table;        <span class="comment">// 老数组</span></span><br><span class="line">    <span class="keyword">int</span> newCapacity = newTable.length;     <span class="comment">// 新数组的长度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; src.length; j++) <span class="comment">// 遍历老数组，把老数组中所有键值对拷贝到新数组</span></span><br><span class="line">        Entry&lt;K,V&gt; e = src[j];    <span class="comment">// 记录下老数组第 j 个链表，接下来会链表上的键值对都拷贝到新数组</span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;        <span class="comment">// 如果链表不为空才需要拷贝</span></span><br><span class="line">            src[j] = <span class="keyword">null</span>;        <span class="comment">// 先老数组第j个链表置为空链表</span></span><br><span class="line">            <span class="keyword">do</span> &#123;                <span class="comment">// 循环遍历刚才记录下来的链表，把所有键值对都采用头插法插入到新数组对应链表</span></span><br><span class="line">                Entry&lt;K,V&gt; next = e.next;        <span class="comment">// 记录下当前结点的下个结点</span></span><br><span class="line">                <span class="keyword">int</span> i = indexFor(e.hash, newCapacity);    <span class="comment">// 求出该键值对在新数组的下标,即该键值对应该被插入到新数组第几个链表</span></span><br><span class="line">                e.next = newTable[i];    <span class="comment">// 把结点的next指针指向新数组的第i个链表头结点</span></span><br><span class="line">                newTable[i] = e;    <span class="comment">// 新数组第i个链表的头结点前移，指向当前结点</span></span><br><span class="line">                e = next;        <span class="comment">// 把指向当前结点的指针后移</span></span><br><span class="line">            &#125; <span class="keyword">while</span> (e != <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>其中最关键的就是其中的 do while()循环，这里面就是会发生循环链表的代码。</p></li></ul><p>现在先走一遍正常扩容的流程,假设有下面这个HashMap, 假设数组大小为2</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210822148-740596617.png" alt="img"></p><p>现在需要对它进行扩容，扩容后数组大小为原来的两倍，创建一个大小为4的数组</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210822686-391022651.png" alt="img"></p><p>假设a、b两个数扩容后刚好又hash冲突了，即又在同一个链表中，所在下标为3；c在下标为1的链表中。下面开始扩容。</p><p>e指针指向了老数组的第1个链表</p><h3 id="执行上面的do-while循环，第一轮循环："><a href="#执行上面的do-while循环，第一轮循环：" class="headerlink" title="执行上面的do while循环，第一轮循环："></a>执行上面的do while循环，第一轮循环：</h3><p><a href="https://img2020.cnblogs.com/blog/1456655/202012/1456655-20201211210823926-116268729.png"><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210823926-116268729.png" alt="img"></a></p><h3 id="第二轮循环："><a href="#第二轮循环：" class="headerlink" title="第二轮循环："></a>第二轮循环：</h3><h3 id=""><a href="#" class="headerlink" title=""></a><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20210820225941991-619872774.png" alt="img"></h3><h3 id="第三轮也是最后一轮循环，前面已经假设结点-c-将在新数组中的第二个链表"><a href="#第三轮也是最后一轮循环，前面已经假设结点-c-将在新数组中的第二个链表" class="headerlink" title="第三轮也是最后一轮循环，前面已经假设结点 c 将在新数组中的第二个链表"></a>第三轮也是最后一轮循环，前面已经假设结点 c 将在新数组中的第二个链表</h3><p><a href="https://img2020.cnblogs.com/blog/1456655/202012/1456655-20201211210826842-959746908.png"><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210826842-959746908.png" alt="img"></a></p><p>至此，老数组中的健值对已全部拷贝到新数组中</p><h3 id="多线程环境中扩容"><a href="#多线程环境中扩容" class="headerlink" title="多线程环境中扩容"></a>多线程环境中扩容</h3><p>假设在第 二 次循环中的第二步（执行完e.next = newTable[i]；）后当前线程的时间片刚好用完了，当前线程被挂起，这时刚好又有一个线程 P2 也来执行扩容操作，它并不会从第二步开始执行，而是重新从第一步开始执行，加入新线程后的扩容图为</p><p><a href="https://img2020.cnblogs.com/blog/1456655/202012/1456655-20201211210829300-1877613427.png"><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1456655-20201211210829300-1877613427.png" alt="img"></a></p><p>可以看到，线程2扩容之后的newTable中的单链表形成了一个环，后续执行get操作的时候，会触发死循环，引起CPU的100%问题。</p><h1 id="扩容后，元素是如何重新分布的"><a href="#扩容后，元素是如何重新分布的" class="headerlink" title="扩容后，元素是如何重新分布的"></a>扩容后，元素是如何重新分布的</h1><ul><li><p>HashMap的初始化是在插入第一个元素时调用resize() 完成的</p></li><li><p>不指定容量，默认容量为16</p></li><li><p>指定容量也不一定按照你的值来，会经过tableSizeFor转成不小于输入值的2的n次幂</p><p>tableSizeFor<code>转换成2的n次幂不是直接赋值给</code>capacity<code>，而是先将值暂时保存在</code>threshold<code>，见源码</code>457<code>，然后在put第一个元素resize时，婉转的传递给</code>newCap</p></li><li><p>put元素时，元素的位置取决于数组的长度和key的hash值按位与的结果 <code>i = (n - 1) &amp; hash</code></p></li><li><p>如果这里没有元素直接放在这里</p></li><li><p>如果有，判断是不是键冲突，如果一样就新值覆盖旧值</p></li><li><p>如果有且不是键冲突，则将其放在元素的next位置，判断元素长度是否大于8，大于8进行树化</p></li><li><p>只有当size大于了扩容阈值 <code>size &gt; threshold</code>， 才会触发扩容，扩容前，当前元素已经放好了</p></li><li><p>扩容时，容量和扩容阈值都翻倍，必须小于 1&lt;&lt;30</p></li><li><p>扩容时，元素在新表中的位置分情况</p></li><li><p>当元素只是孤家寡人即元素的next==null时，位置为e.hash &amp; (newCap - 1)</p></li><li><p>当元素有next节点时，该链表上的元素分两类</p><ul><li> e.hash &amp; oldCap = 0的，在新表中与旧表中的位置一样</li><li> e.hash &amp; oldCap != 0的，位置为旧表位置+旧表容量</li></ul></li><li><p>当前节点时树的话</p><ul><li>(e.hash &amp; bit) == 0 在新表中与旧表中的位置一样</li><li>(e.hash &amp; bit) != 0  位置为旧表位置+旧表容量</li><li>在新的newCap中，判断阶段如果节点数小于6进行树退化，重新树化</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;HashMap的实现原理&quot;&gt;&lt;a href=&quot;#HashMap的实现原理&quot; class=&quot;headerlink&quot; title=&quot;HashMap的实现原理&quot;&gt;&lt;/a&gt;HashMap的实现原理&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;</summary>
      
    
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/categories/Collection/"/>
    
    
    <category term="Collection" scheme="https://leslieaibin.github.io/tags/Collection/"/>
    
  </entry>
  
  <entry>
    <title>02.索引</title>
    <link href="https://leslieaibin.github.io/2021/09/04/MySQL/02.%E7%B4%A2%E5%BC%95/"/>
    <id>https://leslieaibin.github.io/2021/09/04/MySQL/02.%E7%B4%A2%E5%BC%95/</id>
    <published>2021-09-04T12:17:42.000Z</published>
    <updated>2021-09-04T08:47:40.314Z</updated>
    
    <content type="html"><![CDATA[<h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h2 id="什么是索引"><a href="#什么是索引" class="headerlink" title="什么是索引"></a>什么是索引</h2><p>索引是一个单独的，存储在磁盘上的数据结构，包含着对数据表里所有记录的引用指针，使用索引可以快速记录找出在某个或多个列中有一特定值的行，所有MySQL列数据都可以被索引，所有MySQL列类型都可以被索引，对相关列使用时提高查询操作速度的最佳途径。</p><p>索引是在存储引擎中实现的，因此，每种存储引擎的索引都不一定完全相同，并且每种存储引擎也不一定支持所有索引类型。MySQL中索引的存储类型有两种，即BTREE和HASH，具体和表的存储引擎相关。<strong>MyISAM和InnoDB存储引擎只支持BTREE索引；MEMORY/HEAP存储引擎可以支持HASH和BTREE索引。</strong></p><p>优点：</p><ul><li>通过创建唯一索引，可以保证数据库表中每一行数据的唯一性</li><li>可以大大加快数据的查询速度，这也是创建索引的主要原因</li><li>在实现数据的参考完整性方面，可以加速表和表之间的连接</li><li>在使用分组和排序子句进行数据查询时，也可以显著减少查询中分组和排序的时间。</li></ul><p>缺点：</p><ul><li>创建索引和维护索引需要耗费时间，并且随着数据量的增加所耗费的时间也会增加</li><li>索引需要占磁盘空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果有大量的索引，索引文件可能比数据文件更快达到最大文件尺寸</li><li>当对表中的数据进行增加、删除和修改的时候，索引也要动态地维护，这样就降低了数据的维护速度。</li></ul><h2 id="索引的分类"><a href="#索引的分类" class="headerlink" title="索引的分类"></a>索引的分类</h2><p>按数据结构分类可分为：<strong>B+tree索引、Hash索引、Full-text索引</strong>。</p><p>按物理存储分类可分为：<strong>聚簇索引、二级索引（辅助索引）</strong>。</p><p>按字段特性分类可分为：<strong>主键索引、普通索引、前缀索引</strong>。</p><p>按字段个数分类可分为：<strong>单列索引、联合索引（复合索引、组合索引）</strong>。</p><h3 id="按数据结构分类"><a href="#按数据结构分类" class="headerlink" title="按数据结构分类"></a>按数据结构分类</h3><p>MySQL索引按数据结构分类可分为：<strong>B+tree索引、Hash索引、Full-text索引</strong>。</p><table><thead><tr><th>-</th><th>InnoDB</th><th>MyISAM</th><th>Memory</th></tr></thead><tbody><tr><td>B+tree索引</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Hash索引</td><td>×</td><td>×</td><td>√</td></tr><tr><td>Full-text索引</td><td>√（MySQL5.6+）</td><td>√</td><td>×</td></tr></tbody></table><p><strong>B+tree</strong> 是MySQL中被存储引擎采用最多的索引类型。<strong>B+tree</strong> 中的 <code>B</code> 代表平衡（balance），而不是二叉（binary），因为 <strong>B+tree</strong> 是从最早的平衡二叉树演化而来的。下面展示B+tree数据结构与其他数据结构的对比。</p><h4 id="B-tree与B-tree的对比"><a href="#B-tree与B-tree的对比" class="headerlink" title="B+tree与B-tree的对比"></a><strong>B+tree与B-tree的对比</strong></h4><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037684393" alt="B-tree结构（图片来源于网络）"></p><p><strong>相对于B-tree，B+tree有以下两点不同：</strong></p><ul><li>B+tree 非叶子节点只存储键值信息， 数据记录都存放在叶子节点中。而B-tree的非叶子节点也存储数据。所以B+tree单个节点的数据量更小，在相同的磁盘I/O次数下，能查询更多的节点。</li><li>B+tree 所有叶子节点之间都采用<strong>双向链表</strong>连接。适合MySQL中常见的基于范围的顺序检索场景，而B-tree无法做到这一点。</li></ul><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037684392" alt="B+tree结构（图片来源于网络）"></p><h4 id="B-tree与红黑树的对比"><a href="#B-tree与红黑树的对比" class="headerlink" title="B+tree与红黑树的对比"></a>B+tree与红黑树的对比</h4><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037684042" alt="红黑树结构（图片来源于网络）"></p><p><strong>红黑树</strong>是一种<strong>弱平衡二叉查找树</strong>。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，<strong>红黑树确保没有一条路径会比其他路径长出两倍</strong>。</p><p>对于有N个叶子结点的 <strong>B+tree</strong>，其搜索复杂度为 <code>O(logdN)</code> ，其中 <strong>d</strong>(degree) 为 <strong>B+tree</strong> 的度，表示节点允许的最大子节点个数为<strong>d</strong>个，在实际应用当中，<strong>d</strong>值一般是大于100的，即使数据量达到千万级别时<strong>B+tree</strong>的高度依然维持在3-4左右，保证了3-4次磁盘I/O操作就能查询到目标数据。</p><p><strong>红黑树</strong>是二叉树，节点子节点个数为两个，意味着其搜索复杂度为 <code>O(logN)</code>，树的高度也会比 <strong>B+tree</strong> 高出不少，因此<strong>红黑树</strong>检索到目标数据所需经历的磁盘I/O次数更多。</p><h4 id="B-tree与Hash的对比"><a href="#B-tree与Hash的对比" class="headerlink" title="B+tree与Hash的对比"></a>B+tree与Hash的对比</h4><p>Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。虽然 Hash 索引效率高，但是 Hash 索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些。 Hash 索引仅仅能满足 <code>=</code> , <code>IN</code> 和 <code>&lt;=&gt;</code>(表示NULL安全的等价) 查询，不能使用范围查询。</p><p>由于 Hash 索引比较的是进行 Hash 运算之后的 Hash值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。</p><ul><li>Hash 索引无法适用数据的排序操作。</li><li>Hash 索引不能利用部分索引键查询</li><li>Hash 索引依然需要回表扫描。</li><li>Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。</li></ul><p><strong>由于范围查询是MySQL数据库查询中常见的场景，Hash表不适合做范围查询，它更适合做等值查询。另外Hash表还存在Hash函数选择和Hash值冲突等问题。因此，B+tree索引要比Hash表索引有更广的适用场景。</strong></p><h3 id="按照物理存储分类"><a href="#按照物理存储分类" class="headerlink" title="按照物理存储分类"></a>按照物理存储分类</h3><p>MySQL索引按叶子节点存储的是否为完整表数据分为：<strong>聚簇索引、二级索引（辅助索引）</strong>。全表数据存储在聚簇索引中，聚簇索引以外的其他索引叫做二级索引，也叫辅助索引。</p><h4 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h4><p>聚簇索引的每个叶子节点存储了一行完整的表数据，叶子节点间按id列递增连接，可以方便地进行顺序检索。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688814" alt="聚簇索引B+tree示意图（图片来源于网络）"><br>（图片来源于网络）</p><p>InnoDB表要求必须有聚簇索引，默认在主键字段上建立聚簇索引，在没有主键字段的情况下，表的第一个非空的唯一索引将被建立为聚簇索引，在前两者都没有的情况下，InnoDB将自动生成一个隐式的自增id列，并在此列上建立聚簇索引。</p><h5 id="以MyISAM为存储引擎的表不存在聚簇索引。"><a href="#以MyISAM为存储引擎的表不存在聚簇索引。" class="headerlink" title="以MyISAM为存储引擎的表不存在聚簇索引。"></a>以MyISAM为存储引擎的表不存在聚簇索引。</h5><p>MyISAM表中的主键索引和非主键索引的结构是一样的，索引的叶子节点不存储表数据，存放的是表数据的地址。所以，MyISAM表可以没有主键。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688815" alt="MyISAM索引B+tree示意图（图片来源于网络）"><br>（图片来源于网络）</p><p>MyISAM表的数据和索引是分开存储的。MyISAM表的主键索引和非主键索引的区别仅在于主键索引的B+tree上的key必须符合主键的限制，非主键索引B+tree上的key只要符合相应字段的特性就可以了。</p><h4 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h4><p>二级索引的叶子节点并不存储一行完整的表数据，而是存储了聚簇索引所在列的值。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688816" alt="二级索引B+tree示意图（图片来源于网络）"><br>（图片来源于网络）</p><h5 id="回表查询"><a href="#回表查询" class="headerlink" title="回表查询"></a>回表查询</h5><p>由于二级索引的叶子节点不存储完整的表数据，索引当通过二级索引查询到聚簇索引列值后，还需要回到聚簇索引也就是表数据本身进一步获取数据。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/1460000037688817" alt="回表查询示意图（图片来源于网络）"><br>（图片来源于网络）</p><p>回表查询 需要额外的 <strong>B+tree</strong> 搜索过程，必然增大查询耗时。</p><p>需要注意的是，<strong>通过二级索引查询时，回表不是必须的过程</strong>，当<strong>SELECT的所有字段在单个二级索引中都能够找到</strong>时，就不需要回表，MySQL称此时的二级索引为<strong>覆盖索引</strong>或触发了<strong>索引覆盖</strong>。<br>可以用Explain命令查看SQL语句的执行计划，执行计划的Extra字段中若出现<strong>Using index</strong>，表示查询触发了<strong>索引覆盖</strong>。</p><h3 id="按字段特性分类"><a href="#按字段特性分类" class="headerlink" title="按字段特性分类"></a>按字段特性分类</h3><p>MySQL索引按字段特性分类可分为：<strong>主键索引、普通索引、前缀索引</strong>。</p><ul><li><strong>主键索引</strong></li></ul><p>建立在主键上的索引被称为<strong>主键索引</strong>，一张数据表只能有一个主键索引，索引列值不允许有空值，通常在创建表时一起创建。</p><ul><li><strong>唯一索引</strong></li></ul><p>建立在UNIQUE字段上的索引被称为<strong>唯一索引</strong>，一张表可以有多个唯一索引，索引列值允许为空，列值中出现多个空值不会发生重复冲突。</p><ul><li><strong>普通索引</strong></li></ul><p>建立在普通字段上的索引被称为<strong>普通索引</strong>。</p><ul><li><strong>前缀索引</strong></li></ul><p><strong>前缀索引</strong>是指对字符类型字段的前几个字符或对二进制类型字段的前几个bytes建立的索引，而不是在整个字段上建索引。前缀索引可以建立在类型为char、varchar、binary、varbinary的列上，可以大大减少索引占用的存储空间，也能提升索引的查询效率。</p><h3 id="按索引字段个数分类"><a href="#按索引字段个数分类" class="headerlink" title="按索引字段个数分类"></a>按索引字段个数分类</h3><p>MySQL索引按字段个数分类可分为：<strong>单列索引、联合索引（复合索引、组合索引）</strong>。</p><ul><li>单列索引</li></ul><p>建立在单个列上的索引被称为单列索引。</p><ul><li>联合索引（复合索引、组合索引）</li></ul><p>建立在多个列上的索引被称为联合索引，又叫复合索引、组合索引。</p><h2 id="聚簇索引和非聚簇索引有什么区别"><a href="#聚簇索引和非聚簇索引有什么区别" class="headerlink" title="聚簇索引和非聚簇索引有什么区别"></a>聚簇索引和非聚簇索引有什么区别</h2><p>在InnoDB存储引擎中，可以将B+树索引分为聚簇索引和辅助索引（非聚簇索引）。无论是何种索引，每个页的大小都为16KB，且不能更改。</p><p>聚簇索引是根据主键创建的一棵B+树，聚簇索引的叶子节点存放了表中的所有记录。辅助索引是根据索引键创建的一棵B+树，与聚簇索引不同的是，其叶子节点仅存放索引键值，以及该索引键值指向的主键。也就是说，如果通过辅助索引来查找数据，那么当找到辅助索引的叶子节点后，很有可能还需要根据主键值查找聚簇索引来得到数据，这种查找方式又被称为书签查找。因为辅助索引不包含行记录的所有数据，这就意味着每页可以存放更多的键值，因此其高度一般都要小于聚簇索引。</p><h2 id="索引的实现原理"><a href="#索引的实现原理" class="headerlink" title="索引的实现原理"></a>索引的实现原理</h2><p>在MySQL中，索引是在存储引擎层实现的，不同存储引擎对索引的实现方式是不同的，下面我们探讨一下MyISAM和InnoDB两个存储引擎的索引实现方式。</p><h3 id="MyISAM索引实现："><a href="#MyISAM索引实现：" class="headerlink" title="MyISAM索引实现："></a>MyISAM索引实现：</h3><p>MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址，MyISAM索引的原理图如下。这里假设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-1.png" alt="img"></p><p>如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示。同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-2.png" alt="img"></p><h3 id="InnoDB索引实现："><a href="#InnoDB索引实现：" class="headerlink" title="InnoDB索引实现："></a>InnoDB索引实现：</h3><p>虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。</p><p>第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。</p><p>下图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-3.png" alt="img"></p><p>第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。下图为定义在Col3上的一个辅助索引。这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。</p><p><img src="http://test-1874253.oss-cn-beijing.aliyuncs.com/img/index-4.png" alt="img"></p><p>了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;索引&quot;&gt;&lt;a href=&quot;#索引&quot; class=&quot;headerlink&quot; title=&quot;索引&quot;&gt;&lt;/a&gt;索引&lt;/h1&gt;&lt;h2 id=&quot;什么是索引&quot;&gt;&lt;a href=&quot;#什么是索引&quot; class=&quot;headerlink&quot; title=&quot;什么是索引&quot;&gt;&lt;/a&gt;什么是索</summary>
      
    
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://leslieaibin.github.io/tags/MySQL/"/>
    
  </entry>
  
</feed>
